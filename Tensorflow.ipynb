{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PKIp_xaO5psn",
        "QRjAeZCYzgh3",
        "W4skGjP66yW1",
        "-LGdVM2_Atrw",
        "WOJ400nj8UxO",
        "cX1lFt5UEtua",
        "io0_fPX_EiAN",
        "lYCKFjVaREXP",
        "6u9ZLl7tCsOq",
        "YTh6vXLEWatx",
        "9Su900NJyWDj",
        "UFsVm-srMhSu",
        "Dp6QtMEhGYaq",
        "2n7XxItEXUCk",
        "7HwdG2W_XLpu",
        "MK44Ilq7Xico",
        "aLIl-GvOKX4t",
        "A8db_sKVwEvK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "PKIp_xaO5psn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>KERAS.LOSSES</h1></center>**<br>\n",
        "Dans keras.losses, on a des fonctions et des classes:<br>\n",
        "1. **keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True)** est une fonction qu'on directement utilisée dans tf.GradientTape.<br>\n",
        "2. **a = keras.losses.CategoricalCrossentropy(from_logits=True)** est une classe, on fait **a(y_true, y_pred)**.<br>\n",
        "On a aussi **KERAS.METRICS**, **KERAS.OPTIMIZERS**, ETC.<br>\n",
        "\n",
        "**<center><h1>Training Keras Model</h1></center>**<br>\n",
        "On peut noter **04** approches:<br>\n",
        "1. **fit:** c'est la méthode standard.<br>\n",
        "\n",
        "2. **keras.Model:** Créer une classe qui hérite de la classe **keras.models.Model** or **keras.Model**. Cette classe doit implémenter **train_step** qui utilise **tf.GradientTape** pour mettre à jour les **poids** du modèle par **batch**. On peut aussi implémenter **test_step** pour le test, **call** pour le **forward**, **metrics** qui retourne la liste des métriques (mise à jour), **computer_loss** pour retourner la **loss**.<br>\n",
        "\n",
        "3. **@tf.function:** Créer une fonction en la faisant précédée par **@tf.function**. Cette approche permet à la fonction créée de pouvoir être compiler c'est à dire utiliser le **tf.GradientTape**. La fonction ainsi créée peut être utilisée dans une fonction qui fait une boucle sur le nombre d'époques et donne entrée **batch** par **batch** à la fonction qui met à jour les poids suivant les batchs donnés.<br>\n",
        "\n",
        "4. **train_on_batch:** C'est une **méthode** de la classe Model de keras, tout modèle de keras peut donc y accéder. On crée d'abord un modèle **model**, on utilise d'abord une boucle sur le nombre d'époque suivie d'une boucle qui prend **batch par batch**, on fait à chaque fois **model.train_on_batch(x_batch, y_batch)** qui retourne la **loss** sur le batch et les métriques si c'es définit dans le compile de **model**.<br>\n",
        "\n",
        "**<center><h1>Passage par valeur des modèles</h1></center>**<br>\n",
        "Supposons qu'on ait 03 modèles: <br>\n",
        "\n",
        "**model1 = tf.keras.models.Sequential()**<br>\n",
        "**model2 = tf.keras.models.Sequential()**<br>\n",
        "**model3 = tf.keras.models.Sequential()**<br>\n",
        "\n",
        "**model3.add(model1**)<br>\n",
        "**mdoel3.model1.trainable = False** <br>\n",
        "**model3.add(model2)**<br>\n",
        "\n",
        "model1 est utilisé dans model3, même si c'est son trainable=False, toute modification (mise à jour) fait sur model1 en dehors va se répercuter sur model3.model1, même si les modifications sont faites à l'intérieur d'une fonction.<br>\n",
        "**NB:** Dès qu'on crée un modèle, on l'utilise pour intialiser ou l'affecter ou à un autre modèle les modifications apportées sur un de ces modèles affectent le modèle de base. Voir la section: Method using train_on_batch.<br>\n",
        "\n",
        "**<center><h1>Bahdanau Attention</h1></center>**<br>\n",
        "C'est une attention additive, l'objectif est de prendre l'état caché du decoder comme query et le output de l'encoder comme value pour produre un vecteur de contexte. Le vecteur de contexte est concaténé avec l'embedding de l'entrée du decoder (qui prend token par token), et sert d'entrée à la couche rnn, lstm ou gru.<br>\n",
        "\n",
        "Q = Decoder hidden state (None, decoder_unit)<br>\n",
        "    at the begining, Q = Encoder hidden state<br>\n",
        "\n",
        "V = Encoder output (None, sequence, feature)<br>\n",
        "\n",
        "Q = tf.expand_dims(Q, axis=1) # (None, 1, decoder_unit)<br>\n",
        "EncQ = Dense1(Q) # (None, 1, units)<br>\n",
        "EncV = Dense2(V) # (None, sequence, units)<br>\n",
        "sum = tf.nn.tanh(EncQ+EncV) # activation (None, sequence, units)<br>\n",
        "\n",
        "score = Dense3(sum) # (None, sequence, 1)<br>\n",
        "attention = tf.nn.softmax(score, axis=1) # (None, sequence, 1) softmax based on token position<br>\n",
        "\n",
        "context_vector = attention*V # (None, sequence, feature)<br>\n",
        "context_vector = tf.nn.sum(context_vector, axis=1) # (None, feature)<br>\n",
        "\n",
        "context_vector sera utilisé dans le decoder et concaténer avec l'entrée (qui se fait token par token)<br>\n",
        "x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # (None, 1, feature+embedding_dim_x) x vient de l'embedding x est de type (None, 1) car on traite par token Embedding donne (None, 1, embedding_dim_x)<br>\n",
        "\n",
        "\n",
        "**<center><h1>Paramètres et Sorties</h1></center>**<br>\n",
        "\n",
        "**<h2>MLP (Dense)</h2>**<br>\n",
        "**1. Sortie:** Si l'entrée est de dimension 2, la sortie sera **(None, units)**, si l'entrée est de dimension 3 (séquences), la sortie sera **(None, sequence, units)**, si l'entrée est de dimension 4 (convolutions ou images), la sortie sera **(None, H, W, units)**.<br>\n",
        "\n",
        "**2. Paramètres:** **D*W + W**, avec D la dimension de l'entrée, W le nombre de units.<br>\n",
        "\n",
        "**<h2>CNN (Conv2D)</h2>**<br>\n",
        "**1. Sortie:** **math.floor((n - f + p) / s) + 1**, avec n la taille de l'entrée, f la taille du filtre, p = f - 1 si padding = 'same' et p = 0 si padding='valid', s est la taille du stride. ON considère la partie entière inférieure.<br>\n",
        "**NB:** Si conv2DTranspose ou UpSampling2D, on effectue l'opération inverse **s × (n + f - p)**.<br>\n",
        "\n",
        "\n",
        "**Paramètres:** Le nombre de paramètres de la couche, dépend du nombre de canal de la couche précédente. La couche actuelle contient par exemple 2 filtres, et que la couche précédente contient 3 canaux, le filtre 1 va être dupliqué sur les 3 canaux et si la taille du filtre est (2, 2), donc y aura 3 × (2 × 2) paramètres à apprendre avec le même biais donc 3 × (2 × 2) + 1. Le même processus s'applique sur le filtre 2. La formule générale est alors:<br> <center>**(hauteur_filtre × largeur_filtre × nombre_canaux_couche_precedente + 1 ) × nombre_filtres**</center><br>\n",
        "\n",
        "**Les couches de Pooling n'ont pas de paramètres à apprendre**<br>\n",
        "\n",
        "\n",
        "**<h2>RNN</h2>**<br>\n",
        "**1. Sortie:** Par défaut, retourne (None, units). Si return_sequences = True, (None, sequence, units). Si return_state = True, on aura deux outputs, (None, units), (None, units). Si return_sequences=True et return_state=True on aura (None, sequence, units), (None, units).<br>\n",
        "**NB:** Ceci est valable pour les **GRU**, pour les **LSTM**, return_sate=True donne deux état (None, units) pour hidden_state et (None, units) pour cell_state.\n",
        "\n",
        "**2. Paramètres:** L'entrée correspond à deux vecteurs concaténés: x (dernière dimension de l'entrée: **shape[-1]**) et h. x le token d'entrée et h l'état caché.<br>\n",
        "**<center>RNN: (x + h) × h + h</center>**<br>\n",
        "**<center>LSTM: 4 × [(x + h) × h + h] </center>** <br>\n",
        "**<center>GRU: 3 × [(x + h) × h + h]</center>**"
      ],
      "metadata": {
        "id": "jjT2qFZpM6_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calcul de AP (Average Precision) et mAP (mean Average Precision)**<br>\n",
        "https://www.youtube.com/watch?v=FppOzcDvaDI&list=PL3Q9L9bKi20IatsPIesEJeu6JYBY-Wk1G&index=3&t=394s"
      ],
      "metadata": {
        "id": "0eORfXkDK1LI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random projection: https://scikit-learn.org/stable/modules/random_projection.html"
      ],
      "metadata": {
        "id": "Lq6mGpSwiTck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. loss = tf.losses.BinaryCrossEntropy(): loss(y_true, y_pred) fait la somme et retourne une seule valeur\n",
        "   Pour que loss soit une liste, il faut mettre reduction = 'none' sur la classe BinaryCrossEtropy(reduction='none')\n",
        "\n",
        "2. loss = tf.losses.binary_crossentropy(y_true, y_pred) retourne une liste de loss\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YrM0wXLO4CQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
        "# GradientTape permet d'effectuer une opération différentielle\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  y = x * x\n",
        "dy_dx = g.gradient(y, x)\n",
        "print(dy_dx)"
      ],
      "metadata": {
        "id": "005CLkXttZDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(5.0)\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  with tf.GradientTape() as gg:\n",
        "    gg.watch(x)\n",
        "    y = x * x\n",
        "  dy_dx = gg.gradient(y, x)  # dy_dx = 2 * x\n",
        "d2y_dx2 = g.gradient(dy_dx, x)  # d2y_dx2 = 2\n",
        "\n",
        "\n",
        "print(dy_dx)\n",
        "print(d2y_dx2)\n"
      ],
      "metadata": {
        "id": "Eflq0DJeuTe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persitent = True permet d'appeller le tape plusieurs fois\n",
        "\n",
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape(persistent=True) as g:\n",
        "  g.watch(x)\n",
        "  y = x * x\n",
        "  z = y * y\n",
        "dz_dx = g.gradient(z, x)  # (4*x^3 at x = 3)\n",
        "print(dz_dx)\n",
        "\n",
        "dy_dx = g.gradient(y, x)\n",
        "print(dy_dx)\n",
        "\n",
        "\"\"\"\n",
        "NB: si on utilise un modèle sans watch, par défaut toutes les trainable_variables sont mis dans watch de manière implicite, donc on a pas besoin de le spéficier\n",
        "    car les poids sont des tf.Variable pas des tf.constant, et par défaut un tf.Variable est directement mis dans watch.\n",
        "    Si on veut enléver cet effet par défaut, on utilise le paramètre watch_accessed_variables=False (voir exemple suivant)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vRkS-ESJud2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(2.0) # watch actif par défaut\n",
        "w = tf.Variable(5.0) # watch actif par défaut\n",
        "with tf.GradientTape(\n",
        "    watch_accessed_variables=False, persistent=True) as tape:\n",
        "  tape.watch(x)\n",
        "  y = x ** 2  # Gradients will be available for `x`.\n",
        "  z = w ** 3  # No gradients will be available as `w` isn't being watched.\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(dy_dx) # tf.Tensor(4.0, shape=(), dtype=tf.float32)\n",
        "\n",
        "# No gradients will be available as `w` isn't being watched.\n",
        "dz_dw = tape.gradient(z, w)\n",
        "print(dz_dw) # None"
      ],
      "metadata": {
        "id": "zHgbIm1lvk4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.keras.layers.Dense(32)\n",
        "b = tf.keras.layers.Dense(32)\n",
        "\n",
        "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "  tape.watch(a.variables)  # Since `a.build` has not been called at this point\n",
        "                           # `a.variables` will return an empty list and the\n",
        "                           # tape will not be watching anything. a.variables = []\n",
        "  result = b(a(inputs))\n",
        "\n",
        "tape.gradient(result, a.variables)  # The result of this computation will be\n",
        "                                      # a list of `None`s since a's variables\n",
        "                                      # are not being watched."
      ],
      "metadata": {
        "id": "ADEwaXi7w4JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept: GradientTape**"
      ],
      "metadata": {
        "id": "QRjAeZCYzgh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@propety:\n",
        "En Python, @property est un décorateur utilisé pour définir une méthode au sein d'une classe qui agit comme un attribut en lecture seule.\n",
        "Lorsqu'une classe hérite d'une autre classe, la notation @property sur une méthode permet à la classe dérivée d'accéder à cette méthode comme\n",
        "un attribut en lecture seule sans avoir besoin d'appeler explicitement la méthode. Cela permet d'encapsuler la logique de calcul d'un attribut au\n",
        "sein de la classe et de fournir un accès plus propre à cet attribut pour les classes dérivées.\n",
        "\n",
        "@tf.function est un décorateur, qui permet de transformer une fonction en un graphe de calcul tensorflow.\n",
        "Il permet dans certains contextes d'accélérer le calcul. IL est conseillé si la fonction contient\n",
        "des opérations tensorflow.\n",
        "\"\"\"\n",
        "\n",
        "class BaseClass:\n",
        "    def __init__(self, value):\n",
        "        self._value = value\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self._value\n",
        "\n",
        "class DerivedClass(BaseClass):\n",
        "    def __init__(self, value, extra):\n",
        "        super().__init__(value)\n",
        "        self.extra = extra\n",
        "\n",
        "# Utilisation\n",
        "obj = DerivedClass(42, \"extra_data\")\n",
        "print(obj.value)  # Accès à l'attribut \"value\" comme s'il s'agissait d'un attribut direct\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Dans cet exemple, la classe BaseClass définit un attribut en lecture seule value en utilisant @property.\n",
        "La classe dérivée DerivedClass peut y accéder comme si c'était un attribut direct,\n",
        "même si la logique pour le calcul de value est encapsulée dans BaseClass.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Avec metrics, si on fait self.metrics on aura une liste de metriques\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "oCw6DA5jc2zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *args\n",
        "\"\"\"\n",
        "En Python, *args est une syntaxe utilisée pour permettre à une fonction de recevoir un nombre variable d'arguments positionnels. Lorsque vous\n",
        "utilisez *args comme paramètre dans la définition d'une fonction, cela signifie que la fonction peut accepter\n",
        "un nombre arbitraire d'arguments positionnels, et ces arguments seront regroupés dans un tuple.\n",
        "\"\"\"\n",
        "def fonction_avec_args(arg1, *args):\n",
        "    print(\"arg1:\", arg1)\n",
        "    print(\"args:\", args)\n",
        "\n",
        "# Utilisation de la fonction\n",
        "fonction_avec_args(1, 2, 3, 4, 5)\n",
        "\n",
        "\"\"\"\n",
        "Dans cet exemple, arg1 est un argument positionnel classique, tandis que *args est utilisé pour collecter tous les arguments positionnels supplémentaires dans un tuple appelé args.\n",
        "Lorsque la fonction est appelée avec plusieurs arguments après arg1, ils sont automatiquement regroupés dans le tuple args. Vous pouvez ensuite parcourir ce tuple pour traiter\n",
        "les arguments supplémentaires comme vous le souhaitez.\n",
        "\n",
        "L'utilisation de *args est courante lorsque vous devez définir une fonction qui peut prendre un nombre\n",
        "variable d'arguments, par exemple, pour implémenter des fonctions génériques ou des wrappers autour d'autres fonctions.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9ZyZwFOPgC00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# **kwargs\n",
        "\"\"\"\n",
        "\n",
        "En Python, **kwargs est une syntaxe similaire à *args, mais elle est utilisée pour permettre à une fonction de recevoir un nombre variable d'arguments mots-clés (ou paramètres nommés). Lorsque vous utilisez **kwargs\n",
        "comme paramètre dans la définition d'une fonction, cela signifie que la fonction peut accepter un nombre arbitraire d'arguments mots-clés, et ces arguments seront regroupés dans un dictionnaire.\n",
        "\"\"\"\n",
        "\n",
        "def fonction_avec_kwargs(arg1, **kwargs):\n",
        "    print(\"arg1:\", arg1)\n",
        "    print(\"kwargs:\", kwargs)\n",
        "\n",
        "# Utilisation de la fonction\n",
        "fonction_avec_kwargs(1, a=2, b=3, c=4)\n",
        "\n",
        "\"\"\"\n",
        "Dans cet exemple, arg1 est un argument positionnel classique, tandis que **kwargs est utilisé pour collecter tous les\n",
        "arguments mots-clés supplémentaires dans un dictionnaire appelé kwargs. Lorsque la fonction est appelée avec des arguments mots-clés supplémentaires (par exemple, a=2, b=3, c=4),\n",
        "ces arguments sont regroupés dans le dictionnaire kwargs, où les noms des arguments sont les clés et leurs valeurs sont les valeurs correspondantes.\n",
        "\n",
        "L'utilisation de **kwargs est courante lorsque vous devez définir une fonction qui peut accepter un nombre variable d'arguments mots-clés, ce qui peut être utile pour personnaliser\n",
        "le comportement d'une fonction ou pour transmettre un grand nombre de paramètres de manière plus flexible.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aeH49dHHgle5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OBAyQqIzcx8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "EXAMPLE : LOSS IS NOT GIVEN IN COMPILE\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_states()` yourself at the time of your choosing.\n",
        "        return [self.loss_tracker, self.mae_metric] ## List all metrics\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute our own loss\n",
        "            loss = keras.losses.mean_squared_error(y, y_pred) ## if loss if given in comile, we can use by self.compute_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars)) ## optimizer is given in self.optimizer\n",
        "\n",
        "        # Compute our own metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()} ## bar progress for user {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        # Compute predictions\n",
        "        y_pred = self(x, training=False) ## Freeze weights\n",
        "        loss = keras.losses.mean_squared_error(y, y_pred)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "# Construct an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "# We don't passs a loss or metrics here.\n",
        "model.compile(optimizer=\"adam\")\n",
        "\n",
        "# Just use `fit` as usual -- you can use callbacks, etc.\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "model.fit(x, y, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EXAMPLE : LOSS IS GIVEN IN COMPILE\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_states()` yourself at the time of your choosing.\n",
        "        return [self.loss_tracker, self.mae_metric] ## List all metrics\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute our own loss\n",
        "            loss = self.compute_loss(y, y_pred) ### Changed line\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars)) ## optimizer is given in self.optimizer\n",
        "\n",
        "        # Compute our own metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()} ## bar progress for user {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        # Compute predictions\n",
        "        y_pred = self(x, training=False) ## Freeze weights\n",
        "        loss = self.compute_loss(y, y_pred) ### Changed line\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "# Construct an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "# We don't passs a loss or metrics here.\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Just use `fit` as usual -- you can use callbacks, etc.\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "model.fit(x, y, epochs=5)"
      ],
      "metadata": {
        "id": "keMpVnjq4d6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EXAMPLE: PONDERATION OF CLASSES USING WEIGHTS\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        if len(data) == 3:\n",
        "            x, y, sample_weight = data\n",
        "        else:\n",
        "            sample_weight = None\n",
        "            x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute the loss value.\n",
        "            # The loss function is configured in `compile()`.\n",
        "            loss = self.compute_loss(\n",
        "                y=y,\n",
        "                y_pred=y_pred,\n",
        "                sample_weight=sample_weight,\n",
        "            )\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics.\n",
        "        # Metrics are configured in `compile()`.\n",
        "        for metric in self.metrics:\n",
        "            if metric.name == \"loss\":\n",
        "                metric.update_state(loss)\n",
        "            else:\n",
        "                metric.update_state(y, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        "# Construct and compile an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# You can now use sample_weight argument\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "sw = np.random.random((1000, 1))\n",
        "model.fit(x, y, sample_weight=sw, epochs=3)"
      ],
      "metadata": {
        "id": "okfA_q-F6f4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept - GAN EXAMPLE: GradientTape**"
      ],
      "metadata": {
        "id": "W4skGjP66yW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create the discriminator\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
        "        layers.Dense(7 * 7 * 128),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((7, 7, 128)),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ],
      "metadata": {
        "id": "XxDQ3-Av64lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_loss_tracker = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_tracker = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape: ##  We can either use with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics and return their value.\n",
        "        self.d_loss_tracker.update_state(d_loss)\n",
        "        self.g_loss_tracker.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_tracker.result(),\n",
        "            \"g_loss\": self.g_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "JoWOgMs76-ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset. We use both the training & test MNIST digits.\n",
        "batch_size = 64\n",
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "# To limit the execution time, we only train on 100 batches. You can train on\n",
        "# the entire dataset. You will need about 20 epochs to get nice results.\n",
        "gan.fit(dataset.take(100), epochs=1)"
      ],
      "metadata": {
        "id": "6FQZPGe17JJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept - Image and Text Similarity: GradientTape**"
      ],
      "metadata": {
        "id": "-LGdVM2_Atrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EXAMPLE: In this example, the loss is computing on the class\n",
        "         the optimizer is given in compile, we use self.optimizer to use it.\n",
        "         https://keras.io/examples/vision/nl_image_search/\n",
        "\"\"\"\n",
        "class DualEncoder(keras.Model):\n",
        "    def __init__(self, text_encoder, image_encoder, temperature=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.text_encoder = text_encoder\n",
        "        self.image_encoder = image_encoder\n",
        "        self.temperature = temperature\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def call(self, features, training=False):\n",
        "        # Place each encoder on a separate GPU (if available).\n",
        "        # TF will fallback on available devices if there are fewer than 2 GPUs.\n",
        "        with tf.device(\"/gpu:0\"):\n",
        "            # Get the embeddings for the captions.\n",
        "            caption_embeddings = text_encoder(features[\"caption\"], training=training)\n",
        "        with tf.device(\"/gpu:1\"):\n",
        "            # Get the embeddings for the images.\n",
        "            image_embeddings = vision_encoder(features[\"image\"], training=training)\n",
        "        return caption_embeddings, image_embeddings\n",
        "\n",
        "    def compute_loss(self, caption_embeddings, image_embeddings):\n",
        "        # logits[i][j] is the dot_similarity(caption_i, image_j).\n",
        "        logits = (\n",
        "            tf.matmul(caption_embeddings, image_embeddings, transpose_b=True)\n",
        "            / self.temperature\n",
        "        )\n",
        "        # images_similarity[i][j] is the dot_similarity(image_i, image_j).\n",
        "        images_similarity = tf.matmul(\n",
        "            image_embeddings, image_embeddings, transpose_b=True\n",
        "        )\n",
        "        # captions_similarity[i][j] is the dot_similarity(caption_i, caption_j).\n",
        "        captions_similarity = tf.matmul(\n",
        "            caption_embeddings, caption_embeddings, transpose_b=True\n",
        "        )\n",
        "        # targets[i][j] = avarage dot_similarity(caption_i, caption_j) and dot_similarity(image_i, image_j).\n",
        "        targets = keras.activations.softmax(\n",
        "            (captions_similarity + images_similarity) / (2 * self.temperature)\n",
        "        )\n",
        "        # Compute the loss for the captions using crossentropy\n",
        "        captions_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=targets, y_pred=logits, from_logits=True\n",
        "        )\n",
        "        # Compute the loss for the images using crossentropy\n",
        "        images_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=tf.transpose(targets), y_pred=tf.transpose(logits), from_logits=True\n",
        "        )\n",
        "        # Return the mean of the loss over the batch.\n",
        "        return (captions_loss + images_loss) / 2\n",
        "\n",
        "    def train_step(self, features):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            caption_embeddings, image_embeddings = self(features, training=True)\n",
        "            loss = self.compute_loss(caption_embeddings, image_embeddings)\n",
        "        # Backward pass\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        # Monitor loss\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def test_step(self, features):\n",
        "        caption_embeddings, image_embeddings = self(features, training=False)\n",
        "        loss = self.compute_loss(caption_embeddings, image_embeddings)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}"
      ],
      "metadata": {
        "id": "593tvL0vA2nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5  # In practice, train for at least 30 epochs\n",
        "batch_size = 256\n",
        "\n",
        "vision_encoder = create_vision_encoder(\n",
        "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
        ")\n",
        "text_encoder = create_text_encoder(\n",
        "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
        ")\n",
        "dual_encoder = DualEncoder(text_encoder, vision_encoder, temperature=0.05)\n",
        "dual_encoder.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.001)\n",
        ")"
      ],
      "metadata": {
        "id": "nnK4nwxM7qFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept - Relevant method for GAN - @tf.function: GradientTape**"
      ],
      "metadata": {
        "id": "WOJ400nj8UxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "\n",
        "# save checkpoints\n",
        "checkpoint_dir = \"training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator=discriminator)\n",
        "\n",
        "# Constant\n",
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal((num_examples_to_generate, noise_dim))\n",
        "\n",
        "# @tf.function enables to use compile with train_step\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "# Train function\n",
        "def train(datasets, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for img_batch in datasets:\n",
        "            train_step(img_batch)\n",
        "\n",
        "        # Produce images for the GIF\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator,\n",
        "                                epoch+1,\n",
        "                                seed)\n",
        "\n",
        "        # Save the model every 15 epochs\n",
        "        if (epoch+1)%15 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "\n",
        "        print(\"Time for epoch {} is {} sec\".format(epoch+1, time.time()-start))\n",
        "\n",
        "    # Generate after the final epoch\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                                epoch,\n",
        "                                seed)\n",
        "\n",
        "# Predicion\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4,4,i+1)\n",
        "        plt.imshow(predictions[i, :, :, :]*127.5 + 127.5)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('generated_image/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "# Train\n",
        "train(train_dataset, EPOCHS)\n",
        "\n",
        "# Restore\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# Plot\n",
        "def display_image(epoch):\n",
        "    return PIL.Image.open(\"generated_image/image_at_epoch_{:04d}.png\".format(epoch))\n",
        "display_image(EPOCHs)"
      ],
      "metadata": {
        "id": "UltzLG6r8fMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We can use an other approach\n",
        "\"\"\"\n",
        "# @tf.function enables to use compile with train_step\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "        # Train discriminator\n",
        "        noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
        "        generated_images = generator.predict(noise)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Train generator\n",
        "        noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
        "        generated_images = generator(noise, training=True)\n",
        "        fake_output = discriminator(generated_images, training=False)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n"
      ],
      "metadata": {
        "id": "a-kBS1vQAVn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method using train_on_batch**"
      ],
      "metadata": {
        "id": "cX1lFt5UEtua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This method use an other approach for training : train_on_batch\n",
        "https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch/\n",
        "\"\"\"\n",
        "\n",
        "# Define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(32, 32, 3)):\n",
        "    in_image = Input(shape=in_shape)\n",
        "    # Normal\n",
        "    x = Conv2D(64, (3, 3), padding='same')(in_image)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Downsample\n",
        "    x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Downsample\n",
        "    x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Downsample\n",
        "    x = Conv2D(256, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Classifier\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(in_image, x)\n",
        "\n",
        "    # Compile model\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "    in_lat = Input(shape=(latent_dim,))\n",
        "    # Foundation for 4x4 image\n",
        "    n_nodes = 256 * 4 * 4\n",
        "    x = Dense(n_nodes)(in_lat)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Reshape((4, 4, 256))(x)\n",
        "\n",
        "    # Upsample to 8x8\n",
        "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Upsample to 16x16\n",
        "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Upsample to 32x32\n",
        "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = Conv2D(3, (3, 3), activation='tanh', padding='same')(x)\n",
        "\n",
        "    model = Model(in_lat, x)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4vUhW-GkEzQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Define the gan model that combine discriminator that is frozen and generator that is not frozen\n",
        "NB: Freeze discriminator\n",
        "    Not Freeze generator\n",
        "\"\"\"\n",
        "def define_gan(g_model, d_model):\n",
        "    # make weights in the discriminator not trainable\n",
        "    d_model.trainable = False\n",
        "    # connect them\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(g_model)\n",
        "    # add the discriminator\n",
        "    model.add(d_model)\n",
        "    # compile model\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Wqy5HvpEJYBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and prepare cifar10 training images\n",
        "def load_real_samples():\n",
        "    # load cifar10 dataset\n",
        "    (trainX, _), (_, _) = load_data()\n",
        "    # convert from unsigned ints to floats\n",
        "    X = trainX.astype('float32')\n",
        "    # scale from [0,255] to [-1,1]\n",
        "    X = (X - 127.5) / 127.5\n",
        "    return X\n",
        "\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "    # choose random instances\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    # retrieve selected images\n",
        "    X = dataset[ix]\n",
        "    # generate 'real' class labels (1)\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # generate points in the latent space\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    # reshape into a batch of inputs for the network\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    # generate points in latent space\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    # predict outputs\n",
        "    X = g_model.predict(x_input, verbose=0)\n",
        "    # create 'fake' class labels (0)\n",
        "    y = zeros((n_samples, 1))\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "oNd7sF7mLGin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create and save a plot of generated images\n",
        "def save_plot(examples, epoch, n=7):\n",
        "     # scale from [-1,1] to [0,1]\n",
        "     examples = (examples + 1) / 2.0\n",
        "     # plot images\n",
        "     for i in range(n * n):\n",
        "         # define subplot\n",
        "         pyplot.subplot(n, n, 1 + i)\n",
        "         # turn off axis\n",
        "         pyplot.axis('off')\n",
        "         # plot raw pixel data\n",
        "         pyplot.imshow(examples[i])\n",
        "     # save plot to file\n",
        "     filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "     pyplot.savefig(filename)\n",
        "     pyplot.show()"
      ],
      "metadata": {
        "id": "bmrZgAQYLRTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n",
        "     # prepare real samples\n",
        "     X_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "     # evaluate discriminator on real examples\n",
        "     _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "     # prepare fake examples\n",
        "     x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "     # evaluate discriminator on fake examples\n",
        "     _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "     # summarize discriminator performance\n",
        "     print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "     # save plot\n",
        "     save_plot(x_fake, epoch)\n",
        "     # save the generator model tile file\n",
        "     filename = 'generator_model_%03d.h5' % (epoch+1)\n",
        "     g_model.save(filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "k8xdX-hMLodD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):\n",
        "     bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "     half_batch = int(n_batch / 2)\n",
        "     # manually enumerate epochs\n",
        "     for i in range(n_epochs):\n",
        "     # enumerate batches over the training set\n",
        "         for j in range(bat_per_epo):\n",
        "            \"\"\"\n",
        "              Train the discriminator\n",
        "              NB: The same discriminator and generator is used in all training\n",
        "            \"\"\"\n",
        "             # get randomly selected 'real' samples\n",
        "             X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "             # update discriminator model weights\n",
        "             d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "             # generate 'fake' examples\n",
        "             X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "             # update discriminator model weights\n",
        "             d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "              Train the generator\n",
        "            \"\"\"\n",
        "             # prepare points in latent space as input for the generator\n",
        "             X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "             # create inverted labels for the fake samples\n",
        "             y_gan = ones((n_batch, 1))\n",
        "             # update the generator via the discriminator's error\n",
        "             g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "             # summarize loss on this batch\n",
        "         print('epoch %d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "         (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "         # evaluate the model performance, sometimes\n",
        "         if (i+1) % 10 == 0:\n",
        "             summarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ],
      "metadata": {
        "id": "A2I2fUiQLq1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NB: d_model et g_model sont utilisés pour créer gan_model\n",
        "    Il faut noter que d_model.train_on_batch va mettre à jour les poids de d_model dans gan_model (c'est le même d_model)\n",
        "    aussi toutes les modifications de g_model vont répercuter sur le g_model dans gan_model donc c'est le même\n",
        "    \"\"\"\n",
        "\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "metadata": {
        "id": "x1KpLF68MvYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Translation**"
      ],
      "metadata": {
        "id": "io0_fPX_EiAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dans cet exemple, on pose l'hypothèse que les données sont déjà représentées sous forme de séquence c'est à dire qu'on n'a\n",
        "pas besoin de la couche d'Embedding. Dans le cas courant, où les données sont représentées sous forme de vecteur, il faut nécessairement un embedding\n",
        "pour avoir chaque mot représenté en vecteur.\n",
        "https://www.kaggle.com/code/akshat0007/machine-translation-english-to-french-rnn-lstm\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BtVyENa2yVvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "input_encoder = Input(shape=(None, features))\n",
        "encoder = LSTM(units=latent_dim, return_states=True)\n",
        "output_encoder, state_h, state_c = encoder(input_encoder)\n",
        "\n",
        "# Decoder\n",
        "input_decoder = Input(shape=(None, features))\n",
        "decoder = LSTM(units=latent_dim, return_states=True, return_sequences=True)\n",
        "output_lstm, _, _ = decoder(input_decoder, initial_state=[state_h, state_c])\n",
        "dense_layer = Dense(units=vocab_size, activation=\"softmax\")\n",
        "dense_output = dense_layer(output_lstm)\n",
        "\n",
        "# Model\n",
        "model = Model([input_encoder, input_encoder], dense_output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) # one hot in label\n",
        "\n",
        "# Train\n",
        "model.fit([encoder_data, decoder_data], y_decoder, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "Qe9VyiFrEmNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "After training, we build an encoder and decoder depending on the training model for prediction\n",
        "\"\"\"\n",
        "\n",
        "# Build Encoder\n",
        "encoder = Model(input_encoder, [output_encoder, state_h, state_c])\n",
        "\n",
        "# Build Decoder\n",
        "input_decoder = Input(shape=(1, features))\n",
        "input_h = Input(shape=(latent_dim, ))\n",
        "input_c = Input(shape=(latent_dim, ))\n",
        "output_lstm, state_h state_c = decoder(input_decoder, initial_state=[input_h, input_c])\n",
        "output_decoder = dense_layer(output_lstm)\n",
        "\n",
        "decoder = Model([input_decoder, input_h, input_c], [output_decoder, state_h, state_c])"
      ],
      "metadata": {
        "id": "iGceijhDj4Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "aZSdXGBOwV9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "metadata": {
        "id": "nHWRPsmZyK-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BahdanauAttention in LSTM using Hidden state as query**"
      ],
      "metadata": {
        "id": "lYCKFjVaREXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "ChatBot Introduction Colab: https://www.kaggle.com/code/alincijov/dialog-chatbot-using-bahdanau-attention\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ilKSwJYkoAME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset for train and test\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)  # Define the buffer size, typically the number of training examples.\n",
        "BATCH_SIZE = 64  # Define the batch size for training data.\n",
        "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE  # Calculate the number of steps per training epoch.\n",
        "embedding_dim = 256  # Define the dimension of word embeddings.\n",
        "units = 1024  # Define the number of units or neurons in a recurrent neural network (RNN) layer.\n",
        "vocab_inp_size = len(inp_lang.word_index) + 1  # Calculate the size of the input vocabulary.\n",
        "vocab_tar_size = len(targ_lang.word_index) + 1  # Calculate the size of the target vocabulary.\n",
        "\n",
        "# Create a TensorFlow dataset from the input and target tensors, and shuffle it using the specified BUFFER_SIZE.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Batch the dataset into batches of BATCH_SIZE and drop any remaining examples that don't fit into a batch.\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Get an example input batch and an example target batch from the dataset.\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "\n",
        "# Print the shapes of the example input and target batches.\n",
        "print(\"Example Input Batch Shape:\", example_input_batch.shape)\n",
        "print(\"Example Target Batch Shape:\", example_target_batch.shape)"
      ],
      "metadata": {
        "id": "9dyI5sSvntWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "BahdanauAttention: prend en entrée le hidden_state de l'encoder considéré comme query, et la sortie de l'encoder considéré comme key et value.\n",
        "La sortie de la couche BahdanauAttention utilisée dans le décodeur et concaténer avec le mot en cours de traitement (son embedding).\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ia1vR80aYOxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom class called \"Encoder\" that inherits from the tf.keras.Model class.\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()  # Call the constructor of the parent class.\n",
        "        self.batch_sz = batch_sz  # Store the batch size as an instance variable.\n",
        "        self.enc_units = enc_units  # Store the number of units in the GRU layer.\n",
        "\n",
        "        # Create an embedding layer to convert input tokens into dense vectors.\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Create a GRU (Gated Recurrent Unit) layer with specified parameters.\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # Define the forward pass for the encoder.\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)  # Pass the input through the embedding layer. --------------------------------(None, sequence, embedding_dim)\n",
        "        output, state = self.gru(x, initial_state=hidden)  # Pass through the GRU. --------------------------(None, sequence, enc_units), (None, enc_units)\n",
        "        return output, state  # Return the output sequence and final hidden state. --------------------------(None, sequence, enc_units), (None, enc_units)\n",
        "\n",
        "    # Initialize the hidden state (typically with zeros).\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "Cdj5ig4yzWcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Q = Decoder hidden state (None, decoder_unit)\n",
        "    at the begining, Q = Encoder hidden state\n",
        "\n",
        "V = Encoder output (None, sequence, feature)\n",
        "\n",
        "Q = tf.expand_dims(Q, axis=1) # (None, 1, decoder_unit)\n",
        "EncQ = Dense1(Q) # (None, units)\n",
        "EncV = Dense2(V) # (None, sequence, units)\n",
        "sum = tf.nn.tanh(EncQ+EncV) # activation (None, sequence, units)\n",
        "\n",
        "score = Dense3(sum) # (None, sequence, 1)\n",
        "attention = tf.nn.softmax(score, axis=1) # (None, sequence, 1) softmax based on token position\n",
        "\n",
        "context_vector = attention*V # (None, sequence, feature)\n",
        "context_vector = tf.nn.sum(context_vector, axis=1) # (None, feature)\n",
        "\n",
        "context_vector sera utilisé dans le decoder et concaténer avec l'entrée (qui se fait token par token)\n",
        "x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # (None, 1, feature+embedding_dim_x) x vient de l'embedding x est de type (None, 1) car on traite par token Embedding donne (None, 1, embedding_dim_x)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DM5eeUy8OkQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        \"\"\"\n",
        "          query = hidden state dec = (None, latent_dim)\n",
        "          values = outputs of enc = (None, sequence, latent_dim)\n",
        "        \"\"\"\n",
        "        # (None, 1, latent_dim)\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        # (None, sequence, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        # (batch_size, sequence, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # (None, sequence, latent_dim)\n",
        "        context_vector = attention_weights * values\n",
        "\n",
        "        # (None, latent_dim)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "iZCkRue02acu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # used for attention\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x) # (batch_size, 1, hidden_size)\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ],
      "metadata": {
        "id": "rg4J57zf5JAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0)) # return False if 0 and True else (0 is the pad token)\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask # reduce to 0 if correspond to pad token (False)\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "29PQAbBOe5sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "loss = 1\n",
        "print(tf.reduce_mean([0, 0.2,0.3]))\n",
        "loss+=tf.reduce_mean([0, 0.2,0.3])\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSNyDhPq9lJ6",
        "outputId": "525aeeac-5f4a-4133-eb0a-11a4e6ddf2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.16666667, shape=(), dtype=float32)\n",
            "tf.Tensor(1.1666666, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        # (BATCH_SIZE, 1)\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<sos>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "metadata": {
        "id": "g69pILvhe8t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 40\n",
        "\n",
        "# Training taking batch per batch\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "    if(epoch % 4 == 0):\n",
        "        print('Epoch:{:3d} Loss:{:.4f}'.format(epoch,\n",
        "                                          total_loss / steps_per_epoch))"
      ],
      "metadata": {
        "id": "VVIdz4EJe9lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **tf.data.Dataset**"
      ],
      "metadata": {
        "id": "6u9ZLl7tCsOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator\n",
        "# + load image: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ohFAFc_cHltF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "l = [1,2,9,8,4]\n",
        "np.random.shuffle(l)"
      ],
      "metadata": {
        "id": "5N8fIqP3v8Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEwMkq-jwLUu",
        "outputId": "64edc318-9246-454f-e043-4072db358d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 9, 1, 8, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class CustomDataGenerator(Sequence):\n",
        "    def __init__(self, x_data, y_data, batch_size, shuffle=True):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.x_data))\n",
        "\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x_data) / self.batch_size)) # np.ceil : partie entière inférieure -->\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = (index + 1) * self.batch_size\n",
        "\n",
        "        batch_x = self.x_data[self.indexes[start:end]]\n",
        "        batch_y = self.y_data[self.indexes[start:end]]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "# Example usage:\n",
        "# Create some example data\n",
        "x_data = np.random.rand(100, 32, 32, 3)\n",
        "y_data = np.random.randint(0, 2, size=(100,))\n",
        "\n",
        "# Create an instance of the custom data generator\n",
        "batch_size = 32\n",
        "data_generator = CustomDataGenerator(x_data, y_data, batch_size)\n",
        "\n",
        "# Iterate through the data generator for training\n",
        "for epoch in range(epochs):\n",
        "    for batch_x, batch_y in data_generator:\n",
        "        # Train your model on batch_x and batch_y\n"
      ],
      "metadata": {
        "id": "APK-wSal437N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Source dataset**"
      ],
      "metadata": {
        "id": "WjdSkMTOLmKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data don't fit in memory\n",
        "data = [1,2,3]\n",
        "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mFQ8YeACwgP",
        "outputId": "1f241c63-5cc9-49a1-ffc8-f6176cb7c609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read lines from Files\n",
        "files = [\"text1\", \"text2\"]\n",
        "dataset = tf.data.TextLineDataset(files)\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoV_Jm-JItVI",
        "outputId": "6b0a220f-7472-4985-f83f-42c18f243640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Le senegal', shape=(), dtype=string)\n",
            "tf.Tensor(b'La gambie', shape=(), dtype=string)\n",
            "tf.Tensor(b'Le Maroc', shape=(), dtype=string)\n",
            "tf.Tensor(b'La Tunisie', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read name of files giving extension\n",
        "path = '*.txt'\n",
        "dataset = tf.data.Dataset.list_files(path)\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh6moXcKJ-eh",
        "outputId": "15a1c852-cee7-4d26-fa6c-ea761b4da963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'./text1.txt', shape=(), dtype=string)\n",
            "tf.Tensor(b'./text2.txt', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformation**"
      ],
      "metadata": {
        "id": "9eUcOl4NLpNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map\n",
        "map(\n",
        "    map_func,\n",
        "    num_parallel_calls=None,  # representing the number elements to process asynchronously in parallel. If not specified, elements will be processed sequentially. If the value tf.data.AUTOTUNE is used, then the number of parallel calls is set dynamically based on available CPU.\n",
        "    deterministic=None,\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "o4W2UqQ7hDiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. map\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1,2,3])\n",
        "dataset = dataset.map(lambda x: x**2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qS2dzYTLrGM",
        "outputId": "7d138890-13b4-4d2c-b406-603dddcfb26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. map\n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1,2,3], [0,1,1]))\n",
        "dataset = dataset.map(lambda x1, x2: (x1**2, x2))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyj1SdH5M8Yy",
        "outputId": "5516bfcf-9e01-4f43-d4a5-fee2694bc773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0), (4, 1), (9, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter\n",
        "dataset = tf.data.Dataset.range(100)\n",
        "dataset = dataset.filter(lambda x: x < 5)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1033XrBxOEmE",
        "outputId": "764fdcd9-e533-4c4d-d99e-763e6d51f095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply\n",
        "dataset = tf.data.Dataset.range(100)\n",
        "\n",
        "def my_filter(ds):\n",
        "    return ds.filter(lambda x: x < 5)\n",
        "\n",
        "dataset = dataset.apply(my_filter)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT836A9IO8WW",
        "outputId": "a5e9a7cc-6220-47d4-dd18-bb0ab02ba9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as_numpy_iterator\n",
        "dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),\n",
        "                                              'b': [5, 6]})\n",
        "list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5},\n",
        "                                      {'a': (2, 4), 'b': 6}]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zre3TDYjPk1e",
        "outputId": "0b2d73bc-79c8-42cd-f94c-a63007469857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch\n",
        "batch(\n",
        "    batch_size,\n",
        "    drop_remainder=False, # representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n",
        "    num_parallel_calls=None, # number of batches to compute asynchronously in parallel tf.data.AUTOTUNE\n",
        "    deterministic=None,\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "L3wubBukS7NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch\n",
        "dataset = tf.data.Dataset.range(8)\n",
        "dataset = dataset.batch(3)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpWQFS3HTgEa",
        "outputId": "507624ca-0a4c-40b0-b46f-55831cbaa811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(8)\n",
        "dataset = dataset.batch(3, drop_remainder=True)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WLNHRHjTqJ4",
        "outputId": "e435bbb8-5882-4566-d6b3-4db2fb89f80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5])]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cardinality\n",
        "dataset = tf.data.Dataset.range(42)\n",
        "print(dataset.cardinality().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq5IHbdsUGew",
        "outputId": "3c33d032-ea0c-4691-ee12-5d32bc90c7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flat_map\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "dataset = dataset.flat_map(tf.data.Dataset.from_tensor_slices)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyeFZgNOX9Pe",
        "outputId": "01a378e4-6923-4d56-88c4-8827c217d7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from_tensors: Creates a Dataset with a single element, comprising the given tensors.\n",
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E3zcl10d99L",
        "outputId": "1c9db929-328e-4bb2-8c54-a8e2d9f6fe5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from_tensors: Creates a Dataset with a single element, comprising the given tensors.\n",
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMx4A6FidrWR",
        "outputId": "0fc911d6-a77b-41ae-8bc3-5bf0cbec857e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2, 3], dtype=int32)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make dataset**"
      ],
      "metadata": {
        "id": "LpL4Hh9ogXLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.data.Dataset.range(10)\n",
        "dataset = (\n",
        "    data\n",
        "    .map(lambda x: x**2, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(2)\n",
        ")\n",
        "\n",
        "for element in dataset:\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoR_EVxif2j-",
        "outputId": "b576c596-9687-437e-8c2d-fddc470b678e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
            "tf.Tensor([4 9], shape=(2,), dtype=int64)\n",
            "tf.Tensor([16 25], shape=(2,), dtype=int64)\n",
            "tf.Tensor([36 49], shape=(2,), dtype=int64)\n",
            "tf.Tensor([64 81], shape=(2,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements.\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UpA-D10k6SM",
        "outputId": "f210ac99-ae09-4000-aec8-9d8718c066d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a 2D tensor produces 1D tensor elements.\n",
        "dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxIVOUzAlILU",
        "outputId": "58024479-926d-4e82-abf8-2b1e6fafd994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2], dtype=int32), array([3, 4], dtype=int32)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a tuple of 1D tensors produces tuple elements containing WAY FOR DATASET PROCESSING\n",
        "# scalar tensors.\n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwIGJN_VlKhf",
        "outputId": "8b7d0c38-db61-491c-9c4a-7ea058a21113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 3, 5), (2, 4, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary structure is also preserved.\n",
        "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
        "list(dataset.as_numpy_iterator())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhFuHt-rlgEB",
        "outputId": "c23972dd-c59f-482d-80b6-2fcc0dfa600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'a': 1, 'b': 3}, {'a': 2, 'b': 4}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two tensors can be combined into one Dataset object.\n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfzsesavoLss",
        "outputId": "1df4e2de-1f24-4c23-b87b-11d494c85624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 3], dtype=int32), b'A'),\n",
              " (array([2, 1], dtype=int32), b'B'),\n",
              " (array([3, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two tensors can be combined into one Dataset object.\n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "# Both the features and the labels tensors can be converted\n",
        "# to a Dataset object separately and combined after.\n",
        "features_dataset = tf.data.Dataset.from_tensor_slices(features)\n",
        "labels_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
        "dataset = tf.data.Dataset.zip((features_dataset, labels_dataset))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C0IIy3El_w2",
        "outputId": "dab322d4-00c0-4b36-ae98-e3748d229678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 3], dtype=int32), b'A'),\n",
              " (array([2, 1], dtype=int32), b'B'),\n",
              " (array([3, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A batched feature and label set can be converted to a Dataset\n",
        "# in similar fashion.\n",
        "batched_features = tf.constant([[[1, 3], [2, 3]],\n",
        "                                [[2, 1], [1, 2]],\n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
        "batched_labels = tf.constant([['A', 'A'],\n",
        "                              ['B', 'B'],\n",
        "                              ['A', 'B']], shape=(3, 2, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices((batched_features, batched_labels))\n",
        "for element in dataset.as_numpy_iterator():\n",
        "    print(element)\n",
        "# show shape\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvb5qWxAmhWJ",
        "outputId": "9e5e556f-5f37-458b-ceb0-4d4ef7a9dddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([[b'A'],\n",
            "       [b'A']], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([[b'B'],\n",
            "       [b'B']], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([[b'A'],\n",
            "       [b'B']], dtype=object))\n",
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(2, 1), dtype=tf.string, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A batched feature and label set can be converted to a Dataset\n",
        "# in similar fashion.\n",
        "batched_features = tf.constant([[[1, 3], [2, 3]],\n",
        "                                [[2, 1], [1, 2]],\n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
        "batched_labels = tf.constant([['A', 'A'],\n",
        "                              ['B', 'B'],\n",
        "                              ['A', 'B']], shape=(3, 2)) # change shape\n",
        "dataset = tf.data.Dataset.from_tensor_slices((batched_features, batched_labels))\n",
        "for element in dataset.as_numpy_iterator():\n",
        "    print(element)\n",
        "# show shape\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0sNf58ZnaNw",
        "outputId": "d248faad-825b-4261-fe98-f512e9261c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([b'A', b'A'], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([b'B', b'B'], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([b'A', b'B'], dtype=object))\n",
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(2,), dtype=tf.string, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**prefetch**"
      ],
      "metadata": {
        "id": "fX7ffpU5pxW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a Dataset that prefetches elements from this dataset.\n",
        "\n",
        "Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n",
        "\n",
        "Note: Like other Dataset methods, prefetch operates on the elements of the input dataset. It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 batches, of 20 examples each)."
      ],
      "metadata": {
        "id": "p3COrWBzqI8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefetch(\n",
        "    buffer_size, # \tA tf.int64 scalar tf.Tensor, representing the maximum number of elements that will be buffered when prefetching. If the value tf.data.AUTOTUNE is used, then the buffer size is dynamically tuned.\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "fQhednphqdZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.prefetch(2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1Z9_4_Gpzds",
        "outputId": "9985df51-9471-42c9-a2bb-0e8a64b378b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**shuffle**"
      ],
      "metadata": {
        "id": "MsfWy4RirprZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
        "dataset = dataset.repeat(2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0ULYvLnrzY_",
        "outputId": "83636872-c6b4-4a7b-840f-07b070ca4911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2, 1, 0, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
        "dataset = dataset.repeat(2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqXtVp1yrrJ_",
        "outputId": "b8e60c1a-ca71-4b60-baee-1833e4ddfbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 0, 1, 0, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**take**"
      ],
      "metadata": {
        "id": "aDsa7tmQswPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.take(3)\n",
        "list(dataset.as_numpy_iterator())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glWxAt5zsxqW",
        "outputId": "22e3937b-c980-42fe-dce0-bd7af708fcbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**take_while**"
      ],
      "metadata": {
        "id": "1aI88Jlqs14S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.take_while(lambda x: x < 5)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORT2p2o1s3i1",
        "outputId": "f7f0f5ff-9eef-4cc9-e5af-2b0c11740e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**unbatch**"
      ],
      "metadata": {
        "id": "nSJOfv6BtCHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splits elements of a dataset into multiple elements.\n",
        "\n",
        "For example, if elements of the dataset are shaped [B, a0, a1, ...], where B may vary for each input element, then for each element in the dataset, the unbatched dataset will contain B consecutive elements of shape [a0, a1, ...]."
      ],
      "metadata": {
        "id": "UN-J8a8stFYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\n",
        "dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\n",
        "dataset = dataset.unbatch()\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tfBZ9M3tDvQ",
        "outputId": "ac24ecd0-fdb8-4234-cb61-05107c4a8559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 1, 2, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**unique**"
      ],
      "metadata": {
        "id": "07Kj5p7DtNMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 37, 2, 37, 2, 1])\n",
        "dataset = dataset.unique()\n",
        "sorted(list(dataset.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW_WECHitOh3",
        "outputId": "9e7ea7e0-970e-4fdf-ca7e-dc2f4667d8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 37]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**window**"
      ],
      "metadata": {
        "id": "_VnJMIsDuVU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returns a dataset of \"windows\".\n",
        "\n",
        "Each \"window\" is a dataset that contains a subset of elements of the input dataset. These are finite datasets of size size (or possibly fewer if there are not enough input elements to fill the window and drop_remainder evaluates to False).\n",
        "\n"
      ],
      "metadata": {
        "id": "tbKmDjA6vxvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "  print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeVOk5gBuWwU",
        "outputId": "3014d67b-aa94-4e47-b150-ba232faf9c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2]\n",
            "[3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shift argument determines the number of input elements to shift between the start of each window. If windows and elements are both numbered starting at 0, the first element in window k will be element k * shift of the input dataset. In particular, the first element of the first window will always be the first element of the input dataset."
      ],
      "metadata": {
        "id": "3JFCs1jhwzvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "    print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSAuUKPYw0VX",
        "outputId": "0a5dabdd-fdc4-4801-e477-94458cef8b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2]\n",
            "[1, 2, 3]\n",
            "[2, 3, 4]\n",
            "[3, 4, 5]\n",
            "[4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stride argument determines the stride between input elements within a window."
      ],
      "metadata": {
        "id": "upwjM_YHxITF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1, stride=2,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "  print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1JAVcYKxJk2",
        "outputId": "fa1de2fb-e6cf-412b-a247-630b4df72709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 4]\n",
            "[1, 3, 5]\n",
            "[2, 4, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
        "                                              [6, 7, 8, 9, 10]))\n",
        "dataset = dataset.window(2)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4LcuZNexgtZ",
        "outputId": "74ab4620-fdf1-4244-9d55-9e5a8f92536b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_WindowDataset element_spec=(DatasetSpec(TensorSpec(shape=(), dtype=tf.int32, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(), dtype=tf.int32, name=None), TensorShape([])))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
        "                                              [6, 7, 8, 9, 10]))\n",
        "dataset = dataset.window(2)\n",
        "\n",
        "for w in dataset: # w is a tuple\n",
        "  print(\"#############\")\n",
        "  print(w[0].batch(2))\n",
        "  print(list(w[0].as_numpy_iterator()))\n",
        "  print(list(w[1].as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e_YNOVtxkY2",
        "outputId": "c25e9bb8-d7c9-4e4d-f910-53f11c50529c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#############\n",
            "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "[1, 2]\n",
            "[6, 7]\n",
            "#############\n",
            "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "[3, 4]\n",
            "[8, 9]\n",
            "#############\n",
            "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "[5]\n",
            "[10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
        "                                          drop_remainder=True)\n",
        "batched = dataset.flat_map(lambda x:x.batch(3))\n",
        "for batch in batched:\n",
        "  print(batch)\n",
        "  print(batch.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa8Aw8ZC0c2O",
        "outputId": "9c1fb0aa-303c-4e59-ef29-18249440468e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2], shape=(3,), dtype=int64)\n",
            "[0 1 2]\n",
            "tf.Tensor([1 2 3], shape=(3,), dtype=int64)\n",
            "[1 2 3]\n",
            "tf.Tensor([2 3 4], shape=(3,), dtype=int64)\n",
            "[2 3 4]\n",
            "tf.Tensor([3 4 5], shape=(3,), dtype=int64)\n",
            "[3 4 5]\n",
            "tf.Tensor([4 5 6], shape=(3,), dtype=int64)\n",
            "[4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**zip**"
      ],
      "metadata": {
        "id": "KOnM-gqg4yd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
        "b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\n",
        "ds = tf.data.Dataset.zip(a, b)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfm5Srm_40hY",
        "outputId": "fa34d2e6-a43c-4069-d663-863c80aa7852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 4), (2, 5), (3, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.zip(b, a)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy6UQ0Xq4-si",
        "outputId": "dd809439-a662-4655-bdca-b51a70f8fc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4, 1), (5, 2), (6, 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The `datasets` argument may contain an arbitrary number of datasets.\n",
        "c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\n",
        "                                           #       [9, 10],\n",
        "                                           #       [11, 12] ]\n",
        "ds = tf.data.Dataset.zip(a, b, c)\n",
        "for element in ds.as_numpy_iterator():\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK-YTFxY5JA6",
        "outputId": "197b1d22-c685-4f57-a06e-f517c88b38c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4, array([7, 8]))\n",
            "(2, 5, array([ 9, 10]))\n",
            "(3, 6, array([11, 12]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of elements in the resulting dataset is the same as\n",
        "# the size of the smallest dataset in `datasets`.\n",
        "d = tf.data.Dataset.range(13, 15)  # ==> [ 13, 14 ]\n",
        "ds = tf.data.Dataset.zip(a, d)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4gAECr15N7V",
        "outputId": "baeaaa16-4c3b-4a8f-8700-ea9edbbcc059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 13), (2, 14)]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.data.Dataset.from_tensor_slices(([1,2,3], [5,5,7]))\n",
        "for i in a:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NJqbgsj8KDS",
        "outputId": "346dcab5-f7b7-44f0-fddd-33d685bce68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=7>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image - Text - Sequence**"
      ],
      "metadata": {
        "id": "YTh6vXLEWatx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Module**\n",
        "\n",
        "* **Class**\n",
        "\n",
        "* **Function**"
      ],
      "metadata": {
        "id": "dsojJ4J0k7_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sur Tensorflow, on a des modules, des classes et des fonctions\n",
        "tf.keras.preprocessing: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing [Module: image, text, sequence]\n",
        "tf.keras.utils: https://www.tensorflow.org/api_docs/python/tf/keras/utils: exemple :\n",
        "tf.keras.utils.to_categorical(\n",
        "    y, num_classes=None, dtype='float32'\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kolFTPjHYqUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune model application\n",
        "https://keras.io/api/applications/"
      ],
      "metadata": {
        "id": "lTqpBUOxWckZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Callbacks**"
      ],
      "metadata": {
        "id": "9Su900NJyWDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "callbacks permet de controler le train\n",
        "tf.keras.callbacks.Callback\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks [Callback, ModelCheckpoint]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9Re2h08fyYgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\"\"\"\n",
        "self c'est le modèle\n",
        "\"\"\"\n",
        "class MyCustomCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print(f\"Starting epoch {epoch}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Finished epoch {epoch}. Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}\")\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        print(f\"Training batch {batch}...\")\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        print(f\"Finished training batch {batch}. Loss: {logs['loss']:.4f}\")\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        print(\"Starting validation...\")\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        print(\"Finished validation. Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}\")\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        print(\"Starting prediction...\")\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        print(\"Finished prediction.\")\n",
        "\n",
        "# Créez un modèle Keras simple à des fins d'exemple\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Générez des données factices pour l'exemple\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Entraînez le modèle avec l'utilisation de votre callback personnalisé\n",
        "history = model.fit(x_train, y_train, epochs=3, callbacks=[MyCustomCallback()])\n",
        "\n",
        "# Effectuez une évaluation du modèle\n",
        "model.evaluate(x_test, y_test, callbacks=[MyCustomCallback()])\n",
        "\n",
        "# Effectuez des prédictions\n",
        "model.predict(x_test[:5], callbacks=[MyCustomCallback()])\n"
      ],
      "metadata": {
        "id": "dle0BHI75shA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = 'drive/MyDrive/autoACN_densenet40_cifar100'\n",
        "# Créer un callback pour enregistrer les checkpoints tous les 50 époques\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, 'model_weights_{epoch:03d}.h5'),\n",
        "    save_weights_only=True,\n",
        "    save_best_only=False,\n",
        "    save_freq=SAVE_PERIOD*STEPS_PER_EPOCH # Sauvegarder tous les 50 époques\n",
        ")\n",
        "# Train the DenseNet-40 model\n",
        "history = model_densenet40.fit(train_gen,\n",
        "                     steps_per_epoch=x_train.shape[0] // batch_size, epochs=epochs,\n",
        "                     validation_data=(x_val, y_val), callbacks=[keras.callbacks.LearningRateScheduler(lr_schedule), checkpoint_callback])\n"
      ],
      "metadata": {
        "id": "rIFsfz1_46AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * 2.08))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULhea89O6paT",
        "outputId": "f4b4a6bd-2123-46ec-f93d-93474a1c0f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored model, accuracy: 208.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple plus avancé\n",
        "class GradientStabilityCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, source_ds, target_ds):\n",
        "        self.source_ds = source_ds\n",
        "        self.target_ds = target_ds\n",
        "        self.gradient_variances_source = []\n",
        "        self.gradient_variances_target = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        trainable_weights = self.model.model.trainable_weights\n",
        "        gradients_source = []\n",
        "        gradients_target = []\n",
        "\n",
        "        # Choisissez un lot de données à partir de l'ensemble source\n",
        "        source_batch = next(iter(self.source_ds))\n",
        "        target_batch = next(iter(self.target_ds))\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape_source,  tf.GradientTape(persistent=True) as tape_target:\n",
        "            # Passe avant avec les données source\n",
        "            source_input = source_batch[0][0] # (x, y, context), (x, y, context)\n",
        "            target_input = target_batch[0][0]\n",
        "\n",
        "            source_logits = self.model.model(source_input, training=True)\n",
        "            target_logits = self.model.model(target_input, training=True)\n",
        "\n",
        "\n",
        "        # trainable_weights: liste de tf.Variables, avec chaque tf.Variables les poids d'une couche (une matrice)\n",
        "        for weight in trainable_weights:\n",
        "            # Vérifiez si le poids est connecté au calcul de source_logits\n",
        "            gradients_source.append(tape_source.gradient(source_logits, weight)) # weight est de type tf.Variables et contient les poids d'une couche donnée\n",
        "            gradients_target.append(tape_target.gradient(target_logits, weight))\n",
        "\n",
        "\n",
        "        gradient_variance_source = [np.var(grad.numpy()) for grad in gradients_source]\n",
        "        gradient_variance_target = [np.var(grad.numpy()) for grad in gradients_target]\n",
        "\n",
        "        # Enregistrez ou stockez éventuellement gradient_variance selon vos besoins\n",
        "\n",
        "        self.gradient_variances_source.append(gradient_variance_source)\n",
        "        self.gradient_variances_target.append(gradient_variance_target)\n",
        "        #print(f\"Époque {epoch + 1}, Variance des gradients : {gradient_variance}\")\n",
        "\n",
        "# Create an instance of the GradientStabilityCallback with your source and target datasets\n",
        "gradient_stability_callback = GradientStabilityCallback(final_source_ds, final_target_ds)\n"
      ],
      "metadata": {
        "id": "oiVjqmp3qro_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value = 10*3.09\n",
        "a = '{:.05f}'.format(value)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B0boIbhs6wtt",
        "outputId": "51c6e84e-8feb-4925-ef0f-77c70fa0239e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'30.90000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value = 10*3.09\n",
        "a = f'{value:.02f}'\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "p4p2yww39AF5",
        "outputId": "8ef75da5-4d9c-46d2-f25e-327b3b677db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'30.90'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value = 1009*3.09\n",
        "a = f'{value:19.02f}'\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "drHoivvfZVP9",
        "outputId": "a68ebd43-0c50-4405-ca09-1d6a5cea567d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'            3117.81'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = '{:2d}'.format(10)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Dz3GKPBW8WW_",
        "outputId": "fc2ce253-aa80-49cf-ab44-73fa484f0ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = '{:03d}'.format(10)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5M3NS6CP8eGy",
        "outputId": "b2c8310c-c79d-42c0-eda3-733ba5eb3623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'010'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Value: %03d\" % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wPpH66PI8GfZ",
        "outputId": "e354ab48-551d-4352-b523-19c25795cad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Value: 002'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Value: %.03f\" % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dvAgObS_8itP",
        "outputId": "000af559-6237-47e6-c16d-402beaf723c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Value: 2.000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Value: %.03f %02d\" % (2, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NyAtywTa9aGx",
        "outputId": "5157eb71-65ed-4863-d978-ee123333aa85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Value: 2.000 02'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save Model**"
      ],
      "metadata": {
        "id": "UFsVm-srMhSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://www.tensorflow.org/tutorials/keras/save_and_load"
      ],
      "metadata": {
        "id": "LKrVSGWLXfGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les formats de fichiers .keras, .ckpt (Checkpoint), et .h5 (HDF5) sont tous utilisés pour enregistrer des modèles TensorFlow (notamment avec l'API Keras). Chacun a ses propres caractéristiques et avantages. Voici les principales différences entre ces formats de fichiers :\n",
        "\n",
        "**.keras (SavedModel):**\n",
        "\n",
        "Format par défaut lors de l'enregistrement d'un modèle Keras avec TensorFlow.\n",
        "Contient le modèle complet, y compris l'architecture, les poids, la configuration et les informations d'entraînement.\n",
        "Peut être utilisé pour le déploiement en production et pour la reprise de l'entraînement sans avoir à répéter la définition du modèle.\n",
        "Fournit une structure hiérarchique qui permet de stocker plusieurs versions du modèle et des signatures de fonction pour le déploiement.<br>\n",
        "**Le modèle est enrégistrer sur un fichier zip. model.save(\"model.keras\")**<br>\n",
        "\n",
        "**.ckpt (Checkpoint):**\n",
        "\n",
        "Enregistre principalement les poids du modèle, pas l'architecture.\n",
        "Utilisé pour sauvegarder uniquement les poids d'un modèle, ce qui permet de réutiliser les mêmes couches avec des architectures différentes.\n",
        "Souvent utilisé pour la reprise de l'entraînement et la sauvegarde de points de contrôle (checkpoints) à différents stades de l'entraînement.\n",
        "Vous devez spécifier l'architecture du modèle lors du chargement des poids depuis un fichier .ckpt.<br>\n",
        "**Enrégistre trois fichiers. model.save_weights(\"model.ckpt\")**<br>\n",
        "\n",
        "\n",
        "**.h5 (HDF5):**\n",
        "\n",
        "Peut enregistrer l'ensemble du modèle, y compris l'architecture, les poids et la configuration.\n",
        "Facile à partager avec d'autres utilisateurs, car il contient toutes les informations nécessaires pour reconstruire et utiliser le modèle.\n",
        "Utile pour enregistrer des modèles complets pour la reprise de l'entraînement ou pour des expériences de recherche.\n",
        "Peut également être utilisé pour enregistrer uniquement les poids si vous le souhaitez.\n",
        "En résumé, le format .keras (SavedModel) est généralement recommandé pour le déploiement en production, car il contient toutes les informations nécessaires pour le modèle, tandis que le format .ckpt est idéal pour la reprise de l'entraînement et la sauvegarde des poids. Le format .h5 est polyvalent, car il peut enregistrer l'ensemble du modèle ou uniquement les poids, ce qui le rend pratique pour diverses situations. Le choix du format dépend de l'utilisation spécifique de votre modèle et de vos besoins en matière de partage et de reprise de l'entraînement.<br>\n",
        "**Enrégistre un seul fichier avec model.save(\"model.h5\") ou model.save_weights(\"model.h5\")**"
      ],
      "metadata": {
        "id": "LAV8F4kDfTui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embedding**"
      ],
      "metadata": {
        "id": "Dp6QtMEhGYaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A voir obligatoirement pour construire une couche embedding from scratch: https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup\n",
        "class CustomEmbedding(keras.layers.Layer):\n",
        "    def __init__(self, input_dim, output_dim, mask_zero=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.mask_zero = mask_zero\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.embeddings = self.add_weight(\n",
        "            shape=(self.input_dim, self.output_dim),\n",
        "            initializer=\"random_normal\",\n",
        "            dtype=\"float32\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.nn.embedding_lookup(self.embeddings, inputs) # voir : https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if not self.mask_zero:\n",
        "            return None\n",
        "        return tf.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "layer = CustomEmbedding(10, 32, mask_zero=True)\n",
        "x = np.random.random((3, 10)) * 9\n",
        "x = x.astype(\"int32\")\n",
        "\n",
        "y = layer(x)\n",
        "mask = layer.compute_mask(x)\n",
        "a = LSTM(3)(y, mask=mask)\n",
        "\n",
        "print(mask)\n",
        "\n",
        "params: correspond aux tensors de paramètres nombre de ligne taille du vocabulaire, nombre de colonne output_dim\n",
        "ids: les ids ou tokens pour l'entrée donnée\n",
        "\n",
        "\"\"\"\n",
        "EXEMPLE:\n",
        "SOIT Params = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
        "et ids = [0, 3, 4]\n",
        "\n",
        "alors l'embedding va être calculé de la façon suivante: pour 0 on prend [1,2], pour 3 on prend [7, 8], 4 prend [9, 10]\n",
        "\n",
        "Voir embedding avec mask = True dans https://www.tensorflow.org/guide/keras/understanding_masking_and_padding\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_cIA6DEzGdaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Réseau de neurones séquentiel**"
      ],
      "metadata": {
        "id": "2n7XxItEXUCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM**"
      ],
      "metadata": {
        "id": "08eGL_H2YdmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = tf.keras.layers.LSTM(2, return_sequences=True, return_state=True)\n",
        "o, c, h = lstm(b)"
      ],
      "metadata": {
        "id": "yJGECWQHYnm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e6175f2-bc00-4ba4-cf03-e9a5949264de",
        "id": "LR1ibfbLYnm2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 2), dtype=float32, numpy=\n",
              "array([[[-0.0064925 ,  0.00696212],\n",
              "        [-0.00547939,  0.0159462 ],\n",
              "        [-0.0029227 ,  0.00401334],\n",
              "        [-0.0029227 ,  0.00401334],\n",
              "        [-0.0029227 ,  0.00401334],\n",
              "        [-0.0029227 ,  0.00401334]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675402a7-e472-4993-f988-36fbf7858879",
        "id": "kRUwlMO8Ynm4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.0029227 ,  0.00401334]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f81a16e-6aba-459f-fcb8-af9868648991",
        "id": "bbOx1JejYnm5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.00583435,  0.00805774]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GRU**"
      ],
      "metadata": {
        "id": "q6Xs5zNXYbfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = tf.keras.layers.SimpleRNN(2, return_sequences=True, return_state=True, activation=\"softmax\")\n",
        "o,  h = lstm(b)"
      ],
      "metadata": {
        "id": "3Ojc8nzUY_N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05e248b-653a-4be3-d04e-87a4834fd309",
        "id": "O2BEEksaY_N7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 2), dtype=float32, numpy=\n",
              "array([[[0.5032558 , 0.4967442 ],\n",
              "        [0.6602687 , 0.33973125],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4307c3-ff82-44c5-8390-1b6e622963b1",
        "id": "ElL73DMoY_N8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.70205325, 0.29794678]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RNN**"
      ],
      "metadata": {
        "id": "JOtSpgQwXnwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output = Hidden\n",
        "lstm = tf.keras.layers.SimpleRNN(2, return_sequences=True, return_state=True, activation=\"softmax\")\n",
        "o,  h = lstm(b)"
      ],
      "metadata": {
        "id": "kGBwxVZxWVjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veFV9V0YWadU",
        "outputId": "b05e248b-653a-4be3-d04e-87a4834fd309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 2), dtype=float32, numpy=\n",
              "array([[[0.5032558 , 0.4967442 ],\n",
              "        [0.6602687 , 0.33973125],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipy_M_vQWcKI",
        "outputId": "cf4307c3-ff82-44c5-8390-1b6e622963b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.70205325, 0.29794678]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec**"
      ],
      "metadata": {
        "id": "7HwdG2W_XLpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "L'entraînement d'un modèle Word2Vec implique l'utilisation d'un corpus de texte pour créer des représentations vectorielles des mots, de manière à capturer leurs relations sémantiques et syntaxiques. Voici une procédure générale pour entraîner un modèle Word2Vec :\n",
        "\n",
        "Préparation du Corpus : Rassemblez un corpus de texte qui sera utilisé pour entraîner le modèle. Plus le corpus est vaste, mieux le modèle peut apprendre les relations entre les mots.\n",
        "\n",
        "Tokenisation : Divisez le texte en unités plus petites, telles que des phrases ou des mots. Pour Word2Vec, la tokenisation est généralement effectuée au niveau des mots.\n",
        "\n",
        "Création de Paires de Contexte-Cible : Pour chaque mot dans le corpus, créez des paires de mots qui apparaissent dans son contexte. Par exemple, pour le mot \"chat\", les paires de contexte-cible pourraient être (\"animal\", \"mignon\"), (\"grimpe\", \"arbre\"), etc.\n",
        "\n",
        "Encodage One-Hot : Convertissez les mots en vecteurs one-hot. Chaque mot est représenté par un vecteur où un seul élément est défini à 1, indiquant la position du mot dans le vocabulaire.\n",
        "\n",
        "Construction du Modèle Word2Vec : Utilisez le corpus préparé pour entraîner le modèle Word2Vec. Deux architectures couramment utilisées sont Skip-Gram et Continuous Bag of Words (CBOW). Dans Skip-Gram, le modèle prédit les mots voisins à partir du mot actuel, tandis que dans CBOW, il prédit le mot actuel à partir de ses voisins.\n",
        "\n",
        "Entraînement du Modèle : Entraînez le modèle en ajustant les poids des vecteurs de mots pour minimiser une fonction de perte. Les algorithmes populaires pour cet entraînement incluent l'algorithme Skip-Gram négatif (Negative Sampling) et l'algorithme de Hierarchical Softmax.\n",
        "\n",
        "Obtention des Vecteurs de Mots : Une fois l'entraînement terminé, les vecteurs de mots appris peuvent être extraits du modèle. Ces vecteurs représentent la sémantique des mots dans un espace vectoriel.\n",
        "\n",
        "Évaluation (Facultatif) : Si des données d'évaluation sont disponibles, vous pouvez évaluer la qualité du modèle en vérifiant sa capacité à effectuer des tâches spécifiques telles que la similarité sémantique ou la complétion de mots.\n",
        "\n",
        "\n",
        "\n",
        "La sémantique se réfère à la signification des mots, des phrases, des expressions et du langage en général."
      ],
      "metadata": {
        "id": "tL45s2_sXOq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntaxe : La syntaxe concerne la structure formelle d'une langue. Elle spécifie comment les mots et les phrases doivent être ordonnés pour former des énoncés corrects sur le plan grammatical. Les règles syntaxiques définissent la manière dont les éléments du langage peuvent être combinés pour créer des unités plus grandes, comme les phrases et les paragraphes.\n",
        "\n",
        "Sémantique : La sémantique concerne la signification des éléments linguistiques. Elle explore comment les mots, les phrases et les discours transmettent des informations et des idées. La sémantique examine les relations sémantiques entre les mots, les nuances de sens, et la manière dont le contexte influence l'interprétation du langage.\n",
        "\n",
        "Lexique : Le lexique fait référence à l'ensemble des mots d'une langue, y compris leurs significations et leurs propriétés grammaticales. C'est la collection des termes et expressions utilisés dans une langue particulière."
      ],
      "metadata": {
        "id": "FtcqSSE7XUbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.andreaperlato.com/theorypost/introduction-to-word2vec/\n",
        "# https://colab.research.google.com/github/davidarps/2022_course_embeddings_and_transformers/blob/main/Visualizing_Attention_with_BertViz.ipynb attention\n",
        "# https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb bert\n",
        "# https://colab.research.google.com/github/BritneyMuller/colab-notebooks/blob/master/Easy_Text_Summarization_with_BART.ipynb#scrollTo=CdyRipC0o8vR: Text Summarisation avec BART\n",
        "# https://lesdieuxducode.com/blog/2019/4/bert--le-transformer-model-qui-sentraine-et-qui-represente tout sur BERT a voir obligatoirement\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding, Reshape, Activation, Input\n",
        "from keras.preprocessing import text\n",
        "from keras.preprocessing.sequence import skipgrams\n",
        "\n",
        "# Exemple de corpus\n",
        "corpus = [\"le petit chat noir\", \"le chien marron\", \"la souris grise\"]\n",
        "\n",
        "# Tokenisation et création des paires de contexte-cible\n",
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "skip_grams = [skipgrams(sequence, vocabulary_size=total_words, window_size=2) for sequence in sequences]\n",
        "data, labels = zip(*skip_grams)"
      ],
      "metadata": {
        "id": "z-T-859WPbeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUnV2tEVBJcI",
        "outputId": "3aa3279e-b3dc-4a13-b58d-2ffd7ba5b8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([[2, 4],\n",
              "   [4, 3],\n",
              "   [2, 3],\n",
              "   [1, 3],\n",
              "   [3, 4],\n",
              "   [1, 8],\n",
              "   [3, 8],\n",
              "   [3, 2],\n",
              "   [3, 1],\n",
              "   [1, 9],\n",
              "   [2, 2],\n",
              "   [2, 1],\n",
              "   [4, 2],\n",
              "   [1, 2],\n",
              "   [4, 8],\n",
              "   [2, 7],\n",
              "   [4, 9],\n",
              "   [3, 5],\n",
              "   [2, 3],\n",
              "   [3, 4]],\n",
              "  [1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1]),\n",
              " ([[5, 1],\n",
              "   [5, 3],\n",
              "   [5, 6],\n",
              "   [5, 1],\n",
              "   [6, 6],\n",
              "   [6, 5],\n",
              "   [6, 1],\n",
              "   [1, 5],\n",
              "   [1, 1],\n",
              "   [6, 8],\n",
              "   [1, 6],\n",
              "   [1, 6]],\n",
              "  [0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1]),\n",
              " ([[8, 6],\n",
              "   [8, 7],\n",
              "   [9, 8],\n",
              "   [7, 1],\n",
              "   [9, 5],\n",
              "   [7, 8],\n",
              "   [8, 9],\n",
              "   [8, 7],\n",
              "   [9, 7],\n",
              "   [9, 6],\n",
              "   [7, 9],\n",
              "   [7, 2]],\n",
              "  [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0])]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hralMPZoBu0G",
        "outputId": "eeeb5a2b-869d-407c-e1cc-96b0eba9a97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[2, 4],\n",
              "  [4, 3],\n",
              "  [2, 3],\n",
              "  [1, 3],\n",
              "  [3, 4],\n",
              "  [1, 8],\n",
              "  [3, 8],\n",
              "  [3, 2],\n",
              "  [3, 1],\n",
              "  [1, 9],\n",
              "  [2, 2],\n",
              "  [2, 1],\n",
              "  [4, 2],\n",
              "  [1, 2],\n",
              "  [4, 8],\n",
              "  [2, 7],\n",
              "  [4, 9],\n",
              "  [3, 5],\n",
              "  [2, 3],\n",
              "  [3, 4]],\n",
              " [[5, 1],\n",
              "  [5, 3],\n",
              "  [5, 6],\n",
              "  [5, 1],\n",
              "  [6, 6],\n",
              "  [6, 5],\n",
              "  [6, 1],\n",
              "  [1, 5],\n",
              "  [1, 1],\n",
              "  [6, 8],\n",
              "  [1, 6],\n",
              "  [1, 6]],\n",
              " [[8, 6],\n",
              "  [8, 7],\n",
              "  [9, 8],\n",
              "  [7, 1],\n",
              "  [9, 5],\n",
              "  [7, 8],\n",
              "  [8, 9],\n",
              "  [8, 7],\n",
              "  [9, 7],\n",
              "  [9, 6],\n",
              "  [7, 9],\n",
              "  [7, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D_gKHl8B4aK",
        "outputId": "961a862b-74b4-4018-f76a-c70f9072f629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = ([ [1,2], [3,4] ], [ [5,6], [7,8] ])\n",
        "c, d = zip(*a)"
      ],
      "metadata": {
        "id": "ZIJPc8HlB8SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTPU8i-zCT1d",
        "outputId": "b9675a5c-c178-4e63-b028-501271f380b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 2], [5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dKHArTBCVCP",
        "outputId": "909a66a1-4787-4789-d74f-a5bc12bc8320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([3, 4], [7, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "CBOW: predict target word in a given context words\n",
        "SKIP-GRAMS: predict context words, given target word\n",
        "see the implementation: https://radimrehurek.com/gensim/models/word2vec.html\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "c2Vsrv0IZzP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvTEv_jwPfhU",
        "outputId": "ef5b8f7e-2f5d-4f21-d17f-9c40ad52594d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4], [1, 5, 6], [7, 8, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.index_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--nQn81yTbpO",
        "outputId": "652b5682-1747-4490-feeb-445bc74e1bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'le',\n",
              " 2: 'petit',\n",
              " 3: 'chat',\n",
              " 4: 'noir',\n",
              " 5: 'chien',\n",
              " 6: 'marron',\n",
              " 7: 'la',\n",
              " 8: 'souris',\n",
              " 9: 'grise'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqkbPgFiPyAF",
        "outputId": "e3a5d8ef-be64-4cad-f895-5331c4a0fb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([[2, 1],\n",
              "   [4, 3],\n",
              "   [2, 3],\n",
              "   [3, 1],\n",
              "   [1, 1],\n",
              "   [4, 1],\n",
              "   [1, 2],\n",
              "   [3, 4],\n",
              "   [3, 2],\n",
              "   [4, 2],\n",
              "   [1, 3],\n",
              "   [2, 1],\n",
              "   [3, 7],\n",
              "   [3, 6],\n",
              "   [2, 4],\n",
              "   [4, 4],\n",
              "   [2, 7],\n",
              "   [2, 4],\n",
              "   [3, 7],\n",
              "   [1, 7]],\n",
              "  [0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
              " ([[6, 1],\n",
              "   [6, 2],\n",
              "   [5, 1],\n",
              "   [5, 6],\n",
              "   [1, 6],\n",
              "   [6, 5],\n",
              "   [5, 3],\n",
              "   [6, 6],\n",
              "   [1, 5],\n",
              "   [5, 1],\n",
              "   [1, 1],\n",
              "   [1, 3]],\n",
              "  [1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0]),\n",
              " ([[7, 8],\n",
              "   [8, 9],\n",
              "   [8, 5],\n",
              "   [7, 9],\n",
              "   [9, 8],\n",
              "   [9, 3],\n",
              "   [8, 9],\n",
              "   [7, 6],\n",
              "   [9, 7],\n",
              "   [8, 7],\n",
              "   [7, 6],\n",
              "   [9, 7]],\n",
              "  [1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1])]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exemple 0**"
      ],
      "metadata": {
        "id": "KZZLm5MQ1RzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cet exemple, pour chaque target, 1 contexte positif et 4 contextes négatifs sont utilisés. Les targets et contextes sont donnés en entrée. Un Embedding est utilisé pour le target et 1 Embedding pour les contextes. https://www.tensorflow.org/text/tutorials/word2vec"
      ],
      "metadata": {
        "id": "tx0n4UaC756O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le principe de cet exercice est de construire est de construire une matrice de **target**, **context** et **label**. <br>\n",
        "\n",
        "**target** correspond aux mots cibles. On les répresente en se basant sur les ids des tokens, ça va être un tableau de taille (N, 1) ou (N, ).<br>\n",
        "\n",
        "**context** correspond aux mots contexte, des targets. Pour cet exemple, chaque target aura 5 contextes, le premier c'est le contexte positif et les 4 suivants, les contextes négatifs. Donc un tableau de taille (N, 5).<br>\n",
        "\n",
        "**label** c'est un tableau de taille (N, 5) avec chaque vecteur sous la forme (1, 0, 0, 0, 0) avec 1 pour dire contexte positif et 0 pour dire contexte négatif.<br>\n",
        "\n",
        "Les contextes positifs sont construits avec **tf.keras.preprocessing.skipgrams** et les contextes négatifs par **tf.random.log_uniform_candidate_sampler**<br>\n",
        "\n",
        "\n",
        "Le modèle est entrainé en utilisant deux Embedding, car prenant deux entrées. Le premier Embedding pour le target et le deuxième pour context. tf.einsum est utilisé pour multiplié le codage du target sur le codage du context."
      ],
      "metadata": {
        "id": "y9JSTMGNVxm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construire contextes positif:\n",
        "\n",
        "# Get target and context words for one positive skip-gram.\n",
        "target_word, context_word = positive_skip_grams[0]\n",
        "\n",
        "# Set the number of negative samples per positive context.\n",
        "num_ns = 4\n",
        "\n",
        "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
        "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
        "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
        "    num_sampled=num_ns,  # number of negative context words to sample\n",
        "    unique=True,  # all the negative samples should be unique\n",
        "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
        "    seed=SEED,  # seed for reproducibility\n",
        "    name=\"negative_sampling\"  # name of this operation\n",
        ")\n",
        "\n",
        "# Construire pair positif:\n",
        "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "      example_sequence,\n",
        "      vocabulary_size=vocab_size,\n",
        "      window_size=window_size,\n",
        "      negative_samples=0 # 0 pour dire qu'on ne prend pas de pair négatif\n",
        "      )\n"
      ],
      "metadata": {
        "id": "NDuyphtwFZVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Création d'un tenseur avec une dimension de taille 1\n",
        "tensor_with_singleton_dim = tf.constant([[[1]], [[2]], [[3]]])\n",
        "\n",
        "# Utilisation de tf.squeeze pour supprimer la dimension de taille 1\n",
        "squeezed_tensor = tf.squeeze(tensor_with_singleton_dim, axis=(1,2)) # élimine l'axe 1 et 2\n",
        "\n",
        "# Affichage des formes avant et après l'opération\n",
        "print(\"Avant squeeze :\", tensor_with_singleton_dim.shape)\n",
        "print(\"Après squeeze :\", squeezed_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biO7sq3tF_bw",
        "outputId": "24d7a224-45c5-4331-97d4-f9e1627be18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avant squeeze : (3, 1, 1)\n",
            "Après squeeze : (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p, l = tf.keras.preprocessing.sequence.skipgrams(\n",
        "      [2,3,4,0,0,0],\n",
        "      vocabulary_size=5,\n",
        "      window_size=2,\n",
        "      negative_samples=0)\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8-JrCo2Go5a",
        "outputId": "d340d661-2431-4c4a-9888-2bf066a3ddc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 2], [4, 3], [2, 4], [2, 3], [3, 4], [4, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu0fzocvUFo0",
        "outputId": "11eb828d-30e5-447f-c9ee-bf15ad4a0afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azIO9K05KXMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/text/tutorials/word2vec\n",
        "import tensorflow as tf\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "with open(path_to_file) as f:\n",
        "  lines = f.read().splitlines()\n",
        "for line in lines[:20]:\n",
        "  print(line)\n",
        "\n",
        "\n",
        "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4TGScAo1T5B",
        "outputId": "05e311d0-c2bc-41be-d21d-a50921e95861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KuOd3p8-FYhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in text_ds.take(10):\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ3c7aqZ1hUb",
        "outputId": "5f3a1dc1-f675-491e-fce7-d5c309c16b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'First Citizen:', shape=(), dtype=string)\n",
            "tf.Tensor(b'Before we proceed any further, hear me speak.', shape=(), dtype=string)\n",
            "tf.Tensor(b'All:', shape=(), dtype=string)\n",
            "tf.Tensor(b'Speak, speak.', shape=(), dtype=string)\n",
            "tf.Tensor(b'First Citizen:', shape=(), dtype=string)\n",
            "tf.Tensor(b'You are all resolved rather to die than to famish?', shape=(), dtype=string)\n",
            "tf.Tensor(b'All:', shape=(), dtype=string)\n",
            "tf.Tensor(b'Resolved. resolved.', shape=(), dtype=string)\n",
            "tf.Tensor(b'First Citizen:', shape=(), dtype=string)\n",
            "tf.Tensor(b'First, you know Caius Marcius is chief enemy to the people.', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, create a custom standardization function to lowercase the text and\n",
        "# remove punctuation.\n",
        "import re\n",
        "import string\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  return tf.strings.regex_replace(lowercase,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "\n",
        "# Define the vocabulary size and the number of words in a sequence.\n",
        "vocab_size = 4096\n",
        "sequence_length = 10\n",
        "\n",
        "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
        "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
        "# same length.\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n"
      ],
      "metadata": {
        "id": "YMdj_5br18kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(text_ds.batch(1024))"
      ],
      "metadata": {
        "id": "4y2m_69t2Byq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the created vocabulary for reference.\n",
        "inverse_vocab = vectorize_layer.get_vocabulary()\n",
        "print(inverse_vocab[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z3P0YA-2Odp",
        "outputId": "0530f1ac-5f8c-4581-aa8d-fd31c2ca8207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data in text_ds.\n",
        "text_vector_ds = text_ds.batch(1024).prefetch(tf.data.AUTOTUNE).map(vectorize_layer).unbatch()"
      ],
      "metadata": {
        "id": "wyoLKqVi2Xmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list(text_vector_ds.as_numpy_iterator())\n",
        "print(len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDi2GbZp2f2r",
        "outputId": "e23f9b1c-4533-4a7b-8acc-6f06f9d23f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
        "# (int-encoded sentences) based on window size, number of negative samples\n",
        "# and vocabulary size.\n",
        "import tqdm\n",
        "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
        "  # Elements of each training example are appended to these lists.\n",
        "  targets, contexts, labels = [], [], []\n",
        "\n",
        "  # Build the sampling table for `vocab_size` tokens.\n",
        "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "\n",
        "  # Iterate over all sequences (sentences) in the dataset.\n",
        "  for sequence in tqdm.tqdm(sequences):\n",
        "\n",
        "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
        "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "          sequence,\n",
        "          vocabulary_size=vocab_size,\n",
        "          sampling_table=sampling_table,\n",
        "          window_size=window_size,\n",
        "          negative_samples=0)\n",
        "\n",
        "    # Iterate over each positive skip-gram pair to produce training examples\n",
        "    # with a positive context word and negative samples.\n",
        "    for target_word, context_word in positive_skip_grams:\n",
        "      context_class = tf.expand_dims(\n",
        "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "          true_classes=context_class,\n",
        "          num_true=1,\n",
        "          num_sampled=num_ns,\n",
        "          unique=True,\n",
        "          range_max=vocab_size,\n",
        "          seed=seed,\n",
        "          name=\"negative_sampling\")\n",
        "\n",
        "      # Build context and label vectors (for one target word)\n",
        "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
        "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "\n",
        "      # Append each element from the training example to global lists.\n",
        "      targets.append(target_word)\n",
        "      contexts.append(context)\n",
        "      labels.append(label)\n",
        "\n",
        "  return targets, contexts, labels"
      ],
      "metadata": {
        "id": "qaBx5W6O26Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets, contexts, labels = generate_training_data(\n",
        "    sequences=sequences,\n",
        "    window_size=2,\n",
        "    num_ns=4,\n",
        "    vocab_size=vocab_size,\n",
        "    seed=242)\n",
        "\n",
        "targets = np.array(targets)\n",
        "contexts = np.array(contexts)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"targets.shape: {targets.shape}\")\n",
        "print(f\"contexts.shape: {contexts.shape}\")\n",
        "print(f\"labels.shape: {labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR5-4jaC2whE",
        "outputId": "f4a74208-f693-46cb-ac84-88abd4993843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32777/32777 [00:43<00:00, 761.86it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "targets.shape: (64702,)\n",
            "contexts.shape: (64702, 5)\n",
            "labels.shape: (64702, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf6Jbj-Q3DMu",
        "outputId": "9fbf8359-978a-4e98-9118-ea6b0b65d74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([125, 125, 125, ...,  82,  82,  82])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ycjld_S3Puv",
        "outputId": "3c1b689e-114b-487b-c612-9bfc3063d61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64702,)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl1eWoWG3RCF",
        "outputId": "1ffb39fd-8038-487d-cc9d-5285237b7b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 673,   69,    5,   57, 2119],\n",
              "       [ 144, 1170,   95,    1,   34],\n",
              "       [  16, 1057,  581,  108,    8],\n",
              "       ...,\n",
              "       [   3,  252,   13,  491,  536],\n",
              "       [  28,   40,    4,   61,  753],\n",
              "       [ 674,  133,  244, 3461,   60]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeeARcsF3RGA",
        "outputId": "5a409457-22a2-40dc-8a2d-68a5583889d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64702, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Le premier mot dans contexts est le mot qui se trouve sur le target et les 4 mots qui reste ne sont pas dans le contexte donc faux d'où 0.\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6arJ-yY5duj",
        "outputId": "b5a76eb6-a262-441c-d562-212f0ccdc7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuPPGrQ73bTG",
        "outputId": "73d537f3-921e-4100-b5cd-6a7f7924f135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([64702,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weFHjgAf3dQN",
        "outputId": "e17012fe-5ac6-4f11-b390-4267420a408a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64702, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfog0Wbb36YC",
        "outputId": "fd76d4aa-a936-43da-8170-bcf48b111fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa5YKCF74CNW",
        "outputId": "aaa353d0-eeb7-4df0-d71d-993e9db7914a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of negative samples per positive context.\n",
        "num_ns = 4\n",
        "\n",
        "class Word2Vec(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Word2Vec, self).__init__()\n",
        "    self.target_embedding = tf.keras.layers.Embedding(vocab_size,\n",
        "                                      embedding_dim,\n",
        "                                      input_length=1,\n",
        "                                      name=\"w2v_embedding\")\n",
        "    self.context_embedding = tf.keras.layers.Embedding(vocab_size,\n",
        "                                       embedding_dim,\n",
        "                                       input_length=num_ns+1)\n",
        "\n",
        "  def call(self, pair):\n",
        "    target, context = pair\n",
        "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
        "    # context: (batch, context)\n",
        "    if len(target.shape) == 2:\n",
        "      target = tf.squeeze(target, axis=1)\n",
        "    # target: (batch,)\n",
        "    word_emb = self.target_embedding(target)\n",
        "    # word_emb: (batch, embed)\n",
        "    context_emb = self.context_embedding(context)\n",
        "    # context_emb: (batch, context, embed)\n",
        "    dots = tf.einsum('be,bce->bc', word_emb, context_emb) # b: batch, c: sequence = 5, e: embedding_dim\n",
        "    # dots: (batch, context)\n",
        "    return dots"
      ],
      "metadata": {
        "id": "-FySRXls5Gib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_embedding = tf.keras.layers.Embedding(5,\n",
        "                                  5,\n",
        "                                  input_length=1,\n",
        "                                  name=\"w2v_embedding\")"
      ],
      "metadata": {
        "id": "I_bjjWRm8iWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_embedding(np.array([2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8cRIKZR8pVn",
        "outputId": "2d7f5b4c-f520-402b-83c3-4d21fb6eb338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
              "array([[ 0.01872643,  0.04774718, -0.03377201, -0.0115474 , -0.02404326]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
        "word2vec.compile(optimizer='adam',\n",
        "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                 metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "VwoS98Ty6M41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n"
      ],
      "metadata": {
        "id": "022ovM4E6PxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])\n"
      ],
      "metadata": {
        "id": "lrWr89yB6Tfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "vg4N5DSr67Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "LH5uiCaV7AOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 3\n",
        "vec = weights[index]"
      ],
      "metadata": {
        "id": "DhLWNHR57Wf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example 1: TimeDistributed et einsum**"
      ],
      "metadata": {
        "id": "b5fBuwtrnLDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TimeDistributed enveloppe une couche Dense dans cet exemple pour traiter l'entrée (la séquence) de manière indépendante, c'est à dire chaque timestamp est considéré comme un vecteur d'entrée. Si on ne l'utilise pas, la couche Dense considère toute la séquence comme un vecteur simple donc supprime l'ordre."
      ],
      "metadata": {
        "id": "6ZwUMRKQJopt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, RepeatVector, TimeDistributed\n",
        "\n",
        "# Création du modèle séquentiel\n",
        "model = Sequential()\n",
        "\n",
        "# Ajout d'une couche Dense pour traiter le vecteur d'entrée de dimension 1\n",
        "model.add(Dense(8, input_dim=1, activation='relu'))\n",
        "\n",
        "# Ajout d'une couche RepeatVector pour répéter le vecteur de sortie\n",
        "model.add(RepeatVector(2))\n",
        "\n",
        "# Ajout d'une couche TimeDistributed pour appliquer la couche Dense à chaque pas de temps de la séquence au lieu de considérer la séquence comme un vecteur\n",
        "model.add(TimeDistributed(Dense(4, activation='softmax')))\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Affichage de la structure du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESx8LOAlr71r",
        "outputId": "7c03ad9f-71e8-4dbf-ba9a-6eb9a0f96cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 16        \n",
            "                                                                 \n",
            " repeat_vector (RepeatVecto  (None, 2, 8)              0         \n",
            " r)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 2, 4)              36        \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52 (208.00 Byte)\n",
            "Trainable params: 52 (208.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, RepeatVector, TimeDistributed\n",
        "\n",
        "# Création du modèle séquentiel\n",
        "model = Sequential()\n",
        "\n",
        "# Ajout d'une couche Dense pour traiter le vecteur d'entrée de dimension 1\n",
        "model.add(Dense(8, input_dim=1, activation='relu'))\n",
        "\n",
        "# Ajout d'une couche RepeatVector pour répéter le vecteur de sortie\n",
        "model.add(RepeatVector(2))\n",
        "\n",
        "# Ajout d'une couche TimeDistributed pour appliquer la couche Dense à chaque pas de temps de la séquence\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Affichage de la structure du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtgIzZxJw4E4",
        "outputId": "71fa4506-8edf-4f0d-fc5a-f3f695c754d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 8)                 16        \n",
            "                                                                 \n",
            " repeat_vector_1 (RepeatVec  (None, 2, 8)              0         \n",
            " tor)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2, 4)              36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52 (208.00 Byte)\n",
            "Trainable params: 52 (208.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Tenseurs d'exemple\n",
        "a = tf.constant([[1, 2], [3, 4]])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L7Mh8eq_v58",
        "outputId": "3272d062-4a01-428b-c59a-c55f164bbbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[1, 2],\n",
              "       [3, 4]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = tf.constant([[[5, 6], [7, 8], [9, 10]], [[11, 12], [13, 14], [15, 16]]])\n",
        "b"
      ],
      "metadata": {
        "id": "sRqo9ttY_zrS",
        "outputId": "456b87ce-ab75-4e4b-b909-9c0e8d7ecc83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
              "array([[[ 5,  6],\n",
              "        [ 7,  8],\n",
              "        [ 9, 10]],\n",
              "\n",
              "       [[11, 12],\n",
              "        [13, 14],\n",
              "        [15, 16]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Opération einsum\n",
        "result = tf.einsum('be,bce->bc', a, b)\n",
        "\n",
        "# Affichage du résultat\n",
        "print(result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YJT2e1q_tZG",
        "outputId": "35ed6bbb-d647-4a4c-97a9-3a856e304e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 17  23  29]\n",
            " [ 81  95 109]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QVlyvyH_Z6Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WkokC8HXZ6X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  return tf.strings.regex_replace(lowercase,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "\n",
        "# Define the vocabulary size and the number of words in a sequence.\n",
        "vocab_size = 4096\n",
        "sequence_length = 10\n",
        "\n",
        "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
        "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
        "# same length.\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int')\n"
      ],
      "metadata": {
        "id": "ZOlUQ7axZ6aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"I am very pround\", \"you are here\"]\n",
        "\n",
        "vectorize_layer.adapt(data)"
      ],
      "metadata": {
        "id": "mmJ1zUeEaCxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9JGlwl-aSF2",
        "outputId": "8e8ea697-d1af-4db5-e828-51ca31092b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'you', 'very', 'pround', 'i', 'here', 'are', 'am']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL1sjwcKaZtZ",
        "outputId": "0acb94c8-4ccd-47bc-87e5-bfa02303d301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=int64, numpy=\n",
              "array([[5, 8, 3, 4],\n",
              "       [2, 7, 6, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention**"
      ],
      "metadata": {
        "id": "MK44Ilq7Xico"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dot product Attention**"
      ],
      "metadata": {
        "id": "2ycATS9U0u8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour deux vecteurs $h_i$ et $h_j$, le produit scalaire donne le poids d'attention. on considère que $h$ est un vecteur colonne :<br><br>\n",
        "$score  = h_i^T.h_j$<br><br>\n",
        "$AttentionDot(h_i, h_j) = \\frac{\\exp(score(h_i, h_j))}{\\sum_k \\exp(score(h_i, h_k))}$"
      ],
      "metadata": {
        "id": "b85t8Wkt0zXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class DotProductAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(DotProductAttention, self).__init__()\n",
        "\n",
        "    def call(self, query, keys, values):\n",
        "        \"\"\"\n",
        "          Trois réseaux doivent être utilisés chacun de units = dim, qui produisent query, keys et values\n",
        "          query: (batch, Tq, dim)\n",
        "          keys: (batch, Tk, dim)\n",
        "          values: (batch, Tv, dim)\n",
        "        \"\"\"\n",
        "        # Calcul du produit scalaire entre la requête et les clés\n",
        "        scores = tf.matmul(query, keys, transpose_b=True) # (batch, Tq, Tk)\n",
        "\n",
        "        # Calcul des poids d'attention avec la fonction softmax\n",
        "        attention_weights = tf.nn.softmax(scores, axis=-1) # (batch, Tq, Tk)\n",
        "\n",
        "        # Calcul de la somme pondérée des valeurs\n",
        "        context_vector = tf.matmul(attention_weights, values) # (batch, Tq, dim)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "# Exemple d'utilisation\n",
        "attention_layer = DotProductAttention()\n",
        "\n",
        "# Création d'une requête, de clés et de valeurs fictives\n",
        "query = tf.random.normal([1, 32])\n",
        "keys = tf.random.normal([1, 10, 32])\n",
        "values = tf.random.normal([1, 10, 64])\n",
        "\n",
        "# Calcul de l'attention\n",
        "context_vector, attention_weights = attention_layer(query, keys, values)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Values:\", values)\n",
        "print(\"Attention Weights:\", attention_weights)\n",
        "print(\"Context Vector:\", context_vector)\n"
      ],
      "metadata": {
        "id": "9MeV2RCQGx0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Luong Attention**"
      ],
      "metadata": {
        "id": "pFFcDU4U2mya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour deux vecteurs $h_i$ et $h_j$, le produit scalaire donne le poids d'attention :<br><br>\n",
        "$score  = h_i.W_a.h_j$<br><br>\n",
        "$W_a$ matrices de poids (plusieurs neurones = units=n)<br><br>\n",
        "$AttentionLuong(h_i, h_j) = \\frac{\\exp(score(h_i, h_j))}{\\sum_k \\exp(score(h_i, h_k))}$"
      ],
      "metadata": {
        "id": "VA_wonyM2sQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.W = tf.keras.layers.Dense(units)\n",
        "\n",
        "    def call(self, query, keys):\n",
        "        \"\"\"\n",
        "        query: (batch, dim) souvent le hidden state du decoder (dim=units)\n",
        "        keys: (batch, Tk, dim)\n",
        "        \"\"\"\n",
        "        # Ajout d'une nouvelle dimension à la requête pour permettre la concaténation\n",
        "        query_with_time_axis = tf.expand_dims(query, 1) # (batch, 1, dim)\n",
        "\n",
        "        # Calcul des scores d'attention\n",
        "        score = tf.matmul(query_with_time_axis, self.W(keys), transpose_b=True) # (batch, 1, Tk)\n",
        "\n",
        "        # Calcul des poids d'attention avec la fonction softmax\n",
        "        attention_weights = tf.nn.softmax(score, axis=2) # (batch, 1, Tk)\n",
        "\n",
        "        # Calcul de la somme pondérée des valeurs\n",
        "        context_vector = tf.matmul(attention_weights, keys) # (batch, 1, dim)\n",
        "\n",
        "        return tf.squeeze(context_vector, axis=1), attention_weights # (batch, dim), (batch, 1, Tk)\n",
        "\n",
        "# Exemple d'utilisation\n",
        "units = 32\n",
        "attention_layer = LuongAttention(units)\n",
        "\n",
        "# Création d'une requête et de clés fictives\n",
        "query = tf.random.normal([1, units])\n",
        "keys = tf.random.normal([1, 10, units])\n",
        "\n",
        "# Calcul de l'attention\n",
        "context_vector, attention_weights = attention_layer(query, keys)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Attention Weights:\", attention_weights)\n",
        "print(\"Context Vector:\", context_vector)\n"
      ],
      "metadata": {
        "id": "CMbcTZUfHk77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bahdanau Attention (Additive)**"
      ],
      "metadata": {
        "id": "FAabTCHr29XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour deux vecteurs $h_i$ et $h_j$, le produit scalaire donne le poids d'attention :<br><br>\n",
        "$score  = v_a^T.tanh(W_{a1}.h_i + W_{a2}.h_j)$<br><br>\n",
        "$W_{a1}, W_{a2}$ matrices de poids (plusieurs neurones, units=n) <br><br>\n",
        "$v_a$ vecteur de poids (1 neurone = units=1)<br><br>\n",
        "$AttentionBahdanau(h_i, h_j) = \\frac{\\exp(score(h_i, h_j))}{\\sum_k \\exp(score(h_i, h_k))}$"
      ],
      "metadata": {
        "id": "m4n9VlT83FM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        \"\"\"\n",
        "        query: (batch, dim) souvent le hidden state du decoder\n",
        "        values: (batch, Tv, dim)\n",
        "        \"\"\"\n",
        "        # Ajout d'une nouvelle dimension à la requête pour permettre la concaténation\n",
        "        query_with_time_axis = tf.expand_dims(query, 1) # (batch, 1, dim)\n",
        "\n",
        "        # Calcul des scores d'attention\n",
        "        score = tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)) # (batch, Tv, dim)\n",
        "\n",
        "        # Calcul des poids d'attention\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1) # (batch, Tv, 1)\n",
        "\n",
        "        # Calcul de la somme pondérée des valeurs\n",
        "        context_vector = attention_weights * values # (batch, Tv, dim)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1) # (batch, dim)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "# Exemple d'utilisation\n",
        "units = 32\n",
        "attention_layer = BahdanauAttention(units)\n",
        "\n",
        "# Création d'une requête et de valeurs fictives\n",
        "query = tf.random.normal([1, units])\n",
        "values = tf.random.normal([1, 10, units])\n",
        "\n",
        "# Calcul de l'attention\n",
        "context_vector, attention_weights = attention_layer(query, values)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Values:\", values)\n",
        "print(\"Attention Weights:\", attention_weights)\n",
        "print(\"Context Vector:\", context_vector)\n"
      ],
      "metadata": {
        "id": "oohF0rNkHrNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$Attention(Q,K,V)=softmax(Q⋅W_q+K⋅W_k)⋅V$"
      ],
      "metadata": {
        "id": "ScLzFk0iF1J8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapes algorithmes: <br>\n",
        "1. Expands query si nécessaire<br>\n",
        "2. Calculer scores<br>\n",
        "3. caculer attention<br>\n",
        "4. Faire matmul (dot et Luong) ou * (Bahdanau) de attention avec values.<br>\n",
        "5. Retourner sortie pour dot (sequence), retourner squeeze(sortie, axis=1) pour Luong (vecteur) et reduce_sum(sortie, axis=1) (vecteur).<br>"
      ],
      "metadata": {
        "id": "7vt8Q3FEUMvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Translation Transformer**"
      ],
      "metadata": {
        "id": "TAJg1y38KGku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprendre toutes les lignes du code: <br>\n",
        "https://keras.io/examples/nlp/neural_machine_translation_with_transformer/"
      ],
      "metadata": {
        "id": "81sYM4cCKLa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install keras 3.0.1 and restart runtime\n",
        "! pip install keras --upgrade"
      ],
      "metadata": {
        "id": "l2GgbYlfpGGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We set the backend to TensorFlow. The code works with\n",
        "# both `tensorflow` and `torch`. It does not work with JAX\n",
        "# due to the behavior of `jax.numpy.tile` in a jit scope\n",
        "# (used in `TransformerDecoder.get_causal_attention_mask()`:\n",
        "# `tile` in JAX does not support a dynamic `reps` argument.\n",
        "# You can make the code work in JAX by wrapping the\n",
        "# inside of the `get_causal_attention_mask` method in\n",
        "# a decorator to prevent jit compilation:\n",
        "# `with jax.ensure_compile_time_eval():`.\n",
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "iHPFByEBpkBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.backend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A7tJpAYOpnas",
        "outputId": "45b7f170-bd49-46c5-f654-dd37c67696d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tensorflow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GBlxebi7e3a4",
        "outputId": "7c76373b-b1c3-4866-fa3f-9ef29aff2d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.0.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\"\n",
        "text_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqgiAMUbyCkm",
        "outputId": "80d87b6e-08dd-4e82-ceb9-fe1c72327ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets/spa-eng/spa.txt')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pairs (english_text, spanish_text)\n",
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))\n",
        "text_pairs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn5vJzqoyTeV",
        "outputId": "79e8d7f0-0946-4c3c-afc9-b7baf504def1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Go.', '[start] Ve. [end]'),\n",
              " ('Go.', '[start] Vete. [end]'),\n",
              " ('Go.', '[start] Vaya. [end]'),\n",
              " ('Go.', '[start] Váyase. [end]'),\n",
              " ('Hi.', '[start] Hola. [end]'),\n",
              " ('Run!', '[start] ¡Corre! [end]'),\n",
              " ('Run.', '[start] Corred. [end]'),\n",
              " ('Who?', '[start] ¿Quién? [end]'),\n",
              " ('Fire!', '[start] ¡Fuego! [end]'),\n",
              " ('Fire!', '[start] ¡Incendio! [end]')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into train test val\n",
        "random.shuffle(text_pairs) # shuffle the list\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6DtFDVIziJy",
        "outputId": "02f44bf4-0712-4023-9435-4643830718d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the tokenizer\n",
        "strip_chars = string.punctuation + \"¿\" # string.punctuation is string\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    # input_string: list of string\n",
        "    lowercase = tf_strings.lower(input_string) # convert text to lower and return tf.tensor of dtype=string: <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'mypocket', b'bool'], dtype=object)>\n",
        "    return tf_strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\") # replace characters in strip_chars by \"\"\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1, # + 1: to include [start] for decoder input and [end] for decoder output\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "# Adapt tokenizers to the dataset\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)\n"
      ],
      "metadata": {
        "id": "PhGjJlnLz0cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_vectorization([\"I see the ocean\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK1L9B1w1Wql",
        "outputId": "82a7da53-c8bc-42f4-9962-faec906f9ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 20), dtype=int64, numpy=\n",
              "array([[   3,   75,    2, 1740,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng) # eng : batch of english texts\n",
        "    spa = spa_vectorization(spa) # spa : batch of spanish texts\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": eng,\n",
        "            \"decoder_inputs\": spa[:, :-1], # remove token [end] for the decoder input\n",
        "        },\n",
        "        spa[:, 1:], # remove token [start] for decoder output\n",
        "    )\n",
        "\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs) # [(en, spa), (en, spa), ..., (en, spa)] -> [(en, en, ..., en), (spa, spa, ..., spa)]\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "pRuhrJO23r8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds.take(1): # take the first batch\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcjZTLw2e_0A",
        "outputId": "7a2ac545-b25b-4163-b726-d327e5a0c557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.ops as ops\n",
        "import tensorflow as tf\n",
        "# Create Encoder layer\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\") # (batch, sequence) -> (batch, 1, sequence) or (batch, sequence, 1) -> None=tf.newaxis\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "metadata": {
        "id": "0HPWptUKiJG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1] # number of tokens of each sequence\n",
        "        positions = ops.arange(0, length, 1) # (0, 1, 2, ..., length)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if mask is None:\n",
        "            return None\n",
        "        else:\n",
        "            return ops.not_equal(inputs, 0) # tf.not_equal\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "metadata": {
        "id": "Jbs_Fbg8iLir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "            padding_mask = ops.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = ops.shape(inputs) # (batch, sequence)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = ops.arange(sequence_length)[:, None] # (sequence, 1)\n",
        "        j = ops.arange(sequence_length) # (sequence)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\") # (sequence, sequence)\n",
        "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1])) # (1, sequence, sequence)\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        ) # (batch, 1,1)\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "metadata": {
        "id": "IBXrOuP8mRRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "metadata": {
        "id": "_ECC8ATTpCGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "iE_g3mRgrQf1",
        "outputId": "0b44750f-3c28-4801-8cf7-56d72a889106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ positional_embedding_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │  \u001b[38;5;34m3,845,120\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ transformer_encoder_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embedding_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ functional_11             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15000\u001b[0m)    │ \u001b[38;5;34m12,959,640\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mFunctional\u001b[0m)              │                        │            │ transformer_encoder_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ positional_embedding_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,845,120</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ transformer_encoder_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ functional_11             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">12,959,640</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │                        │            │ transformer_encoder_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,920,434\u001b[0m (152.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,920,434</span> (152.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,960,216\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,216</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m19,960,218\u001b[0m (76.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,960,218</span> (76.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spa_vectorization.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOMDjkror4Nx",
        "outputId": "d4fb208a-bdf9-49b1-d03c-24056351f334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[start]', '[end]', 'de', 'que', 'a', 'no', 'tom', 'la']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict(zip(range(len(spa_vectorization.get_vocabulary()[:10])), spa_vectorization.get_vocabulary()[:10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tyIdd_ZsHkP",
        "outputId": "d9a13378-1b1b-4962-9b89-d79546b8a607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '',\n",
              " 1: '[UNK]',\n",
              " 2: '[start]',\n",
              " 3: '[end]',\n",
              " 4: 'de',\n",
              " 5: 'que',\n",
              " 6: 'a',\n",
              " 7: 'no',\n",
              " 8: 'tom',\n",
              " 9: 'la'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence]) # input_sentence : text\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1] # remove [end]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :]) # get the prediction of sequence i tf.argmax(predictions[0, i, :]).numpy()\n",
        "        ).item(0)\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence\n",
        "\n",
        "\n",
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)"
      ],
      "metadata": {
        "id": "F_MUpitLrsWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.argmax([1,2,3]).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNZw2iryt7Vv",
        "outputId": "b80cfc0a-02fa-4555-9a3d-38e4dd328ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Captionning**"
      ],
      "metadata": {
        "id": "aLIl-GvOKX4t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprendre toutes les lignes du code:<br>\n",
        "https://keras.io/examples/vision/image_captioning/"
      ],
      "metadata": {
        "id": "weY5V7ccKbNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install keras --upgrade"
      ],
      "metadata": {
        "id": "_GcxZTxhIwYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.applications import efficientnet\n",
        "from keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "S_7D6pndI-x9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
        "!wget -q https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
        "!unzip -qq Flickr8k_Dataset.zip\n",
        "!unzip -qq Flickr8k_text.zip\n",
        "!rm Flickr8k_Dataset.zip Flickr8k_text.zip"
      ],
      "metadata": {
        "id": "JYK2Z8H9JZ0z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Images\n",
        "os.listdir(\"/content/Flicker8k_Dataset\")[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X06BcSrGLNQ1",
        "outputId": "8433a7a0-3d0a-4389-cb78-b87d9b9e3940"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1093716555_801aacef79.jpg',\n",
              " '3435233065_3411f2d29d.jpg',\n",
              " '3084011664_76d37c6559.jpg',\n",
              " '3041384194_04316bd416.jpg',\n",
              " '543363241_74d8246fab.jpg',\n",
              " '2363540508_9dd1ccf7c7.jpg',\n",
              " '2095007523_591f255708.jpg',\n",
              " '3250589803_3f440ba781.jpg',\n",
              " '3474406285_01f3d24b71.jpg',\n",
              " '2272548482_0b4aec5cdd.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Captions\n",
        "with open(\"Flickr8k.token.txt\", \"r\") as f:\n",
        "    captions = f.readlines()\n",
        "\n",
        "# Image can have many captions.\n",
        "captions[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0zbS838M0s8",
        "outputId": "f9ad91ed-c533-49ff-e0a4-3320a301d55e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1000268201_693b08cb0e.jpg#0\\tA child in a pink dress is climbing up a set of stairs in an entry way .\\n',\n",
              " '1000268201_693b08cb0e.jpg#1\\tA girl going into a wooden building .\\n',\n",
              " '1000268201_693b08cb0e.jpg#2\\tA little girl climbing into a wooden playhouse .\\n',\n",
              " '1000268201_693b08cb0e.jpg#3\\tA little girl climbing the stairs to her playhouse .\\n',\n",
              " '1000268201_693b08cb0e.jpg#4\\tA little girl in a pink dress going into a wooden cabin .\\n',\n",
              " '1001773457_577c3a7d70.jpg#0\\tA black dog and a spotted dog are fighting\\n',\n",
              " '1001773457_577c3a7d70.jpg#1\\tA black dog and a tri-colored dog playing with each other on the road .\\n',\n",
              " '1001773457_577c3a7d70.jpg#2\\tA black dog and a white dog with brown spots are staring at each other in the street .\\n',\n",
              " '1001773457_577c3a7d70.jpg#3\\tTwo dogs of different breeds looking at each other on the road .\\n',\n",
              " '1001773457_577c3a7d70.jpg#4\\tTwo dogs on pavement moving toward each other .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the images\n",
        "IMAGES_PATH = \"Flicker8k_Dataset\"\n",
        "\n",
        "# Desired image dimensions\n",
        "IMAGE_SIZE = (299, 299)\n",
        "\n",
        "# Vocabulary size\n",
        "VOCAB_SIZE = 10000\n",
        "\n",
        "# Fixed length allowed for any sequence\n",
        "SEQ_LENGTH = 25\n",
        "\n",
        "# Dimension for the image embeddings and token embeddings\n",
        "EMBED_DIM = 512\n",
        "\n",
        "# Per-layer units in the feed-forward network\n",
        "FF_DIM = 512\n",
        "\n",
        "# Other training parameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n"
      ],
      "metadata": {
        "id": "WNlFF6MuML64"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_captions_data(filename):\n",
        "    \"\"\"Loads captions (text) data and maps them to corresponding images.\n",
        "\n",
        "    Args:\n",
        "        filename: Path to the text file containing caption data.\n",
        "\n",
        "    Returns:\n",
        "        caption_mapping: Dictionary mapping image names and the corresponding captions\n",
        "        text_data: List containing all the available captions.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(filename) as caption_file:\n",
        "        caption_data = caption_file.readlines()\n",
        "        caption_mapping = {}\n",
        "        text_data = []\n",
        "        images_to_skip = set()\n",
        "\n",
        "        for line in caption_data:\n",
        "            line = line.rstrip(\"\\n\") # delete \\n\n",
        "            # Image name and captions are separated using a tab\n",
        "            img_name, caption = line.split(\"\\t\")\n",
        "\n",
        "            # Each image is repeated five times for the five different captions.\n",
        "            # Each image name has a suffix `#(caption_number)`\n",
        "            img_name = img_name.split(\"#\")[0]\n",
        "            img_name = os.path.join(IMAGES_PATH, img_name.strip())\n",
        "\n",
        "            # We will remove caption that are either too short to too long\n",
        "            tokens = caption.strip().split()\n",
        "\n",
        "            if len(tokens) < 5 or len(tokens) > SEQ_LENGTH:\n",
        "                images_to_skip.add(img_name)\n",
        "                continue\n",
        "\n",
        "            if img_name.endswith(\"jpg\") and img_name not in images_to_skip:\n",
        "                # We will add a start and an end token to each caption\n",
        "                caption = \"<start> \" + caption.strip() + \" <end>\"\n",
        "                text_data.append(caption)\n",
        "\n",
        "                if img_name in caption_mapping:\n",
        "                    caption_mapping[img_name].append(caption)\n",
        "                else:\n",
        "                    caption_mapping[img_name] = [caption]\n",
        "\n",
        "        for img_name in images_to_skip:\n",
        "            if img_name in caption_mapping:\n",
        "                del caption_mapping[img_name]\n",
        "\n",
        "        return caption_mapping, text_data\n",
        "\n",
        "\n",
        "def train_val_split(caption_data, train_size=0.8, shuffle=True):\n",
        "    \"\"\"Split the captioning dataset into train and validation sets.\n",
        "\n",
        "    Args:\n",
        "        caption_data (dict): Dictionary containing the mapped caption data\n",
        "        train_size (float): Fraction of all the full dataset to use as training data\n",
        "        shuffle (bool): Whether to shuffle the dataset before splitting\n",
        "\n",
        "    Returns:\n",
        "        Traning and validation datasets as two separated dicts\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Get the list of all image names\n",
        "    all_images = list(caption_data.keys())\n",
        "\n",
        "    # 2. Shuffle if necessary\n",
        "    if shuffle:\n",
        "        np.random.shuffle(all_images)\n",
        "\n",
        "    # 3. Split into training and validation sets\n",
        "    train_size = int(len(caption_data) * train_size)\n",
        "\n",
        "    training_data = {\n",
        "        img_name: caption_data[img_name] for img_name in all_images[:train_size]\n",
        "    }\n",
        "    validation_data = {\n",
        "        img_name: caption_data[img_name] for img_name in all_images[train_size:]\n",
        "    }\n",
        "\n",
        "    # 4. Return the splits\n",
        "    return training_data, validation_data\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "captions_mapping, text_data = load_captions_data(\"Flickr8k.token.txt\")\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_data, valid_data = train_val_split(captions_mapping)\n",
        "print(\"Number of training samples: \", len(train_data))\n",
        "print(\"Number of validation samples: \", len(valid_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FNZf7E1POBQ",
        "outputId": "acf7813e-cb2d-4daa-c44d-cc834c0d9cd3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  6114\n",
            "Number of validation samples:  1529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp8J_b4DSLOx",
        "outputId": "e7fdc198-d4a4-4a93-86c4-09595b62881b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Flicker8k_Dataset/1304100320_c8990a1539.jpg': ['<start> The two dogs are running through a field of flowers . <end>',\n",
              "  '<start> Two dogs are running through a field of pink flowers . <end>',\n",
              "  '<start> Two dogs bound over a flower-covered hill . <end>',\n",
              "  '<start> Two dogs playing in a misty field filled with purple flowers <end>',\n",
              "  '<start> Two gray dogs run through a field of pink heather . <end>'],\n",
              " 'Flicker8k_Dataset/2276120079_4f235470bc.jpg': ['<start> A boy runs as others play on a home-made slip and slide . <end>',\n",
              "  '<start> Children in swimming clothes in a field . <end>',\n",
              "  '<start> Little kids are playing outside with a water hose and are sliding down a water slide . <end>',\n",
              "  '<start> Several children are playing outside with a wet tarp on the ground . <end>',\n",
              "  '<start> Several children playing on a homemade water slide . <end>'],\n",
              " 'Flicker8k_Dataset/2410562803_56ec09f41c.jpg': ['<start> A girl using a laptop , another girl , and a boy looking at his cellphone . <end>',\n",
              "  '<start> A group of people sit against a building and use electronics . <end>',\n",
              "  '<start> Three people sit near a street . <end>',\n",
              "  '<start> Three people sitting in front of a store on a bench . <end>',\n",
              "  '<start> Three young people sit outside and engage with electronic devices . <end>'],\n",
              " 'Flicker8k_Dataset/2561295656_4f21fba209.jpg': ['<start> A female swimmer comes up for air . <end>',\n",
              "  '<start> A girl in water , with goggles and swimming cap . <end>',\n",
              "  '<start> A person with swim cap and goggles taking a breath . <end>',\n",
              "  '<start> A swimmer wearing goggles and white cap is in the pool . <end>',\n",
              "  '<start> Swimmer wearing goggles , in water . <end>'],\n",
              " 'Flicker8k_Dataset/2915538325_59e11276dd.jpg': ['<start> A crowd of people in orange vests looks on as a fireball rises into the sky at an airport . <end>',\n",
              "  '<start> A group of people watching a large explosion . <end>',\n",
              "  '<start> A group of people wearing orange vests watch a large fire near a helicopter . <end>',\n",
              "  '<start> People dressed in hi viz jackets are watching a helicopter fly past an explosion . <end>',\n",
              "  '<start> The crowd is watching the fiery explosion . <end>'],\n",
              " 'Flicker8k_Dataset/101654506_8eb26cfb60.jpg': ['<start> A brown and white dog is running through the snow . <end>',\n",
              "  '<start> A dog is running in the snow <end>',\n",
              "  '<start> A dog running through snow . <end>',\n",
              "  '<start> a white and brown dog is running through a snow covered field . <end>',\n",
              "  '<start> The white and brown dog is running over the surface of the snow . <end>'],\n",
              " 'Flicker8k_Dataset/1333888922_26f15c18c3.jpg': ['<start> A brown-haired child in green shoes swings on a swing in a park near the woods . <end>',\n",
              "  '<start> A child swings and the sunshine shines down on her . <end>',\n",
              "  '<start> A child wearing Crocs sits on a swing in a wooded area . <end>',\n",
              "  '<start> A kid swings with his feet up in the air in a forest . <end>',\n",
              "  '<start> The sun breaks through the trees as a child rides a swing . <end>'],\n",
              " 'Flicker8k_Dataset/3036596725_541bbe0955.jpg': ['<start> A greyhound in a race wearing a metal muzzle . <end>',\n",
              "  '<start> A white and black dog racing on a track <end>',\n",
              "  '<start> A white dog with a mouthpiece and a red collar running . <end>',\n",
              "  '<start> A white greyhound dog wearing a muzzle runs around a track . <end>',\n",
              "  '<start> A white racing dog with a muzzle is racing around the turn of a dirt track . <end>'],\n",
              " 'Flicker8k_Dataset/3363836972_c87b58c948.jpg': ['<start> a soccer player kicking a goal in <end>',\n",
              "  '<start> A soccer player kicks a ball into the unmanned goal . <end>',\n",
              "  '<start> A soccer player prepares to kick the ball . <end>',\n",
              "  '<start> Man in red , white and blue sport uniform on field with soccer ball above ground in front of him . <end>',\n",
              "  '<start> View of a soccer ball being kicked into a goal net <end>'],\n",
              " 'Flicker8k_Dataset/2414390475_28a0107bb0.jpg': ['<start> A guy with long brown curly hair wearing a white t-shirt is looking into the camera with something in his mouth . a <end>',\n",
              "  '<start> A man in a white t-shirt eating candy . <end>',\n",
              "  '<start> A man with a lolly pop in his mouth smiles . <end>',\n",
              "  '<start> A person with a lolly pop and a white shirt is smiling in a store . <end>',\n",
              "  '<start> Person in a graphic print t-shirt standing in front of shelves of purses and shoes . <end>'],\n",
              " 'Flicker8k_Dataset/3527184455_1a9c074ff2.jpg': ['<start> A man and a woman holding two young boys are sitting on a park bench , posing for a photograph . <end>',\n",
              "  '<start> A man , woman , and two young boys are sitting on a bench with flowers in the background . <end>',\n",
              "  '<start> There is a man , woman and two boys sitting on a bench . <end>',\n",
              "  '<start> Two adults and two children pose on a park bench . <end>',\n",
              "  '<start> Two adults and two children sit on a park bench . <end>'],\n",
              " 'Flicker8k_Dataset/2978394277_4572967b97.jpg': ['<start> a boy wearing orange jumps from haystacks . <end>',\n",
              "  '<start> A child in an orange shirt jumps off bales of hay while other children watch . <end>',\n",
              "  '<start> A kid jumps off a haystack while other kids watch . <end>',\n",
              "  '<start> The boy in the orange t-shirt is leaping of a pile of hay bales as other children stand and watch . <end>',\n",
              "  '<start> The boy wearing a red sweatshirt is jumping off a pile of hay . <end>'],\n",
              " 'Flicker8k_Dataset/3204922011_185e48949a.jpg': ['<start> A man surfs on a huge green wave . <end>',\n",
              "  '<start> A surfer dressed in black catches a huge wave and starts riding on the descent . <end>',\n",
              "  '<start> A surfer in a black wetsuit rides a wave . <end>',\n",
              "  '<start> A surfer is riding a wave that is beginning to tube . <end>',\n",
              "  '<start> Surfer riding down a curling wave . <end>'],\n",
              " 'Flicker8k_Dataset/2101128963_fdf8b2a0d7.jpg': ['<start> A baseball is recoiling from an action taken on a treated field watched by others . <end>',\n",
              "  '<start> A baseball player on a playing field springs into action . <end>',\n",
              "  '<start> A baseball player standing on the mound . <end>',\n",
              "  '<start> A Philadelphia Phillie pitcher on the pitchers mound with his left leg up behind him . <end>',\n",
              "  '<start> A pitcher in a red and white uniform in a baseball game has just thrown the ball . <end>'],\n",
              " 'Flicker8k_Dataset/2834752476_3177e617f1.jpg': ['<start> A young man sits on a couch and smokes . <end>',\n",
              "  '<start> A young man with a mullet smokes while sitting on a unique couch . <end>',\n",
              "  '<start> Man smoking on a couch . <end>',\n",
              "  '<start> The young man is sitting on a couch smoking a cigarette . <end>',\n",
              "  '<start> Young man in a black shirt smokes on a sofa in a colorful room <end>'],\n",
              " 'Flicker8k_Dataset/2157173498_2eea42ee38.jpg': ['<start> A man is snowboarding and jumping off of a snow hill . <end>',\n",
              "  '<start> A person in a black jacket is snowboarding during the evening . <end>',\n",
              "  '<start> A silhouette of a person snowboarding through a pile of snow . <end>',\n",
              "  '<start> A snowboarder flying off a snow drift with a colorful sky in the background . <end>',\n",
              "  '<start> The person in the parka is on a snowboard . <end>'],\n",
              " 'Flicker8k_Dataset/3697359692_8a5cdbe4fe.jpg': ['<start> A boy is sitting in a car seat in the backseat of a car . <end>',\n",
              "  '<start> A boy making a face while sitting in his car seat <end>',\n",
              "  '<start> A boy sitting in a car making a surprised face <end>',\n",
              "  '<start> A young boy is buckled into a car seat making a silly face . <end>',\n",
              "  '<start> The young boy with a silly face is buckled in a car seat . <end>'],\n",
              " 'Flicker8k_Dataset/535123126_c06c1ab9bf.jpg': ['<start> A brown dog with a pink collar with a heart on it playing with a bigger dog . <end>',\n",
              "  '<start> Big dog trying to bite little dog <end>',\n",
              "  '<start> Both the larger dog and the smaller dog have their mouths open . <end>',\n",
              "  '<start> Two brown dogs fighting each other . <end>',\n",
              "  '<start> Two dogs , both wearing collars , are playing with one another in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/383223174_7165a54c30.jpg': ['<start> A brown dog plays with a stick . <end>',\n",
              "  '<start> A brown dog wearing a key is playing in the dirt . <end>',\n",
              "  '<start> A lean light brown dog has his head down on the ground playing with a stick . <end>',\n",
              "  '<start> A tan dog rests his head in the sand . <end>',\n",
              "  '<start> Two dogs and a person . <end>'],\n",
              " 'Flicker8k_Dataset/1415591512_a84644750c.jpg': ['<start> A girl in boots is active in the grass . <end>',\n",
              "  '<start> A girl is playing in the mud near a car . <end>',\n",
              "  '<start> A young girl in front of a silver car wearing boots , demonstrates some interesting moves . <end>',\n",
              "  '<start> Little girl moving quickly on grass beside silver car . <end>',\n",
              "  '<start> The little girl is spinning around making her hair fly in front of the silver car . <end>'],\n",
              " 'Flicker8k_Dataset/2839932205_3c9c27cd99.jpg': ['<start> A blond person climbs a sheer rock cliff face . <end>',\n",
              "  '<start> A girl climbing a rock face . <end>',\n",
              "  '<start> a girl on the very top of a large rock wall climbing . <end>',\n",
              "  '<start> A person climbs a rock face . <end>',\n",
              "  '<start> A person is climbing to the top of a rock cliff . <end>'],\n",
              " 'Flicker8k_Dataset/3389448506_7025e7cc12.jpg': ['<start> A dog runs toward the camera , his tongee hanging out the side of his mouth <end>',\n",
              "  '<start> A dog gith golden fur runs in dhe park , the sun striking its fur . <end>',\n",
              "  '<start> A light colored dog with tongue hanging out of this mouth running on the grass . <end>',\n",
              "  '<start> A tan dog runs along the grass . <end>',\n",
              "  '<start> The dog plays in the park . <end>'],\n",
              " 'Flicker8k_Dataset/3091177347_58c85c1c3b.jpg': ['<start> a man photographs a woman . <end>',\n",
              "  '<start> A photographer is takeing a picture of a bird mobile . <end>',\n",
              "  '<start> A woman holds something for a professional photograph while the photographer takes the shot . <end>',\n",
              "  '<start> One person is assisting another inside a photo session involving wind chimes . <end>',\n",
              "  '<start> Two people are setting up a photo shoot of a mobile in a white room . <end>'],\n",
              " 'Flicker8k_Dataset/2650485780_29d89268d7.jpg': ['<start> A group of children in a church basement play maracas and tambourines . <end>',\n",
              "  '<start> A group of children play tambourines . <end>',\n",
              "  '<start> a group of young children performing song and playing instruments . <end>',\n",
              "  '<start> Six children in a row with small musical instruments . <end>',\n",
              "  '<start> Six children playing musical instruments and singing in what appears to be a church . <end>'],\n",
              " 'Flicker8k_Dataset/397725001_e51f7c391c.jpg': ['<start> A man attached to strings is watched by a crowd . <end>',\n",
              "  '<start> A man stands below a crowd . <end>',\n",
              "  '<start> People on a cruise ship deck , and overlooking the deck . <end>',\n",
              "  '<start> People stand on the balcony and deck of a boat . <end>',\n",
              "  '<start> The people on the balcony are controlling the man in the white shorts like a puppet . <end>'],\n",
              " 'Flicker8k_Dataset/3201594926_cd2009eb13.jpg': ['<start> A girl wearing white polka dots and black boots walks and a woman in a blue outfit hurridly walks behind her . <end>',\n",
              "  '<start> A hip young woman down the street with a woman in a kimono walks behind her . <end>',\n",
              "  '<start> A woman in boots with a big purse walks down the street followed by a woman in blue . <end>',\n",
              "  '<start> a woman walks with her big purse . <end>',\n",
              "  '<start> Women walk down the street . <end>'],\n",
              " 'Flicker8k_Dataset/1236964638_1808784a3c.jpg': ['<start> A boy flips off a diving board into a pool . <end>',\n",
              "  '<start> A boy is diving off a diving board into a swimming pool . <end>',\n",
              "  '<start> A child is diving into a pool . <end>',\n",
              "  '<start> A child jumping into a swimming pool from the diving board . <end>',\n",
              "  '<start> Child flips off pool diving board , man and another tumbling child at poolside . <end>'],\n",
              " 'Flicker8k_Dataset/2066271441_1f1f056c01.jpg': ['<start> A black dog carrying a colorful ball swims . <end>',\n",
              "  '<start> A black dog is retrieving a ball in water . <end>',\n",
              "  '<start> A black dog is swimming with a ball in his mouth . <end>',\n",
              "  '<start> A black dog swims in water with a colorful ball in his mouth . <end>',\n",
              "  '<start> Black dog paddles through the water with a bright ball in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/496555371_3e1ee0d97d.jpg': ['<start> A black dog is being chase by two brown dogs on the beach . <end>',\n",
              "  '<start> A black dog is followed by two brown dogs over sand . <end>',\n",
              "  '<start> A group of three dogs running across a rocky , sandy beach . <end>',\n",
              "  '<start> One black and white dog and two brown and white dogs moving on sand . <end>',\n",
              "  '<start> Three dogs are running across a sandy landscape . <end>'],\n",
              " 'Flicker8k_Dataset/2929006980_9f9f8f3d21.jpg': ['<start> A man is leaning on a skateboard while holding onto a pole . <end>',\n",
              "  '<start> A man on a roller scooter holding on to rope <end>',\n",
              "  '<start> A man on a skateboard holding on to a kite <end>',\n",
              "  '<start> A man stands on a four-wheeled board attached to a harness . <end>',\n",
              "  '<start> Man on specialized skateboard being propelled by unseen kite <end>'],\n",
              " 'Flicker8k_Dataset/3347798761_5c5260b000.jpg': ['<start> A dirt bike rider is in the air pulling off a trick . <end>',\n",
              "  '<start> A dirt biker who is sideways in the air having come off of a dirt jump . <end>',\n",
              "  '<start> A motorbiker racer performs an aerial stunt as he flies over a dirt hill in the woods . <end>',\n",
              "  '<start> A person on a dirt bike doing a trick over a hill . <end>',\n",
              "  '<start> A person on a dirt bike soaring through the air sideways . <end>'],\n",
              " 'Flicker8k_Dataset/3337461409_e4e317853d.jpg': ['<start> Lambs on a grassy hill . <end>',\n",
              "  '<start> There are three lambs : one white , one black , and one spotted . <end>',\n",
              "  '<start> Three lambs are in a field . <end>',\n",
              "  '<start> Three young sheep walk along the grassy hill . <end>',\n",
              "  '<start> Young sheep in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/1424237335_b3be9920ba.jpg': ['<start> Two children hang from a metal bar close to the ground . <end>',\n",
              "  '<start> Two little girls are hanging by their arms from a metal bar . <end>',\n",
              "  '<start> Two little girls hang on a bar in front of a wooden fence . <end>',\n",
              "  '<start> Two little girls , wearing pink hanging on a tube . <end>',\n",
              "  '<start> Two smiling little blonde girls in pink pants swing from a metal bar . <end>'],\n",
              " 'Flicker8k_Dataset/3057497487_57ecc60ff1.jpg': ['<start> a closeup into a large unique type plan with a lone woman in the center . <end>',\n",
              "  '<start> A person sitting in an airplane display . <end>',\n",
              "  '<start> A woman is sitting in a white bi-plane that hangs from the roof of an air museum . <end>',\n",
              "  '<start> Ride with a model biplane . <end>',\n",
              "  '<start> The plane is hanging from the ceiling in the museum . <end>'],\n",
              " 'Flicker8k_Dataset/3185371756_ff4e9fa8a6.jpg': ['<start> A girl in a purple sweatshirt bends over backwards . <end>',\n",
              "  '<start> A girl bending backwards holding her hat . <end>',\n",
              "  '<start> A person bending backwards . <end>',\n",
              "  '<start> A person in a blue sweatshirt is doing a back bend . <end>',\n",
              "  '<start> A woman in blue bends over backwards on the street . <end>'],\n",
              " 'Flicker8k_Dataset/2844018783_524b08e5aa.jpg': ['<start> Three boys in a building under construction . <end>',\n",
              "  '<start> Three boys play in an unfinished building . <end>',\n",
              "  '<start> Three boys playing in an unfinished space . <end>',\n",
              "  '<start> Three little boys are playing on the floor of an unfinished house . <end>',\n",
              "  '<start> Two young boys sit and one young boy stands on an unfinished wooden floor . <end>'],\n",
              " 'Flicker8k_Dataset/2534424894_ccd091fcb5.jpg': ['<start> A girl jumps over the grass tufts on a sandy area near the sea . <end>',\n",
              "  '<start> A girl running through uneven sand with some withered grass . <end>',\n",
              "  '<start> A girl wearing a jacket and scarf is playing on the beach . <end>',\n",
              "  '<start> A little girl is jumping down a sandy hill . <end>',\n",
              "  '<start> A small girl wearing a green shirt jumping off a grassy , sandy hill with a black scarf in her hand . <end>'],\n",
              " 'Flicker8k_Dataset/2429729667_42effc165d.jpg': ['<start> A girl has her head in a wooden cut out of a pirate ship while people throw tomatos . <end>',\n",
              "  '<start> A little girl throws an object at a man who is standing behind a cutout of a sailor on a ship . <end>',\n",
              "  '<start> A young boy and girl are trying to hit a man with balls in a fair game . <end>',\n",
              "  '<start> Children are throwing food at someone as part of an amusement park game . <end>',\n",
              "  '<start> Children watching a play . <end>'],\n",
              " 'Flicker8k_Dataset/3424424006_98f9d1921c.jpg': ['<start> A bride and groom jump towards each other with arms outstretched . <end>',\n",
              "  \"<start> A groom leaps off of a stone wall and into his wife 's arms . <end>\",\n",
              "  '<start> A man in a suit leaps toward his bride . <end>',\n",
              "  '<start> A man in a tuxedo jumps toward a woman in a wedding dress . <end>',\n",
              "  '<start> A man in wetsuit jumps towards a wet bride . <end>'],\n",
              " 'Flicker8k_Dataset/2495394666_2ef6c37519.jpg': ['<start> A brown dog is standing in a lake . <end>',\n",
              "  '<start> A brown dog is swimming in a creek . <end>',\n",
              "  '<start> A dog swimming in a pond <end>',\n",
              "  '<start> Dog swimming in body of water <end>',\n",
              "  '<start> The brown dog is swimming in the water . <end>'],\n",
              " 'Flicker8k_Dataset/3135504530_0f4130d8f8.jpg': ['<start> One girl is wearing a white t-shirt with red sleeves ; the other has words on hers . <end>',\n",
              "  '<start> two asian girls laughing together <end>',\n",
              "  '<start> Two girls with dark hair and white shirts . <end>',\n",
              "  '<start> Two girls with long hair are smiling and one is hold something white and green . <end>',\n",
              "  '<start> Two women in white shirts talking . <end>'],\n",
              " 'Flicker8k_Dataset/428485639_a82635d6ee.jpg': ['<start> A girl straddles a bike rack on a city street . <end>',\n",
              "  '<start> A little girl in a blue outfit is climbing on metal railings in the street . <end>',\n",
              "  '<start> A little girl in navy blue is posing on a railing . <end>',\n",
              "  '<start> A little girl wearing a navy skirt is climbing on some silver poles . <end>',\n",
              "  '<start> A young girl in a blue skirt is propping herself up on bars of a metal structure outside . <end>'],\n",
              " 'Flicker8k_Dataset/578644583_da3ff18dd1.jpg': ['<start> A child is jumping into a swimming pool . <end>',\n",
              "  '<start> A little boy in black shorts jumps into a backyard pool next to a yellow stucco house . <end>',\n",
              "  '<start> A little boy jumps high above the swimming pool with a man in the background . <end>',\n",
              "  '<start> The boy jumps into the blue pool . <end>',\n",
              "  '<start> Young child in midair descending into pool . <end>'],\n",
              " 'Flicker8k_Dataset/2056930414_d2b0f1395a.jpg': ['<start> A child plays a red toy guitar and sings into multicolored plastic microphone . <end>',\n",
              "  '<start> A little boy is playing with a toy guitar and microphone . <end>',\n",
              "  '<start> A little boy plays a toy guitar while singing into a toy microphone . <end>',\n",
              "  '<start> A little boy with toy microphone and guitar pretends to play music . <end>',\n",
              "  '<start> The child has a small red guitar and toy microphone . <end>'],\n",
              " 'Flicker8k_Dataset/3307667255_26bede91eb.jpg': ['<start> A crowd scene in front of mosque . <end>',\n",
              "  '<start> A large group is shown in the street . <end>',\n",
              "  '<start> A lot of people are gathered around a mosque-like building . <end>',\n",
              "  '<start> Busy marketplace in an Arabian country . <end>',\n",
              "  '<start> There are a lot of people in front of a tan building with colorful squares hanging from the top . <end>'],\n",
              " 'Flicker8k_Dataset/3573202338_f43dd22d28.jpg': ['<start> A girl does a side bend in the surf , another girl behind her , the sun setting . <end>',\n",
              "  '<start> a young girl doing gymnastics on the shore of a beach while another is walking deeper into the beach . <end>',\n",
              "  '<start> Two girls in swimsuits are playing in the water near the seashore . <end>',\n",
              "  '<start> Two girls playing on the <end>',\n",
              "  '<start> Two girls wade in the surf , and one shows of her flexibility . <end>'],\n",
              " 'Flicker8k_Dataset/381514859_b40418d9c3.jpg': ['<start> Two small white dogs are in a yard chasing a red ball . <end>',\n",
              "  '<start> Two small white dogs chasing after a red ball . <end>',\n",
              "  '<start> Two small white dogs chasing a red ball <end>',\n",
              "  '<start> Two West Highland Terriers chase a red ball . <end>',\n",
              "  '<start> Two white dogs chase after a red ball in a yard in front of a white fence . <end>'],\n",
              " 'Flicker8k_Dataset/278496691_c1fd93e2d8.jpg': ['<start> a crowd of people walk . <end>',\n",
              "  '<start> A group of runners carry an injured runner out of a race . <end>',\n",
              "  '<start> A man being carried by a group of other men , people looking on behind a barrier . <end>',\n",
              "  '<start> Group carrying injured man as spectators watch from behind fence . <end>',\n",
              "  '<start> The injured athlete is being carried by several people . <end>'],\n",
              " 'Flicker8k_Dataset/3344233740_c010378da7.jpg': ['<start> A man is standing on a sidewalk in the background with a blurry image of another man in the foreground . <end>',\n",
              "  '<start> A man stands at a busy bus stop . <end>',\n",
              "  '<start> a man stands next to a bus . <end>',\n",
              "  '<start> People in the city . <end>',\n",
              "  '<start> People walking down the street and past an open bus . <end>'],\n",
              " 'Flicker8k_Dataset/2706766641_a9df81969d.jpg': ['<start> A child and floor covered in white powder . <end>',\n",
              "  '<start> A little boy is in the corner covered in a white powder that is all over him and the floor . <end>',\n",
              "  '<start> A little boy with a mess all over his face and feet stands next to a door . <end>',\n",
              "  '<start> A young boy is caught making a mess of his room . <end>',\n",
              "  '<start> A young child covered with white powder . <end>'],\n",
              " 'Flicker8k_Dataset/114051287_dd85625a04.jpg': ['<start> A boy dressed in soccer attire and holding his shoes getting out of a car . <end>',\n",
              "  '<start> A boy in a red soccer strip is holding his boots in his hand whilst stepping out of a car . <end>',\n",
              "  '<start> A boy in glasses is wearing a red shirt . <end>',\n",
              "  '<start> A child getting out of the car wearing soccer shoes . <end>',\n",
              "  '<start> A young boy gets out of the van and prepares his shoes for wear during a soccer game . <end>'],\n",
              " 'Flicker8k_Dataset/3273489163_8209545810.jpg': ['<start> A group stands on tan checkered tiles . <end>',\n",
              "  '<start> many people stand around reading . <end>',\n",
              "  '<start> People are standing on a railway platform reading newspapers . <end>',\n",
              "  '<start> People stand reading papers while waiting for a subway . <end>',\n",
              "  '<start> People waiting for train on tiled platform . <end>'],\n",
              " 'Flicker8k_Dataset/3227594168_3351722aae.jpg': ['<start> Two blonde ladies wearing sunglasses lounge on the grass with a dacshund . <end>',\n",
              "  '<start> Two blonde young women hang out in the grass with a brown dog . <end>',\n",
              "  '<start> Two blond women sit in grass with a small dog . <end>',\n",
              "  '<start> Two women laying on grass with a dog . <end>',\n",
              "  '<start> Two women on a grassy hill lit by the sun ; one looks at a dachshund , the other looks to the side . <end>'],\n",
              " 'Flicker8k_Dataset/2204695848_3d1b140212.jpg': ['<start> A blond girl earring Groucho Marx glasses . <end>',\n",
              "  '<start> A girl in pink wears a funny nose mask . <end>',\n",
              "  '<start> A little girl is smiling whilst wearing a fake nose and glasses . <end>',\n",
              "  '<start> Blonde girl with pink top smiling while wearing funny glasses with large nose . <end>',\n",
              "  '<start> Blond little girl wearing novelty glasses . <end>'],\n",
              " 'Flicker8k_Dataset/527288854_f26127b770.jpg': ['<start> A climber in a yellow hard-hat is seen mid-climb from above . <end>',\n",
              "  '<start> A person wearing a yellow helmet attempts to climb a rock . <end>',\n",
              "  '<start> A woman works hard to maintain a fingerhold as she climbs a rock face . <end>',\n",
              "  '<start> Man straining to climb cliff face . <end>',\n",
              "  '<start> The gal in the yellow hardhat is rock climbing up the steep rock . <end>'],\n",
              " 'Flicker8k_Dataset/3727752439_907795603b.jpg': ['<start> a large woman puts her sunglasses on . <end>',\n",
              "  '<start> A woman in a black dress holding sunglasses . <end>',\n",
              "  '<start> a woman wearing a black and white outfit while holding her sunglasses . <end>',\n",
              "  '<start> The lady is holding her glasses . <end>',\n",
              "  '<start> The woman with blond hair holds her sunglasses . <end>'],\n",
              " 'Flicker8k_Dataset/2654943319_d17fee7800.jpg': ['<start> A kid in purple is doing a skateboard trick . <end>',\n",
              "  '<start> A man in a purple shirt attempts tricks with a skateboard inside a heavily graffiti painted area . <end>',\n",
              "  '<start> A man in a purple shirt is skateboarding in a graffiti-heavy area . <end>',\n",
              "  '<start> A person grinding a ledge on a skateboard . <end>',\n",
              "  '<start> A person wearing a blue hat rides a skateboard off of a cement bench . <end>'],\n",
              " 'Flicker8k_Dataset/2661294969_1388b4738c.jpg': ['<start> A float representing the times of hanging is shown in the back of a truck . <end>',\n",
              "  '<start> A man in a judge costume stand on a red truck and hangs a dummy . <end>',\n",
              "  '<start> Man dressed as a judge pretending to hang another man on top of a truck . <end>',\n",
              "  '<start> Three people in costumes stand on the back of a pickup truck . <end>',\n",
              "  '<start> Three people stand on the back of a truck . <end>'],\n",
              " 'Flicker8k_Dataset/897621891_efb1e00d1d.jpg': ['<start> A boy is swimming underwater holding a toy in his hand . <end>',\n",
              "  '<start> A little boy swimming underwater with a toy in his hand . <end>',\n",
              "  '<start> A little boy swims underwater . <end>',\n",
              "  '<start> A little boy underwater in a pool , holding a plastic dinosaur . <end>',\n",
              "  '<start> Child swimming underwater with a toy in his hand . <end>'],\n",
              " 'Flicker8k_Dataset/3110018626_307a123b59.jpg': ['<start> Two brown and black dogs run through the dry grass . <end>',\n",
              "  '<start> Two dogs are running in a field . <end>',\n",
              "  '<start> Two dogs run around together in the field . <end>',\n",
              "  '<start> Two dogs running through high grass . <end>',\n",
              "  '<start> Two large dogs frolic in a grassy field . <end>'],\n",
              " 'Flicker8k_Dataset/3565749152_7924d15b04.jpg': ['<start> A dog catches a Frisbee in the front yard . <end>',\n",
              "  '<start> A dog playing Frisbee in the front yard , next to a car . <end>',\n",
              "  '<start> A white dog catches a red Frisbee in the grass . <end>',\n",
              "  '<start> a white dog jumping in the air to catch a red Frisbee . <end>',\n",
              "  '<start> The dog leaps to catch the Frisbee in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/3025546819_ce031d2fc3.jpg': ['<start> A dog running through a field with a ball in its mouth <end>',\n",
              "  '<start> A dog runs on brown grass . <end>',\n",
              "  '<start> A wet dog runs through the yellow grass holding a tennis ball . <end>',\n",
              "  '<start> The black and white dog has a ball in its mouth . <end>',\n",
              "  '<start> The black and white dog is in the brown grass with a ball in his mouth . <end>'],\n",
              " 'Flicker8k_Dataset/2287023569_fd7a9c60b8.jpg': ['<start> A dog in mid-flight catches an orange and blue ball in a field of dead grass . <end>',\n",
              "  '<start> A dog jumps up to catch an orange and blue tennis ball . <end>',\n",
              "  '<start> A dog leaps into the air to catch a ball in its mouth . <end>',\n",
              "  '<start> A terrier catches a ball in a field . <end>',\n",
              "  '<start> Small white dog jumping to catch a ball . <end>'],\n",
              " 'Flicker8k_Dataset/2676648667_cb055b4fc6.jpg': ['<start> A woman is sitting in a chair near a brick building . <end>',\n",
              "  '<start> A woman sits in a blue chair outside a brick house . <end>',\n",
              "  '<start> The elderly African woman is sitting on a blue chair in front of a rough brick wall . <end>',\n",
              "  '<start> This woman is sitting in a lawnchair on the sand . <end>',\n",
              "  '<start> Woman in grey shirt and dark skirt sitting in blue chair with white stars in front of a brick wall . <end>'],\n",
              " 'Flicker8k_Dataset/3647750811_395fbd397e.jpg': ['<start> a black and white dog is wearing a red collar whilst walking on the grass . <end>',\n",
              "  '<start> A dog is running awkwardly . <end>',\n",
              "  '<start> A multicolor dog in a red collar crouching on the grass . <end>',\n",
              "  '<start> Black , brown and white dog crouches on three legs in the grass . <end>',\n",
              "  '<start> The dog with the red collar is white , black , and brown . <end>'],\n",
              " 'Flicker8k_Dataset/3629492654_619d7b67ee.jpg': ['<start> A backlit skateboarder ollies over a parking cone . <end>',\n",
              "  '<start> A boy does skateboard tricks at sundown . <end>',\n",
              "  '<start> A man on a skateboard jumping an orange cone . <end>',\n",
              "  '<start> A silhouette of a skateboarder in the air . <end>',\n",
              "  '<start> A skateboarder in silhouette jumps over an orange traffic cone . <end>'],\n",
              " 'Flicker8k_Dataset/3516299821_8f0375d221.jpg': ['<start> A baseball player hitting the ball <end>',\n",
              "  '<start> A girl in a uniform hitting a ball with a bat <end>',\n",
              "  '<start> A softball player in red and white swings and hits the yellow ball . <end>',\n",
              "  '<start> A softball player swinging at a pitch . <end>',\n",
              "  '<start> A teenager dressed in a baseball uniform attempting to hit a baseball during a game . <end>'],\n",
              " 'Flicker8k_Dataset/2471974379_a4a4d2b389.jpg': ['<start> A group of motorcycles wearing black . <end>',\n",
              "  '<start> Bikers are seen riding during a parade , one has an American flag . <end>',\n",
              "  '<start> Man carrying american flag rides motorbike . <end>',\n",
              "  '<start> many motorcyclists ride along the street . <end>',\n",
              "  '<start> People on motorcycles ride down a street with an American flag waving . <end>'],\n",
              " 'Flicker8k_Dataset/3117562746_62f57a02b5.jpg': ['<start> a dog chases another dog . <end>',\n",
              "  '<start> Two dogs are running through the snow with ball in their mouths . <end>',\n",
              "  '<start> Two dogs holding red balls in their mouth , running in the snow . <end>',\n",
              "  '<start> Two dogs in the snow <end>',\n",
              "  '<start> Two tan dogs run in the snow carrying red balls in their mouths . <end>'],\n",
              " 'Flicker8k_Dataset/2596876977_b61ee7ee78.jpg': ['<start> A woman floats with her face out of water in a pool with another woman nearby posing for the camera . <end>',\n",
              "  '<start> Two children are smiling for picture being taken of them in a swimming pool . <end>',\n",
              "  '<start> Two children relaxing by the pool . <end>',\n",
              "  '<start> Two girls in a swimming pool . <end>',\n",
              "  '<start> Two smiling children in a swimming pool . <end>'],\n",
              " 'Flicker8k_Dataset/3321516504_5ee97771cb.jpg': ['<start> A man holds a sleeping baby with a yellow blanket . <end>',\n",
              "  '<start> A man in a black shirt and hat holding a sleeping baby with a yellow afghan . <end>',\n",
              "  '<start> A man in a hat sits on a sofa with an infant . <end>',\n",
              "  '<start> A man with glasses and a hat and a baby . <end>',\n",
              "  '<start> Man sits on sofa holding a sleeping baby wrapped in a blanket <end>'],\n",
              " 'Flicker8k_Dataset/335588286_f67ed8c9f9.jpg': ['<start> A fluffy dog holds a stick in its mouth on a beach . <end>',\n",
              "  '<start> a small white dog catching a stick on the shore at the beach . <end>',\n",
              "  '<start> A white dog has caught a stick on the beach beside the ocean . <end>',\n",
              "  '<start> A white dog is running along a beach with a stick in its mouth . <end>',\n",
              "  '<start> A white dog on a beach is carrying a stick in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/3656030945_fa003bd696.jpg': ['<start> A few puppies get washed in the tub . <end>',\n",
              "  '<start> Small puppies in bathtub being given a shower with handheld showerhead <end>',\n",
              "  '<start> Three puppies are in a bathtub getting sprayed with water from a showerhead . <end>',\n",
              "  '<start> Three puppies are in the tub being sprayed with water by a person . <end>',\n",
              "  '<start> Three white puppies are being washed in a bathtub with hand held shower . <end>'],\n",
              " 'Flicker8k_Dataset/2444741900_5cb3ef3e1d.jpg': ['<start> A bunch of people are standing or sitting in a snow valley . <end>',\n",
              "  '<start> A number of people standing and laying under a mountain covered in snow . <end>',\n",
              "  '<start> Sledding and skiing enthusiasts gather at a snowy rock formation . <end>',\n",
              "  '<start> Snow skiers gather at the bottom of a snowy hill . <end>',\n",
              "  '<start> Some people hanging out in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/3609999845_faf5d2fe74.jpg': ['<start> A boy hits a ball , with a bat , outside , while others in the background watch him . <end>',\n",
              "  '<start> A man hitting a red ball with a bat while running in grass . <end>',\n",
              "  '<start> A young man hitting a ball with a bat . <end>',\n",
              "  '<start> Boy plays baseball in a grass field . <end>',\n",
              "  '<start> man playing cricket , hits the red ball . <end>'],\n",
              " 'Flicker8k_Dataset/2870194345_0bcbac1aa5.jpg': ['<start> A girl is a blue and purple dress is hanging on a railing near a street while holding candy . <end>',\n",
              "  '<start> A little girl in a colorful dress and black boots holds a lollipop and plays near a fence . <end>',\n",
              "  '<start> A little girl in a dress and boots is holding a lolly pop and posing next to a fence . <end>',\n",
              "  '<start> A young girl wearing black boots holds onto the fence and has a lollipop . <end>',\n",
              "  '<start> little girl wearing dress and boots holding lollipop and fence <end>'],\n",
              " 'Flicker8k_Dataset/3108197858_441ff38565.jpg': ['<start> A group of children are raising their hands in the air . <end>',\n",
              "  '<start> A group of kids singing and putting their hands in the air <end>',\n",
              "  '<start> Little kids stand together and raise their hands in the air . <end>',\n",
              "  '<start> Little kids with their hands in the air <end>',\n",
              "  '<start> Some children are raising their hands and clapping . <end>'],\n",
              " 'Flicker8k_Dataset/811663364_4b350a62ce.jpg': ['<start> A girl in a pink swimsuit jumps through a water sprinkler . <end>',\n",
              "  '<start> A little girl in a swimsuit jumps over a sprinkler with her eyes hut . <end>',\n",
              "  '<start> A little girl running through yellow sprinkler in a grassy yard . <end>',\n",
              "  '<start> A young girl running through a sprinkler <end>',\n",
              "  '<start> Little girl in pink bathing suit jumping through a sprinkler toy outside . <end>'],\n",
              " 'Flicker8k_Dataset/485054073_fef8b80b4b.jpg': ['<start> A Frisbee casts a shadow on the dog . <end>',\n",
              "  '<start> a white dog is attempting to catch a green and pink object . <end>',\n",
              "  '<start> A white dog with long hair jumps to catch a red and green toy . <end>',\n",
              "  '<start> A white furry dog jumping to catch a Frisbee . <end>',\n",
              "  '<start> The dog is trying to catch a Frisbee . <end>'],\n",
              " 'Flicker8k_Dataset/2709648336_15455e60b2.jpg': ['<start> A brown dog in midair with a Frisbee in his mouth . <end>',\n",
              "  '<start> A brown dog is catching a Frisbee in midair . <end>',\n",
              "  '<start> A brown dog jumped into the air and caught a Frisbee . <end>',\n",
              "  '<start> A large brown and black dog jumps in the air holding a white Frisbee in its mouth . <end>',\n",
              "  '<start> The dog leaps to catch the Frisbee . <end>'],\n",
              " 'Flicker8k_Dataset/3425851292_de92a072ee.jpg': ['<start> A male athlete is wearing a teal sweatband and a shirt from Nike and is holding a tennis racket . <end>',\n",
              "  '<start> A man plays tennis . <end>',\n",
              "  '<start> A tennis player is carrying a tennis racket . <end>',\n",
              "  '<start> a tennis player wearing a yellow , white and blue shirt carrying a racquet <end>',\n",
              "  '<start> The tennis player is wearing a yellow and blue shirt and a blue headband . <end>'],\n",
              " 'Flicker8k_Dataset/2757803246_8aa3499d26.jpg': ['<start> A child plays outdoors , near a group of people who are mostly seated . <end>',\n",
              "  '<start> A little blond boy is running around in the grass behind a row of benches <end>',\n",
              "  '<start> A little boy is running towards a group of people . <end>',\n",
              "  '<start> A little boy runs around while others look at a stage . <end>',\n",
              "  '<start> A small child wearing blue smiles as he stands behind a group of people . <end>'],\n",
              " 'Flicker8k_Dataset/47871819_db55ac4699.jpg': ['<start> A soccer player in blue is chasing after the player in black and white . <end>',\n",
              "  '<start> The girl in the white strip is falling down as the girl in the blue strip challenges for the soccer ball . <end>',\n",
              "  '<start> The girls are playing soccer . <end>',\n",
              "  '<start> Two women in soccer uniforms playing soccer . <end>',\n",
              "  '<start> Two young women on different teams are playing soccer on a field . <end>'],\n",
              " 'Flicker8k_Dataset/2265367960_7928c5642f.jpg': ['<start> A boy sitting down smiling for the picture . <end>',\n",
              "  '<start> A child holding some shoes . <end>',\n",
              "  '<start> A child in blue and wearing a hat smiles . <end>',\n",
              "  '<start> A young boy smiling and holding sandals . <end>',\n",
              "  '<start> The boy is wearing a hat and holding sandals . <end>'],\n",
              " 'Flicker8k_Dataset/498957941_f0eda42787.jpg': ['<start> A boy in a blue shirt is running . <end>',\n",
              "  '<start> A distorted image of a young boy running <end>',\n",
              "  '<start> A little boy running , blurry picture . <end>',\n",
              "  '<start> A young boy runs . <end>',\n",
              "  '<start> Little boy running very fast . <end>'],\n",
              " 'Flicker8k_Dataset/244399048_8332bb3270.jpg': ['<start> A blurry dog inside on a carpet . <end>',\n",
              "  '<start> A dog is jumping up in the air to catch a toy . <end>',\n",
              "  '<start> A dog standing up on two legs with something in his mouth . <end>',\n",
              "  '<start> Dog jumping up with something in its mouth . <end>',\n",
              "  '<start> The furry brown and white dog is jumping around near a door . <end>'],\n",
              " 'Flicker8k_Dataset/2084157130_f288e492e4.jpg': ['<start> A black and white dog runs beside a brown dog in a green field . <end>',\n",
              "  '<start> The black and white dog along with the brown dog are galloping outside <end>',\n",
              "  '<start> Two dogs race through a field . <end>',\n",
              "  '<start> Two dogs run across the grassy field . <end>',\n",
              "  '<start> Two dogs running fast in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/2542662402_d781dd7f7c.jpg': ['<start> A woman in a blue shirt guides her dog over an obstacle . <end>',\n",
              "  '<start> a woman is running beside a dog that is jumping over a red and white obedience training fence . <end>',\n",
              "  '<start> A woman next to a dog which is running an obstacle course . <end>',\n",
              "  '<start> A woman walking with a Sheltie through a competition obstacle course . <end>',\n",
              "  '<start> The dog is jumping over the hurdles beside a woman . <end>'],\n",
              " 'Flicker8k_Dataset/2362481035_a7600875d0.jpg': ['<start> A blonde boy in green is on a swing . <end>',\n",
              "  '<start> A little girl with blond hair is smiling and sitting in a swing . <end>',\n",
              "  '<start> A young child smiling while on a swing at a playground . <end>',\n",
              "  '<start> The small child is leaning back in a child swing . <end>',\n",
              "  '<start> Toddler boy smiling while in a swing <end>'],\n",
              " 'Flicker8k_Dataset/475778645_65b7343c47.jpg': ['<start> A boy in a harness climbs a rock wall . <end>',\n",
              "  '<start> A small boy hangs from a safety harness next to a climbing wall . <end>',\n",
              "  '<start> A young boy on a harness climbs up a boulder . <end>',\n",
              "  '<start> The boy is climbing a white rock wall . <end>',\n",
              "  '<start> The small child climbs a white rock wall . <end>'],\n",
              " 'Flicker8k_Dataset/381976882_0063d16d88.jpg': ['<start> Four dogs are being walked by two owners . <end>',\n",
              "  '<start> Four dogs on leashes walk down a sidewalk . <end>',\n",
              "  '<start> Four little dogs on leashes take a walk on a wide path . <end>',\n",
              "  '<start> Four small dogs on leashes walking in a park . <end>',\n",
              "  '<start> Someone is walking their dogs . <end>'],\n",
              " 'Flicker8k_Dataset/3205754736_32c29b5208.jpg': ['<start> A man in a blue coat and red hat holds a sign with very small writing . <end>',\n",
              "  '<start> A man in a red hat and blue jacket in a protest is holding up a tablet that talks about God and judgement . <end>',\n",
              "  '<start> A man with a blue coat and a red hat is holding up a sign . <end>',\n",
              "  '<start> Man in a blue coat holding a sign . <end>',\n",
              "  '<start> Men standing with signs on the sidewalk . <end>'],\n",
              " 'Flicker8k_Dataset/2785115802_137fa30000.jpg': ['<start> A black and white dog is swimming . <end>',\n",
              "  '<start> A dog swims in the water . <end>',\n",
              "  '<start> A dog swims through deep water . <end>',\n",
              "  '<start> A large black and white dog is swimming in the water . <end>',\n",
              "  '<start> The black and white dog swims with a brown object in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/3351493005_6e5030f596.jpg': ['<start> A group of people on the slopes , a person is skating boarding , and a bunch of people are surrounding him . <end>',\n",
              "  '<start> Airborne snowboarder in front of a crowd . <end>',\n",
              "  '<start> A snowboarder in the air as others watch . <end>',\n",
              "  '<start> a snowboarder jumps high . <end>',\n",
              "  '<start> A snowboarder jumps while spectators watch . <end>'],\n",
              " 'Flicker8k_Dataset/3229913073_e7857a5966.jpg': ['<start> A little boy streches his body out with his stomach on the grass . <end>',\n",
              "  '<start> A young boy wearing a blue shirt lies on the grass . <end>',\n",
              "  '<start> Boy lies on stomach in grass . <end>',\n",
              "  '<start> Small boy lying on his stomach on the grass . <end>',\n",
              "  '<start> The young boy is laying on his belly in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3259757648_71edb4347b.jpg': ['<start> A dog is jumping over a blue and white obstacle course fence . <end>',\n",
              "  '<start> A dog leaps over a barrier . <end>',\n",
              "  '<start> A dog runs headlong towards a hurdle . <end>',\n",
              "  '<start> A light colored dog leaps over a hurdle . <end>',\n",
              "  '<start> a tan dog jumping over a goal net on a large grassy field <end>'],\n",
              " 'Flicker8k_Dataset/2315807231_6948b3f3a5.jpg': ['<start> A brown dog is shaking off the snow . <end>',\n",
              "  '<start> A brown dog squats in a deep pile of snow . <end>',\n",
              "  '<start> A brown long-haired dog plays in the snow <end>',\n",
              "  '<start> The brown dog is playing in the snow . <end>',\n",
              "  '<start> The brown dog is playing in the white snow . <end>'],\n",
              " 'Flicker8k_Dataset/1982852140_56425fa7a2.jpg': ['<start> An adult and a child run on the beach . <end>',\n",
              "  '<start> A woman and a little girl playing in the sand next to the ocean <end>',\n",
              "  '<start> Two people run down the beach and one of them is pointing . <end>',\n",
              "  '<start> Two people running on a beach . <end>',\n",
              "  '<start> two people running on the shore of a beach <end>'],\n",
              " 'Flicker8k_Dataset/3335370208_460fc19bfa.jpg': ['<start> A man drives a motorbike while another man falls off of it and into the mud . <end>',\n",
              "  '<start> A motocross bike and sidecar team are riding around a bend on a muddy circuit . <end>',\n",
              "  '<start> The man falls out of the sidecar into a puddle during the race . <end>',\n",
              "  '<start> Two men riding a dirt bike and one is falling off into a mud puddle . <end>',\n",
              "  '<start> Two people are racing a sidecar motorcycle in the mud . <end>'],\n",
              " 'Flicker8k_Dataset/2984704498_29b53df5df.jpg': ['<start> A middle aged woman in stylish clothes , holding a camera . <end>',\n",
              "  '<start> A smartly dressed woman wearing a white jacket is holding a camera . <end>',\n",
              "  '<start> A woman dressed nicely stands happily with her camera . <end>',\n",
              "  '<start> a woman holds a camera . <end>',\n",
              "  '<start> A woman in a white jacket is smiling and holding a digital camera . <end>'],\n",
              " 'Flicker8k_Dataset/2883099128_0b056eed9e.jpg': ['<start> A man swings his racket at a tennis ball . <end>',\n",
              "  '<start> A man with no shirt is playing tennis . <end>',\n",
              "  '<start> A man without a shirt playing tennis . <end>',\n",
              "  '<start> A shirtless man is getting ready to hit a tennis ball . <end>',\n",
              "  '<start> A shirtless man playing tennis in an fenced-in area . <end>'],\n",
              " 'Flicker8k_Dataset/3398745929_8cd3bbb8a8.jpg': ['<start> An person runs at the waters edge at the ocean . <end>',\n",
              "  '<start> A person is running across the beach at the waters edge . <end>',\n",
              "  \"<start> A person 's legs , backlit , run through the surf . <end>\",\n",
              "  '<start> Someone runs along the beach in the bright sun . <end>',\n",
              "  \"<start> Someone 's legs are in frame running over a beach shore . <end>\"],\n",
              " 'Flicker8k_Dataset/3165826902_6bf9c4bdb2.jpg': ['<start> A boy is skating along a ledge in an indoor skate center . <end>',\n",
              "  '<start> A guy on Rollerblades is grinding on a rail in a skate park . <end>',\n",
              "  '<start> A rollerblader grinding down a narrow platform at an indoor skate park . <end>',\n",
              "  '<start> a roller-blader grinds a rail at an indoor skate park . <end>',\n",
              "  '<start> Young man with white helmet is rollerblading on a ledge <end>'],\n",
              " 'Flicker8k_Dataset/1072153132_53d2bb1b60.jpg': ['<start> A black and white dog catches a toy in midair . <end>',\n",
              "  '<start> A dog and a tennis ball . <end>',\n",
              "  '<start> A dog is jumping to catch a object thrown at it , <end>',\n",
              "  '<start> A dog leaps while chasing a tennis ball through a grassy field . <end>',\n",
              "  '<start> A multicolor dog jumping to catch a tennis ball in a grassy field . <end>'],\n",
              " 'Flicker8k_Dataset/3549408779_4d453db080.jpg': ['<start> A black and white dog is swimming in some water <end>',\n",
              "  '<start> A black and white dog swimming . <end>',\n",
              "  '<start> A black and white dog swims in blue water . <end>',\n",
              "  '<start> A small black and white dog is swimming in water . <end>',\n",
              "  '<start> A small black and white dog paddles in some clear blue water . <end>'],\n",
              " 'Flicker8k_Dataset/3027399066_ca85495775.jpg': ['<start> A group of greyhound dogs racing with muzzles covering their noses . <end>',\n",
              "  '<start> A group of greyhounds racing with jerseys and muzzles . <end>',\n",
              "  '<start> A group of racing dogs wearing striped uniforms with numbers run down a track . <end>',\n",
              "  '<start> Four greyhound dogs are racing against each other in a competition . <end>',\n",
              "  '<start> Racing dogs , wearing jerseys with numbers , run by . <end>'],\n",
              " 'Flicker8k_Dataset/2432038587_5e4148e277.jpg': ['<start> A black dog chasing geese . <end>',\n",
              "  '<start> A dog chases two geese . <end>',\n",
              "  '<start> A dog chasing 2 geese in an open field . <end>',\n",
              "  '<start> A large , black dog is chasing two geese in a field . <end>',\n",
              "  '<start> Dog runs after two geese in field <end>'],\n",
              " 'Flicker8k_Dataset/3282897060_8c584e2ce8.jpg': ['<start> A man who is resting his head on his hand . <end>',\n",
              "  '<start> A person wearing a white shirt sits and makes a face . <end>',\n",
              "  '<start> A woman is sitting up asleep with her head resting on her hand . <end>',\n",
              "  '<start> A woman resting her face on her hand . <end>',\n",
              "  '<start> This man appears to be sleeping while resting his head on his hand . <end>'],\n",
              " 'Flicker8k_Dataset/2278776373_fe499a93be.jpg': ['<start> A boy walks near buildings . <end>',\n",
              "  '<start> A man in a blue and purple striped shirt and hat is walking past a brick building . <end>',\n",
              "  '<start> A man walking down a street by a garage . <end>',\n",
              "  '<start> A person walking past a brick shed . <end>',\n",
              "  '<start> A young man in a white beanie is walking down the road and passing by a garage . <end>'],\n",
              " 'Flicker8k_Dataset/533713007_bf9f3e25b4.jpg': ['<start> A young boy sits at a picnic table and drinks out of a small cup . <end>',\n",
              "  '<start> Boy drinking , at backyard table full of bowls of food . <end>',\n",
              "  '<start> Child sitting at a backyard picnic table . <end>',\n",
              "  '<start> Little boy is drinking out of a glass at a picnic . <end>',\n",
              "  '<start> The boy drinks from a plastic glass while sitting at a table with food on it . <end>'],\n",
              " 'Flicker8k_Dataset/1594038143_57f299aa8a.jpg': ['<start> A man in a pink shirt is showing a magic trick to a boy in a blue shirt . <end>',\n",
              "  '<start> a small boy wearing a blue shirt pulling an item from a magicians hat . <end>',\n",
              "  \"<start> A smiling boy pulling something from a magician 's bag . <end>\",\n",
              "  '<start> A smiling boy pulls an orange object from a hat . <end>',\n",
              "  '<start> A young boy in a blue jacket pulls something black out of a fabric bag . <end>'],\n",
              " 'Flicker8k_Dataset/2892467862_52a3c67418.jpg': ['<start> A boy in a swimsuit is playing in gushing water . <end>',\n",
              "  '<start> A boy in shorts stands next to a jet of water . <end>',\n",
              "  '<start> A child and two dogs play in the water . <end>',\n",
              "  '<start> A child in black shorts is splashing in a fountain . <end>',\n",
              "  '<start> A young boy plays in the sprinklers , allowing the water to spray completely over his right arm . <end>'],\n",
              " 'Flicker8k_Dataset/1225443522_1633e7121f.jpg': ['<start> A girl walking alone at night on a street . <end>',\n",
              "  '<start> A woman in a blue coat and blue heels walks down a city sidewalk at night . <end>',\n",
              "  '<start> A woman walking down a brick sidewalk . <end>',\n",
              "  '<start> A woman walks down a brick sidewalk at night . <end>',\n",
              "  '<start> A woman walks down a city sidewalk at night . <end>'],\n",
              " 'Flicker8k_Dataset/3016200560_5bf8a70797.jpg': ['<start> A dog runs down a footbride in the fall . <end>',\n",
              "  '<start> A fluffy dog runs across a bridge near a forest . <end>',\n",
              "  '<start> a tan jump running across a narrow bridge . <end>',\n",
              "  '<start> A white dog is running over a bridge . <end>',\n",
              "  '<start> A white dog running over a bridge . <end>'],\n",
              " 'Flicker8k_Dataset/3111482098_11c0f4f309.jpg': ['<start> An ATV rides over a vaste sandy landscape . <end>',\n",
              "  '<start> A person on a large wheeled vehicle drives through an orange desert landscape . <end>',\n",
              "  '<start> A person on an ATV in dunes with a purple sky . <end>',\n",
              "  '<start> A person rides an ATV through the desert . <end>',\n",
              "  '<start> Distant person riding off-road vehicle across sand dunes marked with treads . <end>'],\n",
              " 'Flicker8k_Dataset/2476214153_99a3998509.jpg': ['<start> A boy in yellow shorts kicks a soccer ball in a basketball court . <end>',\n",
              "  '<start> A little boy in orange shorts and flip-flops plays soccer on a basketball court . <end>',\n",
              "  '<start> A young boy kicks a ball in an outdoor court . <end>',\n",
              "  '<start> Buy in orange shorts and flip flops plays with soccer ball . <end>',\n",
              "  '<start> Little boy kicking pink soccer ball on a basketball court . <end>'],\n",
              " 'Flicker8k_Dataset/2602085456_d1beebcb29.jpg': ['<start> A naked woman covered in mud in front of a crowd <end>',\n",
              "  '<start> A naked woman covered in paint <end>',\n",
              "  '<start> A topless woman is covered in mud . <end>',\n",
              "  '<start> Naked woman covered in mud in crowd <end>',\n",
              "  '<start> Topless woman smeared with brown substance , blurry crowd in background . <end>'],\n",
              " 'Flicker8k_Dataset/3635577874_48ebaac734.jpg': ['<start> A man rides his blue bike high in the air over a park . <end>',\n",
              "  '<start> a man wearing blue and riding a blue bike jumping in midair <end>',\n",
              "  '<start> Someone is airborne on a turquoise bicycle . <end>',\n",
              "  '<start> The boy is doing a stunt , through the air , on his bicycle . <end>',\n",
              "  '<start> The man is performing a trick high in the air with a bicycle . <end>'],\n",
              " 'Flicker8k_Dataset/3555729342_cc7a3b67fd.jpg': ['<start> A boy and a girl are standing near the water on a beach . <end>',\n",
              "  '<start> A girl in a cowboy hat and a boy standing on the ocean shore <end>',\n",
              "  '<start> A young boy and girl posing on the beach . <end>',\n",
              "  '<start> The boy and girl are standing in front of the ocean and mountains . <end>',\n",
              "  '<start> The boy in the gray t-shirt is standing next to the girl in the green dress and cowboy hat on the beach . <end>'],\n",
              " 'Flicker8k_Dataset/3730457171_e66dde8c91.jpg': ['<start> A little girl rides a toy bike and laughs . <end>',\n",
              "  '<start> A little girl rides a tricycle . <end>',\n",
              "  '<start> A little girl rides a tricycle . <end>',\n",
              "  '<start> A young girl rides on a toy bicycle with her mouth open . <end>',\n",
              "  '<start> Little girl riding her toy on the sidewalk . <end>'],\n",
              " 'Flicker8k_Dataset/2607099736_8681f601d9.jpg': ['<start> A gymnast is bending over on a yellow mat on the grass . <end>',\n",
              "  '<start> A wrestler jumping and pointing at the mat . <end>',\n",
              "  '<start> a young wrestler being thrown to the yellow mat . <end>',\n",
              "  '<start> The person in the blue shorts is wearing black shoes with white stripes . <end>',\n",
              "  '<start> Wrestler jumping in the air . <end>'],\n",
              " 'Flicker8k_Dataset/307327914_f98f576adb.jpg': ['<start> A closeup of an older man with glasses speaking . <end>',\n",
              "  '<start> A man wearing a blue shirt and glasses . <end>',\n",
              "  '<start> A man with black-rimmed glasses and a mustache is talking . <end>',\n",
              "  '<start> A man with glasses and a mustache is in the middle of a sentence . <end>',\n",
              "  '<start> An older man with glasses is looking off camera . <end>'],\n",
              " 'Flicker8k_Dataset/3741462565_cc35966b7a.jpg': ['<start> A little girl wearing a pink shirt is sitting at the table and drinking a milkshake <end>',\n",
              "  '<start> A small young girl in a pink shirt drinking a large chocolate milkshake . <end>',\n",
              "  '<start> A young girl dressed in pink with a hair barrette pursing her lips at a big chocolate milkshake . <end>',\n",
              "  '<start> A young girl is staring at a large milkshake in a glass . <end>',\n",
              "  '<start> A young girl looks excitedly at a large milkshake . <end>'],\n",
              " 'Flicker8k_Dataset/515702827_be3c6ce857.jpg': ['<start> A child in a pink hat on a pink surfboard . <end>',\n",
              "  '<start> A girl in pink and man in black paddle through water . <end>',\n",
              "  '<start> A man in a black shirt swims next to a girl on a pink surfboard . <end>',\n",
              "  '<start> A man swimming beside a girl on a pink body board . <end>',\n",
              "  '<start> Two children splash through the water , one is wearing a pink swim cap . <end>'],\n",
              " 'Flicker8k_Dataset/3134092148_151154139a.jpg': ['<start> A guy on a surfboard . <end>',\n",
              "  '<start> A man is surfing on a white surfboard with his hands upraised . <end>',\n",
              "  '<start> A man surfing a wave . <end>',\n",
              "  '<start> A surfer is doing a turn on his board . <end>',\n",
              "  '<start> Surfer in wetsuit riding a wave . <end>'],\n",
              " 'Flicker8k_Dataset/3665996775_6d7d9a46f1.jpg': ['<start> A little girl is wearing a flowing dress and carrying water balloons . <end>',\n",
              "  '<start> A young girl in a pink dress with something in her hand . <end>',\n",
              "  '<start> A young girl in a red dress and black shirt with two purple water balloons . <end>',\n",
              "  '<start> A young girl wearing a pink tutu . <end>',\n",
              "  '<start> The girl is wearing a pink tutu and walking through the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3453284877_8866189055.jpg': ['<start> A guy is grinding a rail over a tree on his snowboard . <end>',\n",
              "  '<start> A man snowboarding making a jump off a steel guardrail . <end>',\n",
              "  '<start> A snowboarder grinding up a homemade ramp . <end>',\n",
              "  '<start> a snowboarder is riding his board on ramp made from a piece of metal and a log . <end>',\n",
              "  '<start> The man is skateboarding over a log in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/2464259416_238ef13a2e.jpg': ['<start> A black and brown dog and a grey poodle sticking its butt in the air on the sand . <end>',\n",
              "  '<start> There are two dogs playing in the dirt . <end>',\n",
              "  '<start> Two bigs dogs play with each other . <end>',\n",
              "  '<start> Two dogs are playing in the sand . <end>',\n",
              "  '<start> Two dogs looks at each other while standing on the dirt . <end>'],\n",
              " 'Flicker8k_Dataset/3604391853_b4809fcb8c.jpg': ['<start> a man in a red shirt is laying on the grass reaching out to another person . <end>',\n",
              "  '<start> A man is lying in the grass with his arms outstretched . <end>',\n",
              "  '<start> A man , lying on the grass , hand outstretched to another arm . <end>',\n",
              "  '<start> a man on the ground stretches his hands out to another person . <end>',\n",
              "  '<start> A man reaching for someone on the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3146630574_05d9ebbed1.jpg': ['<start> A black and white dog is running through the water while holding something red in its mouth . <end>',\n",
              "  '<start> A dog is running along a beach with a red object in its mouth . <end>',\n",
              "  '<start> A dog is running in water with a red stick in its mouth <end>',\n",
              "  '<start> A dog runs on the beach with a red toy with a string in his mouth . <end>',\n",
              "  '<start> The brown and white dog is running across the sand with a red object in his mouth . <end>'],\n",
              " 'Flicker8k_Dataset/1019077836_6fc9b15408.jpg': ['<start> A brown dog chases the water from a sprinkler on a lawn . <end>',\n",
              "  '<start> a brown dog plays with the hose . <end>',\n",
              "  '<start> A brown dog running on a lawn near a garden hose <end>',\n",
              "  '<start> A dog is playing with a hose . <end>',\n",
              "  '<start> Large brown dog running away from the sprinkler in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/2578834476_118585730d.jpg': ['<start> A boy mountain bikes down a trail . <end>',\n",
              "  '<start> A dirt biker goes down a dirt hill . <end>',\n",
              "  '<start> A person rides his mountain bike down a steep hill in the woods . <end>',\n",
              "  '<start> A person with a helmet is riding a bike i the grass and dirt . <end>',\n",
              "  '<start> The man races his bike down the hill . <end>'],\n",
              " 'Flicker8k_Dataset/476760133_c33d2bd83d.jpg': ['<start> A black dog is running across the grass carrying something in its mouth . <end>',\n",
              "  '<start> A black dog is running outside with a toy in its mouth . <end>',\n",
              "  '<start> A black dog runs along the green grass carrying a toy in its mouth . <end>',\n",
              "  '<start> A black dog runs on green grass with a toy in his mouth . <end>',\n",
              "  '<start> Black dog is carrying something in its mouth and running in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/95734036_bef6d1a871.jpg': ['<start> a biker bikes in the mountains . <end>',\n",
              "  '<start> A male bicyclist on a mountain road . <end>',\n",
              "  '<start> A man biking in front of mountains . <end>',\n",
              "  '<start> A man is biking down really rough terrain . <end>',\n",
              "  '<start> Man on bicycle trek high in the mountains . <end>'],\n",
              " 'Flicker8k_Dataset/3587596696_9c5964c94d.jpg': ['<start> A Frisbee team huddles around a Frisbee , each holding a part of it . <end>',\n",
              "  '<start> A group of people hold a Frisbee with their fingers . <end>',\n",
              "  '<start> A group of people put two of their fingers on a Frisbee . <end>',\n",
              "  '<start> people put their hands on a Frisbee . <end>',\n",
              "  '<start> several young children with their fingertips on the egde of a white Frisbee <end>'],\n",
              " 'Flicker8k_Dataset/540604040_bec822c144.jpg': ['<start> A girl sliding down a pole <end>',\n",
              "  '<start> A small child with a ponytail dressed in jean shorts and a pink and brown shirt climbs on a pole near wooden playground equipment . <end>',\n",
              "  '<start> A young asian girl is sliding down a pole on outdoor playground equipment . <end>',\n",
              "  '<start> A young girl slides down a bar in a play structure . <end>',\n",
              "  '<start> A young girl sliding down a black pole . <end>'],\n",
              " 'Flicker8k_Dataset/2467856402_0490413d38.jpg': ['<start> A big brother helps a little sister blow bubbles . <end>',\n",
              "  '<start> A boy helping a younger girl blow bubbles . <end>',\n",
              "  '<start> A girl in a black shirt blowing bubbles . <end>',\n",
              "  '<start> A little girl is blowing bubbles through a yellow hoop . <end>',\n",
              "  '<start> A little girl with blonde hair and a blue shirt is blowing bubbles outside with someone . <end>'],\n",
              " 'Flicker8k_Dataset/544576742_283b65fa0d.jpg': ['<start> A rock climber repels off a rocky wall . <end>',\n",
              "  '<start> A woman climbing a rock cliff . <end>',\n",
              "  '<start> A woman in jeans rock climbing . <end>',\n",
              "  '<start> The woman is holding onto a huge rock and has red string around her . <end>',\n",
              "  '<start> Woman goes rock climbing . <end>'],\n",
              " 'Flicker8k_Dataset/1417941060_2a0f7908bc.jpg': ['<start> A baby plays with a young boys face . <end>',\n",
              "  '<start> A baby touches the mans face while he is lying down . <end>',\n",
              "  '<start> A boy who seems ill is being touched in the face by a toddler . <end>',\n",
              "  '<start> A little baby holds the head of his older brother <end>',\n",
              "  '<start> An infant sitting on a cot reaching over to touch the face of an older boy . <end>'],\n",
              " 'Flicker8k_Dataset/2181117039_c4eea8036e.jpg': ['<start> Adults , and children in school uniforms , move through a flock of pigeons . <end>',\n",
              "  '<start> A pair of children in uniforms running through a flock of pigeons . <end>',\n",
              "  '<start> Children in uniforms chase pigeons . <end>',\n",
              "  '<start> Schoolchildren chase some pigeons . <end>',\n",
              "  '<start> Two children in school uniforms chasing birds on a brick paved street . <end>'],\n",
              " 'Flicker8k_Dataset/2728486640_cc2a31d2b0.jpg': ['<start> A dog catching a biscuit in its mouth . <end>',\n",
              "  '<start> A white dog catching a milkbone in his mouth <end>',\n",
              "  '<start> A white dog catching a treat in his mouth . <end>',\n",
              "  '<start> A white dog is jumping for a treat <end>',\n",
              "  '<start> A white dog , with a black collar , opens its mouth wide while in front of a white building . <end>'],\n",
              " 'Flicker8k_Dataset/3242354561_54e5a34925.jpg': ['<start> A blonde dog is catching a ball in its mouth in the snow . <end>',\n",
              "  '<start> A brown dog is catching a ball in its mouth whilst playing in a snow covered field . <end>',\n",
              "  '<start> A dog catching an orange ball , in the snow . <end>',\n",
              "  '<start> A golden retriever catches a tennis ball in the snow . <end>',\n",
              "  '<start> A tan dog catches an orange ball in the snowy yard . <end>'],\n",
              " 'Flicker8k_Dataset/2836360729_6500249fe6.jpg': ['<start> A person buried in moss . <end>',\n",
              "  '<start> A woman is sitting at the beach covered by a lot of seaweed . <end>',\n",
              "  '<start> A woman on the beach is covered in seaweed . <end>',\n",
              "  '<start> A young person is buried in a pile of seaweed on a beach . <end>',\n",
              "  '<start> The smiling woman at the beach is buried in seaweed . <end>'],\n",
              " 'Flicker8k_Dataset/1089755335_0bfbfd30e6.jpg': ['<start> A mother and children is fishing on a boardwalk at night . <end>',\n",
              "  '<start> A woman and three children stand on a deck with a fishing pole . <end>',\n",
              "  '<start> A woman stands with children on a boardwalk at night overlooking the sea . <end>',\n",
              "  '<start> Some people on a pier at night with one girl fishing off it . <end>',\n",
              "  '<start> Woman with three children fishing over boardwalk in the evening . <end>'],\n",
              " 'Flicker8k_Dataset/3310551665_15b79ef4ea.jpg': ['<start> A child looks into a giant bubble . <end>',\n",
              "  '<start> A kid in yellow poking his face inside a bubble . <end>',\n",
              "  '<start> Asian boy puts his head inside a large bubble . <end>',\n",
              "  '<start> a young boy sticking his head inside a huge bubble <end>',\n",
              "  '<start> Child in yellow shirt with head inside of a large bubble . <end>'],\n",
              " 'Flicker8k_Dataset/2728813605_cfc943e1ab.jpg': ['<start> A mature woman in sunglasses and a jean jacket . <end>',\n",
              "  '<start> An elderly lady in sunglasses and a denim jacket . <end>',\n",
              "  '<start> an elderly woman wearing a denim jacket and sunglasses is posing for a picture in front of a green bush . <end>',\n",
              "  '<start> An older woman with gray hair wears sunglasses , a necklace , earrings , and blue shirt and jacket . <end>',\n",
              "  '<start> An old woman in sunglasses and a jean jacket smiles for the camera . <end>'],\n",
              " 'Flicker8k_Dataset/2112921744_92bf706805.jpg': ['<start> A dog on a green hillside . <end>',\n",
              "  '<start> A dog standing on the side of a mountain . <end>',\n",
              "  '<start> A dog stands on the side of a grassy cliff . <end>',\n",
              "  '<start> A fluffy white dog looks down a steep , grassy embankment . <end>',\n",
              "  '<start> A white dog is standing on a grassy hillside . <end>'],\n",
              " 'Flicker8k_Dataset/2279980395_989d48ae72.jpg': ['<start> A girl is buried under several playground balls . <end>',\n",
              "  '<start> A laughing baby is surrounded by balls of various colors . <end>',\n",
              "  '<start> A smiling child is surrounded by colored balls . <end>',\n",
              "  '<start> Little girl lying in many colored plastic balls . <end>',\n",
              "  '<start> The child is covered with colorful balls . <end>'],\n",
              " 'Flicker8k_Dataset/1579798212_d30844b4c5.jpg': ['<start> a child is laying in a bubble bath holding a yellow scrubbing brush up to his mouth as if singing into a microphone . <end>',\n",
              "  '<start> A child sings into a loofa in the bathtub <end>',\n",
              "  '<start> A little boy is laying down in a bubble bath . <end>',\n",
              "  '<start> Boy in bubble bath , yelling or singing into scrubbing brush . <end>',\n",
              "  '<start> The child is surrounded by bubbles while in the bathtub . <end>'],\n",
              " 'Flicker8k_Dataset/2109911919_af45b93ef3.jpg': ['<start> A person climbing up a snowy mountain . <end>',\n",
              "  '<start> A person climbing up the side of a snowy mountain to fetch his or her ski poles . <end>',\n",
              "  '<start> A skier climbs up a snowy trail toward his poles . <end>',\n",
              "  '<start> A climber with a backpack accends a snow covered mountain . <end>',\n",
              "  '<start> Man climbing a steep snow-covered slope . <end>'],\n",
              " 'Flicker8k_Dataset/2994205788_f8b3f2e840.jpg': ['<start> A man asleep on the ground at a subway station , holding a camera tripod . <end>',\n",
              "  '<start> A man holding a telescope and lying down on a train platform . <end>',\n",
              "  '<start> A man lays against a wall near train tracks . <end>',\n",
              "  '<start> A man rests against a cement pillar with his hands on metal equipment . <end>',\n",
              "  '<start> A man sleeping on the ground in a subway . <end>'],\n",
              " 'Flicker8k_Dataset/3151492269_28d8edaa68.jpg': ['<start> A brown dog is running next to a chain link fence while a darker dog stands nearby . <end>',\n",
              "  '<start> Two dogs in a yard . <end>',\n",
              "  '<start> Two dogs run around inside a fence . <end>',\n",
              "  '<start> Two dogs standing in the grass , one is running . <end>',\n",
              "  '<start> Two greyhounds are playing in a fenced yard . <end>'],\n",
              " 'Flicker8k_Dataset/3203878596_cbb307ce3b.jpg': ['<start> Two brown dogs are playing with each other in the snow . <end>',\n",
              "  '<start> Two brown dogs chase each other in the snow . <end>',\n",
              "  '<start> Two brown dogs play in the snow . <end>',\n",
              "  '<start> Two dogs playing in the snow . <end>',\n",
              "  '<start> Two dogs playing or fighting in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/2256231539_05c27179f1.jpg': ['<start> A child holds a football and runs from other children . <end>',\n",
              "  '<start> A young boy in a blue uniform running with a football while playing a game of flag football . <end>',\n",
              "  '<start> A young boy weating blue shorts and cleats holding a football running from other boys . <end>',\n",
              "  '<start> A young male carrying a football and running while two other boys run behind him . <end>',\n",
              "  '<start> The boy in blue runs with the ball whilst being chased by two boys in red . <end>'],\n",
              " 'Flicker8k_Dataset/2685788323_ceab14534a.jpg': ['<start> A man in sunglasses gets ready to pull a chair out to sit down for his meal . <end>',\n",
              "  '<start> A man wearing sunglasses stands by a table at a cafe . <end>',\n",
              "  '<start> Man about to pull out chair and sit down at a restaurant . <end>',\n",
              "  '<start> Man at eatery getting ready to sit down . <end>',\n",
              "  '<start> The large man grabs a seat at a restaurant . <end>'],\n",
              " 'Flicker8k_Dataset/3288274849_07ff76ee93.jpg': ['<start> A person jumping down a hill on his snowboard in the winter <end>',\n",
              "  '<start> A snowboarder glides down a stair rail . <end>',\n",
              "  '<start> A snowboarder goes down a short hill next to stairs . <end>',\n",
              "  '<start> A snowboarder is going down a snowy hill next to a staircase behind a building . <end>',\n",
              "  '<start> Person snowboarding on hill near snow covered stairs with buildings nearby . <end>'],\n",
              " 'Flicker8k_Dataset/1303727828_d1052ee341.jpg': ['<start> A man in a feather hat looking down . <end>',\n",
              "  '<start> A person wears a headdress and sunglasses . <end>',\n",
              "  '<start> A woman in a floral print dress and a shaved head at a store . <end>',\n",
              "  '<start> A woman with a crazy hairdo is shopping outside . <end>',\n",
              "  '<start> The person wearing earrings is wearing a feathered hat . <end>'],\n",
              " 'Flicker8k_Dataset/3352791995_8db4979aca.jpg': [\"<start> A boy looks up into a woman 's face . <end>\",\n",
              "  \"<start> A child embraces its mother 's red coat . <end>\",\n",
              "  '<start> A child puts his hands to the belly of a woman in a red coat . <end>',\n",
              "  '<start> A young boy is touching the stomach of a pregnant woman . <end>',\n",
              "  '<start> The woman in the red jacket looks at the child in a green jacket . <end>'],\n",
              " 'Flicker8k_Dataset/2787868417_810985234d.jpg': ['<start> a blond girl in a pink bathing suit running through the sprinklers <end>',\n",
              "  '<start> A girl in pink runs through a sprinkler . <end>',\n",
              "  '<start> A girl runs through sprinklers on a lawn . <end>',\n",
              "  '<start> A little girl in pink in running through a sprinkler . <end>',\n",
              "  '<start> A little girl wearing a pink dress is running across the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3009018821_ba47396e24.jpg': ['<start> A girl in a swimming pool playing badminton while a lady watches . <end>',\n",
              "  '<start> A woman in a pink bathing suit holds a badminton racket while another lady looks on . <end>',\n",
              "  '<start> A woman sits and watches another woman play in the pool . <end>',\n",
              "  '<start> One woman sitting beside the pool while another plays badminton in the pool . <end>',\n",
              "  '<start> Woman playing badminton in the pool while another woman looks on . <end>'],\n",
              " 'Flicker8k_Dataset/380537190_11d6c0a412.jpg': ['<start> A group of people stand at a farmers market on a dreary day . <end>',\n",
              "  '<start> a white tented fruit stand with several people shopping in it . <end>',\n",
              "  '<start> People shop for fresh produce at an outdoor market in the city . <end>',\n",
              "  '<start> People visiting a street market . <end>',\n",
              "  \"<start> Several people shop at an outdoor farmer 's market on a cloudy day . <end>\"],\n",
              " 'Flicker8k_Dataset/224026428_0165164ceb.jpg': ['<start> A child looks at a guard in red uniform from the other side of a fence <end>',\n",
              "  '<start> a little boy is watching a palace guard stand outside a little black hut . <end>',\n",
              "  '<start> A little boy looling over the fence at a guard standing in front of a black shed . <end>',\n",
              "  '<start> A little kid stands and looks at the military guard who is guarding a building . <end>',\n",
              "  '<start> A young boy stands and watches a British guardsman . <end>'],\n",
              " 'Flicker8k_Dataset/2665586311_9a5f4e3fbe.jpg': ['<start> A girl in pink pants running , an ornate Spanish ruin in the background . <end>',\n",
              "  '<start> The girl dressed in purple walks through the alley , followed by a girl in pink . <end>',\n",
              "  '<start> Two children within the ruins of a building . <end>',\n",
              "  '<start> Two girls , one running away from the wall . <end>',\n",
              "  '<start> Two little girls play around an old abandoned building . <end>'],\n",
              " 'Flicker8k_Dataset/3046429283_08de594901.jpg': ['<start> A man in a leather jacket and leather boots . <end>',\n",
              "  '<start> A man in mostly leather clothing stands in a nighttime entertainment area . <end>',\n",
              "  '<start> A man wearing a leather jacket poses in front of the camera . <end>',\n",
              "  '<start> Black man in black leather jacket <end>',\n",
              "  '<start> Man in leather motorcycle gear . <end>'],\n",
              " 'Flicker8k_Dataset/872512911_ca383b40e4.jpg': ['<start> Large group of people , most setting down on a walkway with two boys standing up holding plates . <end>',\n",
              "  '<start> Many people are sitting and observing or going into a water attraction . <end>',\n",
              "  '<start> Many people sit or stand around the fountain near the Space Needle . <end>',\n",
              "  '<start> People sit by a fountain , a guy with purple hair talks to a guy in a hat . <end>',\n",
              "  '<start> Two men , one with purple hair , at crowded fountain near Seattle Space Needle . <end>'],\n",
              " 'Flicker8k_Dataset/3082474922_9c3533eaf6.jpg': ['<start> A boy is pushing a sledge through the snow at night . <end>',\n",
              "  '<start> A boy with a red hat pushing a snowploe through the snow <end>',\n",
              "  '<start> A small child wearing a red winter cap and a blue and black snowsuit pushing a plow through snow . <end>',\n",
              "  '<start> A young child plows snow manually . <end>',\n",
              "  '<start> Boy wearing red hat , blue jacket pushing plow in snow . <end>'],\n",
              " 'Flicker8k_Dataset/3587077732_0933f1677b.jpg': ['<start> a boy runs through the puddle . <end>',\n",
              "  '<start> A boy splashing in a puddle . <end>',\n",
              "  '<start> A young boy is running through a large puddle outside . <end>',\n",
              "  '<start> A young boy is splashing through a puddle of water . <end>',\n",
              "  '<start> Young boy playing in the water . <end>'],\n",
              " 'Flicker8k_Dataset/3396817186_b299ee0531.jpg': ['<start> A brown and white dog has caught a yellow ball in a grassy field surrounded by trees . <end>',\n",
              "  '<start> a brown dog with a yellow toy in his mouth is jumping off the grassy ground <end>',\n",
              "  '<start> A fluffy brown dog jumping with a ball in his mouth . <end>',\n",
              "  '<start> A white fluffy dog is jumping and catching a toy . <end>',\n",
              "  '<start> The shaggy dog leaps and catches the ball . <end>'],\n",
              " 'Flicker8k_Dataset/3364796213_b8948913b5.jpg': ['<start> A crowd of joyful people parade through an Asian street with black banners . <end>',\n",
              "  '<start> A crowd of people carrying flags bike and walk through the streets . <end>',\n",
              "  '<start> A group of people riding double on bicycles carrying black flags . <end>',\n",
              "  '<start> Asian people are riding bike and holding up banners in a parade . <end>',\n",
              "  '<start> People ride bikes and carry black flags along a road where others are gathered . <end>'],\n",
              " 'Flicker8k_Dataset/3467843559_a457ce37b6.jpg': ['<start> A group of boys sits near the sidewalk and two are smiling while one makes a face . <end>',\n",
              "  '<start> Three boys are posing for a picture , one of them making a silly face . <end>',\n",
              "  '<start> Three boys pose on sidewalk , one boy holding a camera . <end>',\n",
              "  '<start> Three young boys one is holding a camera and another is holding a green toy all are wearing tee shirts and smiling . <end>',\n",
              "  '<start> Three young boys playing outside and posing for a picture <end>'],\n",
              " 'Flicker8k_Dataset/3435015880_eda46ff50f.jpg': ['<start> a guy and a girl jumping up in the air <end>',\n",
              "  '<start> A man and a woman are running and jumping on top of a hill . <end>',\n",
              "  '<start> Two people are running at the top of a mountain . <end>',\n",
              "  '<start> Two people jump up and down on a cliff overlooking a valley . <end>',\n",
              "  '<start> Two women jump in the grass atop a mountain . <end>'],\n",
              " 'Flicker8k_Dataset/3331797838_b3e33dbe17.jpg': ['<start> A blurred vision of a bike rider in front of a hill top . <end>',\n",
              "  '<start> Two bicyclists ride on a road near a green hilly area , one is blurry . <end>',\n",
              "  '<start> two bikers bike across the countryside . <end>',\n",
              "  '<start> Two people ride bike in countryside . <end>',\n",
              "  '<start> Two people , wearing long sleeves and helmets , ride bikes downhill . <end>'],\n",
              " 'Flicker8k_Dataset/133905560_9d012b47f3.jpg': ['<start> A puppy plays with an adult dog in the snow . <end>',\n",
              "  '<start> One dog climbing on the back of another dog in the snow . <end>',\n",
              "  '<start> Two beige dogs are playing in the snow . <end>',\n",
              "  '<start> Two dogs , on standing on the other in the snow . <end>',\n",
              "  '<start> Two yellow labs are playing in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/3025495499_b15797b452.jpg': ['<start> a tennis player hits the ball . <end>',\n",
              "  '<start> A tennis player hits the ball and makes a serious face . <end>',\n",
              "  '<start> A woman in a green sport outfit is attempting to hit a tennis ball with a racket . <end>',\n",
              "  '<start> A young woman in a dark green tennis outfit serves the ball . <end>',\n",
              "  '<start> Female tennis player dressed in green hits yellow ball <end>'],\n",
              " 'Flicker8k_Dataset/3177799416_5bd0382370.jpg': ['<start> A person snowboarding down a snowy hill . <end>',\n",
              "  '<start> A snowboarder is coming down a hill . <end>',\n",
              "  '<start> Person snowboarding down a snow covered slope . <end>',\n",
              "  '<start> Someone is snowboarding down a hill , shredding snow . <end>',\n",
              "  '<start> The man is snowboarding down a snowy hill . <end>'],\n",
              " 'Flicker8k_Dataset/3477315700_52a4d740a5.jpg': ['<start> A little girl in a harness is in midair on a sunny day . <end>',\n",
              "  '<start> A little girl in a pink jacket and hat is swinging in a harness attached to yellow ropes . <end>',\n",
              "  '<start> A young child jumps in a bungee seat in front of a blue sky and tree . <end>',\n",
              "  '<start> Little girl in pink coat on a swing . <end>',\n",
              "  '<start> The little girl wearing pink is having fun bungee jumping . <end>'],\n",
              " 'Flicker8k_Dataset/2949880800_ca9a1bb7e6.jpg': ['<start> two children in swimsuits stand talking in a lake in the woods . <end>',\n",
              "  '<start> Two girls in bathing suits are standing in the water facing each other . <end>',\n",
              "  '<start> Two girls play in the beach . <end>',\n",
              "  '<start> Two girls wearing bikins are standing in the lake , <end>',\n",
              "  '<start> Two young girls in a lake talking to each other . <end>'],\n",
              " 'Flicker8k_Dataset/3266306177_7994dc2865.jpg': ['<start> A brown dog is running in the snow with a smaller black dog running behind it . <end>',\n",
              "  '<start> A large brown dog and small black dog walk on the snow . <end>',\n",
              "  '<start> A little black dog and a large brown dog are out in the snow . <end>',\n",
              "  '<start> Two dogs , a big dog and a small dog , run in the snow . <end>',\n",
              "  '<start> Two dogs are standing in snow , the smaller one barking at the larger one . <end>'],\n",
              " 'Flicker8k_Dataset/2531942624_c3c072064e.jpg': ['<start> A boy in a green striped top is running barefoot through the sand . <end>',\n",
              "  '<start> A boy runs through the sand . <end>',\n",
              "  '<start> A boy wearing a striped shirt runs barefoot in the sandy hill . <end>',\n",
              "  '<start> A young boy in a stripped shirt running down a sand dune . <end>',\n",
              "  '<start> The youngster enjoys playing in the sand . <end>'],\n",
              " 'Flicker8k_Dataset/1808370027_2088394eb4.jpg': ['<start> A dog swims towards a waterfall . <end>',\n",
              "  '<start> a tan and white dog swimming towards a waterfall <end>',\n",
              "  '<start> A yellow dog swims towards a waterfall . <end>',\n",
              "  '<start> The dog swims through the water toward the waterfall . <end>',\n",
              "  '<start> The dog swims towards a waterfall . <end>'],\n",
              " 'Flicker8k_Dataset/2833431496_09d999db4d.jpg': ['<start> A boy and a girl are bending under a fence to look over a ledge . <end>',\n",
              "  '<start> Two children look down squeezing through a fence . <end>',\n",
              "  '<start> Two children peek through a fence and down at water . <end>',\n",
              "  '<start> Two children peer over a rusty ledge . <end>',\n",
              "  '<start> Two children trying to squeeze under some metal bars <end>'],\n",
              " 'Flicker8k_Dataset/308307853_5a51fbdecc.jpg': ['<start> A dog plays on the beach . <end>',\n",
              "  '<start> A white dog is running around a tumbleweed on a sand dune . <end>',\n",
              "  '<start> A white dog walks across the sandy ground with a tumbleweed . <end>',\n",
              "  '<start> A white poodle circles a sparkler embedded in sand . <end>',\n",
              "  '<start> poodle playing on a beach <end>'],\n",
              " 'Flicker8k_Dataset/3603301825_5817727be2.jpg': ['<start> A goalie blocks the puck in a field hockey game . <end>',\n",
              "  '<start> a goalie makes an amazing save . <end>',\n",
              "  '<start> A group of men playing Lacrosse at night . <end>',\n",
              "  '<start> Five men playing a sport on a field with multicolored shirts on . <end>',\n",
              "  '<start> The hockey goalkeeper is reaching out for the ball . <end>'],\n",
              " 'Flicker8k_Dataset/425706089_f138118e12.jpg': ['<start> Two men are standing outside a restaurant at dusk . <end>',\n",
              "  '<start> Two men drink stand in front of a brightly lit restaurant , drinking soda <end>',\n",
              "  '<start> Two men outside of a restaurant . <end>',\n",
              "  '<start> Two men stand in front of a restaurant . <end>',\n",
              "  '<start> Two older men standing in front of a store of sorts . <end>'],\n",
              " 'Flicker8k_Dataset/3663307538_468739e4c3.jpg': ['<start> A group of people sitting in a pink room with candles . <end>',\n",
              "  '<start> A large group of people are sitting down inside a building with red and yellow lights everywhere . <end>',\n",
              "  '<start> People are sitting at square tables in a red room . <end>',\n",
              "  '<start> People in a dimly lit lounge . <end>',\n",
              "  '<start> Several people sitting at small tables in a darkened room . <end>'],\n",
              " 'Flicker8k_Dataset/2176874361_2b4149010b.jpg': ['<start> A black dog runs in front of a large brown and white bull . <end>',\n",
              "  '<start> A dog and a cow play together inside the fence . <end>',\n",
              "  '<start> a small black dog growling at a large brown and white cow . <end>',\n",
              "  '<start> Running dog and cow in fenced area . <end>',\n",
              "  '<start> The dog is running around the cow . <end>'],\n",
              " 'Flicker8k_Dataset/3195969533_98f5de0fab.jpg': ['<start> The black dog on the right is dominant over the other two dogs . <end>',\n",
              "  '<start> Three dogs are running around in the snow . <end>',\n",
              "  '<start> Three dogs in the snow . <end>',\n",
              "  '<start> Three dogs playing in the deep snow outside . <end>',\n",
              "  '<start> Three large dogs run around in white snow . <end>'],\n",
              " 'Flicker8k_Dataset/2226534154_cbcab7ba32.jpg': ['<start> A woman in a purple dress plays with her hair while waiting in a lobby . <end>',\n",
              "  '<start> A woman in a purple dress rubs her head as other people look on . <end>',\n",
              "  '<start> People are gathered at a bar . <end>',\n",
              "  '<start> The woman in the purple dress is looking towards the people at the door with her hand running through her hair . <end>',\n",
              "  '<start> Woman at bar looks on at another woman being approached by a man <end>'],\n",
              " 'Flicker8k_Dataset/2877511986_c965ced502.jpg': ['<start> A girl does a back bend on the beach . <end>',\n",
              "  '<start> A girl doing a back bend at the beach . <end>',\n",
              "  '<start> A girl performs a back bend in the ocean water . <end>',\n",
              "  '<start> A woman in a red , white and blue bathing suit doing a back bend on the beach . <end>',\n",
              "  '<start> A young girl , in a stars and stripes bathing suit , does a back flip on the beach . <end>'],\n",
              " 'Flicker8k_Dataset/3476237185_9389c536a3.jpg': ['<start> A large and a small dog are standing beside each other in a fence . <end>',\n",
              "  '<start> a large black dog chases a small black dog . <end>',\n",
              "  '<start> A large black dog towers over a far smaller black dog . <end>',\n",
              "  '<start> The big black dog is behind the little black dog . <end>',\n",
              "  '<start> Two black dogs are standing on the grass by a wooden fence . <end>'],\n",
              " 'Flicker8k_Dataset/3420278866_1d17c12713.jpg': ['<start> Andy Rodderick gets ready to hit a tennis ball . <end>',\n",
              "  '<start> Andy Roddick plays tennis . <end>',\n",
              "  '<start> A tennis player in mid game holding a racquet . <end>',\n",
              "  '<start> Man dressed in black and white holds his tennis racket up waiting for the ball . <end>',\n",
              "  '<start> Tennis player getting ready to play tennis . <end>'],\n",
              " 'Flicker8k_Dataset/356143774_ef3e93eede.jpg': ['<start> A pair of long necked birds swimming . <end>',\n",
              "  '<start> Two swans glide on river . <end>',\n",
              "  '<start> Two swans swimming in the water . <end>',\n",
              "  '<start> Two swans swimming near the shore . <end>',\n",
              "  '<start> Two white swans in the lake . <end>'],\n",
              " 'Flicker8k_Dataset/3425685827_03683e8e5a.jpg': ['<start> A group of people sitting in a grassy area under a pink and white blossoming tree . <end>',\n",
              "  '<start> People are sitting at a park under flowering trees . <end>',\n",
              "  '<start> People outside sitting on the grass under cherry blossom trees . <end>',\n",
              "  '<start> The students sitting on the grass are eating a lunch from a red backpack . <end>',\n",
              "  '<start> Young people sit on the grass near a crooked tree with pink blossoms . <end>'],\n",
              " 'Flicker8k_Dataset/2607383384_d9ce9de793.jpg': ['<start> Four women wearing energizer bunny ears point to an attraction . <end>',\n",
              "  '<start> Several women , wearing pink \" Energizer \" bunny ears , point to the right . <end>',\n",
              "  '<start> There are 4 women wearing pink Energizer bunny ears . <end>',\n",
              "  '<start> The women have pink bunny ears on their heads . <end>',\n",
              "  '<start> Women wearing bunny ears and race numbers point at something in the distance . <end>'],\n",
              " 'Flicker8k_Dataset/2874876837_80d178ba9b.jpg': ['<start> A boy bouncing on a trampoline . <end>',\n",
              "  '<start> A boy jumping on a trampoline . <end>',\n",
              "  '<start> A boy jumps on a trampoline . <end>',\n",
              "  '<start> A little boy in a white long sleeved t-shirt jumps on a trampoline . <end>',\n",
              "  '<start> Boy jumps on trampoline outside house . <end>'],\n",
              " 'Flicker8k_Dataset/3503624011_733d745d5a.jpg': ['<start> a girl with a star painted on her face smiles . <end>',\n",
              "  '<start> A lady in a sequined hat with red face paint . <end>',\n",
              "  '<start> A woman wearing a red hat and face paint smiles at another woman . <end>',\n",
              "  '<start> A woman with a painted face smiling . <end>',\n",
              "  '<start> The woman has her face painted with a red star and is drinking a beer . <end>'],\n",
              " 'Flicker8k_Dataset/2526041608_a9775ab8d7.jpg': ['<start> A boy in a yellow uniform carrying a football is blocking another boy in a blue uniform . <end>',\n",
              "  '<start> A football player in a yellow jersey is pushing away another player . <end>',\n",
              "  '<start> The young football player is trying to avoid being tackled . <end>',\n",
              "  '<start> Two boys playing football on opposing teams . <end>',\n",
              "  '<start> Two young football players wearing blue and yellow uniforms fight for the ball . <end>'],\n",
              " 'Flicker8k_Dataset/3296715418_29542dcdc2.jpg': ['<start> A beautiful white dog walking in the brown grass . <end>',\n",
              "  '<start> A white dog plays in the grass . <end>',\n",
              "  '<start> A white dog walks over the short grass . <end>',\n",
              "  '<start> The white dog walks along the dead grass with its tongue out . <end>',\n",
              "  '<start> White dog walking outside . <end>'],\n",
              " 'Flicker8k_Dataset/3733074526_82aa8d5f8d.jpg': ['<start> A girl in a costume participates in a parade . <end>',\n",
              "  '<start> A girl in a red and white costume standing on the street . <end>',\n",
              "  '<start> A girl in a red and white costume with onlookers behind her . <end>',\n",
              "  '<start> A small girl dancing in a parade wearing bright red and gold clothes . <end>',\n",
              "  '<start> Children in flamboyant red , white , and gold costumes dancing in a parade . <end>'],\n",
              " 'Flicker8k_Dataset/3562169000_6aa7f1043d.jpg': ['<start> a blue race car almost crashing into a wall of tires <end>',\n",
              "  '<start> A blue race car on the side of the track . <end>',\n",
              "  '<start> A blue race car slides off of the track with its back tires . <end>',\n",
              "  '<start> A blue race car slides off the racetrack and hits white median bumpers with its rear . <end>',\n",
              "  '<start> A nascar driver trying to keep his car on the course <end>'],\n",
              " 'Flicker8k_Dataset/3567061016_62768dcce1.jpg': ['<start> A bird flying in the air <end>',\n",
              "  '<start> a bird flies low to the ground . <end>',\n",
              "  '<start> A bird with its wings spread <end>',\n",
              "  '<start> A hawk flies down towards the grass . <end>',\n",
              "  '<start> A hawk is flying , trailing lines from its legs . <end>'],\n",
              " 'Flicker8k_Dataset/3490736665_38710f4b91.jpg': ['<start> A big dog stands on his hand leg as tennis balls are thrown his direction . <end>',\n",
              "  '<start> A brown and white dog in front of a shed overwhelmed by the onslaught of tennis balls . <end>',\n",
              "  '<start> A brown and white dogs stands in front of a wooden building while tennis balls fly through the air . <end>',\n",
              "  '<start> A dog jumps for several tennis balls thrown at him . <end>',\n",
              "  '<start> A dog stands on his hind legs amid a shower of tennis balls . <end>'],\n",
              " 'Flicker8k_Dataset/3229821595_77ace81c6b.jpg': ['<start> A crowd of people are standing on a snow covered hill watching the sun go down . <end>',\n",
              "  '<start> A group of people are standing on a ledge overlooking low clouds . <end>',\n",
              "  '<start> A group of photographers stands on a hillside in the snow with the sun just below the horizon . <end>',\n",
              "  '<start> A line of people are seen in silhouette on a snowy ridge when the sun is low in the sky . <end>',\n",
              "  '<start> A line of people are standing on the edge of a snow covered path overlooking the clouds in the mountains . <end>'],\n",
              " 'Flicker8k_Dataset/2956562716_5aa3f6ef38.jpg': ['<start> Dogs playing in the yard . <end>',\n",
              "  '<start> Five dogs play in a large fenced yard bordering a group of autumnal trees . <end>',\n",
              "  '<start> Four dogs are playing in a circle and one black do is walking away . <end>',\n",
              "  '<start> Four dogs in a circle on the grass in the distance and a black dog on the grass in forefront . <end>',\n",
              "  '<start> Several dogs of different breeds play in a backyard . <end>'],\n",
              " 'Flicker8k_Dataset/2848266893_9693c66275.jpg': ['<start> A man in a white suit walks down the street holding a newspaper . <end>',\n",
              "  '<start> A man in a white suit walks outside carrying a newspaper . <end>',\n",
              "  '<start> a man wearing a white suit holding a newspaper walking through the streets . <end>',\n",
              "  '<start> The man holding a newspaper is wearing a white suit , black shirt and black shoes . <end>',\n",
              "  '<start> The man is wearing a white suit and walking on the street . <end>'],\n",
              " 'Flicker8k_Dataset/303607405_f36edf16c6.jpg': ['<start> A brown white dog shaking water off . <end>',\n",
              "  '<start> A bulldog with a red bandanna shakes off water . <end>',\n",
              "  '<start> a dog shakes dry . <end>',\n",
              "  '<start> A wet bulldog shakes off water . <end>',\n",
              "  '<start> A wet dog shaking its self dry . <end>'],\n",
              " 'Flicker8k_Dataset/2587818583_4aa8e7b174.jpg': ['<start> A man pulling a small child out of a ball pit <end>',\n",
              "  '<start> A man removes a boy from a ball pit while two other children and another man watch . <end>',\n",
              "  '<start> An adult is pulling a child out of a ball pit . <end>',\n",
              "  '<start> Children playing in a ball pit . <end>',\n",
              "  '<start> two men are watching three children playing in a ball pit full of colored balls . <end>'],\n",
              " 'Flicker8k_Dataset/3171451305_f87b9e09ee.jpg': ['<start> A man and two ladies looking faded as they hold bottles of beer in their hands . <end>',\n",
              "  '<start> A man in a red shirt and two women hold beer <end>',\n",
              "  '<start> Bald man , two women with beers , posing at event . <end>',\n",
              "  '<start> Man in red t-shirt posing with two young women and three beer bottles . <end>',\n",
              "  '<start> Three people holding beers and posing for a picture . <end>'],\n",
              " 'Flicker8k_Dataset/3382105769_b1a4e4c60d.jpg': ['<start> a brown dog retrieves a stick in a rocky river <end>',\n",
              "  '<start> A dog running through a creek . <end>',\n",
              "  '<start> A dog running with something in his mouth in shallow water . <end>',\n",
              "  '<start> A dog with a stick in its mouth runs through the rocks in shallow water . <end>',\n",
              "  '<start> A soaking wet dog is splashing through the water . <end>'],\n",
              " 'Flicker8k_Dataset/693164706_9624582e69.jpg': ['<start> A boy in a red hooded-coat is riding a pool broom like a horse in an empty pool . <end>',\n",
              "  '<start> a little boy wearing a raincoat plays with a mop . <end>',\n",
              "  '<start> A little kid in a red jacket riding a broom like a horse . <end>',\n",
              "  '<start> Boy in raincoat straddle stick outside . <end>',\n",
              "  '<start> The child in raingear is dragging a broom through a puddle . <end>'],\n",
              " 'Flicker8k_Dataset/224702241_05af393148.jpg': ['<start> A blond dog walks in a creek with banks filled with snow . <end>',\n",
              "  '<start> A blonde dog makes his way up an icy stream with snow piled up on the sides . <end>',\n",
              "  '<start> A tan dog walks down a stream between mounds of snow . <end>',\n",
              "  '<start> Brown dog walks through river between snowbanks . <end>',\n",
              "  '<start> The dog walks through the cold water . <end>'],\n",
              " 'Flicker8k_Dataset/531197115_2be4d5034b.jpg': ['<start> A banner about a beauty parlor . <end>',\n",
              "  '<start> A billboard advertising a vacation in on a run-down street . <end>',\n",
              "  '<start> A dark haired man in white walks by a storefront under the sign for a beauty parlor . <end>',\n",
              "  '<start> A man walks under a sign advertising a beauty parlor affixed to a dilapidated building . <end>',\n",
              "  '<start> A man wearing white walks passed a shuttered building with an advertising banner over the door . <end>'],\n",
              " 'Flicker8k_Dataset/2738077433_10e6264b6f.jpg': ['<start> A dog climbing a steep dirt hill . <end>',\n",
              "  '<start> A dog climbs a hill . <end>',\n",
              "  '<start> a great Dane climbing a steep hill <end>',\n",
              "  '<start> A light brown dog is running up . <end>',\n",
              "  '<start> A light dog climbing a wall of dirt . <end>'],\n",
              " 'Flicker8k_Dataset/241346105_c1c860db0d.jpg': ['<start> A college football game is in progress . <end>',\n",
              "  '<start> A football player runs along the sidelines with a football as a crowd watches . <end>',\n",
              "  '<start> An American footballer in a red strip is running down the side of the field with the ball . <end>',\n",
              "  '<start> The football player is running with a football trying to score . <end>',\n",
              "  '<start> The football player is trying to outrun his opponent . <end>'],\n",
              " 'Flicker8k_Dataset/319869052_08b000e4af.jpg': ['<start> A man is on top of a ridge looking at a small stone tower . <end>',\n",
              "  '<start> A man looking at a rock formation . <end>',\n",
              "  '<start> A man puts his hand to his head on a rock wall . <end>',\n",
              "  '<start> A person screening their eyes standing beside a tower of flat stone . <end>',\n",
              "  '<start> A person stands next to a rock monument with his hand near his head . <end>'],\n",
              " 'Flicker8k_Dataset/3036971334_78187a9570.jpg': ['<start> a blond man jumping off a cliff into some water <end>',\n",
              "  '<start> A man is jumping off a rock into a pool of water while three others watch . <end>',\n",
              "  \"<start> Four people are cavorting on the rocks at a river 's edge <end>\",\n",
              "  '<start> People stand by a rocky cliff with water below . <end>',\n",
              "  '<start> Three people on a rocky cliff over a body of water . <end>'],\n",
              " 'Flicker8k_Dataset/3259992722_4c5e895734.jpg': ['<start> A crowd in a European square watching a green shirted man . <end>',\n",
              "  '<start> A gentleman in a green jersey is entertaining a crowd of people . <end>',\n",
              "  '<start> A man in a jersey stands in front of a large crowd . <end>',\n",
              "  '<start> A man with a yellow and green shirt is standing in front of a crowd of people . <end>',\n",
              "  '<start> Man in colorful jersey and cap performs for crowd in urban area . <end>'],\n",
              " 'Flicker8k_Dataset/375171241_0302ad8481.jpg': ['<start> Many people wearing silver leotards are riding bikes on the street . <end>',\n",
              "  '<start> Several men in silver suits are riding bicycles across a street . <end>',\n",
              "  '<start> Three people in reflective clothing riding bikes . <end>',\n",
              "  '<start> Three people in reflective white on bikes . <end>',\n",
              "  '<start> Three people in silver suits are riding bikes in the city . <end>'],\n",
              " 'Flicker8k_Dataset/3498327617_d2e3db3ee3.jpg': ['<start> A dog is fetching a stick from a lake . <end>',\n",
              "  '<start> A dog swimming with a stick in its mouth . <end>',\n",
              "  '<start> a grey dog swimming through a river with a stick in his mouth <end>',\n",
              "  '<start> Dog carries stick in mouth while in water . <end>',\n",
              "  '<start> Dog swimming through water carrying stick in its mouth <end>'],\n",
              " 'Flicker8k_Dataset/506882688_b37d549593.jpg': ['<start> A boy standing next to large fountain , with an office building in the background . <end>',\n",
              "  '<start> Kids are standing in the sprinklers getting soaked with water . <end>',\n",
              "  '<start> People are playing in water fountains . <end>',\n",
              "  '<start> People standing in water spouts in the city on a sunny day . <end>',\n",
              "  '<start> Young person stands in spray from a fountain under a cloudy blue sky . <end>'],\n",
              " 'Flicker8k_Dataset/498404951_527adba7b8.jpg': ['<start> A blonde puppy wearing a red collar is standing in the water . <end>',\n",
              "  '<start> A furry dog with a collar is sitting in a pond . <end>',\n",
              "  '<start> A tan dog swims around in the water . <end>',\n",
              "  '<start> A white dog with long hair wades through a pond surrounded by green grass . <end>',\n",
              "  '<start> White dog at the edge of the water . <end>'],\n",
              " 'Flicker8k_Dataset/3721881082_afe9fc734e.jpg': ['<start> A woman and a girl sitting on a front lawn <end>',\n",
              "  '<start> A woman and girl wearing traditional clothes , sits on the front lawn , reading from a book . <end>',\n",
              "  '<start> A woman wearing colonial clothing is sitting on the grass reading to a young girl . <end>',\n",
              "  '<start> The girl and a lady are sitting on a blanket , reading a book . <end>',\n",
              "  '<start> Two women sitting on a blanket on the lawn while sharing a book . <end>'],\n",
              " 'Flicker8k_Dataset/3320680380_b0d38b3b4a.jpg': ['<start> A child goes skiing . <end>',\n",
              "  '<start> A young girl skiing alongside an adult <end>',\n",
              "  '<start> A young skier receives a lesson in the snow from an adult . <end>',\n",
              "  '<start> Man and child skiing . <end>',\n",
              "  \"<start> The ski instructor is teaching the little girl how to bend her knees and stand on her ski 's . <end>\"],\n",
              " 'Flicker8k_Dataset/3018847610_0bf4d7e43d.jpg': ['<start> A man is jumping on another man with a white face and long hair in a wrestling Ring . <end>',\n",
              "  '<start> A man performs a wrestling move on the wrestler in the rink . <end>',\n",
              "  '<start> A professional wrestler takes a flying leap onto another wrestler . <end>',\n",
              "  '<start> A wrestler is falling onto another wrestler who is laying in a ring . <end>',\n",
              "  '<start> People are watching the wrestler fall . <end>'],\n",
              " 'Flicker8k_Dataset/1394396709_65040d97ab.jpg': ['<start> A brown dog carrying a black object . <end>',\n",
              "  '<start> A dog retrieving in the water . <end>',\n",
              "  '<start> A dog with a water pack is walking through clear green water . <end>',\n",
              "  '<start> The dog is running through the water carrying a black and yellow object in its mouth . <end>',\n",
              "  '<start> The Irish Setter is retrieving a flashlight from the pond . <end>'],\n",
              " 'Flicker8k_Dataset/2192333873_2a0cbe849d.jpg': ['<start> A boy is flying down a snow covered slope on his sled . <end>',\n",
              "  '<start> A boy watches another person falling in the snow . <end>',\n",
              "  '<start> A snowboarder crashes into another . <end>',\n",
              "  '<start> a young boy falling down into the snow with another boy in the background <end>',\n",
              "  '<start> Two children play in the snow with a sled . <end>'],\n",
              " 'Flicker8k_Dataset/965444691_fe7e85bf0e.jpg': ['<start> A closeup of a man holding a baby wearing a blue shirt . <end>',\n",
              "  '<start> A man holds a chubby baby with pink cheeks and blue shirt . <end>',\n",
              "  '<start> A man in black holds a baby . <end>',\n",
              "  '<start> Ever since his baby girl started coming to the arcade with him , the dad enjoys watching others play his favorite pinball game . <end>',\n",
              "  '<start> The man is holding a baby near a carnival game . <end>'],\n",
              " 'Flicker8k_Dataset/2744321686_8811d8428c.jpg': ['<start> A couch sits broken while a man sits a table behind them . <end>',\n",
              "  '<start> A man in a blue shirt reads a paper behind a broken seat . <end>',\n",
              "  '<start> A man reads quietly alone in room . <end>',\n",
              "  '<start> Man in a blue shirt with hand on forehead behind two cushions . <end>',\n",
              "  '<start> Man looking over paperwork with a broken couch in front . <end>'],\n",
              " 'Flicker8k_Dataset/1030985833_b0902ea560.jpg': ['<start> A black dog and a brown dog are jumping up to catch a red toy . <end>',\n",
              "  '<start> A black dog and a brown dog play with a red toy on a courtyard . <end>',\n",
              "  '<start> A brown and black lab are outside and the black lab is catching a toy in its mouth . <end>',\n",
              "  '<start> Black dog snaps at red and black object as brown dog lunges . <end>',\n",
              "  '<start> The Chocolate Lab jumps too late to get the toy as the Black Lab captures it in the driveway . <end>'],\n",
              " 'Flicker8k_Dataset/2301867590_98c0ecb0cb.jpg': ['<start> The children make snow angels next to each other . <end>',\n",
              "  '<start> Two children are making snow angels . <end>',\n",
              "  '<start> Two children lying in the snow making snow angels <end>',\n",
              "  '<start> Two children , one in red and one in blue , making snow angels . <end>',\n",
              "  '<start> Two people in snowsuits laying in the snow making snow angels <end>'],\n",
              " 'Flicker8k_Dataset/169490297_b6ff13632a.jpg': ['<start> A boy in a blue , yellow , and orange shirt holding his arms out from his sides . <end>',\n",
              "  '<start> A boy in a blue , yellow , and orange shirt plays outside . <end>',\n",
              "  '<start> A boy looks down and spreads his arms wide <end>',\n",
              "  '<start> A child with a brightly colored shirt plays outside . <end>',\n",
              "  '<start> The boy in the blue and yellow top is standing with arms outstretched . <end>'],\n",
              " 'Flicker8k_Dataset/3380643902_7e0670f80f.jpg': ['<start> A long-boarder catches himself before hitting the ground . <end>',\n",
              "  '<start> a man wearing a blue and black striped shirt skateboarding down a steap street <end>',\n",
              "  '<start> A skateboarding boy touches his hands to the ground with a long hill in the background . <end>',\n",
              "  '<start> Boy skateboarding on residential street , falling farward with hands on the ground . <end>',\n",
              "  '<start> The skateboarder is turning around while holding onto the ground . <end>'],\n",
              " 'Flicker8k_Dataset/2449552677_ee78f01bae.jpg': ['<start> A man in a wheelchair riding to the park . <end>',\n",
              "  '<start> A person in a wheelchair is on a sidewalk . <end>',\n",
              "  '<start> a person wearing a knit cap riding in a wheelchair along a seidwalk outside of a building . <end>',\n",
              "  '<start> A person with a brown hat and black jacket is in a wheelchair crossing in front of a sign that says \" park \" . <end>',\n",
              "  '<start> The handicapped man wheels past the parking lot . <end>'],\n",
              " 'Flicker8k_Dataset/2479553749_f7ac031940.jpg': ['<start> a little baby standing in front of a colorful merry-go-round <end>',\n",
              "  '<start> A little boy is watching a merry-go-round . <end>',\n",
              "  '<start> A little boy watches a Ferris Wheel in motion . <end>',\n",
              "  \"<start> A tow-headed boy looks on at the children 's merry-go-round . <end>\",\n",
              "  \"<start> Small child looking at a colorful children 's amuseument ride . <end>\"],\n",
              " 'Flicker8k_Dataset/3015368588_ef0a06076d.jpg': ['<start> A runner heading toward a base while the baseman tries to tag him out . <end>',\n",
              "  '<start> one baseball player running toward a base with another waiting on the base <end>',\n",
              "  '<start> These two people are in baseball uniforms , making a play at base . <end>',\n",
              "  '<start> Two men playing baseball with the one in the black and red jersey running toward base . <end>',\n",
              "  '<start> Two people playing baseball . <end>'],\n",
              " 'Flicker8k_Dataset/371522748_dc557bcd6c.jpg': ['<start> A blonde boy is holding a blue umbrella . <end>',\n",
              "  '<start> A little boy smiles as he holds a blue umbrella above him . <end>',\n",
              "  '<start> A wet boy stands under an umbrella . <end>',\n",
              "  '<start> The kid is under the blue umbrella . <end>',\n",
              "  '<start> The little boy in the blue t-shirt is smiling under the blue umbrella even though it is not raining . <end>'],\n",
              " 'Flicker8k_Dataset/2990471798_73c50c76fb.jpg': ['<start> A boy jumps through the air onto something red . <end>',\n",
              "  '<start> A child holds its arm up and laughs . <end>',\n",
              "  '<start> A shirtless boy jumps through a curtain onto a red cushion . <end>',\n",
              "  '<start> A young boy wearing white pants is jumping off the couch . <end>',\n",
              "  '<start> The little boy jumps through the beaded curtain and onto the bed . <end>'],\n",
              " 'Flicker8k_Dataset/2659606300_bea3feaf8b.jpg': ['<start> A baby girl wearing a pink jacket climbs wooden steps . <end>',\n",
              "  '<start> A small child climbs stairs at a beach . <end>',\n",
              "  '<start> A small child climbs steps outdoors in a grassy area . <end>',\n",
              "  '<start> A small child in a pink hoodie ascending tall stairs outdoors . <end>',\n",
              "  '<start> A small child in a pink sweater begins to climb a concrete staircase . <end>'],\n",
              " 'Flicker8k_Dataset/2470486377_c3a39ccb7b.jpg': ['<start> A boy in a black shirt punches a yellow punching bag while a boy in a blue sweatshirt holds the bag . <end>',\n",
              "  '<start> Many children playing outside in the grass practicing punching . <end>',\n",
              "  '<start> Some kids play outside on a nice day . <end>',\n",
              "  '<start> The boy in the black sweatshirt is hitting the yellow object held by the boy in the blue sweatshirt . <end>',\n",
              "  '<start> Two boys talk on a field near palm trees . <end>'],\n",
              " 'Flicker8k_Dataset/2620113705_a8fa89b8f6.jpg': ['<start> A small white dog sits in a field <end>',\n",
              "  '<start> A white and brown dog sitting in the grass . <end>',\n",
              "  '<start> A white and brown dog sitting on a grassy , rocky area . <end>',\n",
              "  '<start> A white dog sits on a rocky lawn . <end>',\n",
              "  '<start> The white dog is sitting in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/506478284_7cf8bdbe36.jpg': ['<start> A couple dressed for a formal event posing together . <end>',\n",
              "  '<start> A couple outside a church after a wedding . <end>',\n",
              "  '<start> A couple posing outside a building , while a woman in a green dress walks by . <end>',\n",
              "  '<start> A young couple in formal pose for a picture . <end>',\n",
              "  '<start> Young couple pose for camera in formal wear , older man and woman in background . <end>'],\n",
              " 'Flicker8k_Dataset/1077931201_1e0bb83105.jpg': ['<start> A man in a wetsuit is throwing a baby wearing a wetsuit up into the air . <end>',\n",
              "  '<start> A man in a wetsuit is throwing a toddler up in the air and is ready to catch him . <end>',\n",
              "  '<start> A man in water throwing a little boy up in the air and waiting for him to come down so he can catch him . <end>',\n",
              "  '<start> The man is in the pool and throwing a small boy into the air . <end>',\n",
              "  '<start> While water droplets fly , a man throws a little boy up in the air . <end>'],\n",
              " 'Flicker8k_Dataset/2939475047_84585ea45c.jpg': ['<start> a football running back getting tackled <end>',\n",
              "  '<start> Football player tackles a player who has the ball , as a third player watches . <end>',\n",
              "  '<start> One football player attempts to get the ball from another football player who is running . <end>',\n",
              "  '<start> The American footballer in brown is tackling the player in whit who is running with the ball . <end>',\n",
              "  '<start> This is a football game in progress . <end>'],\n",
              " 'Flicker8k_Dataset/2963573792_dd51b5fbfb.jpg': ['<start> A little girl slides down a green slide with her arms up at a playground . <end>',\n",
              "  '<start> A little girl sliding down a slide at a playground . <end>',\n",
              "  '<start> A young girl is sliding down a slide at a playground . <end>',\n",
              "  '<start> A young girl slides down a green plastic slide on a playground . <end>',\n",
              "  '<start> The girl is sliding down a green slide . <end>'],\n",
              " 'Flicker8k_Dataset/2229177914_3308fe7d20.jpg': ['<start> A brown dog is jumping over a pole with fire on the ends . <end>',\n",
              "  '<start> A brown dog jumps over hurdle with flames on each end . <end>',\n",
              "  '<start> A light brown dog jumping over a hurdle that has fire on each end . <end>',\n",
              "  '<start> A tan dog is jumping over a hurdle that is on fire on the ends <end>',\n",
              "  '<start> A yellow dog is jumping over a flaming hurdle . <end>'],\n",
              " 'Flicker8k_Dataset/1295671216_cde1b9c9d1.jpg': ['<start> A crowd of people are standing together on a sidewalk , while one man is taking a picture . <end>',\n",
              "  '<start> A guy in a blue sweatshirt taking a picture . <end>',\n",
              "  '<start> A man in a blue sweatshirt taking a picture <end>',\n",
              "  '<start> A person in a crowd views an electronic device . <end>',\n",
              "  '<start> A person in jeans and a blue sweatshirt aims a camera while standing near a crowd of people . <end>'],\n",
              " 'Flicker8k_Dataset/661749711_6f408dad62.jpg': ['<start> A dog jumps to catch a red ball outside . <end>',\n",
              "  '<start> a small shaggy dog plays with a red ball on the grass . <end>',\n",
              "  '<start> A Yorkie trying to catch a red toy . <end>',\n",
              "  '<start> little dog is jumping up to catch a red ball in its mouth . <end>',\n",
              "  '<start> The dog jumps up to catch the red ball . <end>'],\n",
              " 'Flicker8k_Dataset/3124838157_7ef96745b7.jpg': ['<start> A man and two women pose outside a retail store . <end>',\n",
              "  \"<start> A short woman poses between two tall men in front of a store that 's going out of busines . <end>\",\n",
              "  '<start> Three people stand in front of a store window and smile . <end>',\n",
              "  '<start> three people standing outside a store window with two large signs in the background <end>',\n",
              "  '<start> Two tall men and a short woman standing in front of a store that is having a closeout <end>'],\n",
              " 'Flicker8k_Dataset/3527682660_c5e9fa644a.jpg': ['<start> A group of people sitting around a desk . <end>',\n",
              "  '<start> A man is standing in front of three people sitting around a table . <end>',\n",
              "  '<start> Four people are meeting around table in a modern decorated room . <end>',\n",
              "  '<start> Four people gathered around a table <end>',\n",
              "  '<start> Three people sit in front of a man who is standing in front of a orange wall with art pictures on it . <end>'],\n",
              " 'Flicker8k_Dataset/3351704877_28dea303aa.jpg': ['<start> A boy and a girl are riding on a camel in the sand on the beach . <end>',\n",
              "  '<start> A woman and child riding camels near the ocean . <end>',\n",
              "  '<start> Children riding on a camel by a body of water . <end>',\n",
              "  '<start> Two girls ride on the hump of a camel . <end>',\n",
              "  '<start> Two young girls ride a camel near water . <end>'],\n",
              " 'Flicker8k_Dataset/415657941_454d370721.jpg': ['<start> A girl spins a merry-go-round at a playground . <end>',\n",
              "  '<start> A little girl pushes a merry go round in a park while two other kids hold on . ee <end>',\n",
              "  '<start> Children playing on a playground . <end>',\n",
              "  '<start> Children playing on a roundabout . <end>',\n",
              "  '<start> Little girl spinning playground merry-go-round as other kids ride . <end>'],\n",
              " 'Flicker8k_Dataset/3072611047_109bf8b7c3.jpg': ['<start> Two children are diving side by side into a river . <end>',\n",
              "  '<start> Two children jumping into a body of water . <end>',\n",
              "  '<start> Two people dive headfirst into the water . <end>',\n",
              "  '<start> Two people diving into a body of water . <end>',\n",
              "  '<start> Two young boys diving headfirst into water with small waves on it . <end>'],\n",
              " 'Flicker8k_Dataset/306315650_e064f5c677.jpg': ['<start> A lady stands outside of a Mexican market . <end>',\n",
              "  '<start> An Indian woman stands in an outdoor marketplace . <end>',\n",
              "  '<start> A woman in Mexico does needlepoint while tending a store . <end>',\n",
              "  '<start> A woman is shopping in an outdoor marketplace . <end>',\n",
              "  \"<start> There is an open ' Abarrotes Mexico ' store with a man standing in front of it . <end>\"],\n",
              " 'Flicker8k_Dataset/2966190737_ceb6eb4b53.jpg': ['<start> A group of men play croquet . <end>',\n",
              "  '<start> These people are in uniform at a lacrosse type game . <end>',\n",
              "  '<start> Three men in white wait to swing at a ball . <end>',\n",
              "  '<start> Two men dressed in white hit a ball while a third man walks up . <end>',\n",
              "  '<start> Two men in white are playing a game while a man behind them walks towards them . <end>'],\n",
              " 'Flicker8k_Dataset/782017931_75d92bb7a4.jpg': ['<start> A couple is standing against a railing looking at a beautiful lake and sunset . <end>',\n",
              "  '<start> A couple takes in the view at the water at dusk . <end>',\n",
              "  '<start> The couple is standing by the railing overlooking the water . <end>',\n",
              "  '<start> Two people stand against the railing above the water and watch the sunset . <end>',\n",
              "  '<start> Two people stand close together looking at a river from behind a fence . <end>'],\n",
              " 'Flicker8k_Dataset/3492180255_0bd48a18f8.jpg': ['<start> A person in a pink jacket is running onto the field . <end>',\n",
              "  '<start> A spots team hugs after a play . <end>',\n",
              "  '<start> A teammate helps another teammate off of the field . <end>',\n",
              "  '<start> Four atheletes and a man with a crowded stadium in the background . <end>',\n",
              "  '<start> Men are dressed in soccer uniforms . <end>'],\n",
              " 'Flicker8k_Dataset/543264612_c53cc163b4.jpg': ['<start> A chubby or buff kid in shorts is holding on to weights . <end>',\n",
              "  '<start> A small boy is holding some weights . <end>',\n",
              "  '<start> A young boy with no shirt and white shorts . <end>',\n",
              "  '<start> Boy in shorts holding a remote . <end>',\n",
              "  '<start> The little boy is wearing white shorts . <end>'],\n",
              " 'Flicker8k_Dataset/2119660490_ce0d4d1f73.jpg': ['<start> A brown dog is laying on his side on a beige carpet , with a green object in the foreground . <end>',\n",
              "  '<start> A brown dog is laying on its back on a white carpet with a green ball on it . <end>',\n",
              "  '<start> A brown dog is rolling on its back on a carpet with several green toys nearby . <end>',\n",
              "  '<start> A dog lies on its back on a dog bed . <end>',\n",
              "  '<start> The dog is laying on its back near a green ball . <end>'],\n",
              " 'Flicker8k_Dataset/1087539207_9f77ab3aaf.jpg': ['<start> A family playing on a tractor on a beautiful day <end>',\n",
              "  '<start> Children ride a tractor in a field . <end>',\n",
              "  '<start> Several children playing on a Polaris vehicle outdoors . <end>',\n",
              "  '<start> The children played on the four wheeler in the field . <end>',\n",
              "  '<start> The four kids are riding on an ATV in a field . <end>'],\n",
              " 'Flicker8k_Dataset/3375014075_157388f8a9.jpg': ['<start> A dog is preparing to run away from a person interacting with it . <end>',\n",
              "  '<start> A person in a red coat and a running black and brown dog . <end>',\n",
              "  '<start> A woman in a black and orange jacket throws a stick for a brown and black dog to fetch . <end>',\n",
              "  '<start> a woman in a red jacket watches as a black and brown dog runs away from her in woodland clearing . <end>',\n",
              "  '<start> Outside by the trees , a woman wearing jeans and red jacket throws something for a German shepherd to chase . <end>'],\n",
              " 'Flicker8k_Dataset/2426215757_e008a91fcb.jpg': ['<start> A girl waterskis on an autumn day . <end>',\n",
              "  '<start> A person is waterskiing in a lake near autumn colored trees . <end>',\n",
              "  '<start> A person on a waterski . <end>',\n",
              "  '<start> A waterskier being pulled dressed for the cold with a life jacket on . <end>',\n",
              "  '<start> A young person is wakeboarding off the back of a water vehicle . <end>'],\n",
              " 'Flicker8k_Dataset/3416013671_98b5c75046.jpg': ['<start> A grey bearded scottish gentleman in red plaid is playing the bagpipes . <end>',\n",
              "  '<start> A man with a beard in the foreground playing bagpipes <end>',\n",
              "  '<start> A parade of bagpipers walk through a city street . <end>',\n",
              "  '<start> Several bagpipers in Scottish dress . <end>',\n",
              "  '<start> The man with the white beard is playing a red bagpipe . <end>'],\n",
              " 'Flicker8k_Dataset/3523559027_a65619a34b.jpg': ['<start> A formation on a big field with people wearing red , white and blue <end>',\n",
              "  '<start> Many people in formation on a field . <end>',\n",
              "  '<start> Marching bands in formation on a field . <end>',\n",
              "  '<start> The crowd stood in many different lines in the open field . <end>',\n",
              "  '<start> The group of people make single file lines on the field . <end>'],\n",
              " 'Flicker8k_Dataset/2359784186_36c9746d02.jpg': ['<start> A man in a long gray overcoat stands in a courtyard as snow falls . <end>',\n",
              "  '<start> A young boy in a trench coat is holding a red bottle outside of a brick building . <end>',\n",
              "  '<start> A young man is wearing a blue outfit and grey coat . <end>',\n",
              "  '<start> Person spraying squirt bottle in the snow . <end>',\n",
              "  '<start> Woman in coat outside a house while snowing <end>'],\n",
              " 'Flicker8k_Dataset/3631136463_53ff624b82.jpg': ['<start> The brown and black dogs are carrying a big log in the meadow . <end>',\n",
              "  '<start> Two dark colored dogs are walking through the grass both holding a large stick . <end>',\n",
              "  '<start> Two dogs retreiving a large stick of wood <end>',\n",
              "  '<start> Two dogs share a toy in a field of vegetation . <end>',\n",
              "  '<start> Two dogs walking through tall grass carrying a tree branch in their mouths . <end>'],\n",
              " 'Flicker8k_Dataset/2417623030_afdc1024b5.jpg': ['<start> A group of people stand on a brick path . <end>',\n",
              "  '<start> Four runners pose for a picture . <end>',\n",
              "  '<start> They are posing for a picture . <end>',\n",
              "  '<start> Two couples stop to take a photo . <end>',\n",
              "  '<start> Two young couples posing for a picture in exercise clothing . <end>'],\n",
              " 'Flicker8k_Dataset/2597308074_acacc12e1b.jpg': ['<start> A boy and a girl at the beach , throwing sand . <end>',\n",
              "  '<start> a boy flings sand at a girl . <end>',\n",
              "  '<start> A boy with an orange tool on the shore is spraying a girl standing in shallow water with mud . <end>',\n",
              "  '<start> Boy flings mud at girl <end>',\n",
              "  '<start> The young boy flings mud at the barefoot girl in the pond . <end>'],\n",
              " 'Flicker8k_Dataset/2258662398_2797d0eca8.jpg': ['<start> A child in a black wetsuit is in the waves on a surfboard . <end>',\n",
              "  '<start> A kid on a surfboard riding a small wave . <end>',\n",
              "  '<start> A small boy in black is surfing . <end>',\n",
              "  '<start> A young boy in a black wetsuit surfs in the water . <end>',\n",
              "  '<start> A young surfer rides a wave . <end>'],\n",
              " 'Flicker8k_Dataset/2592711202_55f8c64495.jpg': ['<start> A girl dressed in blue enjoys a blue treat while putting her white shoe back on . <end>',\n",
              "  '<start> A girl in a blue dress sitting on the ground eating cotton candy . <end>',\n",
              "  '<start> A girl in a blue dress takes off her shoes and eats blue cotton candy . <end>',\n",
              "  '<start> Child in blue dress holding sandal in one hand and eating blue cotton candy with other hand . <end>',\n",
              "  '<start> The girl in a blue dress is eating some blue cotton candy with one shoe off and one shoe on . <end>'],\n",
              " 'Flicker8k_Dataset/2924908529_0ecb3cdbaa.jpg': ['<start> A group of young women in skimpy red and black uniforms shows off black markings on their legs . <end>',\n",
              "  '<start> cheerleaders pose for the camera . <end>',\n",
              "  '<start> Five women wearing skimpy red and black outfits pose . <end>',\n",
              "  '<start> Five women with red and black halter tops and red and black miniskirts wearing red and white shoes . <end>',\n",
              "  '<start> Women is small tops and skirts pose for the camera . <end>'],\n",
              " 'Flicker8k_Dataset/846085364_fc9d23df46.jpg': ['<start> A bundled-up toddler in the snow . <end>',\n",
              "  '<start> A small boy is looking at footprints in the snow . <end>',\n",
              "  '<start> A small child in winter gear is making tracks in shallow snow . <end>',\n",
              "  '<start> A young child dressed in snowpants and blue hat tentatively steps on snow-covered ice . <end>',\n",
              "  '<start> The child is well bundled as he walks in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/2524084967_a5e011b73d.jpg': ['<start> A cyclist is performing a jump next to a black advertising banner . <end>',\n",
              "  '<start> A male doing a bicycle trick in midair . <end>',\n",
              "  '<start> A man in a white t-shirt jumping something on his yellow bike . <end>',\n",
              "  '<start> A trick cyclist takes air . <end>',\n",
              "  '<start> The man is performing a trick off a ramp with a bicycle . <end>'],\n",
              " 'Flicker8k_Dataset/2055646179_169807fed4.jpg': ['<start> A boy holding a hose next to a man while another boy watches on , held by a woman . <end>',\n",
              "  '<start> A child is playing with a water spout outdoors while the rest of his family watches . <end>',\n",
              "  '<start> A man in an orange shirt is helping a boy squirt water from a hose into a pond whilst a woman and boy watch . <end>',\n",
              "  '<start> A smiling family congregate around a water spout in a pasture . <end>',\n",
              "  '<start> A young child plays with a hose in a field with another child , and two adults . <end>'],\n",
              " 'Flicker8k_Dataset/2931254547_e97c6d0d63.jpg': ['<start> A boy in a red hat admires a barely dressed woman . <end>',\n",
              "  '<start> A man in a red costume and woman in a bikini are passing a crowd of people . <end>',\n",
              "  '<start> a smiling topless woman holding a shell with many people surrounding her <end>',\n",
              "  '<start> A topless woman is holding a conch shell while a crowd looks at her . <end>',\n",
              "  '<start> Many people watching a performance <end>'],\n",
              " 'Flicker8k_Dataset/506343925_b30a235de6.jpg': ['<start> A brown , white , and black dog runs in the sand . <end>',\n",
              "  '<start> a large brown dog is running across sand dunes in front of some small green foliage . <end>',\n",
              "  '<start> A striped dog is running in the desert . <end>',\n",
              "  '<start> A wild dog runs through the desert . <end>',\n",
              "  '<start> A wolf running in sandy plains . <end>'],\n",
              " 'Flicker8k_Dataset/566794440_f9ec673a2f.jpg': ['<start> girls with baseball gloves walking across a baseball field <end>',\n",
              "  '<start> A woman in camouflage and her hair up in a ponytail walks on the field with a black softball glove on one hand . <end>',\n",
              "  '<start> A woman playing baseball walks back to her base while her feamle teammate follows . <end>',\n",
              "  '<start> A woman with a glove on a baseball field with another woman <end>',\n",
              "  '<start> The girls return to the field during their softball game . <end>'],\n",
              " 'Flicker8k_Dataset/2752084369_52e7867da7.jpg': ['<start> A little girl in a red dress and white hat holding two ZARA blue bags . <end>',\n",
              "  '<start> A little girl in a red dress is carrying shopping bags . <end>',\n",
              "  '<start> A little girl is carrying two shopping bags from Zara . <end>',\n",
              "  '<start> A toddler in a red dress carries two Zara shopping bags . <end>',\n",
              "  '<start> A young girl is carrying two large black shopping bags . <end>'],\n",
              " 'Flicker8k_Dataset/180506881_de0f59770f.jpg': [\"<start> The camera focuses on two people 's legs . <end>\",\n",
              "  '<start> The legs and mid-sections of two people with skateboards . <end>',\n",
              "  '<start> Two guys walking , one carrying a skateboard <end>',\n",
              "  '<start> two male skaters walk on sidewalk <end>',\n",
              "  '<start> two people wearing white shirts and jeans each carrying a skateboard <end>'],\n",
              " 'Flicker8k_Dataset/3572942419_16ebdc3d46.jpg': ['<start> a woman at a desk signing paperwork in front of another <end>',\n",
              "  '<start> A woman filling out some paperwork while another woman waits . <end>',\n",
              "  '<start> A woman signs paperwork at an event . <end>',\n",
              "  '<start> Several women are talking outside . <end>',\n",
              "  '<start> These women are filling out forms at a stand outdoors . <end>'],\n",
              " 'Flicker8k_Dataset/539493423_9d7d1b77fa.jpg': [\"<start> A man is holding three things on fire in front of a child 's playground . <end>\",\n",
              "  '<start> A man is in a park with three fire sticks in his hand . <end>',\n",
              "  '<start> A man near a playground holding three sticks on fire . <end>',\n",
              "  '<start> Man holding torch of fire . <end>',\n",
              "  '<start> Man holds three burning sticks while standing near a playground . <end>'],\n",
              " 'Flicker8k_Dataset/2855727603_e917ded363.jpg': ['<start> a black dog splashes in the water . <end>',\n",
              "  '<start> a brown dog walking in a river with trees in the background <end>',\n",
              "  '<start> A large brown dog plays in the water . <end>',\n",
              "  '<start> A large sleek brown dog is standing in the water . <end>',\n",
              "  '<start> The large brown dog is walking into a shallow lake . <end>'],\n",
              " 'Flicker8k_Dataset/3084034954_fe5737197d.jpg': ['<start> A man at a casino hugging two colorfully dressed show girls . <end>',\n",
              "  '<start> A man in a white suit is standing with two women . <end>',\n",
              "  '<start> A man stands in the middle of two woman dressed in brightly colored costumes . <end>',\n",
              "  '<start> A white suited man stands between two showgirls in a casino foyer . <end>',\n",
              "  '<start> Two women in very colorful costumes stand next to a man dressed in all white . <end>'],\n",
              " 'Flicker8k_Dataset/3542484764_77d8920ec9.jpg': ['<start> A man playing cricket , his bat pointed to the sky . <end>',\n",
              "  '<start> Man dressed in white playing sports . <end>',\n",
              "  '<start> The cricketer is swinging a bat in the air . <end>',\n",
              "  '<start> The man wearing knee protectors swings a cricket club . <end>',\n",
              "  '<start> The man wearing white clothes and white leg padding is practicing a sport . <end>'],\n",
              " 'Flicker8k_Dataset/3203872773_6c30f64be3.jpg': ['<start> A bearded man with glasses does a toe-touch . <end>',\n",
              "  '<start> A man jumping into the air <end>',\n",
              "  '<start> A man jumps into the air . <end>',\n",
              "  '<start> A man wearing suspenders and sunglasses leaps up in the air with his arms and legs spread out to the side . <end>',\n",
              "  '<start> A man wearing suspenders performs a split in midair . <end>'],\n",
              " 'Flicker8k_Dataset/2839789830_89668775a4.jpg': ['<start> A black and white dog catches a Frisbee on a grassy field . <end>',\n",
              "  '<start> a black and white dog jumping in the air to catch a white Frisbee . <end>',\n",
              "  '<start> A dog jumping to catch a Frisbee . <end>',\n",
              "  '<start> The black and white dog jumps in the air to catch the white Frisbee on the grassy field . <end>',\n",
              "  '<start> The dog leaps to attempt to catch the Frisbee . <end>'],\n",
              " 'Flicker8k_Dataset/411175971_0fffd3b8c6.jpg': ['<start> A brown dog is shown standing in the water near a muddy beach . <end>',\n",
              "  '<start> A dog happily plays in tidal overflow on a cloudy day . <end>',\n",
              "  '<start> A dog is playing in water on a beach . <end>',\n",
              "  '<start> A tan dog playing with a stick on the shore . <end>',\n",
              "  '<start> The dog runs through the water with a stick in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/1124448967_2221af8dc5.jpg': ['<start> A half naked man is sleeping on his chair outdoors . <end>',\n",
              "  '<start> An older man sits back and relaxes on a patio outside an adobe building where many bicycles are propped . <end>',\n",
              "  '<start> A shirtless man in a white cap relaxes in a deck chair , close to three parked bicycles . <end>',\n",
              "  '<start> Man relaxing in a folding chair on the street . <end>',\n",
              "  '<start> Topless old man wearing slippers , navy blue pants and a white hat while reclining in a chair outside . <end>'],\n",
              " 'Flicker8k_Dataset/2599444370_9e40103027.jpg': ['<start> A black dog paddles behind a black cat in a body of water . <end>',\n",
              "  '<start> A dog and a cat are swimming in a swimming pool . <end>',\n",
              "  '<start> Two black dogs are dog paddling in a sparkling blue pool . <end>',\n",
              "  '<start> Two black dogs are swimming in a pool . <end>',\n",
              "  '<start> Two dogs swimming in a pool . <end>'],\n",
              " 'Flicker8k_Dataset/3163477256_073605e06e.jpg': ['<start> A goalie in a blue jersey catches a soccer ball by a player in a red jersey . <end>',\n",
              "  '<start> A man catches a ball in front of a large crowd . <end>',\n",
              "  '<start> A soccer goalie blocking a shot next to a player from the opposite team . <end>',\n",
              "  '<start> There is a goalie in the air making a save in a game . <end>',\n",
              "  '<start> Two soccer players are playing soccer . <end>'],\n",
              " 'Flicker8k_Dataset/2208067635_39a03834ca.jpg': ['<start> A girl is climbing a rock while someone is filming her . <end>',\n",
              "  \"<start> A little girl is climbing up a rock as her mom 's shadow is casting over the rock . <end>\",\n",
              "  '<start> A small child climbs a large rock while someone casting a shadow takes her picture . <end>',\n",
              "  '<start> A young girl is rock climbing . <end>',\n",
              "  '<start> The long black shadow casts a image on the rock while the young girl climbs the rock . <end>'],\n",
              " 'Flicker8k_Dataset/3048461682_e89f81b1c7.jpg': ['<start> A dog runs over a stick in the leaves . <end>',\n",
              "  '<start> A small white dog is jumping over a branch on the ground covered with leaves . <end>',\n",
              "  '<start> A small white dog leaps over a root in the woods . <end>',\n",
              "  '<start> A white dog jumps over a log . <end>',\n",
              "  '<start> A white dog running in the fallen leaves . <end>'],\n",
              " 'Flicker8k_Dataset/3710520638_866d542a80.jpg': ['<start> A black dog jumping into a lake . <end>',\n",
              "  '<start> A black dog with a red collar is jumping in the water . <end>',\n",
              "  '<start> A black dog with a red collar is jumping out of the water . <end>',\n",
              "  '<start> Black dog with red collar splashing in water <end>',\n",
              "  '<start> The black dog with a red collar is jumping through the water . <end>'],\n",
              " 'Flicker8k_Dataset/3640407952_bb38fb9d55.jpg': ['<start> A man doing a skateboard trick on a skateboard ramp <end>',\n",
              "  '<start> A man in a red shirt make a skateboard jump on a ramp with graffiti . <end>',\n",
              "  '<start> a skateboarder is performing stunt on a graffiti covered skateboard ramp . <end>',\n",
              "  '<start> A skateboarder on a ramp . <end>',\n",
              "  '<start> Man skateboarding off of a ramp . <end>'],\n",
              " 'Flicker8k_Dataset/463875230_f19e83d6df.jpg': ['<start> a girl wearing pink swings on a swing . <end>',\n",
              "  '<start> A little girl is swinging high above a wooden fence on the swing . <end>',\n",
              "  '<start> a young girl in a pick shirt swinging up in the air on a swing set <end>',\n",
              "  '<start> The girl is on a swing . <end>',\n",
              "  '<start> The little girl played on the swing . <end>'],\n",
              " 'Flicker8k_Dataset/397601572_9587a39291.jpg': [\"<start> The back of two men 's heads riding on a train . <end>\",\n",
              "  '<start> The backs of the heads of two men that are plugging their ears while riding the subway . <end>',\n",
              "  '<start> Two guys are sharing headphones and are listening to music on a subway . <end>',\n",
              "  '<start> Two men on a busy subway , seen from behind , <end>',\n",
              "  '<start> Two people sitting together on a subway listening to earphones . <end>'],\n",
              " 'Flicker8k_Dataset/2690702549_cf81da8cf6.jpg': ['<start> Four boys mug for the camera in front of a brick wall . <end>',\n",
              "  '<start> Four boys pose for the camera . <end>',\n",
              "  '<start> Four boys posing for a picture with pumped fists <end>',\n",
              "  '<start> Four boys stand together with their arms bended to show their strength . <end>',\n",
              "  '<start> Four young boys flexing for the camera . <end>'],\n",
              " 'Flicker8k_Dataset/1655781989_b15ab4cbff.jpg': ['<start> A group of mountain climbers <end>',\n",
              "  '<start> A group of people walking in a line through the snow toward a mountain . <end>',\n",
              "  '<start> A line of people are making their way through snow covered mountains . <end>',\n",
              "  '<start> People are walking through a snow covered field with a mountain the background . <end>',\n",
              "  '<start> People facing mountains in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/2623247254_3bfc795121.jpg': ['<start> A guy talks and does something with his hand while others sit near him . <end>',\n",
              "  '<start> a young blond man sitting at a table with a brick wall in the background <end>',\n",
              "  '<start> A young man lights a lighter while another looks on . <end>',\n",
              "  '<start> Two guys at a bar one dark skinned and one light skinned . <end>',\n",
              "  '<start> Two men are sitting next to each other near to a vending machine . <end>'],\n",
              " 'Flicker8k_Dataset/2616643090_4f2d2d1a44.jpg': ['<start> A baby chews on plants . <end>',\n",
              "  '<start> a baby has some grass seeds in his mouth . <end>',\n",
              "  '<start> a baby sticking wheat grass into his mouth <end>',\n",
              "  '<start> A baby wearing green holds onto plants and puts them in its mouth . <end>',\n",
              "  '<start> Small child in green sweater with plant in mouth . <end>'],\n",
              " 'Flicker8k_Dataset/371364900_5167d4dd7f.jpg': ['<start> A black and brown dog is jumping on blocks of concrete in the water . <end>',\n",
              "  '<start> A black dog carefully crosses over some water . <end>',\n",
              "  '<start> Black dog looking at his reflection in the water . <end>',\n",
              "  '<start> Black dog near a dock looks into murky water <end>',\n",
              "  '<start> the black dog jumps on a cinderblock . <end>'],\n",
              " 'Flicker8k_Dataset/2504056718_25ded44ecb.jpg': ['<start> A black and white dog is jumping up to catch a green Frisbee . <end>',\n",
              "  '<start> A black and white dog jumps high to get a green Frisbee . <end>',\n",
              "  '<start> A dog catching a Frisbee in front of a red building . <end>',\n",
              "  '<start> Black and white dog leaping for Frisbee . <end>',\n",
              "  '<start> The dog jumps up to catch the Frisbee . <end>'],\n",
              " 'Flicker8k_Dataset/1247181182_35cabd76f3.jpg': ['<start> a man sits on a rock . <end>',\n",
              "  '<start> A man sitting on a cliff in the mountains . <end>',\n",
              "  '<start> A man wearing a blue shirt crouches on a rocky cliff . <end>',\n",
              "  '<start> A person posing on a mountaintop . <end>',\n",
              "  '<start> The man is sitting at the top of a rocky mountain . <end>'],\n",
              " 'Flicker8k_Dataset/3490186050_4cb4193d4d.jpg': ['<start> A boy dribbles a soccer ball in a grass field next to a parking lot . <end>',\n",
              "  '<start> A boy plays ball on a grassy field . <end>',\n",
              "  '<start> A child in yellow and black kicks a blue and black ball . <end>',\n",
              "  '<start> A little boy is about to kick a black soccer ball . <end>',\n",
              "  '<start> A young boy is playing soccer . <end>'],\n",
              " 'Flicker8k_Dataset/542405691_0594b1ce72.jpg': ['<start> A boy kicks a ball in his living room . <end>',\n",
              "  '<start> A boy kicks a blue ball in a room . <end>',\n",
              "  '<start> A child kicks a ball into the air . <end>',\n",
              "  '<start> A child standing on one foot and surrounded by toys . <end>',\n",
              "  '<start> A little boy is kicking a blue ball on the carpet surrounded by toys . <end>'],\n",
              " 'Flicker8k_Dataset/2562483332_eb791a3ce5.jpg': ['<start> A teenage girl and little girl play on pink toy . <end>',\n",
              "  '<start> A woman and a girl are swinging on a red swing <end>',\n",
              "  '<start> A woman playing with play equipment while a child looks on . <end>',\n",
              "  '<start> Children on a red and yellow swing set . <end>',\n",
              "  '<start> Two kids playing on playground equipment . <end>'],\n",
              " 'Flicker8k_Dataset/3263395801_5e4cee2b9e.jpg': ['<start> A dirt biker in the forest . <end>',\n",
              "  '<start> A dirt biker rides his motocycle through the woods . <end>',\n",
              "  '<start> A motocross bike is being ridden along a woodland path . <end>',\n",
              "  '<start> A motorcyclist navigates a forest trail . <end>',\n",
              "  '<start> A person rides a motorbike on a dirt path surrounded by trees . <end>'],\n",
              " 'Flicker8k_Dataset/247619370_a01fb21dd3.jpg': ['<start> A woman in a black shirt sitting on a red bench . <end>',\n",
              "  '<start> A woman is sitting and staring on a red bench near a building . <end>',\n",
              "  '<start> A woman wearing sunglasses sits on a red bench in front of a yellow building . <end>',\n",
              "  '<start> The woman in the brown shirt is sitting on a bright red bench . <end>',\n",
              "  '<start> Woman in a black shirt sitting on a red bench . <end>'],\n",
              " 'Flicker8k_Dataset/3412036192_d8cd12ed3f.jpg': ['<start> A brown and white dog is jumping up to catch a ball in the park . <end>',\n",
              "  '<start> A dog chases a tennis ball on a well manicured park lawn . <end>',\n",
              "  '<start> A white and brown dog jumps for a tennis ball in midair . <end>',\n",
              "  '<start> A white and brown dog , mid-leap , in a park . <end>',\n",
              "  '<start> A white dog tries to catch a tennis ball high in the air . <end>'],\n",
              " 'Flicker8k_Dataset/3341077091_7ca0833373.jpg': ['<start> A boy is airborne on his skateboard above a set of rails in an industrial setting . <end>',\n",
              "  '<start> A boy with a skateboard if jumping in the air along some railway tracks . <end>',\n",
              "  '<start> A man doing a skateboard trick over a railroad track . <end>',\n",
              "  '<start> A skateboarder does a kickflip along the train tracks . <end>',\n",
              "  '<start> A skateboarder doing a jump on train tracks . <end>'],\n",
              " 'Flicker8k_Dataset/197142902_f05ff198c2.jpg': ['<start> A man and a woman in glasses blow bubbles . <end>',\n",
              "  '<start> A man and woman blow bubbles . <end>',\n",
              "  '<start> A man in a black shirt and a woman in a brown shirt blow bubbles with pink wands . <end>',\n",
              "  '<start> an Asian man and an Asian woman are blowing bubbles from pink plastic hoops . <end>',\n",
              "  '<start> A woman and man are next to each other blowing bubbles . <end>'],\n",
              " 'Flicker8k_Dataset/2549452277_873cb80d3e.jpg': ['<start> A man in a bright yellow jacket is wearing a helmet . <end>',\n",
              "  '<start> A man in a florescent jacket is wearing a helmet . <end>',\n",
              "  '<start> A pony-tailed man in a yellow jacket is wearing a bicycle helmet . <end>',\n",
              "  '<start> The man has on a yellow jacket and a white helmet . <end>',\n",
              "  '<start> The man with the ponytail and helmet looks on . <end>'],\n",
              " 'Flicker8k_Dataset/3547524138_4157f660b0.jpg': ['<start> Adults and children are playing with water balloons in the street . <end>',\n",
              "  '<start> A group of people play a game in the road . <end>',\n",
              "  '<start> A group of people play a game in the street , passing balloons to one another <end>',\n",
              "  '<start> People passing water balloons in the street <end>',\n",
              "  '<start> The early stages of a water balloons toss . <end>'],\n",
              " 'Flicker8k_Dataset/3356901257_83811a19eb.jpg': ['<start> A brown dog on the sand . <end>',\n",
              "  '<start> A brown dog plays in the sand near a man in a green cap . <end>',\n",
              "  '<start> A dog is jumping in the air to catch something . <end>',\n",
              "  '<start> A dog is jumping up for the ball while playing catch in the sand . <end>',\n",
              "  '<start> A dog playing ball in the sand . <end>'],\n",
              " 'Flicker8k_Dataset/3563673070_71fa0903ed.jpg': ['<start> A kayaker in a red kayak paddles as an orange kayak approaches from behind . <end>',\n",
              "  '<start> A man in a red kayak in the water . <end>',\n",
              "  '<start> A man in a red kayak paddles through blue water . <end>',\n",
              "  '<start> a man paddling a red kayak <end>',\n",
              "  '<start> Man paddles red kayak , orange kayak in background . <end>'],\n",
              " 'Flicker8k_Dataset/2866974237_e3c1e267c0.jpg': ['<start> A person wearing a bright pink wig and a yellow shirt , facing away and looking at the ocean . <end>',\n",
              "  '<start> A person with neon pink hair and yellow shirt is looking out across a beach . <end>',\n",
              "  '<start> A person with pink hair looking out at a beach . <end>',\n",
              "  '<start> Girl wearing a pink wig standing on the shore of a beach . <end>',\n",
              "  '<start> The person at the beach is wearing a pink wig . <end>'],\n",
              " 'Flicker8k_Dataset/3195701071_81879257f5.jpg': ['<start> A brown dog is flying through the air . <end>',\n",
              "  '<start> A brown dog is jumping in the air . <end>',\n",
              "  '<start> a brown dog jumping through the air in a grassy yard . <end>',\n",
              "  '<start> A large tan dog jumps in the air over the grass in a fenced yard . <end>',\n",
              "  '<start> A red dog , jumping in midair , on a grassy backyard , shot from behind . <end>'],\n",
              " 'Flicker8k_Dataset/3381788544_2c50e139dd.jpg': ['<start> A group of Asian girls are standing together . <end>',\n",
              "  '<start> A group of asian women in sports attire , and one woman in the center is wearing a baseball cap . <end>',\n",
              "  '<start> Four teenagers in dark clothes looking in various directions . <end>',\n",
              "  '<start> There are several asian people , one wearing a baseball cap . <end>',\n",
              "  '<start> Two girls laugh while other girls look on . <end>'],\n",
              " 'Flicker8k_Dataset/2788628994_61123c03d2.jpg': ['<start> A man in a blue jacket bikes down a forest path . <end>',\n",
              "  '<start> A man rides a bike down a trail in a pine forest . <end>',\n",
              "  '<start> A person on a bike rides through a wooded area . <end>',\n",
              "  '<start> Tall trees reach to the horizon as a cyclist navigates the way through the tangled roots . <end>',\n",
              "  '<start> The biker is riding through the woods . <end>'],\n",
              " 'Flicker8k_Dataset/263854883_0f320c1562.jpg': ['<start> The two small dogs run through the grass . <end>',\n",
              "  '<start> Two fluffy white dogs running in green grass . <end>',\n",
              "  '<start> Two small dogs run through the grass . <end>',\n",
              "  '<start> Two small dogs that look almost identical are playing in the grass . <end>',\n",
              "  '<start> Two yellow dogs run together in green grass . <end>'],\n",
              " 'Flicker8k_Dataset/3673484638_dce87295fe.jpg': ['<start> The two children , one with a scarf tied around their forehead , walk down a modeling runway . <end>',\n",
              "  '<start> Two boys are walking along the stage whilst being watched by several people . <end>',\n",
              "  '<start> Two children walking on a platform . <end>',\n",
              "  '<start> Two children wearing denim walk on a runway . <end>',\n",
              "  '<start> Two little kids walk the catwalk showing off their fashion . <end>'],\n",
              " 'Flicker8k_Dataset/2089539651_9e518ec7de.jpg': ['<start> A hiker with two hiking poles stands on a hillside with a view of the city below him . <end>',\n",
              "  '<start> A hiker with two sticks is a standing on a path that is high up on a hill . <end>',\n",
              "  '<start> A hiking man stands on a cliff overlooking a city . <end>',\n",
              "  '<start> A man hikes on a dirt path high above a city . <end>',\n",
              "  '<start> A person holding poles is standing on a rock ledge with bushes on each side overlooking mountains . <end>'],\n",
              " 'Flicker8k_Dataset/2216568822_84c295c3b0.jpg': ['<start> A roller derby woman wearing a helmet has a tattoo of a white Indian pulling back a bow . <end>',\n",
              "  '<start> a woman wearing a pink crash helmet has a tattoo of a native American on her shoulder . <end>',\n",
              "  '<start> The lady has a tattoo . <end>',\n",
              "  '<start> This helmeted person has a tattoo of an indian lady on their arm . <end>',\n",
              "  '<start> Woman with red crash helmet and Native American tattoo on her arm . <end>'],\n",
              " 'Flicker8k_Dataset/393810324_1c33760a95.jpg': ['<start> A large black dog and a small brown dog are playing in the house . <end>',\n",
              "  '<start> A large black dog has his paw on a small brown dog . <end>',\n",
              "  '<start> A large black dog relaxes while a small brown dog investigates nearby a doorway . <end>',\n",
              "  '<start> two dogs play together . <end>',\n",
              "  '<start> Two dogs tussling on a dog bed , with a french door and a Persian rug in the background . <end>'],\n",
              " 'Flicker8k_Dataset/2869009633_ea3cafd437.jpg': ['<start> four girls play volleyball . <end>',\n",
              "  '<start> Four woman are playing on a beach as a huge ship passes in the background . <end>',\n",
              "  '<start> Four women in bathing suits are playing on the beach . <end>',\n",
              "  '<start> Slightly overweight women in bikinis are playing on a beach . <end>',\n",
              "  '<start> Women playing volleyball in the sand near the ocean . <end>'],\n",
              " 'Flicker8k_Dataset/366713533_bd6d48cf02.jpg': ['<start> A large crowd in heavy clothing is posing for a camera . <end>',\n",
              "  '<start> large group of people walking <end>',\n",
              "  '<start> The people are standing in front of a building . <end>',\n",
              "  '<start> There is a crowd of people of men , women and children . <end>',\n",
              "  '<start> Two men , a woman , and two young boys stand in front of a large gathering of people outside a building . <end>'],\n",
              " 'Flicker8k_Dataset/1143882946_1898d2eeb9.jpg': ['<start> A lady wearing a helmet holding a bike . <end>',\n",
              "  '<start> A woman in a blue vest and a sky blue helmet stands with her bicycle in traffic . <end>',\n",
              "  '<start> A woman in a helmet rides her bike behind a car . <end>',\n",
              "  '<start> A woman with a helmet and a backpack walks next to her bike . <end>',\n",
              "  '<start> Women with bike and helmet wait for traffic . <end>'],\n",
              " 'Flicker8k_Dataset/3199645963_a681fe04f8.jpg': ['<start> A man and a woman sitting on camp chairs and laughing . <end>',\n",
              "  '<start> A man and a woman smile as they sit in yellow lawn chairs . <end>',\n",
              "  '<start> A man and a woman sit in lawn chairs and laugh . <end>',\n",
              "  '<start> A man with a beard and a woman in a red shirt sitting in lawn chairs in front of tents . <end>',\n",
              "  '<start> A woman is smiling at the bearded man sitting in the lawn chair next to her . <end>'],\n",
              " 'Flicker8k_Dataset/3493255026_5fdaa52cbe.jpg': ['<start> A dog playing with a toy . <end>',\n",
              "  '<start> A white and brown dog is playing tug-o-war . <end>',\n",
              "  '<start> A white and brown dog playing with a black toy . <end>',\n",
              "  '<start> a white dog is tugging on a black rope <end>',\n",
              "  '<start> A white dog with brown spots is chewing on a ropey black toy . <end>'],\n",
              " 'Flicker8k_Dataset/1252787177_4b08625897.jpg': ['<start> People walk by a display of underwear hanging in a stall . <end>',\n",
              "  '<start> Three pairs of different-colored underwear hanging from a clothesline with people and cars in the background <end>',\n",
              "  '<start> Three pairs of granny panties hanging on a line . <end>',\n",
              "  '<start> three pairs of underpants are hanging from a line under a red shelter . <end>',\n",
              "  \"<start> Three pairs of women 's underwear are hanging on a wire under an awning . <end>\"],\n",
              " 'Flicker8k_Dataset/384465575_31294122c0.jpg': ['<start> A man and a woman are biking on a sunny day . <end>',\n",
              "  '<start> Man and woman cyclists ride pass signs on rural road . <end>',\n",
              "  '<start> Two bicyclists ride down a hill . <end>',\n",
              "  '<start> Two friends bike down a hill . <end>',\n",
              "  '<start> Two people are riding their bicycles on a dirt road <end>'],\n",
              " 'Flicker8k_Dataset/3308488725_f91d9aba27.jpg': ['<start> a boy in a blue shirt and blue jeans runs across a playground <end>',\n",
              "  '<start> A boy in blue jeans runs on the track at the local school . <end>',\n",
              "  '<start> A boy in jeans runs on a track . <end>',\n",
              "  '<start> A boy runs on colorful lines . <end>',\n",
              "  '<start> A small boy running track <end>'],\n",
              " 'Flicker8k_Dataset/297724467_e8918a6f90.jpg': ['<start> A brown dog standing on a beach next to a blue Frisbee . <end>',\n",
              "  '<start> A dog shaking itself dry next to a blue Frisbee near to a body of water . <end>',\n",
              "  '<start> A dog shaking off water after playing in the water with a Frisbee . <end>',\n",
              "  '<start> The brown dog is shaking itself off . <end>',\n",
              "  '<start> Wet dog shaking off water on beach <end>'],\n",
              " 'Flicker8k_Dataset/462080147_ca088e6541.jpg': ['<start> a man holding a bottle of wine with a box on his head <end>',\n",
              "  '<start> A man holding a wine bottle and wearing a box on his head is standing next to a man wearing a black hoodie . <end>',\n",
              "  '<start> one man wearing a black hoodie sweatshirt and another wearing a box over his head <end>',\n",
              "  '<start> One person is wearing a box on their head and holding a bottle while another man is standing next to him . <end>',\n",
              "  '<start> Two men , one with a box on his head holding a bottle <end>'],\n",
              " 'Flicker8k_Dataset/3038941104_17ee91fc03.jpg': ['<start> A guy on a skateboard is doing a stunt at night . <end>',\n",
              "  '<start> A man wearing green jumps with his skateboard in the street . <end>',\n",
              "  '<start> A skateboarder jumping a traffic cone . <end>',\n",
              "  '<start> A young man taking a jump on a skateboard . <end>',\n",
              "  '<start> The skateboarder does a jump near a traffic cone . <end>'],\n",
              " 'Flicker8k_Dataset/3056530884_27766059bc.jpg': ['<start> Two dark haired girls are on a tire swing . <end>',\n",
              "  '<start> Two girls are swinging together on a tire swing . <end>',\n",
              "  '<start> Two girls swing on a tire swing . <end>',\n",
              "  '<start> Two laughing girls swing in a tire swing . <end>',\n",
              "  '<start> Two young girls laughing on a tire swing . <end>'],\n",
              " 'Flicker8k_Dataset/3255017708_2b02bfcdcf.jpg': ['<start> A man in American flag shorts holds a white cube at the entrance of a marble building . <end>',\n",
              "  '<start> A man in American flag shorts stands at the top of the stairs . <end>',\n",
              "  '<start> A man in flag underwear standing on the steps with a book and black shoes on . <end>',\n",
              "  '<start> A man wearing US flag boxer shorts is standing on a stairway . <end>',\n",
              "  '<start> Person standing on step wearing American flag shorts and holding a box . <end>'],\n",
              " 'Flicker8k_Dataset/3012513414_86180c44cb.jpg': ['<start> A man performs a ski jump in the snow . <end>',\n",
              "  '<start> A skier in a black top making a jump with a blue and white sign on pile of snow underneath . <end>',\n",
              "  '<start> A skier high in the air after a jump . <end>',\n",
              "  '<start> Man on skis attempting to jump over a snow pile <end>',\n",
              "  '<start> The skier is airborne after going off the ramp . <end>'],\n",
              " 'Flicker8k_Dataset/3514194772_43ba471982.jpg': ['<start> A brown dog in running on grass . <end>',\n",
              "  '<start> A brown dog is running through the grass panting . <end>',\n",
              "  '<start> A brown dog is walking on the grass . <end>',\n",
              "  '<start> A brown dog with white paws is trotting through a field of green grass . <end>',\n",
              "  '<start> A panting brown dog walking on the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3599568766_9e96def0ef.jpg': ['<start> A dog runs overtop the dry earth . <end>',\n",
              "  \"<start> A white dog runs along the beach 's shore . <end>\",\n",
              "  '<start> A white dog with a brown patch on his eye , is running on a dirt path . <end>',\n",
              "  '<start> A white dog with brown spots running on a dirt path <end>',\n",
              "  '<start> The white dog ran down the dusty road . <end>'],\n",
              " 'Flicker8k_Dataset/2280354512_c0d035d53f.jpg': ['<start> A black and white dog stands neck deep in clear water . <end>',\n",
              "  '<start> A black and white dog swimming in clear water . <end>',\n",
              "  '<start> A black dog with white facial and chest markings standing in chest high water . <end>',\n",
              "  '<start> A dog is being hit by a small wave in the ocean . <end>',\n",
              "  '<start> A dog plays in the water . <end>'],\n",
              " 'Flicker8k_Dataset/2414986483_004936f84b.jpg': ['<start> A girl dances like a man in costume <end>',\n",
              "  '<start> A little girl and a man dancing . <end>',\n",
              "  '<start> A man in a black suit dances with a young girl in plaid pants in an outdoor plaza . <end>',\n",
              "  '<start> The girl in the pink top is dancing with a man dressed in a blues brothers suit . <end>',\n",
              "  '<start> The little girl dances with a Blues Brothers impersonator . <end>'],\n",
              " 'Flicker8k_Dataset/1579206585_5ca6a24db0.jpg': ['<start> A girl is playing an electric guitar in front of an amplifier . <end>',\n",
              "  '<start> A girl plays her guitar on a dark stage . <end>',\n",
              "  '<start> A woman is playing guitar onstage <end>',\n",
              "  '<start> A woman playing guitar in red and blue light <end>',\n",
              "  '<start> Guitar player performs at a nightclub red guitar . <end>'],\n",
              " 'Flicker8k_Dataset/3155400369_69e3d6d70f.jpg': ['<start> many people carry their drums . <end>',\n",
              "  '<start> Marching band dressed in yellow and green march on the field . <end>',\n",
              "  '<start> Oregon percussionists are marching with the band . <end>',\n",
              "  '<start> People marching on the grass in yellow shirts carrying drums <end>',\n",
              "  '<start> Several people in yellow and black uniforms are lined up carrying drums . <end>'],\n",
              " 'Flicker8k_Dataset/3538021517_b930dc76fc.jpg': ['<start> A closeup of two boys playing soccer in their team uniforms . <end>',\n",
              "  '<start> A goalie lays on the ground after catching a soccer ball . <end>',\n",
              "  '<start> The boy in goal is gathering up the soccer ball in his arms as another boy runs towards him . <end>',\n",
              "  '<start> Two children playing soccer . <end>',\n",
              "  '<start> Two kids are playing soccer together . <end>'],\n",
              " 'Flicker8k_Dataset/416106657_cab2a107a5.jpg': ['<start> A fluffy white dog runs through the woods with his ears flapping in the breeze . <end>',\n",
              "  '<start> A small white dog is running across a grassy field . <end>',\n",
              "  '<start> A white dog runs in the grass , <end>',\n",
              "  '<start> A white dog wearing a red harness runs though the woods . <end>',\n",
              "  '<start> The little white dog wearing the red collar is running in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/1662261486_db967930de.jpg': ['<start> A black and white dog is jumping through a black and white hoop . <end>',\n",
              "  '<start> A black and white dog jumps through a black and white hoop . <end>',\n",
              "  '<start> A brown and white dog jumping through a black and white hoop . <end>',\n",
              "  '<start> A dog jumping through a black and white hoop . <end>',\n",
              "  '<start> A dog jumping through a ring . <end>'],\n",
              " 'Flicker8k_Dataset/3600221224_945df01247.jpg': ['<start> A brown dog runs towards the camera on a dirt trail with mountains in the background . <end>',\n",
              "  '<start> A brown dog runs toward the camera down a rocky trail through the brush with mountains in the background . <end>',\n",
              "  '<start> A dog running on a trail in the mountains . <end>',\n",
              "  '<start> The brown dog is walking along the dirt path with beautiful mountains behind him . <end>',\n",
              "  '<start> Yellow dog is running up a trail . <end>'],\n",
              " 'Flicker8k_Dataset/3522000960_47415c3890.jpg': ['<start> A guy catches a wave on his surfboard <end>',\n",
              "  '<start> A man is surfing a large wave in the ocean . <end>',\n",
              "  '<start> A surfer catches a gnarly wave . <end>',\n",
              "  '<start> A surfer rides in a wave tunnel . <end>',\n",
              "  '<start> Surfer partially visible through crashing wave , shore in background . <end>'],\n",
              " 'Flicker8k_Dataset/3376439178_159e4126de.jpg': ['<start> A skier flies through the air in front of a mountainous landscape . <end>',\n",
              "  '<start> A skier is jumping in the air over a snowfield near a mountain range . <end>',\n",
              "  '<start> A skier performs a high jump in a snow-covered valley . <end>',\n",
              "  '<start> A snow skier is taking a huge leap over a snow slope . <end>',\n",
              "  '<start> Skier in red jumping high in the air over the snow . <end>'],\n",
              " 'Flicker8k_Dataset/3284887033_e2e48f1863.jpg': ['<start> A sandy brown dog is playing with a soccer ball outside . <end>',\n",
              "  '<start> A tan dog chases a black and white soccer ball . <end>',\n",
              "  '<start> A tan dog is playing with a soccer ball . <end>',\n",
              "  '<start> A yellow dog plays with a soccer ball . <end>',\n",
              "  '<start> The yellow dog is playing with a soccer ball . <end>'],\n",
              " 'Flicker8k_Dataset/191592626_477ef5e026.jpg': ['<start> A climber is scaling a mountain cliff . <end>',\n",
              "  '<start> A man climbs up a mountain . <end>',\n",
              "  '<start> A man in a white helmet and huge backpack is rock climbing . <end>',\n",
              "  '<start> A mountain climber follows the edge of the mountain . <end>',\n",
              "  '<start> A mountain climber has reached the top of a brown rock . <end>'],\n",
              " 'Flicker8k_Dataset/404216567_75b50b5a36.jpg': ['<start> A person in uniform is standing in front of a toll bridge . <end>',\n",
              "  '<start> A woman in a bright safety jacket is standing next to large pipes . <end>',\n",
              "  '<start> A woman wearing a fluorecent safety jacket stands near equipment . <end>',\n",
              "  '<start> a woman wearing a neon jacket standing next to a large machine . <end>',\n",
              "  '<start> The woman is wearing a yellow jacket and blue pants . <end>'],\n",
              " 'Flicker8k_Dataset/3437654963_c4fdc17e8b.jpg': ['<start> A mama bear and its cub are growling directly at one another . <end>',\n",
              "  '<start> The bears are facing each other with their mouths wide open . <end>',\n",
              "  '<start> Two bears are growling at each other . <end>',\n",
              "  '<start> Two bears bare their teeth at one another . <end>',\n",
              "  '<start> Two brown bears touching , face to face , with mouths open . <end>'],\n",
              " 'Flicker8k_Dataset/2340206885_58754a799a.jpg': ['<start> A group of dogs look at each other while standing in the snow . <end>',\n",
              "  '<start> three dogs come face to face with each other in a snowy field . <end>',\n",
              "  '<start> Three dogs in the snow . <end>',\n",
              "  '<start> Three dogs meet in the snow . <end>',\n",
              "  '<start> Three dogs playing in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/3329793486_afc16663cc.jpg': ['<start> A man on a snowboard is grinding a ramp . <end>',\n",
              "  '<start> a skier on a snowy ski jump <end>',\n",
              "  '<start> A snowboarder is riding down a ramp amidst snow . <end>',\n",
              "  '<start> A snowboarder prepares to go over a ramp . <end>',\n",
              "  '<start> Snowboarding practice on a snowy hillside <end>'],\n",
              " 'Flicker8k_Dataset/3472485022_5d03e9852d.jpg': ['<start> A brown and white pitbull runs through the grass with a stick in its mouth . <end>',\n",
              "  '<start> A brown dog carries a long stick on the green grass . <end>',\n",
              "  '<start> A brown dog running with a long stick in his mouth . <end>',\n",
              "  '<start> The brown dog carried the stick in the grass . <end>',\n",
              "  '<start> The large brown dog is running through the grass with a large stick in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/2873188959_ff023defa9.jpg': ['<start> a man in blue shorts leaps from cliff into a lake . <end>',\n",
              "  '<start> A man in swimming trunks jumping off a rock into a lake . <end>',\n",
              "  '<start> A man jumps from a rock into the water . <end>',\n",
              "  '<start> a shirtless man jumps into the water . <end>',\n",
              "  '<start> The young man takes an acrobatic leap into the water . <end>'],\n",
              " 'Flicker8k_Dataset/3262793378_773b21ec19.jpg': ['<start> A bicyclist is attempting a trick on a wire in a tropical location . <end>',\n",
              "  '<start> A biker lets go of the handlebars while flying over the ground . <end>',\n",
              "  '<start> An extreme cyclist in red shirt and helmet jumping his bike over a guidewire <end>',\n",
              "  '<start> A person on a bike leaps high in the air at a beach . <end>',\n",
              "  '<start> Person in orange shirt balancing bicycle on wire <end>'],\n",
              " 'Flicker8k_Dataset/1234817607_924893f6e1.jpg': ['<start> a Korean man sells soda . <end>',\n",
              "  '<start> A man is sitting at an outside bar near many soda and beer cans . <end>',\n",
              "  '<start> A man wearing glasses with aluminum cans lined up in front of him . <end>',\n",
              "  '<start> An elderly man is smiling while sitting in front of a row of soda cans . <end>',\n",
              "  '<start> Vendor selling drinks in a stall . <end>'],\n",
              " 'Flicker8k_Dataset/2883907436_82bf4a36b8.jpg': ['<start> A homeless man stands in the street with a black dog . <end>',\n",
              "  '<start> A man and a dog , with a shopping cart full of items . <end>',\n",
              "  '<start> An old man and his dog are standing otuside with a cart . <end>',\n",
              "  '<start> An old man with a large belly is next to a filled shopping cart and a dog on the street . <end>',\n",
              "  '<start> A scruffy fat man is standing next to a dog and a shopping cart full of stuff . <end>'],\n",
              " 'Flicker8k_Dataset/2684323357_c7a6d05d05.jpg': ['<start> A female in blue jean shorts and a black top sitting in a wicker chair . <end>',\n",
              "  '<start> A girl with a newspaper in a cafe . <end>',\n",
              "  '<start> A happy woman wearing a black tank top is sitting in a wicker chair . <end>',\n",
              "  '<start> A woman in a black shirt is sitting on her feet in a wooden chair . <end>',\n",
              "  '<start> A woman sitting in a chair and smiling at the camera . <end>'],\n",
              " 'Flicker8k_Dataset/3204525212_d548c7fca7.jpg': ['<start> A black dog and small white and black dog look up at a kitchen countertop . <end>',\n",
              "  '<start> A large dog and a small dog stand next to the kitchen counter to investigate . <end>',\n",
              "  '<start> a small black and white dog standing next to a large black dog both looking up onto a counter . <end>',\n",
              "  '<start> Dogs ignore plate of food on floor , look up at kitchen counter . <end>',\n",
              "  '<start> The dogs are begging at the kitchen counter . <end>'],\n",
              " 'Flicker8k_Dataset/1346051107_9cdc14e070.jpg': ['<start> A man is playing a saxophone next to a fire hydrant . <end>',\n",
              "  '<start> A man plays saxophone next to a yellow fire hydrant . <end>',\n",
              "  '<start> A man stands by a wall playing a saxophone . <end>',\n",
              "  '<start> Man playing musical instrument standing beside a yellow and red fire hydrant <end>',\n",
              "  '<start> The man is standing next to a fire hydrant and playing a saxophone . <end>'],\n",
              " 'Flicker8k_Dataset/2569643552_23696a9ba5.jpg': ['<start> The two gray dogs are trying to get a red object . <end>',\n",
              "  '<start> Two dogs try to get an orange toy . <end>',\n",
              "  '<start> Two gray puppies are chewing on a plastic red toy . <end>',\n",
              "  '<start> two grey dogs fighting over a red toy . <end>',\n",
              "  '<start> Two puppies play with a red chew toy in a field . <end>'],\n",
              " 'Flicker8k_Dataset/3376014640_ff5b00769f.jpg': ['<start> A man stands on a surfboard in the ocean with a stick in his hand . <end>',\n",
              "  '<start> A man stands on a surfboard , paddling it out into the ocean . <end>',\n",
              "  '<start> a surfer uses an oar to get out in the ocean . <end>',\n",
              "  '<start> Man stands on surfboard with paddle in ocean . <end>',\n",
              "  '<start> The surfer passes a fellow surfer while paddling into the surf . <end>'],\n",
              " 'Flicker8k_Dataset/241345427_ece0d186c2.jpg': ['<start> A football player dodges a tackle from his opponent . <end>',\n",
              "  '<start> A football player in red chases a football player in blue . <end>',\n",
              "  '<start> A football player in red is trying to tackle another player who has the ball . <end>',\n",
              "  '<start> A football player wears a jersey wuth the number \" 4 \" on it . <end>',\n",
              "  '<start> The football player in the gold helmet is running . <end>'],\n",
              " 'Flicker8k_Dataset/639865690_d66d480879.jpg': ['<start> The two boys are playing with fake swords . <end>',\n",
              "  '<start> Two boys fighting with rattan sticks shaped like swords , one standing the other kneeling . <end>',\n",
              "  '<start> Two boys play swords in the grass with rods . <end>',\n",
              "  '<start> Two boys play with large sticks in the yard . <end>',\n",
              "  '<start> Two young boys are swinging stick swords at each other in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/2384550175_e421d3a871.jpg': ['<start> Children are playing on the swings at a park . <end>',\n",
              "  '<start> Children playing on a swing set at a park . <end>',\n",
              "  '<start> seven children are playing on swings in a park . <end>',\n",
              "  '<start> Six children and two adults playing on or near a swing set . <end>',\n",
              "  '<start> Two children on one swing at a park with other children . <end>'],\n",
              " 'Flicker8k_Dataset/2381583688_a6dd0a7279.jpg': ['<start> A lady with glasses and a warm hat looks int other distance . <end>',\n",
              "  '<start> An elderly woman in a knitted cap and white jacket . <end>',\n",
              "  '<start> An elderly woman sits in a chair and wear a winter hat and coat . <end>',\n",
              "  '<start> An old woman wearing a ski hat and glasses is sitting on a blue chair . <end>',\n",
              "  '<start> an old woman wearing a wildly decorated knit cap and a white jacket <end>'],\n",
              " 'Flicker8k_Dataset/3584561689_b6eb24dd70.jpg': ['<start> A group of boys play basketball together . <end>',\n",
              "  '<start> Basketball player makes a shot as other players to try to intercept . <end>',\n",
              "  '<start> Some teenagers are scrambling for a basketball underneath the net . <end>',\n",
              "  '<start> These people are playing basketball outdoors . <end>',\n",
              "  '<start> two men playing basketball under a blue sky <end>'],\n",
              " 'Flicker8k_Dataset/2249264723_d08655d9f2.jpg': ['<start> a boy jumps on the bright colored pillows . <end>',\n",
              "  '<start> A little boy is jumping on a couch that has a yellow and blue cushion resting on it . <end>',\n",
              "  '<start> A young boy jumps on the brown couch in his gray and blue Spiderman outfit . <end>',\n",
              "  '<start> A young child jumping onto a couch . <end>',\n",
              "  '<start> Little boy wearing gray and blue pajamas jumping on furniture with a blue and a orange pillow under him . <end>'],\n",
              " 'Flicker8k_Dataset/3459858555_c3f0087a72.jpg': ['<start> A climber is climbing under an overhang high above the ground . <end>',\n",
              "  '<start> A person hanging off of a cliff . <end>',\n",
              "  '<start> A person is rock climbing underneath of a rock overhang . <end>',\n",
              "  '<start> A rock climber clings to a steep overhanging rock high above a mesa . <end>',\n",
              "  '<start> Scenic view with person dangling precariously from a rock formation <end>'],\n",
              " 'Flicker8k_Dataset/2595102568_347f6d4b07.jpg': ['<start> a groupe of three walk the street . <end>',\n",
              "  '<start> A man , woman , and child stand outside looking serious and waiting for something . <end>',\n",
              "  '<start> An Asian man , woman , and child are standing on a sidewalk . <end>',\n",
              "  '<start> three asian people standing on a sidewalk with a street scene in the background <end>',\n",
              "  '<start> Three Asian people wait on the sidewalk . <end>'],\n",
              " 'Flicker8k_Dataset/3625519177_4c2bb9e7f0.jpg': ['<start> A man jumps in the air while sky surfing . <end>',\n",
              "  '<start> A man performs a waterskiing stunt . <end>',\n",
              "  '<start> a parasailer jumping a trick high in the air at a lake . <end>',\n",
              "  '<start> A person on a wakeboard is high above the water with a crane in the background <end>',\n",
              "  '<start> A waterskier high in the air above the green water . <end>'],\n",
              " 'Flicker8k_Dataset/3503471307_464a8f588c.jpg': ['<start> A boy is doing a jumping stunt on a bicycle in a run down street . <end>',\n",
              "  '<start> A boy is in the air on his bike . <end>',\n",
              "  '<start> A boy performs a one-handed trick on his bicycle by a rundown building . <end>',\n",
              "  '<start> A young man is pulling tricks on his bike in front of a warehouse . <end>',\n",
              "  '<start> The boy does a jumps his bike into the air . <end>'],\n",
              " 'Flicker8k_Dataset/3405100926_e96308ce89.jpg': ['<start> A group of men in green shirts and black pants holding hands <end>',\n",
              "  '<start> Black people dancing in a Boston square . <end>',\n",
              "  '<start> Four men posing on the street in green shirts and black pants . <end>',\n",
              "  '<start> Several men in matching green and black outfits in front of a monument . <end>',\n",
              "  '<start> Three men wearing green t-shirts do a street performance . <end>'],\n",
              " 'Flicker8k_Dataset/3499720588_c32590108e.jpg': ['<start> A dark skinned man plays a blue guitar on the street . <end>',\n",
              "  '<start> A man playing his guitar on the street , surrounded by buildings and street lights . <end>',\n",
              "  '<start> A man plays a blue guitar on the an empty urban street . <end>',\n",
              "  '<start> a man walking the streets while playing the guitar . <end>',\n",
              "  '<start> The man plays his guitar on the local streets . <end>'],\n",
              " 'Flicker8k_Dataset/3258391809_38fc6211f7.jpg': ['<start> A man and a woman adjust a camera on a tripod outdoors . <end>',\n",
              "  '<start> A man and woman setup a camera . <end>',\n",
              "  '<start> A pair work with the camera . <end>',\n",
              "  '<start> The man and the woman worked together to adjust the camera . <end>',\n",
              "  '<start> Two young adults are setting up the video camera for some action . <end>'],\n",
              " 'Flicker8k_Dataset/3287963317_186491ee78.jpg': ['<start> A group poses for a picture in front of a frozen waterfall . <end>',\n",
              "  '<start> Four people crouched near an ice formation . <end>',\n",
              "  '<start> Four people sitting in the snow at the base of a frozen waterfall . <end>',\n",
              "  '<start> There are four people dressed in warm clothes sitting in the snow in front of a huge piece of ice . <end>',\n",
              "  '<start> Two couples pose for a picture in the winter . <end>'],\n",
              " 'Flicker8k_Dataset/820169182_f5e78d7d19.jpg': ['<start> Two babies look up while they are playing in a playpen with a lot of balls . <end>',\n",
              "  '<start> Two boys in tent-like area , with colorful balls on floor . <end>',\n",
              "  '<start> Two children look up . <end>',\n",
              "  '<start> Two kids are in a pen playing with colorful balls . <end>',\n",
              "  '<start> Two young children play with colored balls . <end>'],\n",
              " 'Flicker8k_Dataset/150387174_24825cf871.jpg': ['<start> A man dressed in camouflage riding a motorbike <end>',\n",
              "  '<start> A man is going between two red flag markers on a dirt bike . <end>',\n",
              "  '<start> A man is riding a dirt bike over some rocks . <end>',\n",
              "  '<start> A man wearing camouflage steers a motorcycle across some stones . <end>',\n",
              "  '<start> The man waeribng a helmet is riding a dirt bike over rocks . <end>'],\n",
              " 'Flicker8k_Dataset/1827560917_c8d3c5627f.jpg': ['<start> A dog with a few leashes and a vest on pulls at something with its mouth . <end>',\n",
              "  '<start> A dog with a harness and a toy its mouth . <end>',\n",
              "  '<start> A dog with a reflective harness looks at the camera . <end>',\n",
              "  '<start> A dog with a toy in its mouth eyes the camera . <end>',\n",
              "  '<start> A small black and white dog in a harness is looking at the camera <end>'],\n",
              " 'Flicker8k_Dataset/241345522_c3c266a02a.jpg': ['<start> A man runs on the football field carrying the ball in front of the ref . <end>',\n",
              "  '<start> A man runs with the football at a professional or collegiate game . <end>',\n",
              "  '<start> An American footballer in a white and purple strip is making a run with the ball . <end>',\n",
              "  '<start> A UW football player runs with the ball . <end>',\n",
              "  '<start> The football player runs with the ball across the field . <end>'],\n",
              " 'Flicker8k_Dataset/3682277595_55f8b16975.jpg': ['<start> A brown and white dog trots across shallow water with his mouth open . <end>',\n",
              "  '<start> A brown spotted dog walks in shallow water . <end>',\n",
              "  '<start> A greyhound walks in the rain through a large puddle . <end>',\n",
              "  '<start> A white and brown dog is walking through the water . <end>',\n",
              "  '<start> The dog walks through the water . <end>'],\n",
              " 'Flicker8k_Dataset/3467282545_273a97b628.jpg': ['<start> Three men , one dressed as an Islamic holy man , sit in a room with green walls doing paperwork , . <end>',\n",
              "  '<start> Three men sit on floor in green room . <end>',\n",
              "  '<start> three men sit on the carpet . <end>',\n",
              "  '<start> Three men sit together while one looks at a book . <end>',\n",
              "  '<start> Three middle eastern men are sitting on the floor by a green wall looking at some paperwork . <end>'],\n",
              " 'Flicker8k_Dataset/2396025708_e4a72e2558.jpg': ['<start> A man parasails in the waves , <end>',\n",
              "  '<start> A man rides large waves on a wind sail . <end>',\n",
              "  '<start> A man windsurfs in the ocean . <end>',\n",
              "  '<start> A person parasails on the crest of a wave . <end>',\n",
              "  '<start> A windsurfer in the waves of the ocean . <end>'],\n",
              " 'Flicker8k_Dataset/2558312618_13d362df66.jpg': ['<start> A brown dog is jumping through a field . <end>',\n",
              "  '<start> a brown dog jumps over the grass . <end>',\n",
              "  '<start> A tan dog jumps and runs in a field . <end>',\n",
              "  '<start> The large brown dog is jumping through the tall grass . <end>',\n",
              "  '<start> The tan dog in a black collar runs across a field . <end>'],\n",
              " 'Flicker8k_Dataset/3576741633_671340544c.jpg': ['<start> A boy is in midair doing a skateboard trick at a skate park while two women and a toddler walk behind him . <end>',\n",
              "  '<start> A boy wearing blue jeans is skateboarding . <end>',\n",
              "  '<start> A buy skateboarding at a skate park . <end>',\n",
              "  '<start> A skateboarder in doing a trick in a skate park . <end>',\n",
              "  '<start> A young man does tricks on his skateboard . <end>'],\n",
              " 'Flicker8k_Dataset/2707244524_d57120d74a.jpg': ['<start> A beige dog runs through the tall grass with a tree in the background . <end>',\n",
              "  '<start> A big tan dog runs on a field filled with grass and weeds . <end>',\n",
              "  '<start> A dog is running through tall grass . <end>',\n",
              "  '<start> A dog running through tall grass . <end>',\n",
              "  '<start> A dog with blond hair and floppy ears running in a field . <end>'],\n",
              " 'Flicker8k_Dataset/2900274587_f2cbca4c58.jpg': ['<start> A body of water at sunset . <end>',\n",
              "  '<start> A sunset over a lake . <end>',\n",
              "  '<start> A sunset sky over rippling water . <end>',\n",
              "  '<start> A water scene with a sunset in the background . <end>',\n",
              "  '<start> This is a beautiful sunset on the water . <end>'],\n",
              " 'Flicker8k_Dataset/3149038044_c7c94688c6.jpg': ['<start> A child gets ready to hike the ball to another . <end>',\n",
              "  '<start> Two boys playing flag football with purple jerseys . <end>',\n",
              "  '<start> Two children are playing flag football together . <end>',\n",
              "  '<start> two children are playing with a football on the grass . <end>',\n",
              "  '<start> Two little boys playing flag football in purple jerseys . <end>'],\n",
              " 'Flicker8k_Dataset/1479028910_3dab3448c8.jpg': ['<start> A boy skateboards and does a jump over another skateboard . <end>',\n",
              "  '<start> A skateboarder attempts to do a trick over a homemade ramp . <end>',\n",
              "  '<start> A skateboarder in gray clothes jumps over a boot in front of an apartment . <end>',\n",
              "  '<start> A skateboarder is jumping over an obstacle in front of a white house . <end>',\n",
              "  '<start> A skateboarder jumps another skateboard . <end>'],\n",
              " 'Flicker8k_Dataset/3426789838_8771f0ed56.jpg': ['<start> A child is thrown by a man in the swimming pool . <end>',\n",
              "  '<start> A father launches his daughter in an Oceanside pool . <end>',\n",
              "  '<start> A young girl jumps off the hands of a man in a pool near the ocean . <end>',\n",
              "  '<start> The man throws the child into the water . <end>',\n",
              "  '<start> The man tossed a child into the swimming pool near the ocean . <end>'],\n",
              " 'Flicker8k_Dataset/2368266191_87d77750f1.jpg': ['<start> A dog chases another by a tree . <end>',\n",
              "  '<start> A dog jumps by a tree while another lays on the ground . <end>',\n",
              "  '<start> A dog leaps high in the air while another watches . <end>',\n",
              "  '<start> Two dogs are playing outside . <end>',\n",
              "  '<start> Two dogs play by a tree . <end>'],\n",
              " 'Flicker8k_Dataset/2980348138_91cc6f6d0f.jpg': ['<start> A climber scales a rock wall . <end>',\n",
              "  '<start> a lone rock climber climbing a rock wall <end>',\n",
              "  '<start> A rock climber climbs . <end>',\n",
              "  '<start> Man climbing up a barren rock face . <end>',\n",
              "  '<start> Man climbs crack in rock face at top left of frame , tree at lower right . <end>'],\n",
              " 'Flicker8k_Dataset/3510219078_670b6b3157.jpg': ['<start> A black dog and a brown and white dog running and playing . <end>',\n",
              "  '<start> A black dog chasing a brown and white dog very quickly over a lawn . <end>',\n",
              "  '<start> A black dog is chasing a brown and white dog across the grass . <end>',\n",
              "  '<start> Two dogs play in the park . <end>',\n",
              "  '<start> Two dogs run in a field . <end>'],\n",
              " 'Flicker8k_Dataset/2300920203_f29260b1db.jpg': ['<start> A blond dog playing with a colorful dog toy . <end>',\n",
              "  '<start> A fluffy dog looking at a yellow chew toy . <end>',\n",
              "  '<start> A fluffy dog plays with a small toy in a living room . <end>',\n",
              "  '<start> A fluffy tan dog dropping a colourful toy . <end>',\n",
              "  '<start> A shaggy white dog plays with a colorful chew toy . <end>'],\n",
              " 'Flicker8k_Dataset/3316046339_8e504be038.jpg': ['<start> A biker riding in a forest . <end>',\n",
              "  '<start> A man in blue jumps his dirt bike in a misty forest . <end>',\n",
              "  '<start> A person with a helmet is jumping a bike over something in a wooded area . <end>',\n",
              "  '<start> Biker jumping off a ramp in the forest . <end>',\n",
              "  '<start> The person in the blue jacket is riding in the forest <end>'],\n",
              " 'Flicker8k_Dataset/3409326324_a704565e8f.jpg': ['<start> a group on white and balck birds lined up on a concrete wall <end>',\n",
              "  '<start> A row of birds is sitting in front of a grey cloud . <end>',\n",
              "  '<start> Many birds are sitting on a concrete wall . <end>',\n",
              "  '<start> many birds sit on a ledge . <end>',\n",
              "  '<start> Pigeons framed against a looming storm . <end>'],\n",
              " 'Flicker8k_Dataset/2107837987_ffecfc367a.jpg': ['<start> A boy stands near water with a stone in his hand . <end>',\n",
              "  '<start> A child in a blue shirt is holding something in his hand on a lake shore . <end>',\n",
              "  '<start> A little boy is ready to throw a stone into the water . <end>',\n",
              "  '<start> A skips rocks near a bridge . <end>',\n",
              "  '<start> The little boy is at the side of the river throwing rocks . <end>'],\n",
              " 'Flicker8k_Dataset/3500136982_bf7a85531e.jpg': ['<start> A group of rollerbladers is lined up on the street . <end>',\n",
              "  '<start> A group of rollerblading on a sloping road . <end>',\n",
              "  '<start> A line of rollerbladers crouch down aerodynamically <end>',\n",
              "  '<start> Many people are rollerblading down the street . <end>',\n",
              "  '<start> Rollerbladers roll in formation down a hill . <end>'],\n",
              " 'Flicker8k_Dataset/964197865_0133acaeb4.jpg': ['<start> A baby is trying to eat a large red plastic toy outdoors . <end>',\n",
              "  '<start> A blonde infant chewing on a red toy . <end>',\n",
              "  '<start> A blonde toddler placing his mouth on the edge of a red plastic toy . <end>',\n",
              "  '<start> A child plays with a toy in the grass . <end>',\n",
              "  '<start> A child with his mouth on a red plastic toy . <end>'],\n",
              " 'Flicker8k_Dataset/2710698257_2e4ca8dd44.jpg': ['<start> A man is standing on top of rocks overlooking the ocean . <end>',\n",
              "  '<start> A man sands with his arms out on a rocky ledge in front of the ocean . <end>',\n",
              "  '<start> A man stands atop a rocky cliff over the water . <end>',\n",
              "  '<start> Man standing on the edge of rocks near an ocean . <end>',\n",
              "  '<start> Man standing on top of jagged rocks near the ocean . <end>'],\n",
              " 'Flicker8k_Dataset/210686241_b8e069fff3.jpg': ['<start> A boy being drenched in a downpour of water . <end>',\n",
              "  '<start> A boy playing in water . <end>',\n",
              "  '<start> A child in a white sox shirt is covered in water spray and looks distressed . <end>',\n",
              "  '<start> A young boy wearing a black shirt is getting soaked in the rain . <end>',\n",
              "  '<start> Children playing in water . <end>'],\n",
              " 'Flicker8k_Dataset/3182558164_488b819f14.jpg': ['<start> A basketball player in the air about to make a shot . <end>',\n",
              "  '<start> A basketball player jumps up with the ball as two others watch . <end>',\n",
              "  '<start> A school basketball game is in progress . <end>',\n",
              "  '<start> Basketball player from Eastern goes between two defenders for a shot . <end>',\n",
              "  '<start> Men playing a basketball game . <end>'],\n",
              " 'Flicker8k_Dataset/2245914678_1f82fc3d80.jpg': ['<start> A girl with dyed red hair wearing striped clothing talking on a cellphone . <end>',\n",
              "  '<start> A girl with read dreadlocks is talking on the phone . <end>',\n",
              "  '<start> a red haired girl with a black and white striped shirt talking on a cellphone <end>',\n",
              "  '<start> A woman with bright red hair and striped clothing talks on a phone . <end>',\n",
              "  '<start> A woman with red hair and a black striped shirt talking on the phone . <end>'],\n",
              " 'Flicker8k_Dataset/3228960484_9aab98b91a.jpg': ['<start> Children walking on a sidewalk with yellow backpacks . <end>',\n",
              "  '<start> Two children are walking along a street wearing yellow backpacks . <end>',\n",
              "  '<start> Two children are walking on a sidewalk wearing yellow and red backpacks . <end>',\n",
              "  '<start> Two kids walk up the sidewalk with their backpacks . <end>',\n",
              "  '<start> two young children with yellow backpacks walking down a sidewalk <end>'],\n",
              " 'Flicker8k_Dataset/3579842996_3a62ec1bc7.jpg': ['<start> A person in a yellow shirt and jeans is running on a track . <end>',\n",
              "  '<start> A Special Olympics contestant runs on a racetrack . <end>',\n",
              "  '<start> A woman in a yellow shirt running on a track . <end>',\n",
              "  '<start> A woman wearing a yellow shirt runs along a red track . <end>',\n",
              "  '<start> Special Olympics woman runner on the track . <end>'],\n",
              " 'Flicker8k_Dataset/191003285_edd8d0cf58.jpg': ['<start> A man and a girl sit on the ground and eat . <end>',\n",
              "  '<start> A man and a little girl are sitting on a sidewalk near a blue bag eating . <end>',\n",
              "  '<start> A man and young girl eat a meal on a city street . <end>',\n",
              "  '<start> A man wearing a black shirt and a girl wearing an orange shirt sitting on the pavement eating . <end>',\n",
              "  '<start> A man wearing a black shirt and a little girl wearing an orange dress share a treat . <end>'],\n",
              " 'Flicker8k_Dataset/469617651_278e586e46.jpg': ['<start> A couple of people sit in chairs in a waiting room lit in sunlight . <end>',\n",
              "  '<start> A line of white chairs folded and a few indescript people sitting in the background . <end>',\n",
              "  '<start> People wait in chairs , one person has their shoe off . <end>',\n",
              "  '<start> Photo of an inside of a place with chairs and people sitting in them . <end>',\n",
              "  '<start> Some people are sitting in seats under a white framed glass canopy . <end>'],\n",
              " 'Flicker8k_Dataset/890734502_a5ae67beac.jpg': ['<start> A boy in a black swimsuit playing near the water . <end>',\n",
              "  '<start> A boy is splashing water in his bathing suit . <end>',\n",
              "  '<start> A little shirtless boy in shorts splashes water . <end>',\n",
              "  '<start> Boy in black swim trunks playing in spray of water . <end>',\n",
              "  '<start> Young boy splashes water at the edge of a pool . <end>'],\n",
              " 'Flicker8k_Dataset/1991806812_065f747689.jpg': ['<start> a boxer punches a boxer in the face . <end>',\n",
              "  '<start> A fighter attempts to kick another fighter while the other fighter blocks his kick . <end>',\n",
              "  '<start> a kickboxer jumping for a kick <end>',\n",
              "  '<start> Two boxers are in the ring . <end>',\n",
              "  '<start> Two men kickbox in a ring , one man punching the other . <end>'],\n",
              " 'Flicker8k_Dataset/3686924335_3c51e8834a.jpg': ['<start> a dog gets sprayed by a hose . <end>',\n",
              "  '<start> A dog is being sprayed with water . <end>',\n",
              "  '<start> A dog jumping through the air getting hit by water . <end>',\n",
              "  '<start> An animal is hosed down by a brick wall . <end>',\n",
              "  '<start> Leaping dog sprayed by off screen person with hose . <end>'],\n",
              " 'Flicker8k_Dataset/3261666285_86fceb762d.jpg': ['<start> A basketball player in white is trying to defend against the player in black who is dribbling the ball . <end>',\n",
              "  '<start> An african american runs with a basketball as a caucasion tries to take the ball from him . <end>',\n",
              "  '<start> Guy in black uniform dribbling basketball away from guy in white uniform <end>',\n",
              "  '<start> Two teams are playing basketball as one man is driving towards the hoop . <end>',\n",
              "  '<start> White player attempts to get ball from black player on basketball court . <end>'],\n",
              " 'Flicker8k_Dataset/2314732154_83bc7f7314.jpg': ['<start> A brown dog walks towards another animal hiding in the grass . <end>',\n",
              "  '<start> A dog walks in the grass towards a dog lying down . <end>',\n",
              "  '<start> A grey silky dog is laying in the grass while a brown dog looks on . <end>',\n",
              "  '<start> A standing brown dog watches another dog lay in the grass <end>',\n",
              "  '<start> The brown dog sees a black dog laying in the dry grass . <end>'],\n",
              " 'Flicker8k_Dataset/1956678973_223cb1b847.jpg': ['<start> Children in red shirts play in the leaves . <end>',\n",
              "  '<start> Four boys in red are playing with fallen leaves . <end>',\n",
              "  '<start> Several children leaping into a pile of leaves on the ground . <end>',\n",
              "  '<start> Small children are playing in a pile of dead leaves . <end>',\n",
              "  '<start> Three kids jumping in leaves . <end>'],\n",
              " 'Flicker8k_Dataset/2881468095_d4ce8c0c52.jpg': ['<start> A boy performing tricks on a brick wall with a skateboard . <end>',\n",
              "  '<start> A guy skateboarding on the side of steps . <end>',\n",
              "  '<start> A skateboarder doing tricks on a brick wall next to stairs . <end>',\n",
              "  '<start> A skateboarder is balancing on a brick wall . <end>',\n",
              "  '<start> The skateboarder is balancing himself and his skateboard on the edge of a brick wall . <end>'],\n",
              " 'Flicker8k_Dataset/146098876_0d99d7fb98.jpg': ['<start> A boy and three girls in blue school uniforms walk down a dirt-covered road . <end>',\n",
              "  '<start> A group of children in blue uniforms walk to class . <end>',\n",
              "  '<start> Four children in uniforms stand in front of palm trees . <end>',\n",
              "  '<start> Four teens in school uniforms walk down a tropical road . <end>',\n",
              "  '<start> Group of school children in blue school uniforms . <end>'],\n",
              " 'Flicker8k_Dataset/3286543624_7a327f79ae.jpg': ['<start> a lady looks surprised . <end>',\n",
              "  '<start> an asian girl looking surprised in front of a brick window <end>',\n",
              "  '<start> An Asian girl makes a surprised face while wearing a shirt that says \" Radio \" <end>',\n",
              "  '<start> A woman in a white shirt standing in front of a brick wall . <end>',\n",
              "  '<start> girl wearing radio t-shirt has open mouth <end>'],\n",
              " 'Flicker8k_Dataset/406248253_27b5eba25a.jpg': ['<start> A little girl in a green coat and a boy holding a red sled walk in the snow . <end>',\n",
              "  '<start> Child wearing a Green Bay coat carrying a red sled behind a child in a green and black coat . <end>',\n",
              "  '<start> Two children and walking through the snow carrying a sled . <end>',\n",
              "  '<start> Two small children in snow clothes are walking through the snow while one carries a red sled <end>',\n",
              "  '<start> two young kids walking towards the sidewalk out of the snow . <end>'],\n",
              " 'Flicker8k_Dataset/2959581023_54402c8d88.jpg': ['<start> a man dives headfirst into the water . <end>',\n",
              "  '<start> A man in a green swimsuit entering the water headfirst after jumping off a rock . <end>',\n",
              "  '<start> A man jumps off some rocks into the water . <end>',\n",
              "  '<start> A person falls into the water near some rocks . <end>',\n",
              "  '<start> A person is diving into blue water on a rocky shore . <end>'],\n",
              " 'Flicker8k_Dataset/1884727806_d84f209868.jpg': ['<start> A man and a woman wear mickey mouse ears at an event . <end>',\n",
              "  '<start> A man and woman wearing Mickey Mouse ears stand in a crowd . <end>',\n",
              "  '<start> A man and woman wear Mickey Mouse hats . <end>',\n",
              "  '<start> a man and woman wearing Mickey Mouse ears in a crowd . <end>',\n",
              "  '<start> Two spectators are adorn with Mickey Mouse ears while looking back at an angle from a stadium . <end>'],\n",
              " 'Flicker8k_Dataset/385835044_4aa11f6990.jpg': ['<start> A girl wearing a brown jacket and blue jeans has on some white headphones and is walking . <end>',\n",
              "  '<start> A girl wearing earphones walks past a traffic cone . <end>',\n",
              "  '<start> A woman in black and red listens to an Ipod , walks down the street <end>',\n",
              "  '<start> A woman wearing headphones is walking past a road cone . <end>',\n",
              "  '<start> A woman wearing headphones walks down the street . <end>'],\n",
              " 'Flicker8k_Dataset/3518675890_2f65e23ff9.jpg': ['<start> A brown dog is running in a field . <end>',\n",
              "  '<start> A light brown dog is running through tall grass . <end>',\n",
              "  '<start> Orange dog runs across grass . <end>',\n",
              "  '<start> The brown dog is running on the grass . <end>',\n",
              "  '<start> The skinny brown dog is running through the tall green grass . <end>'],\n",
              " 'Flicker8k_Dataset/2162469360_ff777edc95.jpg': ['<start> A man is wearing a neon yellow vest while leaning over a roof and another man is standing behind him . <end>',\n",
              "  '<start> A worker in a blue hard-hat looks on as another man works <end>',\n",
              "  '<start> One construction worker in a red shirt watching another construction worker with a hammer fix something . <end>',\n",
              "  '<start> Two construction workers working on a roof top . <end>',\n",
              "  '<start> Two workers in yellow vests try to fix something . <end>'],\n",
              " 'Flicker8k_Dataset/2466171114_3fa51415a7.jpg': ['<start> A brown and white dog fetching a toy . <end>',\n",
              "  '<start> A brown dog is carrying a toy in its mouth . <end>',\n",
              "  '<start> A dog running though a grassy field . <end>',\n",
              "  '<start> Brown dog with objest in mouth moving toward camera . <end>',\n",
              "  '<start> The brown dog with the white chest is carrying a ball . <end>'],\n",
              " 'Flicker8k_Dataset/2925760802_50c1e84936.jpg': ['<start> Two girls wait on the street while wearing tight , barely there clothing . <end>',\n",
              "  \"<start> Two ladies stand on a sidewalk wearing skimpy clothes and men 's underwear . <end>\",\n",
              "  '<start> Two scantily-clad women on a city sidewalk . <end>',\n",
              "  '<start> Two women in skimpy outfits are posing to have their picture taken . <end>',\n",
              "  '<start> Two young women in tight clothing . <end>'],\n",
              " 'Flicker8k_Dataset/3016741474_72b4355198.jpg': ['<start> A couple hug each other , while holding a toy tiger . <end>',\n",
              "  '<start> A couple hugs while holding a plastic tiger . <end>',\n",
              "  '<start> A couple with an inflatable tiger . <end>',\n",
              "  '<start> a couple posing with a plastic orange and white tiger <end>',\n",
              "  '<start> A man dressed as a safari hunter poses with a woman and his inflatable tiger toy . <end>'],\n",
              " 'Flicker8k_Dataset/3458625738_297857369c.jpg': ['<start> a bald man is doing the splits on the dancefloor <end>',\n",
              "  '<start> A man in a shirt and tie does the splits on a wood floor <end>',\n",
              "  '<start> An older man does the splits on a hardwood floor . <end>',\n",
              "  '<start> Older man in a nice outfit and tie does the splits on a wood floor . <end>',\n",
              "  '<start> The formally-dressed man smiles upwards as he does a split . <end>'],\n",
              " 'Flicker8k_Dataset/3667492609_97f88b373f.jpg': ['<start> A boys jumps into the water upside down . <end>',\n",
              "  '<start> A child diving headfirst into a lake . <end>',\n",
              "  '<start> A man is falling backward in swim gear over a large body of water nearby an urban area . <end>',\n",
              "  '<start> The man is going into the water . <end>',\n",
              "  '<start> The person is going into the water . <end>'],\n",
              " 'Flicker8k_Dataset/878758390_dd2cdc42f6.jpg': ['<start> A white dog is running on a rocky beach . <end>',\n",
              "  '<start> a white dog runs along the beach <end>',\n",
              "  '<start> A white dog runs on a beach . <end>',\n",
              "  '<start> A white dog walking on the beach . <end>',\n",
              "  '<start> The white dog is running along the beach . <end>'],\n",
              " 'Flicker8k_Dataset/3058627443_1d57ff0a2c.jpg': ['<start> A man falling off his surfboard on the top of a wave . <end>',\n",
              "  '<start> A man is tumbling into the water having fallen off a surfboard . <end>',\n",
              "  '<start> A person is falling off their surfboard . <end>',\n",
              "  '<start> A person performing watersports gets seperated from his apparatus . <end>',\n",
              "  '<start> A person wearing a red shirt is falling off a white surfboard . <end>'],\n",
              " 'Flicker8k_Dataset/2622517932_57c52c376f.jpg': ['<start> A boy in a white shirt is looking through the glass at a little creature . <end>',\n",
              "  '<start> A child looks at rodents in a glass display . <end>',\n",
              "  '<start> A young boy looks through the glass at an aquarium at a stingray . <end>',\n",
              "  '<start> A young child is kneeling and looking at a small creature inside a glass case . <end>',\n",
              "  '<start> The little boy bends down to look at an animal . <end>'],\n",
              " 'Flicker8k_Dataset/3323419265_7fefaa9d5d.jpg': ['<start> A woman laughing and a man using a noise maker . <end>',\n",
              "  '<start> One girl about to blow on a streamer , while the other laughs . <end>',\n",
              "  '<start> One woman with blond hair smiles in the foreground while another prepares to blow a noisemaker in the background . <end>',\n",
              "  '<start> Two women sitting together . <end>',\n",
              "  '<start> Young girl blowing party popper with a laughing woman beside her . <end>'],\n",
              " 'Flicker8k_Dataset/3376435746_1593d9b243.jpg': ['<start> A person in a raincoat stands in a boat going across the water . <end>',\n",
              "  '<start> A person in a yellow slicker is driving a motorboat next to the beach . <end>',\n",
              "  '<start> A person on a boat by the shore . <end>',\n",
              "  '<start> fisherman motors ahead in his boat , facing the sun <end>',\n",
              "  '<start> This person is driving a boat on a secluded beach . <end>'],\n",
              " 'Flicker8k_Dataset/3181599388_68559cfc17.jpg': ['<start> a wrestler throws another wrestler to the ground . <end>',\n",
              "  '<start> Two men engage in a professional wrestling match . <end>',\n",
              "  '<start> two men in a fight in a ring <end>',\n",
              "  '<start> Two men in midair fighting in a professional wrestling ring . <end>',\n",
              "  '<start> Two wrestlers jump in a ring while an official watches . <end>'],\n",
              " 'Flicker8k_Dataset/1674612291_7154c5ab61.jpg': ['<start> A dog is jumping to catch a Frisbee and casts a perfect shadow . <end>',\n",
              "  '<start> A dog jumps and catches a Frisbee in the grass . <end>',\n",
              "  '<start> A dog jumps and catches a toy . <end>',\n",
              "  '<start> A white dog leaps to catch an object . <end>',\n",
              "  '<start> A yellow lab jumping up to catch a toy . <end>'],\n",
              " 'Flicker8k_Dataset/2238019823_79318d1f11.jpg': ['<start> A man surfs by the Golden Gate bridge on a foggy day . <end>',\n",
              "  '<start> A surfer rides a wave under a red bridge . <end>',\n",
              "  '<start> A surfer by a bridge in foggy conditions <end>',\n",
              "  '<start> A surfer under a bridge . <end>',\n",
              "  '<start> Man surfing under the Golden Gate Bridge on a foggy day . <end>'],\n",
              " 'Flicker8k_Dataset/2718027742_70a72f99ae.jpg': ['<start> A child in a bathing suit plays in a sprinkler . <end>',\n",
              "  '<start> A child plays in backyard sprinklers . <end>',\n",
              "  '<start> A child seen from the waist down in a bathing suit standing on a slip and slide with jets of water shooting up <end>',\n",
              "  '<start> A kid standing in a sprinkler . <end>',\n",
              "  '<start> Child standing on yellow sprinkler mat with water spraying . <end>'],\n",
              " 'Flicker8k_Dataset/1388346434_524d0b6dfa.jpg': ['<start> A man , leaning against a concrete wall with his arms resting on top , looks over a balcony . <end>',\n",
              "  '<start> A man with a white mustache stands on a balcony looking at the road below . <end>',\n",
              "  '<start> A man with grey hair and a plaid shirt looks out over a balcony . <end>',\n",
              "  '<start> An elder man overlooks a balcony facing a street . <end>',\n",
              "  '<start> Man leaning on ledge of a balcony . <end>'],\n",
              " 'Flicker8k_Dataset/496971341_22782195f0.jpg': ['<start> A black dog and a black dog are fighting over a soccer ball . <end>',\n",
              "  '<start> two dogs are gnawing at a blue and yellow ball . <end>',\n",
              "  '<start> Two dogs play and fight over a blue ball . <end>',\n",
              "  '<start> Two dogs playing with a ball . <end>',\n",
              "  '<start> Two dogs playing with a blue and green ball . <end>'],\n",
              " 'Flicker8k_Dataset/2322327298_7948338390.jpg': ['<start> A blond lab runs in the snow . <end>',\n",
              "  '<start> a dog runs through the snow . <end>',\n",
              "  '<start> A golden dog is running through the snow . <end>',\n",
              "  '<start> A tan dog walks across the snow . <end>',\n",
              "  '<start> Brown dog runs in snow . <end>'],\n",
              " 'Flicker8k_Dataset/358114269_96fdb5f7c3.jpg': ['<start> A bicycler rides his bike on the road next to rocks with snow . <end>',\n",
              "  '<start> A bicyclist rides down the road near snow . <end>',\n",
              "  '<start> A man in yellow jacket rides a bike . <end>',\n",
              "  '<start> A person wearing a yellow coat rides a bike past some snowy rocks . <end>',\n",
              "  '<start> The bicycle rider is wearing a yellow jacket and a blue helmet while riding on a road during winter time . <end>'],\n",
              " 'Flicker8k_Dataset/3080056515_3013830309.jpg': ['<start> A boy is whispering to a girl wearing a red and white hat and scarf . <end>',\n",
              "  '<start> One person is whispering to another . <end>',\n",
              "  '<start> The boy is whispering in the girls ear . <end>',\n",
              "  '<start> The child in the red and white hat is listening to the child with the brown hair and green jacket . <end>',\n",
              "  '<start> Two children standing very close . <end>'],\n",
              " 'Flicker8k_Dataset/2857473929_4f52662c30.jpg': ['<start> Two men in hats stand on a wide sidewalk . <end>',\n",
              "  '<start> Two men standing on a street . <end>',\n",
              "  '<start> Two men wearing hats are standing on the path beside a brick building . <end>',\n",
              "  '<start> Two men wearing hats stand on the tree-lined sidewalk near a building . <end>',\n",
              "  '<start> Two men with hats on stand in the street . <end>'],\n",
              " 'Flicker8k_Dataset/3677613006_4689cb8e4e.jpg': ['<start> A disk jockey holds a picture of Michael Jackson . <end>',\n",
              "  '<start> A female DJ holds up a Michael Jackson album . <end>',\n",
              "  '<start> a girl holding a picture of Michael Jackson smiling <end>',\n",
              "  '<start> Girl in club DJ both showing camera the cover of Michael Jackson \\'s \" Thriller . \" <end>',\n",
              "  '<start> The girl is wearing headphones and holding a Michael Jackson album . <end>'],\n",
              " 'Flicker8k_Dataset/2156131463_5b53636cf0.jpg': ['<start> A group of people are standing on a beach near to a white sunshade . <end>',\n",
              "  '<start> People in bathing suits are on a beach looking at a landform in the distance . <end>',\n",
              "  '<start> Two men are watching others on a beach shore . <end>',\n",
              "  '<start> Two men in speedos on the beach . <end>',\n",
              "  '<start> Two men stand looking at the ocean at a tropical resort . <end>'],\n",
              " 'Flicker8k_Dataset/2021613437_d99731f986.jpg': ['<start> A boy dribbles a basketball in the gymnasium . <end>',\n",
              "  '<start> A boy dribbling a basketball in a gym . <end>',\n",
              "  '<start> A boy wearing a Steve Nash shirt dribbles a basketball on an indoor court . <end>',\n",
              "  '<start> A child in a gray t-shirt is bouncing a basketball on a basketball court . <end>',\n",
              "  '<start> One little boy dribbles his basketball . <end>'],\n",
              " 'Flicker8k_Dataset/533602654_9edc74385d.jpg': ['<start> Two children lay under a sculpture of a fish , about to swallow them . <end>',\n",
              "  '<start> Two children lie beneath the hoof of a bronze horse sculpture . <end>',\n",
              "  '<start> Two children on their stomachs lay on the ground under a pipe . <end>',\n",
              "  '<start> Two children play beneath a metal statue . <end>',\n",
              "  '<start> Two young girls make faces from below a sculpture . <end>'],\n",
              " 'Flicker8k_Dataset/3265527323_6431f00692.jpg': ['<start> A chicken and a white dog in the mulch . <end>',\n",
              "  '<start> A dog and a chicken next to a building . <end>',\n",
              "  '<start> A white dog rests on a log as a chicken pecks at the ground . <end>',\n",
              "  '<start> Chicken pecking at the ground . <end>',\n",
              "  '<start> The white dog is ignoring the black and white chicken . <end>'],\n",
              " 'Flicker8k_Dataset/2451988767_244bff98d1.jpg': ['<start> a boy with his leg wrapped in blue tape <end>',\n",
              "  '<start> A little boy with his leg covered in painters tape , his brother wearing a superman cape . <end>',\n",
              "  '<start> Boy with blue cast sits with a boy in an orange cape . <end>',\n",
              "  '<start> One boy has his leg wrapped in blue material and the other boy is wearing a red cape . <end>',\n",
              "  '<start> two kids playing super heroes <end>'],\n",
              " 'Flicker8k_Dataset/3349451628_4249a21c8f.jpg': ['<start> A boy in a dusty alley playing stickball . <end>',\n",
              "  '<start> A boy swings a piece of wood . <end>',\n",
              "  '<start> A child swings a bat next to a stone wall . <end>',\n",
              "  '<start> A young boy wearing a blue visor swings a bat . <end>',\n",
              "  '<start> A young boy with a visor on plays ball with his bat in the street . <end>'],\n",
              " 'Flicker8k_Dataset/757332692_6866ae545c.jpg': ['<start> A smiling woman punching a dog . <end>',\n",
              "  '<start> A tan dog licks a girls hand while laying down . <end>',\n",
              "  '<start> A woman dressed in green is playing with her tan dog . <end>',\n",
              "  '<start> The girl with the green scarf and the white dog appear to be playing . <end>',\n",
              "  '<start> The light brown dog with white spots is nibbling on the girls hand . <end>'],\n",
              " 'Flicker8k_Dataset/2304444199_05386d2e9c.jpg': ['<start> A girl climbs a rock wall . <end>',\n",
              "  '<start> A little blond girl on a climbing wall . <end>',\n",
              "  '<start> A young blond girl is climbing up a rock . <end>',\n",
              "  '<start> A young girl wearing a pink shirt climbs a rock climb . <end>',\n",
              "  '<start> The little girl in a pink shirt and jeans is climbing up a rock climbing wall . <end>'],\n",
              " 'Flicker8k_Dataset/3259119085_21613b69df.jpg': ['<start> A group lies in the snow while someone on a blue snow sled jumps over them . <end>',\n",
              "  '<start> A group of people laying in the snow , while another person jumps them . <end>',\n",
              "  '<start> A person rides a sled over several people . <end>',\n",
              "  '<start> A sledder is making a jump over other kids lying in the snow . <end>',\n",
              "  '<start> One boy jumps over several other boys laying in the snow with his sled , while one boy sits on one end . <end>'],\n",
              " 'Flicker8k_Dataset/3757598567_739b7da835.jpg': ['<start> A little boy with a bib on is watching the camera . <end>',\n",
              "  '<start> A small child in gray and orange winks their eye while holding silverware . <end>',\n",
              "  '<start> A tan-skinned child looking at the camera . <end>',\n",
              "  '<start> A young boy winks as he is eating . <end>',\n",
              "  '<start> The little boy is holding a spoon in his hand whilst winking one eye . <end>'],\n",
              " 'Flicker8k_Dataset/607339469_af851c4119.jpg': ['<start> A girl in a purple shirt feeding ducks <end>',\n",
              "  '<start> A girl wearing purple lean over the edge to reach for the ducks . <end>',\n",
              "  '<start> A little girl dressed in a pink shirt , blue shorts and a pink hair ribbon feeding ducks that are swimming in water . <end>',\n",
              "  '<start> A little girl leans over the side of a wall to feed ducks in the water . <end>',\n",
              "  '<start> Little girl feeds the ducks . <end>'],\n",
              " 'Flicker8k_Dataset/447733067_09cfac3286.jpg': ['<start> A girl in a skimpy bikini outfit walks and carries a helmet . <end>',\n",
              "  '<start> A scantily clad girl , in a helmet , walks away from the camera , down a busy sidewalk . <end>',\n",
              "  '<start> A woman wearing a helmet , tall boots , and short shorts walks down the street . <end>',\n",
              "  '<start> Girl in bikini bottoms , boots and a helmet walking away at a street fair . <end>',\n",
              "  '<start> The woman in the purple bikini and pink top is wearing a safety helmet . <end>'],\n",
              " 'Flicker8k_Dataset/3348785391_c243faf6bb.jpg': ['<start> A man in a swimsuit walks on a tightrope . <end>',\n",
              "  '<start> Man falling off a tightrope <end>',\n",
              "  '<start> The men are walking barefoot on a tightrope . <end>',\n",
              "  '<start> Two students try to walk a tightrope on a campus quad , but one falls off . <end>',\n",
              "  '<start> Young people practice walking on the high wire . <end>'],\n",
              " 'Flicker8k_Dataset/2294516804_11e255807a.jpg': ['<start> A baby puffs up its cheeks . <end>',\n",
              "  '<start> A baby sits by his red and green toy pulling a funny face . <end>',\n",
              "  '<start> A cubby cheeked baby in a yellow and red bib playing with a toy . <end>',\n",
              "  '<start> A male baby makes a funny face for the camera . <end>',\n",
              "  '<start> The baby is sitting in a high chair . <end>'],\n",
              " 'Flicker8k_Dataset/2488795251_c108c77b13.jpg': ['<start> The girls smile at the camera . <end>',\n",
              "  '<start> three black girls wearing white shirts smiling <end>',\n",
              "  '<start> three young african-american girls smile for the camera . <end>',\n",
              "  '<start> Three young black girls posing for the camera . <end>',\n",
              "  '<start> Three young girls wearing white dresses smile at the camera . <end>'],\n",
              " 'Flicker8k_Dataset/2479162876_a5ce3306af.jpg': ['<start> A dog walks down the dirt road as a person follows . <end>',\n",
              "  '<start> A tan dog walks ahead of a man in a dry area . <end>',\n",
              "  '<start> A white dog is going for a walk through the desert with its owner . <end>',\n",
              "  '<start> A yellow dog is walking along a mountain trail <end>',\n",
              "  '<start> Dog in desert area with distant man in background . <end>'],\n",
              " 'Flicker8k_Dataset/2574509968_e4692ae169.jpg': ['<start> a large woman stands in the street . <end>',\n",
              "  '<start> A woman in a white shirt standing on a street <end>',\n",
              "  '<start> A woman stands on a street . <end>',\n",
              "  '<start> A woman wearing a white shirt stands on the street . <end>',\n",
              "  '<start> The woman sips her drink on the sidewalk . <end>'],\n",
              " 'Flicker8k_Dataset/3086810882_94036f4475.jpg': ['<start> A dog runs across a barren ground casting a large shadow . <end>',\n",
              "  '<start> a small dog jumping along the sand <end>',\n",
              "  '<start> A small white dog runs across the sand . <end>',\n",
              "  '<start> Brown and white dog runs towards camera , casting long shadow on dirt . <end>',\n",
              "  '<start> Dog running across sand . <end>'],\n",
              " 'Flicker8k_Dataset/3157744152_31ace8c9ed.jpg': ['<start> A barefoot man in his pajamas is looking toward the sky while walking on the tennis court . <end>',\n",
              "  '<start> A barefoot man walks across a tennis court . <end>',\n",
              "  '<start> A man in a blue shirt is walking barefoot . <end>',\n",
              "  '<start> a man wearing a blue shirt walking barefoot on a tennis court <end>',\n",
              "  '<start> The man is wearing a blue sweater and is barefoot on a court . <end>'],\n",
              " 'Flicker8k_Dataset/3110649716_c17e14670e.jpg': ['<start> A man helps another man tie a red ribbon onto his arm . <end>',\n",
              "  \"<start> A man helps tie a red ribbon around another man 's right arm during a street parade . <end>\",\n",
              "  '<start> A man is tying a red arm band around another mans arm in the street . <end>',\n",
              "  '<start> One man helps another attach a red ribbon to his forearm in the midst of a large group of people . <end>',\n",
              "  '<start> Two men stand together ; one is putting something red on his arm . <end>'],\n",
              " 'Flicker8k_Dataset/1024138940_f1fefbdce1.jpg': ['<start> Two different breeds of brown and white dogs play on the beach . <end>',\n",
              "  '<start> Two dogs are making a turn on a soft sand beach . <end>',\n",
              "  '<start> Two dogs playing in the sand at the beach . <end>',\n",
              "  '<start> Two dogs playing together on a beach . <end>',\n",
              "  '<start> Two large tan dogs play along a sandy beach . <end>'],\n",
              " 'Flicker8k_Dataset/3671262694_29fbeb9d95.jpg': ['<start> A man at a skate park doing a stunt . <end>',\n",
              "  '<start> A skateboarder doing maneuvers . <end>',\n",
              "  '<start> A skateboarder is riding his board on a ramp in a skate park . <end>',\n",
              "  '<start> kid doing tricks on a skateboard <end>',\n",
              "  '<start> The skateboarder is doing a trick at the skate park <end>'],\n",
              " 'Flicker8k_Dataset/225699652_53f6fb33cd.jpg': ['<start> Two dolphins flying headfirst into a beautiful tropical blue lake <end>',\n",
              "  '<start> Two dolphins jumped out of the water in this zoo . <end>',\n",
              "  '<start> Two dolphins jumping into the water . <end>',\n",
              "  '<start> Two dolphins jump out of the blue water with palm trees behind them . <end>',\n",
              "  '<start> Two dolphins jump out of the water together . <end>'],\n",
              " 'Flicker8k_Dataset/2480850054_de3433b54a.jpg': ['<start> A boy is kicking up dust as he runs in the dirt by a tree . <end>',\n",
              "  '<start> A boy wearing brown running in dirt . <end>',\n",
              "  '<start> a dirty boy runs through the dirt . <end>',\n",
              "  '<start> A dusty boy runs along a dirt path through the grass . <end>',\n",
              "  '<start> A teenage boy runs through the dirt near a house in the country . <end>'],\n",
              " 'Flicker8k_Dataset/3549464203_8ab9c6160b.jpg': ['<start> A child steps up on a playground toy as arms reach for her . <end>',\n",
              "  '<start> A girl climbs the stairway of a playground as arms reach for her . <end>',\n",
              "  '<start> An adult is encouraging a young girl to try the slide . <end>',\n",
              "  '<start> A small child is climbing up playground equipment while hands reach toward her from behind bars . <end>',\n",
              "  '<start> The girl is at the park playing on the jungle gym . <end>'],\n",
              " 'Flicker8k_Dataset/3245070961_8977fdd548.jpg': ['<start> A boy in a blue shirt runs while smiling . <end>',\n",
              "  '<start> A child in a black shirt , running . <end>',\n",
              "  '<start> A little boy in navy blue is running very fast . <end>',\n",
              "  '<start> A young boy in a dark blue shirt runs as the grassy background blurs . <end>',\n",
              "  '<start> A young boy in dark clothing with a smile sprints . <end>'],\n",
              " 'Flicker8k_Dataset/3437781040_82b06facb3.jpg': ['<start> An ice hockey player in red is challenging the player in white for the puck . <end>',\n",
              "  '<start> The goalie has come out of the goal to steal the puck from the other team . <end>',\n",
              "  '<start> Two athletes playing in a hockey game . <end>',\n",
              "  '<start> Two hockey players trying to get the puck . <end>',\n",
              "  '<start> Two hockey players try to get control of the puck as the referee looks on . <end>'],\n",
              " 'Flicker8k_Dataset/2367816288_7c2d11d3c5.jpg': ['<start> A boy cuts a flip in the grass . <end>',\n",
              "  '<start> A young man doing a flip on the grass . <end>',\n",
              "  '<start> Boy doing cartwheels in backyard . <end>',\n",
              "  '<start> The boy does a flip over a grassy yard . <end>',\n",
              "  '<start> Young boy in a brown shirt doing a back flip <end>'],\n",
              " 'Flicker8k_Dataset/1332722096_1e3de8ae70.jpg': ['<start> Three women standing on a city street . <end>',\n",
              "  '<start> Three women walk down the street . <end>',\n",
              "  '<start> Two girls and a woman walking on the sidewalk <end>',\n",
              "  '<start> Two girls in bright green boots and a woman are together . <end>',\n",
              "  '<start> Two young ladies in green boots are walking through an urban area while an older lady wearing black shoes follows them . <end>'],\n",
              " 'Flicker8k_Dataset/3116985493_04b1dc3345.jpg': ['<start> A lady and her daughter jump in a swimming pool . <end>',\n",
              "  '<start> A woman and a child play in the water . <end>',\n",
              "  '<start> A woman and a girl splashing in water . <end>',\n",
              "  '<start> A woman is holding a small girl in the midst of a large wave . <end>',\n",
              "  '<start> Mother and daughter play in the waves . <end>'],\n",
              " 'Flicker8k_Dataset/3387661249_33e5ba0bc5.jpg': ['<start> A black horse stands in the grass at a fence , while a brown dog looks on . <end>',\n",
              "  '<start> a black horse sticking its head through a fence trying to reach the grass . <end>',\n",
              "  '<start> A brown dog is looking at a black horse that is sticking its head through a fence . <end>',\n",
              "  '<start> A brown dog is looking at the black horse on the other side of the gate . <end>',\n",
              "  '<start> A horse and dog look at each other in a field . <end>'],\n",
              " 'Flicker8k_Dataset/3359551687_68f2f0212a.jpg': ['<start> A girl does a cartwheel in the street while people watch from the sidewalk . <end>',\n",
              "  '<start> a girl doing a cartwheel in front of a crowd <end>',\n",
              "  '<start> A woman is doing a backwards flip in front of a crowd of other people sitting on the sidewalk . <end>',\n",
              "  '<start> Someone in shorts is somersaulting in front of a crowd . <end>',\n",
              "  '<start> The person in the black shirt performed a stunt in the street while the crowd watched . <end>'],\n",
              " 'Flicker8k_Dataset/472860064_a96a228796.jpg': ['<start> A black dog in front of a tree jumping towards a red Frisbee . <end>',\n",
              "  '<start> A dog jumps through the grass . <end>',\n",
              "  '<start> a grey dog jumps in the air to catch a Frisbee in a grassy park <end>',\n",
              "  '<start> A shaggy dog jumps outside in the grass . <end>',\n",
              "  '<start> The black dog is jumping up in the air . <end>'],\n",
              " 'Flicker8k_Dataset/3364861247_d590fa170d.jpg': ['<start> A group of girls and guys hang out , one is making a sad face . <end>',\n",
              "  '<start> A group of women ; one serious , one frowning , and another smiling . <end>',\n",
              "  '<start> A woman in a pink sweater looks pensive next to a crowd of laughing women . <end>',\n",
              "  '<start> A young girl gazes at something in the distance as those around her talk . <end>',\n",
              "  '<start> There are oriental people standing together . <end>'],\n",
              " 'Flicker8k_Dataset/3430526230_234b3550f6.jpg': ['<start> The dogs run through the field near the water . <end>',\n",
              "  '<start> Two black dogs are chasing each other through shallow grass toward water . <end>',\n",
              "  '<start> Two dogs are running towards the water through brown grass . <end>',\n",
              "  '<start> Two dogs are running toward the water . <end>',\n",
              "  '<start> Two dogs run two a pond on a winter day . <end>'],\n",
              " 'Flicker8k_Dataset/2591110592_ef5f54f91c.jpg': ['<start> A child holding a dress that another child is looking at . <end>',\n",
              "  '<start> A child in a jeans jacket and shorts holding up a white dress as another darker-skinned child looks at it . <end>',\n",
              "  '<start> A little girl holding a frilly white dress out for the other little girl to examine . <end>',\n",
              "  '<start> Two girls holding a dress and looking at the ground <end>',\n",
              "  '<start> Two girls holding up a dress at an event . <end>'],\n",
              " 'Flicker8k_Dataset/3213992947_3f3f967a9f.jpg': ['<start> A girl in a red jacket , surrounded by people . <end>',\n",
              "  '<start> A woman in a puffy red jacket poses for a picture at an ice skating rink . <end>',\n",
              "  '<start> A woman in a red coat is smiling , while people in the background are walking around in winter clothing . <end>',\n",
              "  '<start> A woman wearing a red coat smiles down at the camera . <end>',\n",
              "  '<start> The woman in a red jacket is smiling at the camera . <end>'],\n",
              " 'Flicker8k_Dataset/3094568845_d0b56c5651.jpg': ['<start> A race car is spinning out in front of spectators . <end>',\n",
              "  '<start> a racer skids out . <end>',\n",
              "  '<start> A super car is spinning tires on a raceway track creating smoke near a crowd . <end>',\n",
              "  '<start> Green and black car goes into wall at race . <end>',\n",
              "  '<start> Smoke comes from car in professional race <end>'],\n",
              " 'Flicker8k_Dataset/2474047296_fd9179d438.jpg': ['<start> A man in a white shirt and dress pants sits just underneath a stone archway . <end>',\n",
              "  '<start> a man wearing a white shirt and black pants sitting on a staircase <end>',\n",
              "  '<start> An old man sits in an ancient brick archway . <end>',\n",
              "  '<start> An old man with a white shirt and black pants sits on a chair in the opening of a stone tunnel . <end>',\n",
              "  '<start> Elderly man sitting in a doorway . <end>'],\n",
              " 'Flicker8k_Dataset/2866820467_ae699235a7.jpg': ['<start> A black person in black and red is sleeping on a bench with an open black umbrella . <end>',\n",
              "  '<start> A man is sitting on a bench shading himself with an umbrella . <end>',\n",
              "  '<start> A man sitting up taking a nap on a park bench with an open umbrella protecting him from the sun . <end>',\n",
              "  '<start> Man on bench sleeping under umbrella for shade <end>',\n",
              "  '<start> The person in red and black is laying on a bench under a black umbrella . <end>'],\n",
              " 'Flicker8k_Dataset/2565618804_8d7ed87389.jpg': ['<start> A boy in a swimsuit sitting on top of a circular fountain . <end>',\n",
              "  '<start> A boy is perched on a mushroom shaped fountain . <end>',\n",
              "  '<start> A boy next to the opening of a fountain . <end>',\n",
              "  '<start> A crowd watches from the background as a young male sits atop a round shaped water fountain . <end>',\n",
              "  '<start> A girl kneels on a round fountain that sprays water into the air . <end>'],\n",
              " 'Flicker8k_Dataset/2439813616_c9ac54cc9f.jpg': ['<start> A boy skateboards up a concrete ramp . <end>',\n",
              "  '<start> A man does tricks on his skateboard off a ramp . <end>',\n",
              "  '<start> A skateboarder wearing a red plaid shirt does a trick off of a concrete ramp . <end>',\n",
              "  '<start> its a distorted lens ( almost fish eye ) of a teenage boy skateboarding on a concrete block . <end>',\n",
              "  '<start> Skateboard rider balancing on a rock on his skateboard . <end>'],\n",
              " 'Flicker8k_Dataset/3525417522_7beb617f8b.jpg': ['<start> A daschund leaps through short grass . <end>',\n",
              "  '<start> A small brown dog runs through the grass in front of another dog and their owners . <end>',\n",
              "  '<start> A small dog leaping , but not very high . <end>',\n",
              "  '<start> A small dog running in grass . <end>',\n",
              "  '<start> the little brown dog runs past another dog on the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3215117062_6e07a86352.jpg': ['<start> People in a car showroom floor . <end>',\n",
              "  '<start> Some teenagers watch a screen near some Mini Coopers . <end>',\n",
              "  '<start> The people are standing around at the auto show . <end>',\n",
              "  '<start> Two boys looking at display . <end>',\n",
              "  '<start> Two people watch TV from over a white ledge . <end>'],\n",
              " 'Flicker8k_Dataset/2532294586_4cd76a837d.jpg': ['<start> A little girl dressed in pink swings on a swing <end>',\n",
              "  '<start> a young girl rides a rubber horse . <end>',\n",
              "  '<start> A young girl wearing pink rides a swing and smiles . <end>',\n",
              "  '<start> Little girl in pink is on a ride . <end>',\n",
              "  '<start> The girl in pink smiles as she rides on a black swing . <end>'],\n",
              " 'Flicker8k_Dataset/3339319023_5dcc3ef81a.jpg': ['<start> A baseball player swings at a baseball . <end>',\n",
              "  '<start> A batter prepares to swing at a ball . <end>',\n",
              "  '<start> Ballplayers in blue and white uniforms are on the field playing baseball . <end>',\n",
              "  '<start> Catcher crouches behind baseball hitter . <end>',\n",
              "  '<start> The man in the dark blue jersey is holding a bat , and the catcher is holding his mitt out . <end>'],\n",
              " 'Flicker8k_Dataset/3600403707_527aa0596e.jpg': ['<start> A garden shop is being perused by shoppers with a sitting shop owner waving . <end>',\n",
              "  '<start> A man waves to the camera from inside a greenhouse section of a farm products store . <end>',\n",
              "  '<start> a man wearing a grey shirt waving in the middle of a plant nursery <end>',\n",
              "  '<start> People browse for herbs at a greenhouse . <end>',\n",
              "  '<start> Racks of plants at the farm products store . <end>'],\n",
              " 'Flicker8k_Dataset/2204277704_f1c8c741ed.jpg': ['<start> A boy in a fancy living room jumps from couch to couch . <end>',\n",
              "  '<start> A little boy in a yellow shirt and green shorts jumping on the couch . <end>',\n",
              "  '<start> A young boy leaps from one couch to another . <end>',\n",
              "  '<start> A young boy wearing a yellow shirt is jumping from chair to couch . <end>',\n",
              "  '<start> Young boy wearing a yellow shirt jumps onto the brown couch . <end>'],\n",
              " 'Flicker8k_Dataset/2322334640_d4d22619ff.jpg': ['<start> a boy rides his ripstik on the street . <end>',\n",
              "  '<start> A boy with a helmet skateboards across the street . <end>',\n",
              "  '<start> A child in a blue jacket and helmet is on a skateboard . <end>',\n",
              "  '<start> A young boy wearing a helmet skateboards on the street . <end>',\n",
              "  '<start> There is a boy with a helmet and a stripe down the side of his pants riding on a skateboard . <end>'],\n",
              " 'Flicker8k_Dataset/1390268323_2c8204e91c.jpg': ['<start> Two children climb into the back of a vehicle from the front seat . <end>',\n",
              "  '<start> Two children in swim trunks climb through a car <end>',\n",
              "  '<start> two small boys wearing only their underwear climbing a bench in a van <end>',\n",
              "  '<start> Two young boys are climbing over the seat in a vehicle . <end>',\n",
              "  '<start> Two young boys , wearing just underwear , climb around a vehicle . <end>'],\n",
              " 'Flicker8k_Dataset/2677656448_6b7e7702af.jpg': ['<start> a brown and white dog swimming towards some in the pool <end>',\n",
              "  '<start> A dog in a swimming pool swims toward sombody we cannot see . <end>',\n",
              "  '<start> A dog swims in a pool near a person . <end>',\n",
              "  '<start> Small dog is paddling through the water in a pool . <end>',\n",
              "  '<start> The small brown and white dog is in the pool . <end>'],\n",
              " 'Flicker8k_Dataset/1332492622_8c66992b62.jpg': ['<start> A group of people stand on a balcony near a colorful circus building . <end>',\n",
              "  '<start> A woman and children navigate the balcony of an amusement ride . <end>',\n",
              "  '<start> A woman and two children walking through the upper levels of a carnival attraction . <end>',\n",
              "  '<start> People stand on a colorful balcony . <end>',\n",
              "  '<start> People walking in brightly-colored building . <end>'],\n",
              " 'Flicker8k_Dataset/393987665_91d28f0ed0.jpg': ['<start> A woman at an outdoor food stand . <end>',\n",
              "  '<start> A woman makes a purchase at an outdoor vendor . <end>',\n",
              "  '<start> The woman in the red jacket looks as if she was buying something from the open air vendor . <end>',\n",
              "  '<start> The woman is purchasing a product <end>',\n",
              "  '<start> Woman in red coat buying something from a street vendor . <end>'],\n",
              " 'Flicker8k_Dataset/968081289_cdba83ce2e.jpg': ['<start> A boy jumping off of a dock while his friend watches <end>',\n",
              "  '<start> Two boys are climbing a wooden platform and jumping into a river . <end>',\n",
              "  '<start> Two boys jumping off the pier into the water . <end>',\n",
              "  '<start> Two boys preparing to jump off a pier located on a large body of water . <end>',\n",
              "  '<start> Two children jump off the dock into the lake . <end>'],\n",
              " 'Flicker8k_Dataset/3623302162_099f983d58.jpg': ['<start> A dog is attempting a turn by a nearby picnic bench and metal object . <end>',\n",
              "  '<start> A white dog running next to a bench . <end>',\n",
              "  '<start> The big white dog is running in the grass . <end>',\n",
              "  '<start> The white dog is running around in the grass . <end>',\n",
              "  '<start> White dog with collar running in fenced in grassy area <end>'],\n",
              " 'Flicker8k_Dataset/2964438493_413667c04a.jpg': ['<start> A tan dog plays with a white dog in a baby pool . <end>',\n",
              "  '<start> Two dogs are playing in a pool . <end>',\n",
              "  '<start> Two dogs are playing outside . <end>',\n",
              "  '<start> Two dogs wrestle in a kiddie pool . <end>',\n",
              "  '<start> Two yellow dogs play in a green plastic pool . <end>'],\n",
              " 'Flicker8k_Dataset/3235746553_a40416c00e.jpg': ['<start> A brown dog begins to run along a beach with a wave in the background . <end>',\n",
              "  '<start> A brown dog is running on sand next to the ocean . <end>',\n",
              "  '<start> A dog is galloping on the beach . <end>',\n",
              "  '<start> A dog is running along a beach in front of the ocean . <end>',\n",
              "  '<start> A dog leaps by the ocean . <end>'],\n",
              " 'Flicker8k_Dataset/3482314155_bd1e668b4e.jpg': ['<start> A bull is charging a man in an arena . <end>',\n",
              "  '<start> A guy is running away from a black bull . <end>',\n",
              "  '<start> A man in a bull ring is being charged down by the bull . <end>',\n",
              "  '<start> A man running away from a charging bull . <end>',\n",
              "  '<start> Man in ring bending backwards with a bull behind him . <end>'],\n",
              " 'Flicker8k_Dataset/486712504_36be449055.jpg': ['<start> A dog is jumping across an obstacle . <end>',\n",
              "  '<start> A dog jumps over a red and blue hurdle . <end>',\n",
              "  '<start> A dog leaps over a red and blue jump . <end>',\n",
              "  '<start> A Golden Retreiver jumps over an obstacle . <end>',\n",
              "  '<start> a tan dog jumping over a red and blue toy <end>'],\n",
              " 'Flicker8k_Dataset/2909875716_25c8652614.jpg': ['<start> A girl in a field with a yellow scarf . <end>',\n",
              "  '<start> a girl in along grass field is spinning some yellow material around her . <end>',\n",
              "  '<start> A woman in a field enjoys her clothing being blown by the wind . <end>',\n",
              "  '<start> A young woman in a sunny meadow watches her yellow scarf blow in the wind . <end>',\n",
              "  '<start> Woman in a field of tall grass and wildflowers holding up a yellow scarf <end>'],\n",
              " 'Flicker8k_Dataset/3326454455_960e5442e9.jpg': ['<start> A male soccer player wearing a red uniform jumping in the air and pulling up his shorts . <end>',\n",
              "  '<start> A soccer player pulls his shorts up . <end>',\n",
              "  '<start> A soccer player wearing a red costume makes an obscene gesture . <end>',\n",
              "  '<start> Man in red sports uniform and blue shoes jumping and pull up legs of shorts . <end>',\n",
              "  '<start> We can see the white underwear of the man wearing the red soccer jersey because he is pulling up his shorts . <end>'],\n",
              " 'Flicker8k_Dataset/3601978895_9fec23ce0c.jpg': ['<start> a man leans against a large robot . <end>',\n",
              "  '<start> Two men are standing under a large work of art by a brick building . <end>',\n",
              "  '<start> Two men are standing under what looks to be a giant robot . <end>',\n",
              "  '<start> Two men standing at the feet of a large sculpture . <end>',\n",
              "  '<start> Two men standing near a metal structure in from of a brick wall . <end>'],\n",
              " 'Flicker8k_Dataset/2719102611_fef453bf30.jpg': ['<start> A man in a black and white uniform stands on a motorbike doing a stunt . <end>',\n",
              "  '<start> A motorcycle rider stands on top of his bike . <end>',\n",
              "  '<start> A motorcycle rider starts to sand up on the seat of his white motorcycle . <end>',\n",
              "  '<start> Someone is on a black and white motorcycle and putting their feet on the seat . <end>',\n",
              "  '<start> This person is doing a stunt on a motorcycle . <end>'],\n",
              " 'Flicker8k_Dataset/3721082512_8277087f3f.jpg': ['<start> a man riding a bike through the forest <end>',\n",
              "  '<start> A mountain biker rides through a shady trail . <end>',\n",
              "  '<start> A mountain biker travels along a dirt trail inside a heavily wooded area . <end>',\n",
              "  '<start> A person biking near trees . <end>',\n",
              "  '<start> Bicyclist in racing gear rides through forest area . <end>'],\n",
              " 'Flicker8k_Dataset/3439414478_8038ba9409.jpg': ['<start> A brown dog jumping in the air <end>',\n",
              "  '<start> A brown dog jumps in a wooded area . <end>',\n",
              "  '<start> A brown dog jumps in the air . <end>',\n",
              "  '<start> A dog jumping into the air . <end>',\n",
              "  '<start> Dog running along a dirt path . <end>'],\n",
              " 'Flicker8k_Dataset/3559993787_c49644dcc5.jpg': ['<start> A biker in the woods . <end>',\n",
              "  '<start> a cyclist is making his bike jump between two rocks . <end>',\n",
              "  '<start> a guy on a bike jumping from one large rock to another <end>',\n",
              "  '<start> A man jumps his bicycle in the air between two rocks . <end>',\n",
              "  '<start> Person on bike in air above two large boulders with sun overhead . <end>'],\n",
              " 'Flicker8k_Dataset/2528552898_9e49a7033f.jpg': ['<start> A yellow car is driving away from the water . <end>',\n",
              "  '<start> A yellow race car is driving on a track in front of a group of people . <end>',\n",
              "  '<start> A yellow race car is driving through water on the race course . <end>',\n",
              "  '<start> A yellow race car sliding through a corner as spectators watch . <end>',\n",
              "  '<start> A yellow race car in a curve , with smoke behind it . <end>'],\n",
              " 'Flicker8k_Dataset/956164675_9ee084364e.jpg': ['<start> A runner in a yellow shirt is cresting a hill . <end>',\n",
              "  '<start> A runner with one green shoe and one white shoe runs uphill . <end>',\n",
              "  '<start> A single runner is watched by onlookers in a race . <end>',\n",
              "  '<start> Man wearing green sneakers runs down highway . <end>',\n",
              "  '<start> The runner in red and yellow has just made it up the hill . <end>'],\n",
              " 'Flicker8k_Dataset/3627679667_0e3de9fc90.jpg': ['<start> A blond girl rides the waves . <end>',\n",
              "  '<start> A person in a black wetsuit is surfing a small wave on a beige surfboard . <end>',\n",
              "  '<start> A woman is attempting to ride a small wave . <end>',\n",
              "  '<start> Person surfboards on a wave . <end>',\n",
              "  '<start> The lady is surfing and riding a wave . <end>'],\n",
              " 'Flicker8k_Dataset/2995935078_beedfe463a.jpg': ['<start> A baseball player swinging a bat <end>',\n",
              "  '<start> A cricketer wielding a wears a white suit and black helmet with a face guard . <end>',\n",
              "  '<start> A man is wearing white and playing cricket . <end>',\n",
              "  '<start> Cricket player on field , swinging bat . <end>',\n",
              "  '<start> The person in the white uniform and kneepads is playing a game with a wooden racquet . <end>'],\n",
              " 'Flicker8k_Dataset/3209966887_5b744bd050.jpg': ['<start> A man draws characters with his feel on the street . <end>',\n",
              "  '<start> a man paints chinese characters . <end>',\n",
              "  '<start> A person drawing Chinese characters with his feet . <end>',\n",
              "  '<start> A person paints Asian characters on a banner . <end>',\n",
              "  '<start> A person using a brush to paint chinese characters on a vertical banner . <end>'],\n",
              " 'Flicker8k_Dataset/2633082074_32c85f532c.jpg': ['<start> A boy climbing a tree . <end>',\n",
              "  '<start> A child climbs a tree . <end>',\n",
              "  '<start> A child standing crouched on a tree limb . <end>',\n",
              "  '<start> a young girl climbs a tree . <end>',\n",
              "  '<start> A young man is climbing on a low tree branch in a park . <end>'],\n",
              " 'Flicker8k_Dataset/2917843040_7c9caaaa8a.jpg': ['<start> A guy in red jumping . <end>',\n",
              "  '<start> A man jumping on the hard ground . <end>',\n",
              "  '<start> A man leaps into the air . <end>',\n",
              "  '<start> A person jumps outside . <end>',\n",
              "  '<start> A person wearing a red shirt jumps high above a rocky and grassy field . <end>'],\n",
              " 'Flicker8k_Dataset/2918769188_565dd48060.jpg': ['<start> a person doing the backstroke in a swimming pool <end>',\n",
              "  '<start> A person swimming in a swimming pool . <end>',\n",
              "  '<start> A swimmer is doing the backstroke in the swimming pool . <end>',\n",
              "  '<start> Swimmer does backstroke in swimming lane . <end>',\n",
              "  '<start> The arm of a swimmer rises from the water inside the striped lane marker . <end>'],\n",
              " 'Flicker8k_Dataset/3099923914_fd450f6d51.jpg': ['<start> A group of people sit at a table in front of a large building . <end>',\n",
              "  '<start> People are drinking and walking in front of a brick building . <end>',\n",
              "  '<start> People are enjoying drinks at a table outside a large brick building . <end>',\n",
              "  '<start> Two people are seated at a table with drinks <end>',\n",
              "  '<start> Two people are sitting at an outdoor cafe in front of an old building . <end>'],\n",
              " 'Flicker8k_Dataset/1999444757_1b92efb590.jpg': ['<start> A girl in white is swinging a sword . <end>',\n",
              "  '<start> A lady shows her sword <end>',\n",
              "  '<start> A woman is swordfighting with an unseen opponent . <end>',\n",
              "  '<start> Boy in martial arts-style uniform holding a sword . <end>',\n",
              "  '<start> Two women watching people in white shirts , one of those persons holding a sword . <end>'],\n",
              " 'Flicker8k_Dataset/348380010_33bb0599ef.jpg': ['<start> A brown dog is laying on its back on the grass with a ball in its mouth . <end>',\n",
              "  '<start> A brown dog lies on its back in the grass , holding a ball in its mouth . <end>',\n",
              "  '<start> A brown dog with a tennis ball its mouth rolling on its back on a grassy surface . <end>',\n",
              "  '<start> A dog lays on his back with a favorite tennis ball in his mouth . <end>',\n",
              "  '<start> A tan dog plays with a tennis ball while rolling around in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3415228562_4efa9c9b70.jpg': ['<start> A family is watching a girl on the phone walk by . <end>',\n",
              "  '<start> A girl in a dress walks while a family stands in the background . <end>',\n",
              "  '<start> A woman walks and talks on her cellphone while nearby men watch . <end>',\n",
              "  '<start> a woman wearing a blue dress walking by a group of staring guys <end>',\n",
              "  '<start> Lady on a cellphone walking in front of a group of men . <end>'],\n",
              " 'Flicker8k_Dataset/3058439373_9276a4702a.jpg': ['<start> A crowd of people are standing in front of Italian style buildings . <end>',\n",
              "  '<start> A crowd of people stand looking at somthing in a European courtyard . <end>',\n",
              "  '<start> A crowd of people stands attentively in a plaza with buildings in the background . <end>',\n",
              "  '<start> A group of people are looking at the buildings . <end>',\n",
              "  '<start> Group of people standing in the town square looking up . <end>'],\n",
              " 'Flicker8k_Dataset/2502079538_10ef2e976b.jpg': ['<start> a camel carries two peoples stuff . <end>',\n",
              "  '<start> a couple of people in the desert walking in front of a large tan camel <end>',\n",
              "  '<start> A woman , child , and camel with supplies walking near a tree . <end>',\n",
              "  '<start> camel standing next to tree in desert carrying water <end>',\n",
              "  '<start> Two people stand by a camel with containers strapped to him . <end>'],\n",
              " 'Flicker8k_Dataset/3118505332_b0792489b5.jpg': ['<start> A man and a woman pose for the camera with pursed lips . <end>',\n",
              "  '<start> a man and a woman posing for a picture <end>',\n",
              "  '<start> A man and a woman smile as they dance . <end>',\n",
              "  '<start> A man and woman making funny faces for picture . <end>',\n",
              "  '<start> A woman and a man with a blue shirt are posing for a photograph . <end>'],\n",
              " 'Flicker8k_Dataset/3597924257_d0da3c5fe6.jpg': ['<start> A brown and white dog runs in a field of yellow flowers . <end>',\n",
              "  '<start> A brown dog running at a lean across a lawn . <end>',\n",
              "  '<start> A brown dog runs through a field of grass spotted with yellow flowers <end>',\n",
              "  '<start> The brown dog runs through the field . <end>',\n",
              "  '<start> The tan and white dog is running in the field . <end>'],\n",
              " 'Flicker8k_Dataset/429283612_37f6e7fb7f.jpg': ['<start> A man and a woman looking at ruins . <end>',\n",
              "  '<start> Two people are observing some ruins . <end>',\n",
              "  '<start> Two people are standing on a hill overlooking rolling green grass . <end>',\n",
              "  '<start> Two people take in the view from a hillside . <end>',\n",
              "  '<start> Two tourists photograph a countryside and ruins <end>'],\n",
              " 'Flicker8k_Dataset/3413571342_b9855795e2.jpg': ['<start> A man in colorful shorts is surfing under a wave . <end>',\n",
              "  '<start> A man in colorful trunks surfing a wave on a white surfboard . <end>',\n",
              "  '<start> A surfer rides a wave in a clear blue ocean . <end>',\n",
              "  '<start> a surfer surfs a wave . <end>',\n",
              "  '<start> Man in multicolor trunks riding a surfboard on a wave . <end>'],\n",
              " 'Flicker8k_Dataset/3404906655_bc51c69c1e.jpg': ['<start> A man in a blue jacket riding a dog sled over a snow covered plain . <end>',\n",
              "  '<start> A man on a sled is pulled through the snow by his dogs . <end>',\n",
              "  '<start> A team of dogs is pulling a dog sled . <end>',\n",
              "  '<start> A team of dogs pulling a man on a sled . <end>',\n",
              "  '<start> Five dogs pull a man on a sled through the snow . <end>'],\n",
              " 'Flicker8k_Dataset/2891924845_92f69b0f18.jpg': ['<start> A man and a woman in front of a train . <end>',\n",
              "  '<start> A man and woman look to the right , the man is talking on a cellphone . <end>',\n",
              "  '<start> A woman and a man talking on his phone are at a train station <end>',\n",
              "  '<start> Man is on cellphone in front of train with a young woman behind him . <end>',\n",
              "  '<start> Two people , one on the phone , in front of a train . <end>'],\n",
              " 'Flicker8k_Dataset/2482629385_f370b290d1.jpg': ['<start> A brown dog wading into a marshy pond . <end>',\n",
              "  '<start> A dog on the edge of a body of water . <end>',\n",
              "  '<start> A dog walking into a lake with reeds in the background <end>',\n",
              "  '<start> A dog wearing a blue leash walks into a body of water . <end>',\n",
              "  '<start> A large brown dog leans into the water from the grassy shore . <end>'],\n",
              " 'Flicker8k_Dataset/3030294889_78b2ccbe51.jpg': ['<start> Killer whales perform for a crowd . <end>',\n",
              "  '<start> Three dolphins are jumping out of a pool in front of a crowd of people . <end>',\n",
              "  '<start> Three Orca whales jump in a pool at seaworld . <end>',\n",
              "  '<start> Three whales are jumping into the air at the same time in front of a very large crowd . <end>',\n",
              "  '<start> Three whales are jumping in the air while people watch . <end>'],\n",
              " 'Flicker8k_Dataset/2584957647_4f9235c150.jpg': ['<start> A dog is wading through deep water while holding a stick . <end>',\n",
              "  '<start> A white and brown dog is carrying a stick in the water . <end>',\n",
              "  '<start> A white dog with a brown spot over one eye in a pool of blue water with a stick in its mouth . <end>',\n",
              "  '<start> A white dog with brown spots on his face with a stick in his mouth swimming in water . <end>',\n",
              "  '<start> The white dog brings a stick from the water . <end>'],\n",
              " 'Flicker8k_Dataset/3211210739_3dea005fde.jpg': ['<start> A boy jumps in a gymnastic competition . <end>',\n",
              "  '<start> A male gymnast upside down in midair . <end>',\n",
              "  '<start> A track athlete does a pole vault . <end>',\n",
              "  '<start> A young man is running and performing a trick over a balance beam . <end>',\n",
              "  '<start> The gymnast does a flip over the bar . <end>'],\n",
              " 'Flicker8k_Dataset/2766148353_70b2e8070f.jpg': ['<start> A man with a many colored Mohawk smiling . <end>',\n",
              "  '<start> A man with a piercing and a rainbow colored Mohawk is looking off camera . <end>',\n",
              "  '<start> A person with a colorful Mohawk and tank top smiling . <end>',\n",
              "  '<start> A smiling person with a brightly colored Mohawk hairstyle . <end>',\n",
              "  '<start> A woman with a multicolored Mohawk , earring and grey tank top is smiling . <end>'],\n",
              " 'Flicker8k_Dataset/3594566537_55bd712fdb.jpg': ['<start> a man falls out of his kayak . <end>',\n",
              "  '<start> A man is falling out of his kayak as his paddles go flying . <end>',\n",
              "  '<start> Man kayaking losing his paddle and falling out of the boat . <end>',\n",
              "  '<start> The man falls into the water while his paddle flies and his kayak tips . <end>',\n",
              "  '<start> The man threw his paddle in the air and fell out of the boat and into the water . <end>'],\n",
              " 'Flicker8k_Dataset/2865409854_afedf98860.jpg': ['<start> Children and a few adults are playing in a water fountain on the ground . <end>',\n",
              "  '<start> In an urban fountain , a number of kids and a couple of adults wade through , barefooted . <end>',\n",
              "  '<start> People are gathered in a city and barefoot children stand near a water fountain . <end>',\n",
              "  '<start> People at a park with a public waterspout area . <end>',\n",
              "  '<start> People play in the fountain on a sunny day . <end>'],\n",
              " 'Flicker8k_Dataset/1778020185_1d44c04dae.jpg': ['<start> A brown dog runs for a white and black dog on the grass . <end>',\n",
              "  '<start> A white dog and a brown dog play in the grass . <end>',\n",
              "  '<start> The dogs are in the field playing . <end>',\n",
              "  '<start> Two dogs playing on grass . <end>',\n",
              "  '<start> two dogs play together . <end>'],\n",
              " 'Flicker8k_Dataset/1527513023_3d8152b379.jpg': ['<start> A little boy plays with a water toy while others watch . <end>',\n",
              "  \"<start> A little boy splashes into the small pool at the end of a yellow slip n 'slide . <end>\",\n",
              "  '<start> A young boy slides down a yellow water slide . <end>',\n",
              "  '<start> a young boy sliding on the grass in an innertube <end>',\n",
              "  '<start> A young boy splashes in a yellow wading poll while mom watches <end>'],\n",
              " 'Flicker8k_Dataset/2208055895_37cd8e1edf.jpg': ['<start> A boy stands inside a half-completed igloo . <end>',\n",
              "  '<start> A boy wearing winter clothing in an igloo <end>',\n",
              "  '<start> A childing hiding in a snow fort . <end>',\n",
              "  '<start> a man in a stripy hat is standing in a house built from ice that has a pair of boots in the doorway . <end>',\n",
              "  '<start> Child inside of large snow fort . <end>'],\n",
              " 'Flicker8k_Dataset/3673165148_67f217064f.jpg': ['<start> A brown and white dog is standing in shallow water on a beach near a large rock outcrop . <end>',\n",
              "  '<start> A brown and white dog on the beach . <end>',\n",
              "  '<start> A dog standing on a beach . <end>',\n",
              "  '<start> A dog stands on the beach with a large rock behind him . <end>',\n",
              "  '<start> An unusual looking dog is standing in front of a beautiful backdrop . <end>'],\n",
              " 'Flicker8k_Dataset/397547349_1fd14b95af.jpg': ['<start> A man walking a small white and a big white dog on leashes . <end>',\n",
              "  '<start> A man walking down a sidewalk with 2 dogs on leashes . <end>',\n",
              "  '<start> A man walking two dogs down a street . <end>',\n",
              "  '<start> A man walks two dogs in the city . <end>',\n",
              "  '<start> a man walks two dogs on leashes down the street <end>'],\n",
              " 'Flicker8k_Dataset/3042405316_ba3a01926b.jpg': ['<start> A girl in a blue sweater with a white pattern is jumping into a pile of leaves . <end>',\n",
              "  '<start> A girl in a sweater diving into a pile of leaves . <end>',\n",
              "  '<start> A girl is jumping into a pile of leaves <end>',\n",
              "  '<start> A girl is jumping into a pile of leaves . <end>',\n",
              "  '<start> A young girl is diving into a pile of brown leaves in the yard . <end>'],\n",
              " 'Flicker8k_Dataset/2992614450_b5a6692239.jpg': ['<start> A bicyclist is jumping a horizontal wooden structure with countryside in front of him . <end>',\n",
              "  '<start> A dirt bike in midair <end>',\n",
              "  '<start> A man on a motorbike in midair <end>',\n",
              "  '<start> A person is in the air on a contraption that resembles a bicycle . <end>',\n",
              "  '<start> Someone on a dirt bike , high in the air , near a building . <end>'],\n",
              " 'Flicker8k_Dataset/3231751379_10ebf7150c.jpg': ['<start> A goalie is crouching in a defensive position in front of the goal . <end>',\n",
              "  '<start> A hockey player in blue and red guarding the goal . <end>',\n",
              "  '<start> An ice hockey goalkeeper in a red and blue strip is on his knees in front of the goal . <end>',\n",
              "  '<start> An ice hockey player is bending down on the ice . <end>',\n",
              "  '<start> The hockey player knelt on the ice . <end>'],\n",
              " 'Flicker8k_Dataset/2273105617_7c73d2d2d3.jpg': ['<start> a elderly woman in a tan jacket is standing by the door of a wooden house carrying a green and beige bag . <end>',\n",
              "  '<start> A man in a brown coat standing on a porch <end>',\n",
              "  '<start> A man in a brown jacket standing in front of an open porch door . <end>',\n",
              "  '<start> An old lady standing on a porch looking off in the distance <end>',\n",
              "  '<start> The lady on the porch is wearing a brown jacket . <end>'],\n",
              " 'Flicker8k_Dataset/2528521798_fb689eba8d.jpg': ['<start> A white car racing in the dirt and water <end>',\n",
              "  '<start> A white race car drives through a puddle . <end>',\n",
              "  '<start> A white race car makes a splash through a wet track . <end>',\n",
              "  '<start> A white race car splashes through a puddle on a dirt road <end>',\n",
              "  '<start> A white rally car is throwing mud into the air as it approaches a bend in the track . <end>'],\n",
              " 'Flicker8k_Dataset/1045521051_108ebc19be.jpg': ['<start> A person eats takeout while watching a small television . <end>',\n",
              "  '<start> A person sits on the floor and eats in front of a television . <end>',\n",
              "  '<start> A television with a picture of a girl on it . <end>',\n",
              "  '<start> A young man sits on the floor by the television with a fast food meal in front of him . <end>',\n",
              "  '<start> Someone is laying in front of the TV eating food . <end>'],\n",
              " 'Flicker8k_Dataset/630476551_2ee7399f77.jpg': ['<start> A child is playing on the beach splashing water everywhere . <end>',\n",
              "  '<start> A child is splashing in the surf . <end>',\n",
              "  '<start> A girl plays on the shore at the beach . <end>',\n",
              "  '<start> A girl splashing in a wave at the beach . <end>',\n",
              "  \"<start> A young child is splashed by the ocean 's waves while she plays on the beach . <end>\"],\n",
              " 'Flicker8k_Dataset/3203908917_53e53c03d1.jpg': ['<start> A masked man helps burn a flag . <end>',\n",
              "  '<start> I man with a covered face burning an israei flag in front of a crowd . <end>',\n",
              "  '<start> Men burn an Israeli flag . <end>',\n",
              "  '<start> Some middle eastern people have set an Israeli flag on fire . <end>',\n",
              "  '<start> The man is wearing a red shirt and red flannel handkerchief while watching a flag burn . <end>'],\n",
              " 'Flicker8k_Dataset/2831314869_5025300133.jpg': ['<start> A fisherman sits on the roll of chain . <end>',\n",
              "  '<start> a man in boots sitting on a machine <end>',\n",
              "  '<start> A man resting his legs on spool of metal cable . <end>',\n",
              "  '<start> A man wearing big , brown , rubber boots is sitting down of a machine with big chains . <end>',\n",
              "  '<start> a young man relaxing his legs on a pice of machinery <end>'],\n",
              " 'Flicker8k_Dataset/445861800_75fc6a8c16.jpg': ['<start> Three men walking on a sidewalk in a city . <end>',\n",
              "  '<start> Three people are walking down the street with cars and buildings in the background . <end>',\n",
              "  '<start> Three people stand along a main road . <end>',\n",
              "  '<start> Three people walking on a sidewalk with 3 light colored cars in the background . <end>',\n",
              "  '<start> three people wearing winter clothes standing on the sidewalk near a street <end>'],\n",
              " 'Flicker8k_Dataset/3214573346_d3a57f0328.jpg': ['<start> A small dog leaps across a brown pillow . <end>',\n",
              "  '<start> a small white and black dog jumping over a big brown couch . <end>',\n",
              "  '<start> A small white dog with brown on his face and back is jumping over a cushion . <end>',\n",
              "  '<start> A white dog with black spots jumps in midair . <end>',\n",
              "  '<start> White dog high jumping over some pillows . <end>'],\n",
              " 'Flicker8k_Dataset/3408130183_f038bdaa4f.jpg': ['<start> A black and a brown dog are walking through the woods . <end>',\n",
              "  '<start> A brown and a black dog are running . <end>',\n",
              "  '<start> A dog with a brown spot around one eye walking in front of a black dog . <end>',\n",
              "  '<start> Two dogs are running along a grassy path . <end>',\n",
              "  '<start> Two dogs running through the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3240090389_97a8c5d386.jpg': ['<start> A person in a red shirt on a skateboard . <end>',\n",
              "  '<start> A person riding a skateboard . <end>',\n",
              "  '<start> A teenage male grinds on his skateboard . <end>',\n",
              "  '<start> The skateboarder does a trick on a ramp . <end>',\n",
              "  '<start> While doing tricks , the skateboarder is at the top of the half pipe . <end>'],\n",
              " 'Flicker8k_Dataset/1301140633_046e4e8010.jpg': ['<start> a boy in a blue shirt with dirt on his face <end>',\n",
              "  '<start> A boy with a dirty face smiles . <end>',\n",
              "  '<start> A child with a dirty face looks at the camera and smiles . <end>',\n",
              "  '<start> Blond child with dirty face holding yellow bottle with red cap , plants in background . <end>',\n",
              "  '<start> The boy has blonde hair and a dirty face . <end>'],\n",
              " 'Flicker8k_Dataset/3726025663_e7d35d23f6.jpg': ['<start> A group of people ride in a race <end>',\n",
              "  '<start> A large group of bicycles riding their bikes . <end>',\n",
              "  '<start> Bicycles in a race . <end>',\n",
              "  '<start> Bikers participate in a race . <end>',\n",
              "  '<start> There are many men racing on their bicycles . <end>'],\n",
              " 'Flicker8k_Dataset/2064792226_97e41d8167.jpg': ['<start> A girl is taking a picture of a girl and guy on a colorfully decorated pink bike . <end>',\n",
              "  '<start> A girl sits on a decorated bike with a younger boy while another girl takes a picture . <end>',\n",
              "  '<start> Two people on a bicycle are posing for a picture <end>',\n",
              "  '<start> Two people ridding a colorfully decorated bicycle . <end>',\n",
              "  '<start> Two people ride a colorful bike while a blond woman takes their picture . <end>'],\n",
              " 'Flicker8k_Dataset/358607894_5abb1250d3.jpg': ['<start> A man in a black hat reaches into a box . <end>',\n",
              "  '<start> A man in a black hat touches a cardboard box . <end>',\n",
              "  '<start> A man in a black hat , with a cardboard box . <end>',\n",
              "  '<start> A man wearing a black hat opening a cardboard box . <end>',\n",
              "  '<start> The man is opening a box . <end>'],\n",
              " 'Flicker8k_Dataset/3613242966_a1c63a0174.jpg': ['<start> A dog plays in the water . <end>',\n",
              "  '<start> a dog runs through the water . <end>',\n",
              "  '<start> A dog swims in the water . <end>',\n",
              "  '<start> A tan dog splashes as he swims through the water . <end>',\n",
              "  '<start> the dog is somehow causing a wave in the water . <end>'],\n",
              " 'Flicker8k_Dataset/3084018061_df66d98325.jpg': ['<start> Five people are sitting in a bar , while a tv plays nearby . <end>',\n",
              "  '<start> Older men at bar drinking alcohol <end>',\n",
              "  '<start> Three men drink at a reflective bar . <end>',\n",
              "  '<start> Three men stand at a bar with drinks . <end>',\n",
              "  '<start> Three men stand in a bar with a purple counter . <end>'],\n",
              " 'Flicker8k_Dataset/1473080948_bae2925dc8.jpg': ['<start> A kayaker wearing a blue wetsuit and black helmet paddles his yellow kayak in murky rolling rapids . <end>',\n",
              "  '<start> A man kayaking through rapids . <end>',\n",
              "  '<start> A man wearing a life jacket and helmet is water rafting down a river . <end>',\n",
              "  '<start> A person in a blue shirt , helmet and life jacket paddles a yellow kayak . <end>',\n",
              "  '<start> A person white-water rafting in turbulent water . <end>'],\n",
              " 'Flicker8k_Dataset/390992388_d74daee638.jpg': ['<start> A girl treks through the snow with her backpack on . <end>',\n",
              "  '<start> A hiker is climbing up a snowy mountain . <end>',\n",
              "  '<start> A hiker using hiking poles on a snowy mountain . <end>',\n",
              "  '<start> Someone hikes through a snowy mountain range <end>',\n",
              "  '<start> The woman is hiking up a snowy hill . <end>'],\n",
              " 'Flicker8k_Dataset/1398873613_7e3174dd6c.jpg': ['<start> A man smiles and holds onto a rope on a boat . <end>',\n",
              "  '<start> A man wearing a brown shirt is talking to a man in a white shirt . <end>',\n",
              "  '<start> A man with a brown t-shirt holds on to a wire while another man looks on . <end>',\n",
              "  '<start> Two men on a boat . <end>',\n",
              "  '<start> Two men one has a white shirt and other one has on a brown shirt and sunglasses . <end>'],\n",
              " 'Flicker8k_Dataset/2799871904_3b3125518a.jpg': ['<start> A gray haired woman in a yellow shirt sitting under a blue sign . <end>',\n",
              "  '<start> An older woman sits under a sign advertising a 3 slice special . <end>',\n",
              "  '<start> A woman facing down is sitting under an advertisment . <end>',\n",
              "  '<start> A woman sits underneath a sale sign . <end>',\n",
              "  '<start> A woman wearing a yellow shirt sits on a wooden bench . <end>'],\n",
              " 'Flicker8k_Dataset/313326614_b2adbe59e0.jpg': ['<start> A man in a red jacket is standing at the top of some steps at night . <end>',\n",
              "  '<start> A man in a red jacket is standing at the top of the stadium steps . <end>',\n",
              "  '<start> a man in a red shirt at the top of a set of stairs with arena lights on in the background <end>',\n",
              "  '<start> A man stands at the top of a flight of stairs at the entrance to a stadium . <end>',\n",
              "  '<start> A man stands at the top of a stadium staircase . <end>'],\n",
              " 'Flicker8k_Dataset/3226254560_2f8ac147ea.jpg': ['<start> A dog in a snowy area . <end>',\n",
              "  '<start> A spotted dog catching a ball on a snowy field . <end>',\n",
              "  '<start> A white and brown spotted dog runs along the snow to catch a ball . <end>',\n",
              "  '<start> A white dog is running fast on a trail covered by snow . <end>',\n",
              "  '<start> The brown and white dog is playing in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/3173976185_8a50123050.jpg': ['<start> a black and white dog is standing on the grass with its mouth wide open . <end>',\n",
              "  '<start> A black and white dog looks at the camera with an open mouth . <end>',\n",
              "  '<start> A black and white dog , on a green field , barking at the camera . <end>',\n",
              "  '<start> A black and white dog runs with its mouth open . <end>',\n",
              "  '<start> The black and white dog has its mouth wide open . <end>'],\n",
              " 'Flicker8k_Dataset/3671950830_b570bac1b9.jpg': ['<start> A man on a motorcycle rides donuts with a crowd watching <end>',\n",
              "  '<start> A motorcycle rider spinning his tires in a circle . <end>',\n",
              "  '<start> A motorcyclist burns rubber in a circle while a crowd watches . <end>',\n",
              "  '<start> A person in a yellow helmet on a blue motorcycle is doing tricks . <end>',\n",
              "  '<start> Person on blue motorcycle with smoking back tire and people watching in the background . <end>'],\n",
              " 'Flicker8k_Dataset/2338627102_6708a9b4fd.jpg': ['<start> A man in a red jacket and khaki pants is walking through a part of what looks like Arizona . <end>',\n",
              "  '<start> A man wearing jeans and a hooded , long sleeved top , and a backpack , walks in a desert . <end>',\n",
              "  '<start> A person with a red hooded jacket and a black backpack is walking near a rocky wall . <end>',\n",
              "  '<start> Man wearing red looks on at desert <end>',\n",
              "  '<start> There is a lone hiker in the middle of a prairie with his back to the camera , showing his backpack . <end>'],\n",
              " 'Flicker8k_Dataset/3574244361_715ac347cd.jpg': ['<start> A child on a swing . <end>',\n",
              "  '<start> A girl swinging hard enough to get herself vertical . <end>',\n",
              "  '<start> A little girl with a white shirt and brown hair is swinging almost completely upside down in a park . <end>',\n",
              "  '<start> A young child swings in a park setting . <end>',\n",
              "  '<start> A young girl upside down on a swing set <end>'],\n",
              " 'Flicker8k_Dataset/3559429170_3183c404b9.jpg': ['<start> A boy wearing a helmet and no shirt , in the air on a bike . <end>',\n",
              "  '<start> A man going over a jump on his bike with a river in the background <end>',\n",
              "  '<start> A man on a bike does a very high jump . <end>',\n",
              "  '<start> A man without a shirt , wearing a helmet , jumping a bike in the air near water . <end>',\n",
              "  '<start> A woman doing a jump on a bike <end>'],\n",
              " 'Flicker8k_Dataset/3206919175_e3a11b6874.jpg': ['<start> A group of people gather with only their legs showing and one of them is holding a cigarette . <end>',\n",
              "  '<start> a man holds a cigarette . <end>',\n",
              "  '<start> Hands and feet of several people holding cigarettes . <end>',\n",
              "  '<start> No faces are shown in this picutre of jeans and sweatshirts . <end>',\n",
              "  '<start> The legs and lower bodies of people sitting and smoking . <end>'],\n",
              " 'Flicker8k_Dataset/241345533_99c731403a.jpg': ['<start> A coach at a game . <end>',\n",
              "  '<start> A coach for a game listens to his headphones and watches the game . <end>',\n",
              "  '<start> A coach wearing a white shirt and hat on the sidelines of a game . <end>',\n",
              "  '<start> A football coach watches a play being made . <end>',\n",
              "  '<start> A man wearing a white shirt is wearing an at&t headphone at a game . <end>'],\n",
              " 'Flicker8k_Dataset/2662570182_350baa020f.jpg': ['<start> A father pushes his daughters go-kart while another girl watches <end>',\n",
              "  '<start> A girl riding in a toy car with a man behind her <end>',\n",
              "  '<start> A man pushes a child in a blue car while another child looks on . <end>',\n",
              "  '<start> The little girl is driving the small blue car . <end>',\n",
              "  '<start> Two small children play with a toy riding car in the street with a grown up . <end>'],\n",
              " 'Flicker8k_Dataset/2088460083_42ee8a595a.jpg': ['<start> A broken down hummer gets towed on a truck bed . <end>',\n",
              "  '<start> A damaged vehicle is carried by a repair truck in a night-time scene . <end>',\n",
              "  '<start> A flat bed truck in a parking lot with an army vehicle on its bed . <end>',\n",
              "  '<start> An old , beat-up jeep being towed away . <end>',\n",
              "  '<start> Dirty SUV sits on the bed of a tow truck at night . <end>'],\n",
              " 'Flicker8k_Dataset/2905942129_2b4bf59bc0.jpg': [\"<start> A couple of smiling little boys ride together in a plastic chair-swing , one on the other 's lap . <end>\",\n",
              "  '<start> Children swinging on a blue swing in the park . <end>',\n",
              "  '<start> The two children swinging together on a swing . <end>',\n",
              "  '<start> Two little kids laugh on a blue swing . <end>',\n",
              "  '<start> Two smiling , small children , one child holding the other on a swing . <end>'],\n",
              " 'Flicker8k_Dataset/3041348852_872c027c16.jpg': ['<start> Five small white dogs are wearing muzzles and running . <end>',\n",
              "  '<start> Five white and white and brown , muzzled dogs run across a green , grassy lawn . <end>',\n",
              "  '<start> Five white dogs with muzzles are running towards the camera . <end>',\n",
              "  '<start> Little muzzled white dogs are running in the grass . <end>',\n",
              "  '<start> Several dogs in muzzles are racing on the grass . <end>'],\n",
              " 'Flicker8k_Dataset/2623939135_0cd02ffa5d.jpg': ['<start> An attractive woman holds a halo above her head . <end>',\n",
              "  '<start> A woman in a dress raises her arm over her head . <end>',\n",
              "  '<start> A woman is looking at the ceiling while taking off her hat . <end>',\n",
              "  '<start> A woman looking up towards a wide ring , she is holding over her head , a drink in her other hand . <end>',\n",
              "  '<start> A woman looking upward with her hand above her head . <end>'],\n",
              " 'Flicker8k_Dataset/230016181_0c52b95304.jpg': ['<start> A person and their tan dog go for a ride in a rowboat . <end>',\n",
              "  '<start> A woman and a dog rowing down a wide river . <end>',\n",
              "  '<start> a woman wearing an orange jacket sitting in a canoe on a lake with a dog behind her <end>',\n",
              "  '<start> A woman with a dog canoe down a river . <end>',\n",
              "  '<start> Woman and dog in rowboat on the water . <end>'],\n",
              " 'Flicker8k_Dataset/3591457224_88281dd04f.jpg': ['<start> A clown holding a broom with both arms raised . <end>',\n",
              "  '<start> A clown in a colorful shirt and cowboy hat is raising his arms in a crowd of people . <end>',\n",
              "  '<start> a man dressed as a clown is performing before and audience . <end>',\n",
              "  '<start> A man wearing a purple hat and clown makeup is cheering to a crowd . <end>',\n",
              "  '<start> Clown holding broom smiles at people . <end>'],\n",
              " 'Flicker8k_Dataset/510791586_3913ade6a7.jpg': ['<start> A girl wading through water in a lake . <end>',\n",
              "  '<start> A lit girl splashes around in natural water . <end>',\n",
              "  '<start> a young child running in the shallows at a lake . <end>',\n",
              "  '<start> A young girl playing in the water with others watching in the background . <end>',\n",
              "  '<start> Someone is splashing through ankle-high sun-lit water . <end>'],\n",
              " 'Flicker8k_Dataset/2882589788_cb0b407a8d.jpg': ['<start> A girl in a blue uniform raises her arm . <end>',\n",
              "  '<start> A young cheerleader is cheering <end>',\n",
              "  '<start> A young female cheerleader dressed in a blue uniform is cheering in front of a group of band members . <end>',\n",
              "  '<start> A young girl in a blue and white cheerleading costume holds her right arm up while her other hand is on her hip . <end>',\n",
              "  '<start> Girl in blue and white uniform doing cheers <end>'],\n",
              " 'Flicker8k_Dataset/554774472_b5d165ff69.jpg': ['<start> The children play in the pool . <end>',\n",
              "  '<start> Two children are playing in an outdoor swimming pool . <end>',\n",
              "  '<start> Two children playing in a swimming pool . <end>',\n",
              "  '<start> Two children play in the water of an above-ground pool . <end>',\n",
              "  '<start> Two little girls playing in the pool . <end>'],\n",
              " 'Flicker8k_Dataset/3592992234_6d3fe58a70.jpg': ['<start> A man in a white shirt swinging a stick <end>',\n",
              "  '<start> A man in a white shirt walks in the tall grass holding a stick . <end>',\n",
              "  '<start> A man is walking in a field carrying a stick . <end>',\n",
              "  '<start> A man with a stick in his left hand in a field <end>',\n",
              "  '<start> Man near golf course preparing to throw a stick <end>'],\n",
              " 'Flicker8k_Dataset/861661418_8a37024ace.jpg': ['<start> A brown dog picks up a twig from a stone surface . <end>',\n",
              "  '<start> A brown puppy chewing on a stick . <end>',\n",
              "  '<start> A dog with big ears is holding a small stick in its mouth . <end>',\n",
              "  '<start> A puppy has a stick in its mouth . <end>',\n",
              "  '<start> A puppy with big ears chewing on a stick . <end>'],\n",
              " 'Flicker8k_Dataset/1469358746_2a879abaf3.jpg': ['<start> A man and his dog in the mountains . <end>',\n",
              "  '<start> A man and his dog on the top of a mountain . <end>',\n",
              "  '<start> a man holding a camera is sitting on a mountain with a black dog . <end>',\n",
              "  '<start> A man poses with his black dog at the top of a mountain . <end>',\n",
              "  '<start> A man with a dog . <end>'],\n",
              " 'Flicker8k_Dataset/3614595423_f9e0ab4fb0.jpg': ['<start> A bunch of kids are climbing on a tree and hamming it up . <end>',\n",
              "  '<start> Children climb a tree . <end>',\n",
              "  '<start> Children posing in a tree <end>',\n",
              "  '<start> Eight tan children making faces in a tree <end>',\n",
              "  '<start> Several children are in a tree , laughing and with their hands on their chins . <end>'],\n",
              " 'Flicker8k_Dataset/3594822096_e1144b85d6.jpg': ['<start> A biker moving quickly past trees . <end>',\n",
              "  '<start> A guy is on his bicycle . <end>',\n",
              "  '<start> A man rides his bike through the woods . <end>',\n",
              "  '<start> A man with a shaved head riding a mountain bike . <end>',\n",
              "  '<start> The man has a goatee and wear black gloves while riding a bike . <end>'],\n",
              " 'Flicker8k_Dataset/3627216820_4952bacbcb.jpg': ['<start> a dog jumps over another dog as both animals are trying to catch the same ball . <end>',\n",
              "  '<start> Two black and white dogs playing with a ball . <end>',\n",
              "  '<start> Two dogs playing , one dog is jumping in the air above the second dog . <end>',\n",
              "  '<start> two terriers jumping after a tennis ball in a park <end>',\n",
              "  '<start> Two white and black dogs play and jump in a fenced area . <end>'],\n",
              " 'Flicker8k_Dataset/3141613533_595723208d.jpg': ['<start> Two boys standing in an empty corn field in the winter . <end>',\n",
              "  '<start> Two people stand on a harvested field in cold weather . <end>',\n",
              "  '<start> Two young boys standing in a corn field after the harvest . <end>',\n",
              "  '<start> Two young boys wearing jackets frolic in a large field . <end>',\n",
              "  '<start> Two young people brave the cold . <end>'],\n",
              " 'Flicker8k_Dataset/109823395_6fb423a90f.jpg': ['<start> A four wheeler jumping in an empty field . <end>',\n",
              "  '<start> A man on a four wheeler is flying through the air . <end>',\n",
              "  '<start> A person is riding an orange ATV in a large empty field . <end>',\n",
              "  '<start> Man jumping with all terrain vehicle <end>',\n",
              "  '<start> Man on an ATV catching air ! <end>'],\n",
              " 'Flicker8k_Dataset/3298199743_d8dd8f94a0.jpg': ['<start> A person in a green shirt jumping on a lawn near several other crowds of people . <end>',\n",
              "  '<start> A person with a green shirt jumps high over the grass . <end>',\n",
              "  '<start> A young boy in a green shirt is jumping . <end>',\n",
              "  '<start> a young man wearing a green shirt in jumping in the air <end>',\n",
              "  '<start> Young boy jumping in the air with his knees bent and arms spread . <end>'],\n",
              " 'Flicker8k_Dataset/3359089834_263e529c71.jpg': ['<start> A group of dogs are playing together in snow . <end>',\n",
              "  '<start> A pack of dogs playing in the snow . <end>',\n",
              "  '<start> Four dogs are playing on a field covered in snow . <end>',\n",
              "  '<start> Two black and two white dogs are playing in the snow . <end>',\n",
              "  '<start> Two black dogs and 2 white dogs interact with one another in a snowy field . <end>'],\n",
              " 'Flicker8k_Dataset/3638440337_6d5c19a8f0.jpg': ['<start> A boy jumps over a red and black rope at a crowded park . <end>',\n",
              "  '<start> A man dressed and a black shirt and pants is high jumping over a red and black pole . <end>',\n",
              "  '<start> A man wearing black jumps over a red and black striped pole . <end>',\n",
              "  '<start> A young man is jumping over a long pole at a skate park . <end>',\n",
              "  '<start> Man in black jumps over a rope as crowd looks on . <end>'],\n",
              " 'Flicker8k_Dataset/3197482764_2f289cb726.jpg': ['<start> Two girls are dressed up and sitting on a bed laughing . <end>',\n",
              "  '<start> Two girls dressed to party sit on a bed laughing . <end>',\n",
              "  '<start> Two woman in dresses smiling at the camera . <end>',\n",
              "  '<start> Two young ladies are sitting on a small be in skimpy dresses . <end>',\n",
              "  '<start> Two young women sit on the edge of the bed all dressed up . <end>'],\n",
              " 'Flicker8k_Dataset/3476451861_5b9c9ce191.jpg': ['<start> A bicyclist is performing a trick on a tall tree . <end>',\n",
              "  '<start> A person is riding a bike on a tree . <end>',\n",
              "  '<start> A person riding a bike with blue wheels on a tree trunk at night . <end>',\n",
              "  '<start> A young person doing a bike trick on a trunk of a tree . <end>',\n",
              "  '<start> Person is riding a bike with blue tires up a tree . <end>'],\n",
              " 'Flicker8k_Dataset/3268407162_6274e0f74f.jpg': ['<start> A man in an orange shirt hitting a tennis ball with a racket . <end>',\n",
              "  '<start> A man plays tennis dressed in U of Miami colors . <end>',\n",
              "  '<start> A man wearing an orange shirt hits a ball with a tennis racket . <end>',\n",
              "  '<start> a tennis player hits the ball . <end>',\n",
              "  '<start> man dressed in orange and white hitting a tennis ball with racquet <end>'],\n",
              " 'Flicker8k_Dataset/504385521_6e668691a3.jpg': ['<start> A big dog shakes itself dry while standing in a creek . <end>',\n",
              "  '<start> A blond dog shakes water off next to a lake . <end>',\n",
              "  '<start> A brown dog is splashing water everywhere by shaking the water off of itself . <end>',\n",
              "  '<start> A tan dog is shaking water off its fur . <end>',\n",
              "  '<start> A white dog is standing by a river shaking himself dry . <end>'],\n",
              " 'Flicker8k_Dataset/1620397000_3883e3ecd3.jpg': ['<start> A black and white spotted dog is jumping over the small stream of water . <end>',\n",
              "  '<start> A black and white spotted dog jumps over a stream . <end>',\n",
              "  '<start> A dog jumps over a creek . <end>',\n",
              "  '<start> A spotted dog jumps over a muddy creek . <end>',\n",
              "  '<start> A white dog with black spots jumps over a stream . <end>'],\n",
              " 'Flicker8k_Dataset/439492931_a96d590e40.jpg': ['<start> A cluster of four brown dogs play in a field of brown grass . <end>',\n",
              "  '<start> Four dogs are together in the field of dry grass . <end>',\n",
              "  '<start> Four dogs in a grassy area . <end>',\n",
              "  '<start> Four medium-sized dogs wrestle with each other on a grass field . <end>',\n",
              "  '<start> Four small dogs play outside . <end>'],\n",
              " 'Flicker8k_Dataset/242559369_9ae90ed0b4.jpg': ['<start> A naked woman is taking a dip in an isolated rocky pool . <end>',\n",
              "  '<start> A naked woman kneels on the rocks of a shallow stream . <end>',\n",
              "  '<start> A naked woman steps into the water . <end>',\n",
              "  '<start> A nude woman submerges herself in a natural pool . <end>',\n",
              "  '<start> Woman wearing a body suit standing on some large rocks with a green hill in the background . <end>'],\n",
              " 'Flicker8k_Dataset/3567604049_da9e1be4ba.jpg': ['<start> A man is about to do a belly-smacker into the pool . <end>',\n",
              "  '<start> A man jumps into the blue water pool . <end>',\n",
              "  '<start> A young boy jumps into a pool with outstretched arms . <end>',\n",
              "  '<start> The boy in the black swim trunks dives into the pool . <end>',\n",
              "  '<start> The boy is jumping into the large pool . <end>'],\n",
              " 'Flicker8k_Dataset/2344898759_5674382bcd.jpg': ['<start> A girl is talking on the phone while sitting on a wall <end>',\n",
              "  '<start> A woman in blue sits on a curb next to blue railings in front of the ocean . <end>',\n",
              "  '<start> A woman relaxes on a pier with railings while on the phone . <end>',\n",
              "  '<start> A woman talking on a cellphone near water . <end>',\n",
              "  '<start> A woman talks on a cellphone while sitting in front of blue railings that are in front of the ocean . <end>'],\n",
              " 'Flicker8k_Dataset/2901074943_041aba4607.jpg': ['<start> A child plays on the floor . <end>',\n",
              "  '<start> A little girl throws a pink and yellow chunk of chalk . <end>',\n",
              "  '<start> A small girl is sitting on the cement dropping some chalk <end>',\n",
              "  '<start> A young child plays with sidewalk chalk by dropping it on the gound . <end>',\n",
              "  '<start> A young girl throwing her pink chalk . <end>'],\n",
              " 'Flicker8k_Dataset/2326730558_75c20e5033.jpg': ['<start> A beige dog and brown dog in the snow . <end>',\n",
              "  '<start> A brown dog kisses the ear of a white dog in the snow . <end>',\n",
              "  \"<start> One dog liking another 's face in the snow . <end>\",\n",
              "  '<start> Two dogs playing in snow . <end>',\n",
              "  '<start> Two dogs play in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/3139118874_599b30b116.jpg': ['<start> Two girls pose for a picture at Christmastime . <end>',\n",
              "  '<start> Two girls stand in front of a Christmas tree , with their arms around each other . <end>',\n",
              "  '<start> Two girls who look alike pose in front of a Christmas tree . <end>',\n",
              "  '<start> Two young girls pose smiling for a picture with a Christmas tree behind them . <end>',\n",
              "  '<start> Two young women smiling in front of a christmas tree . <end>'],\n",
              " 'Flicker8k_Dataset/1056338697_4f7d7ce270.jpg': ['<start> A blond woman in a blue shirt appears to wait for a ride . <end>',\n",
              "  '<start> A blond woman is on the street hailing a taxi . <end>',\n",
              "  '<start> A woman is signaling is to traffic , as seen from behind . <end>',\n",
              "  '<start> A woman with blonde hair wearing a blue tube top is waving on the side of the street . <end>',\n",
              "  '<start> The woman in the blue dress is holding out her arm at oncoming traffic . <end>'],\n",
              " 'Flicker8k_Dataset/3561537309_e271d57492.jpg': ['<start> A boy in blue shorts standing in the surf . <end>',\n",
              "  '<start> A boy is standing in the ocean with his arms outstretched . <end>',\n",
              "  '<start> A child in water . <end>',\n",
              "  '<start> A young boy wearing blue swim trunks on the beach walking into the water . <end>',\n",
              "  '<start> The young boy opens his arms as waves come crashing near him . <end>'],\n",
              " 'Flicker8k_Dataset/3215238223_29de2b35cb.jpg': ['<start> A boy rides a skateboard with a bike to his right . <end>',\n",
              "  '<start> A guy grinds a windowsill near an old windmill <end>',\n",
              "  '<start> A guy is grinding on a window ledge in a city . <end>',\n",
              "  '<start> A person in black is coming out of a window of a tan and red building . <end>',\n",
              "  '<start> A person skateboarding near a windmill . <end>'],\n",
              " 'Flicker8k_Dataset/1095980313_3c94799968.jpg': ['<start> A little girl in a blue swimsuit is walking along a wooden fence next to a sandy beach . <end>',\n",
              "  '<start> A little girl with arms outstretched is posing at the beach . <end>',\n",
              "  '<start> A young girl walks on a railing in front of the beach . <end>',\n",
              "  '<start> Little girl in blue swimsuit standing on a handrail near a beach . <end>',\n",
              "  '<start> The little girl in the blue bathing suit is posing at the beach . <end>'],\n",
              " 'Flicker8k_Dataset/3296584432_bef3c965a3.jpg': ['<start> A brown dog chases something a man behind him threw on the beach . <end>',\n",
              "  '<start> A man and a dog on the beach . <end>',\n",
              "  '<start> A man is interacting with a dog that is running in the opposite direction . <end>',\n",
              "  '<start> A man playing fetch with his dog on a beach . <end>',\n",
              "  '<start> A man walking behind a running dog on the beach . <end>'],\n",
              " 'Flicker8k_Dataset/2282043629_91b7831352.jpg': ['<start> A family of 7 poses in the snow <end>',\n",
              "  '<start> A family poses in a snowy forest . <end>',\n",
              "  '<start> A family standing in the snow on a sledding trip . <end>',\n",
              "  '<start> A family stands in the snowy woods . <end>',\n",
              "  '<start> A man and a woman pose in the snow with four children . <end>'],\n",
              " 'Flicker8k_Dataset/3420338549_bd78d35243.jpg': ['<start> A group of men in suits are standing in front of a statue of a lion . <end>',\n",
              "  '<start> A group of men stand talking in front of a statute of a blue lion . <end>',\n",
              "  '<start> A group of people in suits stand around a man in a pink shirt who is lecturing . <end>',\n",
              "  '<start> Man giving lecture to interested people in front of a clue statue . <end>',\n",
              "  '<start> Men standing in front of a statue of a lion . <end>'],\n",
              " 'Flicker8k_Dataset/1262454669_f1caafec2d.jpg': ['<start> A girl in a white shirt is sitting on a park bench with a dog next to her . <end>',\n",
              "  '<start> A woman eats on a bench while a brown and white leashed dog stands next to her . <end>',\n",
              "  '<start> a woman is sitting on a bench with a latte in her lap and a white dog on a blue leash to her side . <end>',\n",
              "  '<start> A woman sits on a bench at the park with her dog in front of her . <end>',\n",
              "  '<start> Woman sitting on bench and holding the leash of a large white and brown dog . <end>'],\n",
              " 'Flicker8k_Dataset/2782433864_5a0c311d87.jpg': ['<start> The three dogs are standing in the sand . <end>',\n",
              "  '<start> Three small dogs stand in the sand and stare at each other . <end>',\n",
              "  '<start> Three small dogs , two of which are sniffing noses . <end>',\n",
              "  '<start> Two dogs meet and check out a third dog at the beach . <end>',\n",
              "  '<start> Two small dogs facing a third dog . <end>'],\n",
              " 'Flicker8k_Dataset/3583704941_611353857e.jpg': ['<start> A horse jockey is riding on a course . <end>',\n",
              "  '<start> A woman on a horse . <end>',\n",
              "  '<start> A woman on a racing horse . <end>',\n",
              "  '<start> girl with helmet riding a brown horse <end>',\n",
              "  '<start> The rider of the brown horse is wearing a blue shirt . <end>'],\n",
              " 'Flicker8k_Dataset/3374722123_6fe6fef449.jpg': ['<start> An elderly woman is wearing a pink striped shirt . <end>',\n",
              "  '<start> an older woman in a pink striped shirt <end>',\n",
              "  '<start> An older woman with a striped shirt rubbing her chin . <end>',\n",
              "  '<start> A woman in a pink striped shirt , with her hand up . <end>',\n",
              "  '<start> Older lady is appears to be getting ready to cover her mouth . <end>'],\n",
              " 'Flicker8k_Dataset/3093971101_543237971d.jpg': ['<start> A surfer in a black surfing suit in motion . <end>',\n",
              "  '<start> Guy in black and blue wetsuit surfing <end>',\n",
              "  '<start> It looks like the surfer is riding a big wave . <end>',\n",
              "  '<start> One man in a wetsuit surfing a wave . <end>',\n",
              "  '<start> Surfer in wetsuit riding before a wave <end>'],\n",
              " 'Flicker8k_Dataset/3173014908_b3e69594b6.jpg': ['<start> A person skiing downhill in the snow . <end>',\n",
              "  '<start> A skier puffs up a cloud of snow . <end>',\n",
              "  '<start> A skier traveling downhill in deep snow . <end>',\n",
              "  '<start> Someone is skiing down a step snowy hill . <end>',\n",
              "  '<start> The skier is buried in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/3643684044_a131168127.jpg': ['<start> A team of four judges rates a competition . <end>',\n",
              "  '<start> Four judges are sitting at a table with the center left one speaking . <end>',\n",
              "  '<start> Four people are sitting at a table , with microphones and bottles of water in front of them . <end>',\n",
              "  '<start> Man in red shirt speaks into microphone <end>',\n",
              "  '<start> The gentleman is speaking while the others are listening . <end>'],\n",
              " 'Flicker8k_Dataset/1287475186_2dee85f1a5.jpg': ['<start> A boy sitting in water . <end>',\n",
              "  '<start> A small boy is sitting in the water and water is splashing up through his legs . <end>',\n",
              "  '<start> A young boy in a swimming suit sits in water . <end>',\n",
              "  '<start> A young boy sitting on a water jet in a pool . <end>',\n",
              "  '<start> Little boy sitting in water with a fountain coming up through his lap . <end>'],\n",
              " 'Flicker8k_Dataset/3450776690_38605c667d.jpg': ['<start> A girl in a pink dress carries a younger girl . <end>',\n",
              "  '<start> A girl in a pink skirt runs holding a her sister . <end>',\n",
              "  '<start> A little girl carries a younger girl on the sidewalk . <end>',\n",
              "  '<start> A little girl is holding a younger little girl and running with her . <end>',\n",
              "  '<start> Two young girls embrace on the sidewalk . <end>'],\n",
              " 'Flicker8k_Dataset/1100214449_d10861e633.jpg': ['<start> A boy in s striped shirt is jumping in front of a water fountain . <end>',\n",
              "  '<start> A boy is jumping off the side of a running stone water fountain in front of a building . <end>',\n",
              "  '<start> A happy boy is jumping in front OD city fountain . <end>',\n",
              "  '<start> A little boy is jumping in front of a fountain . <end>',\n",
              "  '<start> A little boy is playfully jumping off the side of a fountain . <end>'],\n",
              " 'Flicker8k_Dataset/3590739067_58baffb3a7.jpg': ['<start> A woman is outside playing the guitar . <end>',\n",
              "  '<start> A woman with a guitar sings in front of a building and grass . <end>',\n",
              "  '<start> a woman with a nylon stringed guitar is playing in a field <end>',\n",
              "  '<start> A young woman lifts her voice in song in a field near an old wooden structure . <end>',\n",
              "  '<start> The girl plays a guitar while singing in a rural scene . <end>'],\n",
              " 'Flicker8k_Dataset/3300019891_8f404d94a1.jpg': ['<start> A large crowd dressed in renaissance attire gathers together in a city street . <end>',\n",
              "  '<start> People are dressed in Victorian outfits in a crowded outdoor area . <end>',\n",
              "  '<start> Some people in medieval costume are walking through a crowded street . <end>',\n",
              "  '<start> street scene of elegant dressed people of older times <end>',\n",
              "  '<start> There is a large gathering of people in costumes outside on the street . <end>'],\n",
              " 'Flicker8k_Dataset/3096918227_f9d26a7db2.jpg': ['<start> A skateboarder is performing a grab trick while hovering above a ramp , which is located within a city . <end>',\n",
              "  '<start> A skateboarder makes a high jump . <end>',\n",
              "  '<start> A skateboarder soars above a ramp . <end>',\n",
              "  '<start> Man in midair on skateboard <end>',\n",
              "  '<start> Skateboarder in midair at a park . <end>'],\n",
              " 'Flicker8k_Dataset/2426724282_237bca30b5.jpg': ['<start> A dog in a field jumps for a Frisbee . <end>',\n",
              "  '<start> a small black and white jumping to catch something in its mouth . <end>',\n",
              "  '<start> A small , white dog with his tongue out is jumping up to catch a toy . <end>',\n",
              "  '<start> A white dog is jumping up in the air to catch a Frisbee . <end>',\n",
              "  '<start> White dog with dark markings jumping to catch an object . <end>'],\n",
              " 'Flicker8k_Dataset/2701603045_6cbdc4ce7c.jpg': ['<start> A boy is wading through water . <end>',\n",
              "  '<start> A boy up to his knees in water . <end>',\n",
              "  '<start> a boy wearing white shorts , walks through the water . <end>',\n",
              "  '<start> A young boy with white swim trunks walks out of the water . <end>',\n",
              "  '<start> The boy is wading through the blue ocean . <end>'],\n",
              " 'Flicker8k_Dataset/3737539561_d1dc161040.jpg': ['<start> There are two kids in swimmies playing outside next to some trees . <end>',\n",
              "  '<start> Two boys with long blond hair are climbing on a hillside . <end>',\n",
              "  '<start> Two boys with water wings climb a tree . <end>',\n",
              "  '<start> Two children posing for a picture wearing water wings and sitting on a rock . <end>',\n",
              "  '<start> Two little boys are sitting on a clump of dirt . <end>'],\n",
              " 'Flicker8k_Dataset/2754271176_4a2cda8c15.jpg': ['<start> A man in blue clothing sorts through the contents of a plastic bag . <end>',\n",
              "  '<start> A man is bending down and digging in a white bag . <end>',\n",
              "  '<start> a woman bends down to reach in a plastic bag . <end>',\n",
              "  '<start> The man in the blue jacket is reaching into a white bag . <end>',\n",
              "  '<start> The man in the blue jacket is rummaging through a white plastic bag at the roadside . <end>'],\n",
              " 'Flicker8k_Dataset/3130064588_6d1d3fa2dd.jpg': ['<start> Two boys on a boat riding though the water . <end>',\n",
              "  '<start> Two boys sitting on a boat in the water . <end>',\n",
              "  '<start> Two men are riding a blue and orange boat . <end>',\n",
              "  '<start> Two men sit on the dock overlooking blue water . <end>',\n",
              "  '<start> two young men with shirts are riding on the back of a boat with an orange deck . <end>'],\n",
              " 'Flicker8k_Dataset/1860543210_47e94cf652.jpg': ['<start> A guy in gray is walking across the street at night . <end>',\n",
              "  '<start> A man walking across a crosswalk with long hair , a green hoodie , and a backpack . <end>',\n",
              "  '<start> A man with long hair is making an \" OK \" sign with his hand while he walks down a street . <end>',\n",
              "  '<start> A man with long hair wearing gray clothes and a backpack . <end>',\n",
              "  '<start> a young man wearing grey pants and backpack with long brown hair <end>'],\n",
              " 'Flicker8k_Dataset/3497255828_f27e009aac.jpg': ['<start> A girl in pink and purple is climbing a ladder . <end>',\n",
              "  '<start> A girl poses on a rusty fire escape ladder in hot pink gloves , skirt and heels . <end>',\n",
              "  '<start> A model on a ladder in front of a rustic building . <end>',\n",
              "  \"<start> Girl in colorful clothes and makeup poses on a building 's rusty ladder . <end>\",\n",
              "  '<start> The woman is posing in high heels on a rusty ladder . <end>'],\n",
              " 'Flicker8k_Dataset/530454257_66d58b49ee.jpg': ['<start> A boy in camouflage jacket notices several yellow ducks on display . <end>',\n",
              "  '<start> A little boy , in a camouflage jacket , looks at a display of many yellow rubber ducks . <end>',\n",
              "  '<start> A young boy looks at a display of rubber ducks . <end>',\n",
              "  '<start> A young boy wearing army gear is picking up a rubber ducky in a market . <end>',\n",
              "  '<start> Small boy looking at a display of yellow rubber ducks . <end>'],\n",
              " 'Flicker8k_Dataset/2970067128_8842ab3603.jpg': ['<start> A person on a bike jumping over a bench in the park . <end>',\n",
              "  '<start> A person on a bmx bike , leaping onto a bench . <end>',\n",
              "  '<start> A person performing tricks on a bicycle in a skate park . <end>',\n",
              "  '<start> A person riding a bicycle going over a raised platform . <end>',\n",
              "  '<start> Jumping a bicycle onto a park bench . <end>'],\n",
              " 'Flicker8k_Dataset/2818735880_68b3dfe1f5.jpg': ['<start> brown dogs are running down a trail <end>',\n",
              "  '<start> A group of dogs runs down a path through dry grass and bushes . <end>',\n",
              "  '<start> A pack of dogs are running away down a trail . <end>',\n",
              "  '<start> Five brown dogs are walking down a grassy path . <end>',\n",
              "  '<start> Many dogs are running the same way in a field . <end>'],\n",
              " 'Flicker8k_Dataset/3457784061_8f77f43a9c.jpg': ['<start> A man bowls with a red ball . <end>',\n",
              "  '<start> A man bowls with a red bowling ball . <end>',\n",
              "  '<start> A man is getting ready to throw a bowling ball in a bowling alley . <end>',\n",
              "  '<start> a young man about to throw a red bowling ball down the lane <end>',\n",
              "  '<start> Man bowling in a dimly lit bowling alley . <end>'],\n",
              " 'Flicker8k_Dataset/3126773489_7ae425af17.jpg': ['<start> a basketball player defends another player . <end>',\n",
              "  '<start> A man with a basketball blocks an attempt to take his ball . <end>',\n",
              "  '<start> Man runs by other man with basketball at a game . <end>',\n",
              "  '<start> The player in the white dribbles the ball , while the player in the orange tries to stop him . <end>',\n",
              "  '<start> Two men are playing during a basketball game . <end>'],\n",
              " 'Flicker8k_Dataset/3528105511_12ff45dc9c.jpg': ['<start> A motorcyclist on a green bike is airborne . <end>',\n",
              "  '<start> A person on a dirt bike is in the air . <end>',\n",
              "  '<start> A person rides a motorbike through the air . <end>',\n",
              "  '<start> A person riding a dirt bike . <end>',\n",
              "  '<start> Motorcross jumper in mid-flight beneath a grey sky . <end>'],\n",
              " 'Flicker8k_Dataset/453756106_711c20471a.jpg': ['<start> A large , brown , fluffy dog with a small white and brown dog on a dirt surface . <end>',\n",
              "  '<start> a large dog is playing with a small dog in the dirt . <end>',\n",
              "  '<start> A small dog and a large dog play together . <end>',\n",
              "  '<start> Bigg playing with little dog in dirt . <end>',\n",
              "  '<start> Two dogs play with each other in the dirt . <end>'],\n",
              " 'Flicker8k_Dataset/2273871383_1ddb3562ea.jpg': ['<start> An elderly man standing near a younger man . <end>',\n",
              "  '<start> An older gentleman in brown gives a look of astonishment to the camera . <end>',\n",
              "  '<start> An older man confronts the camera while a young man in a blue jacket looks on . <end>',\n",
              "  '<start> An older man standing by a younger man with earphones <end>',\n",
              "  '<start> A older man in beige stands near a younger man in blue in front of a building . <end>'],\n",
              " 'Flicker8k_Dataset/492493570_c27237a396.jpg': ['<start> A girl chases a bird across the sand at the edge of the ocean . <end>',\n",
              "  '<start> A girl in a pink suit chases a gull on a beach . <end>',\n",
              "  '<start> Girl in pink bathing suit with right arm in air behind a seagull on the beach near the water . <end>',\n",
              "  '<start> The little girl plays along the shoreline as the seagull passes by . <end>',\n",
              "  '<start> Young girl in red bathing suit feeding a seagull <end>'],\n",
              " 'Flicker8k_Dataset/832128857_1390386ea6.jpg': ['<start> A red haired little boy smiles while swinging . <end>',\n",
              "  '<start> A redheaded child is happily swinging in park . <end>',\n",
              "  '<start> A smiling child is swinging on a swing . <end>',\n",
              "  '<start> Boy playing on the swing . <end>',\n",
              "  '<start> Young Blonde boy on swing set in park <end>'],\n",
              " 'Flicker8k_Dataset/437404867_209625774d.jpg': ['<start> A woman is sitting on a sidewalk with a cellphone at her ear . <end>',\n",
              "  '<start> A woman rests on the curb of a city street while talking on her cellphone . <end>',\n",
              "  '<start> A woman sits on the curb while talking on her cellphone . <end>',\n",
              "  '<start> A woman sits on the edge of a sidewalk with a garbage bin beside her <end>',\n",
              "  '<start> Woman sits on the curb talking on a cellphone . <end>'],\n",
              " 'Flicker8k_Dataset/3241892328_4ebf8b21ce.jpg': ['<start> A female lionist jumping in a green field with a green mountain in the background . <end>',\n",
              "  '<start> A lion jumping through tall grass . <end>',\n",
              "  '<start> A mountain lion is leaping off of a rock . <end>',\n",
              "  '<start> a tiger jumps off a rock . <end>',\n",
              "  '<start> Cougar pouncing off rock . <end>'],\n",
              " 'Flicker8k_Dataset/2650620212_0586016e0d.jpg': ['<start> A black dog is walking along the side of a pool . <end>',\n",
              "  '<start> A black dog runs around an outdoor swimming pool . <end>',\n",
              "  '<start> A black dog walking beside a pool . <end>',\n",
              "  '<start> A black poodle walks on the edge of a pool . <end>',\n",
              "  '<start> A fluffy blank poodle is walking on the edge of a pool . <end>'],\n",
              " 'Flicker8k_Dataset/2862004252_53894bb28b.jpg': ['<start> A beagle walks through the grass . <end>',\n",
              "  '<start> A black and tan dog standing in a field near trees <end>',\n",
              "  '<start> A brown and tan dog walks through the green grass . <end>',\n",
              "  '<start> a smal hound dog walking through the grass outside . <end>',\n",
              "  '<start> The dog is walking through a grassy area . <end>'],\n",
              " 'Flicker8k_Dataset/3691800116_6a7b315e46.jpg': ['<start> A batter playing cricket missed the ball and the person behind him is catching it . <end>',\n",
              "  '<start> A cricket player misses the pitch . <end>',\n",
              "  '<start> A man struck out playing cricket . <end>',\n",
              "  '<start> A man wearing white , including shin guards , swings the bat in a cricket game . <end>',\n",
              "  '<start> The three men are playing cricket . <end>'],\n",
              " 'Flicker8k_Dataset/3355683198_715fb1a2ac.jpg': ['<start> A boy in a blue and white tie dye t-shirt is skateboarding on the railing of a building . <end>',\n",
              "  '<start> A boy in a tie dyed shirt is riding a skateboard down a railing . <end>',\n",
              "  '<start> A kid is skateboarding on a handrail . <end>',\n",
              "  '<start> A skateboarder goes down a stair railing . <end>',\n",
              "  '<start> A teenage boy in rides a hand-railing on a skateboard outside a columned brick building . <end>'],\n",
              " 'Flicker8k_Dataset/3168841415_c0705a327a.jpg': ['<start> a boy in a brown shirt , throwing a Frisbee . <end>',\n",
              "  '<start> A boy leaping to catch a flying Frisbee . <end>',\n",
              "  '<start> A child trying to catch a Frisbee . <end>',\n",
              "  '<start> A young child leaps and stretches to catch a blue Frisbee . <end>',\n",
              "  '<start> The little kid runs to grab the blue Frisbee that is flying through the air . <end>'],\n",
              " 'Flicker8k_Dataset/257588281_39e1c9d929.jpg': ['<start> A black dog chases a brown dog with a stick through the water . <end>',\n",
              "  '<start> A brown dog is running through water with a stick in its mouth . <end>',\n",
              "  '<start> two dogs playing in the water with a stick <end>',\n",
              "  '<start> Two dogs playing with a stick in the water . <end>',\n",
              "  '<start> Two dogs running through the water with a stick . <end>'],\n",
              " 'Flicker8k_Dataset/3632047678_f202609e50.jpg': ['<start> a group of several people sitting on the floor inside of a building <end>',\n",
              "  '<start> A group of anime cosplayers sitting in a hall . <end>',\n",
              "  '<start> A group of teenagers sitting in the hall at school . <end>',\n",
              "  '<start> People wearing costumes wait in a room . <end>',\n",
              "  '<start> The actors wait inside the doors . <end>'],\n",
              " 'Flicker8k_Dataset/112243673_fd68255217.jpg': ['<start> People on ATVs and dirt bikes are traveling along a worn path in a field surrounded by trees . <end>',\n",
              "  \"<start> Three people are riding around on ATV 's and motorcycles . <end>\",\n",
              "  '<start> Three people on motorbikes follow a trail through dry grass . <end>',\n",
              "  '<start> Three people on two dirt-bikes and one four-wheeler are riding through brown grass . <end>',\n",
              "  '<start> Three people ride off-road bikes through a field surrounded by trees . <end>'],\n",
              " 'Flicker8k_Dataset/2930514856_784f17064a.jpg': ['<start> A man surfing a small wave and another man on a surfboard paddling toward it . <end>',\n",
              "  '<start> A surfer jumps a wave as one paddles to the wave . <end>',\n",
              "  '<start> A surfer vertical in a wave with another approaching him <end>',\n",
              "  '<start> Two men are surfing in the ocean on a huge wave . <end>',\n",
              "  '<start> Two surfers catch a wave . <end>'],\n",
              " 'Flicker8k_Dataset/2290589734_b588471345.jpg': ['<start> One boy in a black shirt is grabbing the flag of the boy in the red shirt with the football . <end>',\n",
              "  '<start> Two boys are playing flag football . <end>',\n",
              "  '<start> Two boys playing a game of flag football . <end>',\n",
              "  '<start> Two boys with mouthguards and one is holding a football while the other reaches for him . <end>',\n",
              "  '<start> Young football players with mouthguards . <end>'],\n",
              " 'Flicker8k_Dataset/1803631090_05e07cc159.jpg': [\"<start> A girl in a firefighter 's uniform looks back and says something . <end>\",\n",
              "  '<start> A woman is dressed in a \" fire department \" uniform . <end>',\n",
              "  '<start> A young female firefighter stands in front of a crowd . <end>',\n",
              "  '<start> The lady is wearing a blue fire department shirt . <end>',\n",
              "  '<start> The woman wearing a fire department uniform is talking to people . <end>'],\n",
              " 'Flicker8k_Dataset/3323498985_fd9d2803fd.jpg': ['<start> A man falling over in an ocean wave <end>',\n",
              "  \"<start> A man in swimming trunks plays in the ocean 's waves . <end>\",\n",
              "  '<start> A man is falling into waves . <end>',\n",
              "  '<start> a surfer falling of his board into a wave <end>',\n",
              "  '<start> A young man in swim shorts is jumping over a wave in the ocean . <end>'],\n",
              " 'Flicker8k_Dataset/2042009399_afad34e7c1.jpg': ['<start> A group of boys play flag football while some bystanders watch . <end>',\n",
              "  '<start> Kids playing tag football . <end>',\n",
              "  '<start> several boys playing flag football in blue and white uniforms <end>',\n",
              "  '<start> Some boys in team uniforms are outside playing sports while people watch . <end>',\n",
              "  '<start> Young boys play touch football . <end>'],\n",
              " 'Flicker8k_Dataset/3708266246_97a033fcc7.jpg': ['<start> A black and white dog is going through an obstacle course . <end>',\n",
              "  '<start> A black and white dog jumps over a bar . <end>',\n",
              "  '<start> A black dog leaping over a hurdle . <end>',\n",
              "  '<start> A border collie jumping over a hurdle . <end>',\n",
              "  '<start> Black and white dog jumping over a blue obstacle <end>'],\n",
              " 'Flicker8k_Dataset/3258874419_23fec1bdc1.jpg': ['<start> A dog , wearing a number 8 , running in a race . <end>',\n",
              "  '<start> A greyhound dog wearing a yellow and black shirt runs along a dirt racetrack . <end>',\n",
              "  '<start> A greyhound runs in a race , bee striped jacket , number eight . <end>',\n",
              "  '<start> Grey dog with muzzle and with the # 8 yellow striped identification is running . <end>',\n",
              "  '<start> Racedog has the number 8 . <end>'],\n",
              " 'Flicker8k_Dataset/2465218087_fca77998c6.jpg': ['<start> A man holding a paddle is standing in front of a yellow kayak . <end>',\n",
              "  '<start> A man is standing in the water with a kayak . <end>',\n",
              "  '<start> A man stands next to his yellow boat in the water . <end>',\n",
              "  '<start> A person in red and blue holding a paddle in front of a yellow canoe in the water . <end>',\n",
              "  '<start> Person standing in the water by a yellow boat with an oar in their hand . <end>'],\n",
              " 'Flicker8k_Dataset/3657016761_d553e514d9.jpg': ['<start> A child at a water park is sprayed from all sides by a ring of water . <end>',\n",
              "  '<start> A child in a pink and black bathing suit walks through water mist from colored rings . <end>',\n",
              "  '<start> A young girl stands under three large rings that shoot water in a water park . <end>',\n",
              "  '<start> Colorful rings spraying water at little girl wearing swimsuit . <end>',\n",
              "  '<start> The little girl in her bathing suit stands near the sprinkers and squeals . <end>'],\n",
              " 'Flicker8k_Dataset/268365231_a0acecdc45.jpg': ['<start> A couple in black clothes are walking towards a white gate . <end>',\n",
              "  '<start> A man and a woman dressed in black walk towards a gate near a wooded area . <end>',\n",
              "  '<start> A man and a woman walk away with their arms around each other . <end>',\n",
              "  '<start> Man and woman wearing black walk with arms around each other . <end>',\n",
              "  '<start> Two people dressed in black are leaving . <end>'],\n",
              " 'Flicker8k_Dataset/3356748019_2251399314.jpg': ['<start> Cyclists are leaping into the air whilst being watched by spectators . <end>',\n",
              "  '<start> Three dirt bike racers head over a jump . <end>',\n",
              "  '<start> Three men form an arch during a BMX bike race sponsored by Coca-Cola . <end>',\n",
              "  '<start> Three men on mountain bikes go over a sand hill . <end>',\n",
              "  '<start> Three riders wearing black jerseys jump their BMX bikes into the air . <end>'],\n",
              " 'Flicker8k_Dataset/241345770_9f8aa6723c.jpg': ['<start> A group of football players are playing football . <end>',\n",
              "  '<start> A quarterback gets ready to throw the football . <end>',\n",
              "  '<start> A quarterback ready to pass the football in the middle of a play . <end>',\n",
              "  '<start> A quarterback scans the football field while the offensive line protects him . <end>',\n",
              "  '<start> There is a notre dame quarterback dropping back into the pocket at a game . <end>'],\n",
              " 'Flicker8k_Dataset/2142232919_c857a09dd7.jpg': ['<start> A black dog carries an orange ball , walking on the ground covered in leaves . <end>',\n",
              "  '<start> A black dog with an orange toy in its mouth is walking in fall leaves . <end>',\n",
              "  '<start> A black lab puppy runs with an orange ball on an autumn day . <end>',\n",
              "  '<start> Black dog with orange ball approaches camera across dead leaves . <end>',\n",
              "  '<start> The black dog walks through brown leaves with an orange ball . <end>'],\n",
              " 'Flicker8k_Dataset/3759492488_592cd78ed1.jpg': ['<start> A boy hanging onto a pole . <end>',\n",
              "  '<start> A kid in a green shirt playing in the park <end>',\n",
              "  '<start> A little kid swings on a pole at a playground . <end>',\n",
              "  '<start> The boy in the green shirt swings with one arm on the silver pole . <end>',\n",
              "  '<start> The boy is swinging on a pole at the beach . <end>'],\n",
              " 'Flicker8k_Dataset/3231237864_8cb1c6d863.jpg': ['<start> A competitive jumper is caught by the camera in midair . <end>',\n",
              "  '<start> A cricket bowler in action . <end>',\n",
              "  '<start> A man contorts his body as he plays baseball . <end>',\n",
              "  '<start> Ballplayer in blue uniform midair with legs stretched out . <end>',\n",
              "  '<start> Man running and almost falling . <end>'],\n",
              " 'Flicker8k_Dataset/177302997_5b2d770a0a.jpg': ['<start> A child holding on to the bar while riding a horse on a carousel ride . <end>',\n",
              "  '<start> A child is riding a plastic horse at an amusement park . <end>',\n",
              "  '<start> A child on a fake horse ride . <end>',\n",
              "  '<start> A child sitting on a carousel horse . <end>',\n",
              "  '<start> Row of plastic horses that form a childrens ride with one child riding . <end>'],\n",
              " 'Flicker8k_Dataset/2257099774_37d0d3aa9a.jpg': ['<start> An elderly Asian woman wearing a blue winter coat and red hat in front of a food counter . <end>',\n",
              "  '<start> A woman in a red cap in a store . <end>',\n",
              "  '<start> A woman wearing a red hat and black coat . <end>',\n",
              "  '<start> A woman with a red hat and face stands in front of jars . <end>',\n",
              "  '<start> The hapy asian woman is at the market . <end>'],\n",
              " 'Flicker8k_Dataset/866841633_05d273b96d.jpg': ['<start> A man wearing a orange vest is canoeing in the blue water . <end>',\n",
              "  '<start> A person paddles a boat while another has fallen into the water . <end>',\n",
              "  '<start> One person kayaks as another kayer sinks their boat . <end>',\n",
              "  '<start> Two kayakers ; one paddling and one in the water . <end>',\n",
              "  '<start> Two small canoes are out in the middle of the water . <end>'],\n",
              " 'Flicker8k_Dataset/2892413015_5ecd9d972a.jpg': ['<start> A little blonde girl going up a hill . <end>',\n",
              "  '<start> A little girl in a green shirt and pink shorts is running up a grassy hill near a pavilion . <end>',\n",
              "  '<start> A young girl is walking up a steep grassy hill . <end>',\n",
              "  '<start> The child in the green shirt is running up the hill with a picnic table behind her . <end>',\n",
              "  '<start> The little blond haired child is walking up the slope . <end>'],\n",
              " 'Flicker8k_Dataset/1472230829_803818a383.jpg': ['<start> A group of people in a boat , white water rafting . <end>',\n",
              "  '<start> A group of seven people are rafting in the rapids in a green boat . <end>',\n",
              "  '<start> Rafting boat on river . <end>',\n",
              "  '<start> seven people are riding a green raft in a white water river . <end>',\n",
              "  '<start> Seven rafters are paddling and riding the rapids in a green raft . <end>'],\n",
              " 'Flicker8k_Dataset/3331009729_d3b14738e6.jpg': ['<start> A girl walks on a sidewalk while talking on a cellphone . <end>',\n",
              "  '<start> A woman walking while talking on the phone . <end>',\n",
              "  '<start> A woman walks with a book while talking on a cellphone . <end>',\n",
              "  '<start> A woman wearing a blue coat walks and talks on her cellphone . <end>',\n",
              "  '<start> The girl in the ski jacket is walking near the buildings . <end>'],\n",
              " 'Flicker8k_Dataset/2394267183_735d2dc868.jpg': ['<start> A dog goes through an obstacle course while a person looks on . <end>',\n",
              "  '<start> A dog is going through a slalom style obstacle course . <end>',\n",
              "  '<start> A dog performs a slalom-like obstacle while the owner walks along side . <end>',\n",
              "  '<start> A dog plays with a man by running around poles . <end>',\n",
              "  '<start> The woman is training a white dog to zigzag through metal poles . <end>'],\n",
              " 'Flicker8k_Dataset/3514019869_7de4ece2a5.jpg': ['<start> a black and brown dog jumping over two white and purple stiped poles <end>',\n",
              "  '<start> A dog jumps over a hurdle in the grass . <end>',\n",
              "  '<start> A dog jumps over an obstacle . <end>',\n",
              "  '<start> Black and brown dog jumping over hurdle with white supports . <end>',\n",
              "  '<start> Dog performing during an outdoor dog show . <end>'],\n",
              " 'Flicker8k_Dataset/3092756650_557c5f2d03.jpg': ['<start> A group of Indian men are just standing around with their arms crossed . <end>',\n",
              "  '<start> A group of men stand outside . <end>',\n",
              "  '<start> Four men from another country look at the camera . <end>',\n",
              "  '<start> Men wearing hats stand with arms folded . <end>',\n",
              "  '<start> Several men wearing ethnic hats are watching the photographer in an outdoor market . <end>'],\n",
              " 'Flicker8k_Dataset/3491607076_922ec561d9.jpg': ['<start> A man holds a trophy on the stage . <end>',\n",
              "  '<start> A race car driver accepts his trophy . <end>',\n",
              "  '<start> a racer holds up his trophy . <end>',\n",
              "  '<start> The racing winner accepts his trophy . <end>',\n",
              "  '<start> Winning racer displaying his trophy and waving to the crowd . <end>'],\n",
              " 'Flicker8k_Dataset/1053804096_ad278b25f1.jpg': ['<start> A girl in pigtails splashes in the shallow water . <end>',\n",
              "  '<start> A girls plays in the surf . <end>',\n",
              "  '<start> a girl with pigtails is playing in the ocean by the beach . <end>',\n",
              "  '<start> A girl with pigtails plays in the water . <end>',\n",
              "  '<start> A young girl in pigtails plays in the water . <end>'],\n",
              " 'Flicker8k_Dataset/2426828433_ce894d1c54.jpg': ['<start> Three black dogs on grass . <end>',\n",
              "  '<start> Three black dogs play in the glass . <end>',\n",
              "  '<start> Three black dogs play in the grass . <end>',\n",
              "  '<start> three dogs run through the grass . <end>',\n",
              "  '<start> Three large black dogs are playing in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3522076584_7c603d2ac5.jpg': ['<start> a biker performs a trick in the air . <end>',\n",
              "  '<start> A child rides a bike high in the air . <end>',\n",
              "  '<start> A person flying through the air on a bicycle . <end>',\n",
              "  '<start> A person is jumping while riding a bike . <end>',\n",
              "  '<start> A person on a bike flies through the air with the sun flaring through the bike frame . <end>'],\n",
              " 'Flicker8k_Dataset/2480820830_bdec1f5b76.jpg': ['<start> Two black dogs are jumping in waves at the beach <end>',\n",
              "  '<start> Two black dogs play in the waves at the beach . <end>',\n",
              "  '<start> Two black dogs run into the white waves on a beach . <end>',\n",
              "  '<start> Two dog are playing the waves at a beach . <end>',\n",
              "  '<start> Two dogs are running around in the water . <end>'],\n",
              " 'Flicker8k_Dataset/3324746155_71e14f60ce.jpg': ['<start> A man kicks a soccer ball on a field . <end>',\n",
              "  '<start> A man wearing a blue shirt kicks a soccer ball along a green field . <end>',\n",
              "  '<start> a man wearing blue plays soccer . <end>',\n",
              "  '<start> A soccer player in a blue AIG shirt is kicking the ball . <end>',\n",
              "  '<start> Man in AIG t-shirt playing soccer . <end>'],\n",
              " 'Flicker8k_Dataset/2714878018_1593c38d69.jpg': ['<start> A boy jumping over some water . <end>',\n",
              "  '<start> A boy wearing swimming trunks jumps over some sprinkler water in a backyard . <end>',\n",
              "  '<start> A little boy in glasses jumps into a spray of water . <end>',\n",
              "  '<start> a young boy jumping through a mist of water . <end>',\n",
              "  '<start> Young boy with glasses playing in the sprinkler . <end>'],\n",
              " 'Flicker8k_Dataset/2666205903_8d287669e1.jpg': ['<start> A child is holding a colorful object and overlooking a crowd of people while sitting on the shoulders of an older person . <end>',\n",
              "  \"<start> A girl in a blue sweater sits on a person 's shoulders and carries a pinwheel . <end>\",\n",
              "  \"<start> A girls in a blue shirt holds a flower while sitting on a man 's shoulders . <end>\",\n",
              "  '<start> A young oriential girl is standing above the crowd playing with a pinwheel <end>',\n",
              "  '<start> Girl in blue sweater and holding a multicolor toy sitting on the shoulders of a man with grey hair . <end>'],\n",
              " 'Flicker8k_Dataset/838074897_9d6270b3cd.jpg': ['<start> A brown haired little girl is jumping through squirts of water . <end>',\n",
              "  '<start> A girl runs through sprinklers that shoot water out of the ground . <end>',\n",
              "  '<start> A young girl in red pants plays in a water fountain area . <end>',\n",
              "  '<start> Little girl is jumping up in the sprinklers getting soaked . <end>',\n",
              "  '<start> The girl is wearing a white shirt and red pants , and jumps through water . <end>'],\n",
              " 'Flicker8k_Dataset/3327487011_1372c425fb.jpg': ['<start> A classroom full of students is looking in the same direction inside a bamboo structure . <end>',\n",
              "  '<start> A group of children mostly wearing white uniform shirts sit and wait . <end>',\n",
              "  '<start> A group of students in uniforms listens attentively to the front of the class . <end>',\n",
              "  '<start> A large group of girls are all staring in the same direction . <end>',\n",
              "  '<start> The young girls are listening with books in front of them . <end>'],\n",
              " 'Flicker8k_Dataset/3485599424_94de8ede51.jpg': ['<start> A brown and white dog plays in the yard by a house . <end>',\n",
              "  '<start> A brown and white dog standing in a yard . <end>',\n",
              "  '<start> A dog chained in fronr of a house . <end>',\n",
              "  '<start> A dog stands on the grass while tied up . <end>',\n",
              "  \"<start> A leashed dog is in the backyard of someone 's home . <end>\"],\n",
              " 'Flicker8k_Dataset/2885382946_f541ea5722.jpg': ['<start> A boy and two men shooting off a water rocket at the beach . <end>',\n",
              "  '<start> A group of people are standing on the beach in front of some boats . <end>',\n",
              "  '<start> A group of people launch an air rocket in front of a marina . <end>',\n",
              "  '<start> A lady and a little boy use a pump to launch a rocket at a marina . <end>',\n",
              "  '<start> A little boy made blasted something off with water . <end>'],\n",
              " 'Flicker8k_Dataset/2525716531_e6dedee421.jpg': ['<start> A man in a safety suit training a police German Shephard . <end>',\n",
              "  '<start> A man trains a dog to attack . <end>',\n",
              "  '<start> A man wearing padded arm protection is being bitten by a German shepherd dog . <end>',\n",
              "  '<start> A man wearing pads on his limbs is being bitten by a dog . <end>',\n",
              "  '<start> A man with a quilted glove is bitten by a dog . <end>'],\n",
              " 'Flicker8k_Dataset/337793983_ac5b2e848e.jpg': ['<start> a couple men sitting outside of a bar <end>',\n",
              "  '<start> Men sit and talk at the storefront of a cafe . <end>',\n",
              "  '<start> There are two people inside , and two men outside , a cafe ; with a tv on in the background . <end>',\n",
              "  '<start> Two men are sitting at a table outside a coffee shop . <end>',\n",
              "  '<start> Two men sit outside a cafe painted blue . <end>'],\n",
              " 'Flicker8k_Dataset/3252985078_c4ee2aca4e.jpg': ['<start> A crowd of men wearing paper numbers on their shirts run in a race . <end>',\n",
              "  '<start> A group of people are running a race . <end>',\n",
              "  '<start> A large pack of men jog in a race . <end>',\n",
              "  '<start> People with numbers on their chests are running in a pack . <end>',\n",
              "  '<start> There is a large crowd of runners . <end>'],\n",
              " 'Flicker8k_Dataset/261737543_b8fdc24671.jpg': ['<start> A kid is jumping off the side of a mountain just outside a city . <end>',\n",
              "  '<start> A man jumping on a hill overlooking a town . <end>',\n",
              "  '<start> A man jumps off a cliff with a city view below . <end>',\n",
              "  '<start> A man leaping from a rocky hill . <end>',\n",
              "  '<start> A person jumping off of a high rock . <end>'],\n",
              " 'Flicker8k_Dataset/475313618_bdb2f72be5.jpg': ['<start> A female in bluejeans is standing in an enclosed area with arms folded . <end>',\n",
              "  '<start> A girl stands in a dimly lit area . <end>',\n",
              "  '<start> a lone woamn wearing a black hoodie and blue jeans standing on a sidewalk <end>',\n",
              "  '<start> Girl stands in subway waiting on something . <end>',\n",
              "  '<start> Girl with crossed arms stands in stone corridor , seated figure in background . <end>'],\n",
              " 'Flicker8k_Dataset/489134459_1b3f46fc03.jpg': ['<start> a boy and a girl stand in front of a house . <end>',\n",
              "  '<start> A girl stands nearby while a boy sits in an open doorway . <end>',\n",
              "  '<start> A girl stands outside of a blue and white home while a younger child sits on its stoop . <end>',\n",
              "  '<start> A little girl leans on a concrete wall next to a blue door where a shirtless child sits . <end>',\n",
              "  '<start> A young girl stands against a blue and white house with a young boy who sits . <end>'],\n",
              " 'Flicker8k_Dataset/235065283_1f9a3c79db.jpg': ['<start> A man climb up a snowy mountain . <end>',\n",
              "  '<start> A man in ice climbing gear holds a rope . <end>',\n",
              "  '<start> A man on a huge chunk of snow , holding a rope . <end>',\n",
              "  '<start> A man wearing winter clothes and a hardhat is climbing over a snowy ledge using a rope attached to his waist . <end>',\n",
              "  '<start> A mountaineer is following a rope through a snowy trail . <end>'],\n",
              " 'Flicker8k_Dataset/2657643451_b9ddb0b58f.jpg': ['<start> A person and a dog run on a paved road near a forest . <end>',\n",
              "  '<start> A person runs with a dog . <end>',\n",
              "  '<start> A person jogs down a gravel road after a small dog . <end>',\n",
              "  '<start> A woman and dog running down an asphalt , tree lined road . <end>',\n",
              "  '<start> Someone in a green shirt running behind a small dog . <end>'],\n",
              " 'Flicker8k_Dataset/3116011063_f4071ccce6.jpg': ['<start> a man falling off of a surfboard in the ocean <end>',\n",
              "  '<start> A surfer flies over a crashing wave . <end>',\n",
              "  '<start> A surfer is falling into a big ocean wave <end>',\n",
              "  '<start> Surfer in black wetsuit falling off his board into the water . <end>',\n",
              "  '<start> The surfer is wiped out by the wave . <end>'],\n",
              " 'Flicker8k_Dataset/2615811117_42b1838205.jpg': ['<start> A baby in a life jacket on a raft . <end>',\n",
              "  '<start> A baby is wearing an adult life jacket whilst sitting in a dinghy inside the house . <end>',\n",
              "  '<start> A happy baby wears an orange life vest . <end>',\n",
              "  '<start> A young kid wearing a life jacket <end>',\n",
              "  '<start> The toddler sits in the boat with a life jacket on indoors . <end>'],\n",
              " 'Flicker8k_Dataset/3557148230_7fc843e5de.jpg': ['<start> A boy standing on a tricycle . <end>',\n",
              "  '<start> A little baby on a tricycle seems to not be wearing any clothes . <end>',\n",
              "  '<start> A toddler looking behind him while standing on a red tricycle . <end>',\n",
              "  '<start> The child stand on the seat of his trike in the park . <end>',\n",
              "  '<start> The small child is standing on a tricycle . <end>'],\n",
              " 'Flicker8k_Dataset/84713990_d3f3cef78b.jpg': ['<start> A group of people on a blue raft going down a river . <end>',\n",
              "  '<start> A group of people paddle their blue inflatable raft down the rapids . <end>',\n",
              "  '<start> a group of people white water rafting in a blue raft . <end>',\n",
              "  '<start> Several people are rafting down a choppy river in rocky terrain . <end>',\n",
              "  '<start> Some people are riding a raft down a white water river . <end>'],\n",
              " 'Flicker8k_Dataset/2435166927_28b8130660.jpg': ['<start> A girl in a gray shit is throwing her hands up . <end>',\n",
              "  '<start> A girl in a grey shirt puts her hands over her head in a gesture . <end>',\n",
              "  '<start> A young dark haired girl with her hands raised over her head . <end>',\n",
              "  '<start> A young girl in a grey illustrated shirt is holding her hands over her head . <end>',\n",
              "  '<start> A young girl raises her arms over her head in front of a couple of other people in the park . <end>'],\n",
              " 'Flicker8k_Dataset/2534194182_ac53035cf4.jpg': ['<start> a group of band members doing a routine <end>',\n",
              "  '<start> A group of girls , in white skirts and green tops , walk in a circle carrying rifles in front of a drum line . <end>',\n",
              "  '<start> A marching band performing . <end>',\n",
              "  '<start> A marching band performs in an auditorium <end>',\n",
              "  '<start> Some marching band members in green and white outfits . <end>'],\n",
              " 'Flicker8k_Dataset/2371809188_b805497cba.jpg': ['<start> A boy climbs an indoor rock climbing wall . <end>',\n",
              "  '<start> A boy climbs a rock wall . <end>',\n",
              "  '<start> A boy is climbing up a rock-climbing wall while an older boy stands on the ground <end>',\n",
              "  '<start> Boy rock climbing on a blue wall while an adult looks away . <end>',\n",
              "  '<start> Little boy climbing an indoor rock climbing wall . <end>'],\n",
              " 'Flicker8k_Dataset/3123770450_cedc16d162.jpg': ['<start> a deer and several turkeys together in the snow <end>',\n",
              "  '<start> A deer looks at 5 turkeys in the snow . <end>',\n",
              "  '<start> Deer and turkeys in the snow . <end>',\n",
              "  '<start> Deer and turkeys stand on snow covered ground . <end>',\n",
              "  '<start> Large turkeys and deer stand in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/1361420539_e9599c60ae.jpg': ['<start> A black dog is running in the grass . <end>',\n",
              "  '<start> A black poodle is running through the grass . <end>',\n",
              "  '<start> A small black dog is in the grass . <end>',\n",
              "  '<start> The black dog is running through the grass . <end>',\n",
              "  '<start> The black dog is walking through the tall grass . <end>'],\n",
              " 'Flicker8k_Dataset/2953015871_cae796b6e7.jpg': ['<start> A black and tan dog rolls on his back in a field . <end>',\n",
              "  '<start> A black dog rolling in the green grass . <end>',\n",
              "  '<start> A dog rolls on his back . <end>',\n",
              "  '<start> A dog rolls on his back in the grass . <end>',\n",
              "  '<start> A dog with paws in the air lying on grass <end>'],\n",
              " 'Flicker8k_Dataset/3583903436_028b06c489.jpg': ['<start> A boy is playing on a green swing in front of a wooden barn . <end>',\n",
              "  '<start> A boys swings on a green swing outside a old wooden structure . <end>',\n",
              "  '<start> A young boy in a green swing rides through the air near a barn . <end>',\n",
              "  '<start> A young boy swings alongside an old wooden building . <end>',\n",
              "  '<start> The boy swings next to the barn . <end>'],\n",
              " 'Flicker8k_Dataset/1032122270_ea6f0beedb.jpg': ['<start> A woman crouches near three dogs in a field . <end>',\n",
              "  '<start> Three dogs are playing on grassy hill with a blue sky . <end>',\n",
              "  '<start> Three dogs are standing in the grass and a person is sitting next to them <end>',\n",
              "  '<start> Three dogs on a grassy hill <end>',\n",
              "  '<start> Three dogs stand in a grassy field while a person kneels nearby . <end>'],\n",
              " 'Flicker8k_Dataset/3350671534_2a5d45a961.jpg': ['<start> A man in a grey winter hat and purple sweatshirt skateboarding . <end>',\n",
              "  '<start> A man Rollerblades on a skate course . <end>',\n",
              "  '<start> An inline skater wearing a purple jacket is performing a trick on a ramp . <end>',\n",
              "  '<start> guy rollerskating on skate ramp <end>',\n",
              "  '<start> Man with purple sweater at the top of a skateboard ramp . <end>'],\n",
              " 'Flicker8k_Dataset/387974450_bcd205daac.jpg': ['<start> A black dog runs along a field where black birds are beginning to fly . <end>',\n",
              "  '<start> A dark colored dog running in a field with multilple birds in the background . <end>',\n",
              "  '<start> A dog runs at birds taking flight <end>',\n",
              "  '<start> A grey dog chases a bunch of crows , a river in the background . <end>',\n",
              "  '<start> The dog chases the birds in the field . <end>'],\n",
              " 'Flicker8k_Dataset/3534952095_975cca0056.jpg': ['<start> A lady riding a mini motorcycle <end>',\n",
              "  '<start> an african-american woman rides her moped . <end>',\n",
              "  '<start> A woman on a motorcycle is wearing heels . <end>',\n",
              "  '<start> A woman wearing a black skirt and pumps is riding her white and red moped . <end>',\n",
              "  '<start> Woman riding a small red and white motorcycle and wearing a matching red helmet and scarf <end>'],\n",
              " 'Flicker8k_Dataset/3389321512_b11f499dab.jpg': ['<start> The women have been wounded . <end>',\n",
              "  '<start> Two women in black have blood on their face and knee . <end>',\n",
              "  '<start> Two women , one sitting in a chair , the other standing , appear to be injured . <end>',\n",
              "  '<start> Two women sport bloody wounds . <end>',\n",
              "  '<start> Two women talk while standing underneath a white tent . <end>'],\n",
              " 'Flicker8k_Dataset/3429391520_930b153f94.jpg': ['<start> A bicyclist catches some air <end>',\n",
              "  '<start> A helmeted boy on a bike flies through the air as he rides among dirt hills with a river in the background . <end>',\n",
              "  '<start> A man is doing a stunt outside on his bike <end>',\n",
              "  '<start> Bike rider doing a high jump over hilly track , water in background . <end>',\n",
              "  '<start> This helmeted person is doing a stunt on a bicycle outdoors . <end>'],\n",
              " 'Flicker8k_Dataset/2998861375_02817e0147.jpg': ['<start> A group of army members aim their guns . <end>',\n",
              "  '<start> military personnel dressed in fatigues and ear protection laying on their stomachs shooting guns . <end>',\n",
              "  '<start> Military personnel learning how to shoot their rifles . <end>',\n",
              "  '<start> Military personnel shoot rifles . <end>',\n",
              "  '<start> People dressed in camo are bent down getting ready to fire their guns . <end>'],\n",
              " 'Flicker8k_Dataset/3119875880_22f9129a1c.jpg': ['<start> A boy climbs rocks . <end>',\n",
              "  '<start> A boy crawls through a rock tunnel with his brother and father behind him . <end>',\n",
              "  '<start> A man watches two small boys playing in a naturally formed rock . <end>',\n",
              "  '<start> Children playing on rocks . <end>',\n",
              "  '<start> Kids play in a rocky area . <end>'],\n",
              " 'Flicker8k_Dataset/41999070_838089137e.jpg': ['<start> A few dogs swimming in a lake . <end>',\n",
              "  '<start> A group of dogs in water playing with toys and balls . <end>',\n",
              "  '<start> A group of dogs playing in a large pool . <end>',\n",
              "  '<start> Many dogs are swimming and playing in a fountain in a public park . <end>',\n",
              "  '<start> Several dogs swim in a pool and two black dogs are playing tug of war with a toy . <end>'],\n",
              " 'Flicker8k_Dataset/3386375153_20c56d0aae.jpg': ['<start> A bicycle goes downhill . <end>',\n",
              "  '<start> A bicyclist wearing a dark helmet and a blue jacket jumps over a mound in a field . <end>',\n",
              "  '<start> A man in a blue jacket riding a bike <end>',\n",
              "  '<start> A man is biking on a hill . <end>',\n",
              "  '<start> A person rides their bike down a hill . <end>'],\n",
              " 'Flicker8k_Dataset/3298175192_bbef524ddc.jpg': ['<start> A black and white dog is chewing on a camera . <end>',\n",
              "  '<start> A black and white dog rests its head on a camera . <end>',\n",
              "  '<start> A puppy plays with a camera . <end>',\n",
              "  '<start> Black and white dog chewing on a canon camera setting in the grass the camera is black and white . <end>',\n",
              "  '<start> Black and white puppy gnaws camera . <end>'],\n",
              " 'Flicker8k_Dataset/2898810636_84fb5c0b63.jpg': ['<start> A child in a blue shirt jumping off a bench . <end>',\n",
              "  '<start> A child jumping off bleachers with a blue shirt . <end>',\n",
              "  '<start> A child wearing a blue shirt is jumping in the air . <end>',\n",
              "  '<start> A child wearing a jersey jumps in the air . <end>',\n",
              "  '<start> A girl jumps in the air . <end>'],\n",
              " 'Flicker8k_Dataset/2929272606_2a5923b38e.jpg': ['<start> A little girl in a blue shirt is pointing at the water on the beach . <end>',\n",
              "  '<start> A little girl with a blue shirt is standing by a man wearing sunglasses on the beach . <end>',\n",
              "  '<start> A young girl is looking at a body of water while an older male kneels behind her . <end>',\n",
              "  '<start> A young girl is pointing at water on a beach . <end>',\n",
              "  '<start> A young girl is standing on the shore and pointing to the ocean . <end>'],\n",
              " 'Flicker8k_Dataset/3383491811_fd9d3a891d.jpg': ['<start> A brown dog with a black collar licks its own mouth . <end>',\n",
              "  '<start> A dog licks his nose . <end>',\n",
              "  '<start> A large dog licking its nose . <end>',\n",
              "  '<start> Brown dog with black collar licking nose . <end>',\n",
              "  '<start> Dog sticking out its tongue . <end>'],\n",
              " 'Flicker8k_Dataset/3636418958_f038130bb2.jpg': ['<start> A girl in hot pink leotard is leaping through the air . <end>',\n",
              "  '<start> A gymnast vaults through the air . <end>',\n",
              "  '<start> a young girl wearing a pink leotard jump in midair <end>',\n",
              "  '<start> Group of gymnast look on as a girl in a red bodysuit completes a stunt . <end>',\n",
              "  '<start> The gymnast is wearing a red outfit and jumping . <end>'],\n",
              " 'Flicker8k_Dataset/2878272032_fda05ffac7.jpg': ['<start> A dog chases a ball that has dropped in the water . <end>',\n",
              "  '<start> A dog on a log looks at a splash in the water as another dog looks on . <end>',\n",
              "  '<start> dogs playing in a stream <end>',\n",
              "  '<start> Two dogs are staring at a splash in the water <end>',\n",
              "  '<start> Two dogs look at something splashing in the water . <end>'],\n",
              " 'Flicker8k_Dataset/2396100671_3a9d67f03d.jpg': ['<start> A boy in a costume is sitting on a bike . <end>',\n",
              "  '<start> A child in a dragon costume on a bike . <end>',\n",
              "  '<start> A child wearing a costume rides a bike in winter . <end>',\n",
              "  '<start> A little boy on bike wearing dragon costume <end>',\n",
              "  '<start> A young boy sits on his bike wearing a dragon costume . <end>'],\n",
              " 'Flicker8k_Dataset/3676460610_8c52e8a355.jpg': ['<start> A woman biking along a trail surrounded by various plants . <end>',\n",
              "  '<start> A woman rides a bike on a trail through a field . <end>',\n",
              "  '<start> A woman rides a bike over a dirt path through the long grass . <end>',\n",
              "  '<start> A woman riding a bicycle in a field . <end>',\n",
              "  '<start> Woman on bicycle riding down dirt trail . <end>'],\n",
              " 'Flicker8k_Dataset/300314926_0b2e4b64f5.jpg': ['<start> A man gets lots of air time as he wakeboards . <end>',\n",
              "  '<start> A man is waterskiing on one ski and jumping out of the water . <end>',\n",
              "  '<start> A wakeboarder leaps in the air . <end>',\n",
              "  '<start> A waterskier is jumping through the air whilst holding onto the line . <end>',\n",
              "  '<start> The man on the board uses the wave to jump high into the air . <end>'],\n",
              " 'Flicker8k_Dataset/3415311628_c220a65762.jpg': ['<start> A man and a boy ride a go kart <end>',\n",
              "  '<start> A man helps a boy steer a go-cart . <end>',\n",
              "  '<start> An old man drives a go cart with a little boy . <end>',\n",
              "  '<start> Man and child riding in go cart . <end>',\n",
              "  '<start> Old man teaching little kid to drive . <end>'],\n",
              " 'Flicker8k_Dataset/3413019648_e787f0cb88.jpg': ['<start> A kayaker fights the rapids . <end>',\n",
              "  '<start> a man in a green kayak paddles down some rapids in front of a waterfall <end>',\n",
              "  '<start> A man kayaking down rapids . <end>',\n",
              "  '<start> A man kayaking through rapids in a river <end>',\n",
              "  '<start> A person in a green canoe paddles down rapids carrying oars and wearing an orange and black top . <end>'],\n",
              " 'Flicker8k_Dataset/1525153022_06c48dbe52.jpg': ['<start> A black dog is running through the shallow edge of a large body of water . <end>',\n",
              "  '<start> A black dog is running through the water . <end>',\n",
              "  '<start> A black dog jumps high out of the water . <end>',\n",
              "  '<start> a black and tan dobbermen running through the ocean . <end>',\n",
              "  '<start> The dog runs through the water . <end>'],\n",
              " 'Flicker8k_Dataset/1425069590_570cc7c2d8.jpg': ['<start> A girl begins to climb a red piece of playground equipment . <end>',\n",
              "  '<start> A little girl climbing at a playground . <end>',\n",
              "  '<start> a little girl dressed in yellow is holding onto two red handles . <end>',\n",
              "  '<start> A small girl dressed in yellow wearing flip flops climbing onto red playground equipment . <end>',\n",
              "  '<start> A young girl makes her way onto red recreational equipment . <end>'],\n",
              " 'Flicker8k_Dataset/3720366614_dfa8fe1088.jpg': ['<start> A small black dog is standing on two feet and wearing a pink tutu . <end>',\n",
              "  '<start> Small dog in costume stands on hind legs to reach dangling flowers . <end>',\n",
              "  '<start> The dog is jumping up beside a red wall . <end>',\n",
              "  '<start> The small brown and black down is wearing a pink tutu . <end>',\n",
              "  '<start> The small dog wearing a tutu stands on its hind legs . <end>'],\n",
              " 'Flicker8k_Dataset/3697003897_d8ac13be9a.jpg': ['<start> a man wearing inline skates is skating down a cement wall <end>',\n",
              "  '<start> A rollerblader is sliding down a railing . <end>',\n",
              "  '<start> A skater slides down a wall beside a long staircase . <end>',\n",
              "  '<start> A teenage boy is riding a skateboard on the stone handrail of a flight of outdoor steps . <end>',\n",
              "  '<start> The in-line skater slides down the wall . <end>'],\n",
              " 'Flicker8k_Dataset/616177206_0e16c33f6b.jpg': ['<start> A black policeman is smiling at a larger woman <end>',\n",
              "  '<start> A policeman grins at a woman wearing beads on a crowded street <end>',\n",
              "  '<start> A policeman hugging a woman on the street . <end>',\n",
              "  '<start> A police officer has his arm around a woman on the street . <end>',\n",
              "  '<start> A woman chats with a smiling police officer . <end>'],\n",
              " 'Flicker8k_Dataset/854333409_38bc1da9dc.jpg': ['<start> The dog on the right has a red object in his mouth , and the other dog has biting it . <end>',\n",
              "  '<start> Two black dogs playing with orange object run across grass . <end>',\n",
              "  '<start> Two black dogs play with a toy . <end>',\n",
              "  '<start> Two black labs run , one carrying an orange dog toy . <end>',\n",
              "  '<start> Two dark dogs run together and one holds something in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/2929506802_5432054d77.jpg': ['<start> a boy pushes a wagon full of pumpkins . <end>',\n",
              "  '<start> A boy pushes a wagon with two pumpkins . <end>',\n",
              "  '<start> A boy smiling , leaning over a wagon filled with two large pumpkins . <end>',\n",
              "  '<start> A child squats behind a wagon with two pumpkins in it . <end>',\n",
              "  '<start> boy pushing wagon with two pumpkins in it <end>'],\n",
              " 'Flicker8k_Dataset/624742559_ff467d8ebc.jpg': ['<start> A child in a green hat swings on monkey bars at a blue playground . <end>',\n",
              "  '<start> A child playing on a playground play set . <end>',\n",
              "  '<start> A child swinging on a playground play set . <end>',\n",
              "  '<start> A little boy is climbing on the monkey bars at a playground . <end>',\n",
              "  '<start> Kids playing at a park jungle gym . <end>'],\n",
              " 'Flicker8k_Dataset/3107592525_0bcd00777e.jpg': ['<start> A couple posing for the camera with rain jackets on . <end>',\n",
              "  '<start> A couple stands covered in plastic ; she smiles and he scowls . <end>',\n",
              "  '<start> A lady and a man wear rain ponchos . <end>',\n",
              "  '<start> A man and a woman in plastic coverings . <end>',\n",
              "  '<start> The man and woman are wearing a protective plastic raincoat . <end>'],\n",
              " 'Flicker8k_Dataset/3376898612_41c91de476.jpg': ['<start> A group of 5 men in the air in front of a canal and houses . <end>',\n",
              "  '<start> Five guys in tuxes and sneakers are jumping in the air . <end>',\n",
              "  '<start> Five men dressed in tuxedos and tennis shoes are jumping for a silly wedding photo . <end>',\n",
              "  '<start> Five men in tuxedos jump for joy in front of a mountain range . <end>',\n",
              "  '<start> five men wearing tuxedos jump up in the air in front of a small river <end>'],\n",
              " 'Flicker8k_Dataset/3399284917_721aefe2a7.jpg': ['<start> A child on a kiddie swing being pushed by a woman <end>',\n",
              "  '<start> An adult smiles with a child on a swing . <end>',\n",
              "  '<start> A young woman watches as a young blond boy swings in a chair swing with buildings visible in the background . <end>',\n",
              "  '<start> The woman stands outdoors , next to a child in a swing . <end>',\n",
              "  '<start> Woman standing , with a child on a swing . <end>'],\n",
              " 'Flicker8k_Dataset/3440724965_03d6ca5399.jpg': ['<start> A man has his hand on his head while a speaker is speaking . <end>',\n",
              "  '<start> A man in a suit touches his head while another speaks at a microphone . <end>',\n",
              "  '<start> A man is scratching his head at a meeting while a person spoke . <end>',\n",
              "  '<start> A man wearing a suit scratches the back of his head at a meeting . <end>',\n",
              "  '<start> a picture taken from the back of osme kind of large meetinghall . <end>'],\n",
              " 'Flicker8k_Dataset/2868776402_aef437e493.jpg': ['<start> A girl in a pink bicycle rides in front of a restaraunt . <end>',\n",
              "  '<start> A little girl in pink riding down the street on a pink and purple bike . <end>',\n",
              "  '<start> A young girl rides a bicycle past a cafe . <end>',\n",
              "  '<start> A young girl wearing pink is riding her bike in front of a store on a boardwalk . <end>',\n",
              "  '<start> Girl riding a bike on a street near many stores . <end>'],\n",
              " 'Flicker8k_Dataset/3518608016_46453d8b18.jpg': ['<start> A woman is petting a dog outside . <end>',\n",
              "  '<start> A woman is petting her dog near a stone path . <end>',\n",
              "  '<start> A woman playing with a brown dog on a garden path . <end>',\n",
              "  '<start> A woman plays with a brown dog . <end>',\n",
              "  '<start> A woman plays with her dog outside . <end>'],\n",
              " 'Flicker8k_Dataset/3326086533_23a0a54a8e.jpg': ['<start> A black dog clutches a pink purse in his teeth and runs . <end>',\n",
              "  '<start> A black dog is running on the grass with a pink purse in its mouth . <end>',\n",
              "  '<start> A brown dog retrieves a pink toy . <end>',\n",
              "  '<start> A little black dog is running in the grass with a pink purse in its mouth . <end>',\n",
              "  '<start> The wet dog has retrieved the pink purse with aqua handles . <end>'],\n",
              " 'Flicker8k_Dataset/3062173277_bfb5ef4c45.jpg': ['<start> A group of people are rowing a boat in a contest . <end>',\n",
              "  '<start> A rowing team races forward in competition with the motivation of their leader in front of the boat . <end>',\n",
              "  '<start> Boat number 5 has several men with life jackets paddling the water . <end>',\n",
              "  '<start> People in orange vests are rowing with great effort . <end>',\n",
              "  '<start> Several people are rowing a boat while being cheered on by a person with a drum <end>'],\n",
              " 'Flicker8k_Dataset/380041023_0dfd712ef1.jpg': ['<start> A brown and black dog runs through the leaves . <end>',\n",
              "  '<start> A brown dog is running . <end>',\n",
              "  '<start> A brown dog with a red collar jumping across a leafy lawn . <end>',\n",
              "  '<start> A dog with a brindle-colored coat is running across the yard . <end>',\n",
              "  '<start> The brown dog is wearing a red collar . <end>'],\n",
              " 'Flicker8k_Dataset/2888658480_e922a3dec2.jpg': ['<start> A man jumps off a rock into the water <end>',\n",
              "  '<start> Swimmers jump from rocks above blue-green water . <end>',\n",
              "  '<start> Two boys jump from rocks into a green mountain pool . <end>',\n",
              "  '<start> Two people jump off the rocks and into the greenish water below . <end>',\n",
              "  '<start> Two swimmers are jumping off the tall rock into the water . <end>'],\n",
              " 'Flicker8k_Dataset/447722389_4b51b7e13d.jpg': ['<start> A brown and white dog is jumping high and catching a blue ball . <end>',\n",
              "  '<start> A dog is jumping and catching a small , blue ball in a park surrounded by two other dogs . <end>',\n",
              "  '<start> A dog jumps and catches a blue ball in his mouth . <end>',\n",
              "  '<start> A dog jumps in the air to catch a blue ball . <end>',\n",
              "  '<start> Three dogs run on grass , one leaps to catch blue ball . <end>'],\n",
              " 'Flicker8k_Dataset/3678098428_40c1b74cc2.jpg': ['<start> A bearded man at a fair wearing a black tank top and a plaid hat . <end>',\n",
              "  '<start> A guy with a black tank top . <end>',\n",
              "  '<start> A man in a black tank top wearing a red plaid hat <end>',\n",
              "  '<start> A man wearing a black tank top and red plaid hat is smiling as a man behind him is playing with a colorful object . <end>',\n",
              "  '<start> A man with face peircings and a red fadora hat smiles at a fair . <end>'],\n",
              " 'Flicker8k_Dataset/2825668136_107223182c.jpg': ['<start> A bike rider jumping off his bike , doing a trick <end>',\n",
              "  '<start> A guy is doing a trick on a bike . <end>',\n",
              "  '<start> A man is performing a jumping trip on his bicycle . <end>',\n",
              "  '<start> A man with a bike jumps high above the concrete . <end>',\n",
              "  '<start> Bike rider jumps off of gray stone rise , does trick in air . <end>'],\n",
              " 'Flicker8k_Dataset/2098418613_85a0c9afea.jpg': ['<start> A brown chow mix dog is standing in front of a van with euro plats in the middle of a messy yard . <end>',\n",
              "  '<start> A brown dog standing in a muddy yard . <end>',\n",
              "  '<start> A brown dogs walks near a green van and some junk . <end>',\n",
              "  '<start> A large brown dog stands in front of a green van in the yard of a house . <end>',\n",
              "  '<start> A yellow dog is standing in front of a green car and next to a toilet . <end>'],\n",
              " 'Flicker8k_Dataset/3744832122_2f4febdff6.jpg': ['<start> A boy pitches in a baseball game . <end>',\n",
              "  '<start> A boy winding up for a pitch . <end>',\n",
              "  '<start> A young baseball player winds up to throw the ball . <end>',\n",
              "  '<start> A young person pitches in a baseball game . <end>',\n",
              "  '<start> The baseball player is throwing the ball . <end>'],\n",
              " 'Flicker8k_Dataset/3517362674_0f5296de19.jpg': ['<start> A girl is blowing bubbles heavily . <end>',\n",
              "  '<start> A little girl closes her eyes and blows through a bubble wand . <end>',\n",
              "  '<start> A little girl with dark hair blowing bubbles . <end>',\n",
              "  '<start> A small girl blows on an orange bubble stick . <end>',\n",
              "  '<start> A young girl is blowing bubbles with an orange bubble wand . <end>'],\n",
              " 'Flicker8k_Dataset/3249278583_95cd8206da.jpg': ['<start> A complete dog sled team in motion . <end>',\n",
              "  '<start> A dog sled with two passengers travelling through the snow . <end>',\n",
              "  '<start> A team of dogs pulls a sleigh holding two people across the snow . <end>',\n",
              "  '<start> Two people are on a sled pulled by many dogs . <end>',\n",
              "  '<start> Two people on a sled pulled by a team of dogs . <end>'],\n",
              " 'Flicker8k_Dataset/2872806249_00bea3c4e7.jpg': ['<start> An elderly person in bright orange overalls is standing alongside a street . <end>',\n",
              "  '<start> A person wearing orange overalls stands on the sidewalk . <end>',\n",
              "  '<start> A woman in red overalls stands on sidewalk . <end>',\n",
              "  '<start> The man in the red overalls stands on the sidewalk . <end>',\n",
              "  '<start> Woman in red overalls standing on the sidewalk . <end>'],\n",
              " 'Flicker8k_Dataset/406642021_9ec852eccf.jpg': ['<start> A climber wearing a red shirt is climbing a rock face on a snowy day . <end>',\n",
              "  '<start> A man in a red shirt climbing a rock with his bare hands . <end>',\n",
              "  '<start> A man is climbing over a short but sheer rocky cliff . <end>',\n",
              "  '<start> A mean wearing a red shirt clinging to a rock face . <end>',\n",
              "  '<start> A person scales a rock . <end>'],\n",
              " 'Flicker8k_Dataset/3516285214_59823b341e.jpg': ['<start> A person surfs in the curl of a wave , obsured by the falling water . <end>',\n",
              "  '<start> A person surfs through a wave as it crashes down . <end>',\n",
              "  '<start> A surfer is riding in the barrel of a wave . <end>',\n",
              "  '<start> Someone is surfing underneath a wave on a white surfboard . <end>',\n",
              "  '<start> The large wave is crashing down over a surfer . <end>'],\n",
              " 'Flicker8k_Dataset/2261346505_302c67951d.jpg': ['<start> A group of foreign people stand with umbrellas on the side of the street . <end>',\n",
              "  '<start> A group of people with clear umbrellas standing on the street . <end>',\n",
              "  '<start> People trying to stay dry with umbrellas in the city . <end>',\n",
              "  '<start> People walk in the rain with umbrellas . <end>',\n",
              "  '<start> Several people are walking on a rainy busy street in Asia with clear umbrellas . <end>'],\n",
              " 'Flicker8k_Dataset/2736902411_a0010f89ae.jpg': ['<start> The girls are taking a picture of themselves . <end>',\n",
              "  '<start> Two blonde girls are taking a picture of themselves . <end>',\n",
              "  '<start> Two blonde women are smiling while one is holding a camera to capture their image . <end>',\n",
              "  '<start> Two girls taking a picture of themselves <end>',\n",
              "  '<start> Two young girls are taking a picture of themselves with a camera . <end>'],\n",
              " 'Flicker8k_Dataset/3522989916_f20319cc59.jpg': ['<start> A brown dog and a grey dog play in the grass . <end>',\n",
              "  '<start> A brown dog barks at a grey dog in the grass . <end>',\n",
              "  '<start> A grey dog and a tan dog playing on a grassy field . <end>',\n",
              "  '<start> Two dogs , one light brown and one grey , play outdoors on the grass . <end>',\n",
              "  '<start> Two dogs playing on grass . <end>'],\n",
              " 'Flicker8k_Dataset/2689001252_e0016c89f0.jpg': ['<start> little girls in swimsuits are laughing <end>',\n",
              "  '<start> A girl in a yellow bathing suit laughs and points at a girl in an orange suit while another girls looks on . <end>',\n",
              "  '<start> Girl in bathing suit pointing and laughing at child in orange bathing bottoms while another girl looks on <end>',\n",
              "  '<start> The girl in yellow is laughing at the girl wearing orange whilst being watched by the girl in blue . <end>',\n",
              "  '<start> Three children in swimsuites are having fun outside near a white building . <end>'],\n",
              " 'Flicker8k_Dataset/3021318991_fa28e3bca7.jpg': ['<start> A female lawn hockey player hitting the ball <end>',\n",
              "  '<start> A girl in an orange uniform hits a ball in field hockey . <end>',\n",
              "  '<start> A girl in orange is hitting the ball in field hockey . <end>',\n",
              "  '<start> An athletic girl in an orange uniform is on a playing field of green grass and swinging at a ball . <end>',\n",
              "  '<start> A woman hockey player in an orange strip is striking the ball with her stick . <end>'],\n",
              " 'Flicker8k_Dataset/2720985888_8f5920e8cf.jpg': ['<start> A little girl laughs while playing in a play house . <end>',\n",
              "  '<start> A little girl with ponytails laughs near a plastic castle play set . <end>',\n",
              "  \"<start> a small girl playing in a little tikes' playground set . <end>\",\n",
              "  '<start> A smiling little blonde girl holds stands in a play structure and holds a green toy . <end>',\n",
              "  '<start> A young girl smiling in a plastic play structure . <end>'],\n",
              " 'Flicker8k_Dataset/428796930_476a3d6395.jpg': ['<start> A black dog is playing with a green toy in yellow grass . <end>',\n",
              "  '<start> a black dog is running with a green toy between its paws . <end>',\n",
              "  '<start> A black dog outside with a green toy . <end>',\n",
              "  '<start> A black dog playing with a green toy . <end>',\n",
              "  '<start> A black dog plays with a green object . <end>'],\n",
              " 'Flicker8k_Dataset/3621647714_fc67ab2617.jpg': ['<start> A man is standing on snow with trees and mountains all around him . <end>',\n",
              "  '<start> A man standing in snow with a mountain in the background <end>',\n",
              "  '<start> A man standing near a mountain range <end>',\n",
              "  '<start> A man stands on a snowy hill next to a mountain . <end>',\n",
              "  '<start> A man stands on snow and looks out at mountains and forests . <end>'],\n",
              " 'Flicker8k_Dataset/509200598_171a1ab6c8.jpg': ['<start> A black dog is looking down at another black dog lying on the grass . <end>',\n",
              "  '<start> Two big black dogs play with each other in the grass . <end>',\n",
              "  '<start> Two black dogs are frolicking around the grass together . <end>',\n",
              "  '<start> Two black dogs are playing on the grass . <end>',\n",
              "  '<start> two black dogs play together on a lawn <end>'],\n",
              " 'Flicker8k_Dataset/3607405494_0df89110a6.jpg': ['<start> Three black dogs wearing muzzles race through the green grass . <end>',\n",
              "  '<start> Three dogs leaping up in the air as they compete in a race . <end>',\n",
              "  '<start> Three dogs wearing vest are running on the green grass . <end>',\n",
              "  '<start> Three muzzled and numbered dogs running through the grass . <end>',\n",
              "  '<start> Three muzzled black dogs race through the grass . <end>'],\n",
              " 'Flicker8k_Dataset/3319586526_3994e9cd58.jpg': ['<start> A group of people wearing costumes jump as they walk down the street . <end>',\n",
              "  '<start> A group of silk clad performers dance in the street as a sparse crowd watches . <end>',\n",
              "  '<start> People in a parade wearing multi-colored clothes and dancing . <end>',\n",
              "  '<start> Street dancers in blue and red pants . <end>',\n",
              "  '<start> Two women in motley high kick at a parade . <end>'],\n",
              " 'Flicker8k_Dataset/2445783904_e6c38a3a3d.jpg': ['<start> A dog , nose to the ground , walks in a grassy field . <end>',\n",
              "  '<start> A dog with a red collar is walked on a field . <end>',\n",
              "  '<start> a grey dog walking on a leash in some grass <end>',\n",
              "  '<start> Brown dog on a leash is sniffing the ground in a field of grass . <end>',\n",
              "  '<start> The large brown dog with the red collar is in the grass . <end>'],\n",
              " 'Flicker8k_Dataset/488549693_a1f51d8c4a.jpg': ['<start> Two children are standing on the shore next to a body of water . <end>',\n",
              "  '<start> Two children standing at the edge of a river , holding a butterfly-catcher . <end>',\n",
              "  '<start> Two children stand with a net by a shallow shore . <end>',\n",
              "  '<start> two girls look into the water . <end>',\n",
              "  '<start> two kids playing on the beach , close to the water <end>'],\n",
              " 'Flicker8k_Dataset/2091171488_c8512fec76.jpg': ['<start> A female wearing pink gloves and a brown jacket is smiling in the snow . <end>',\n",
              "  '<start> A woman standing in the snow with people in the background . <end>',\n",
              "  '<start> A young woman in a spring coat and purple gloves stands in falling snow . <end>',\n",
              "  '<start> A young woman looks happy in winter clothes while it snows . <end>',\n",
              "  '<start> Young asian woman with pink gloves stands in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/2717686269_80c4b5ac9e.jpg': ['<start> A brown and white dog relaxes on a carpet in sunlight . <end>',\n",
              "  '<start> A brown dog resting on a red , white , and blue afghan rug . <end>',\n",
              "  '<start> A German short-haired pointer rests on a rug by a sunny window . <end>',\n",
              "  '<start> A small brown and white dog lines on a red area rug in a patch of sunlight . <end>',\n",
              "  '<start> Window shades cast light and shadow on a dog lying on a colorful carpet . <end>'],\n",
              " 'Flicker8k_Dataset/3120953244_b00b152246.jpg': ['<start> A boy blowing bubbles into the camera . <end>',\n",
              "  '<start> A little boy and a little girl are playing outside with bubbles . <end>',\n",
              "  '<start> A small boy blowing bubbles while a small girl stands behind him in the grass . <end>',\n",
              "  '<start> The girl has a passifier while the boy is making bubbles <end>',\n",
              "  '<start> Two small blonde children blowing bubbles in a park . <end>'],\n",
              " 'Flicker8k_Dataset/3170551725_1276644eab.jpg': ['<start> A person does a trick in the air on a skateboard . <end>',\n",
              "  '<start> A snowboarder is leaping a mogul . <end>',\n",
              "  '<start> There are two people on a ski run and one is high in the air making a jump . <end>',\n",
              "  '<start> There are two snowboarders , one , who is dressed in white , is doing a trick . <end>',\n",
              "  '<start> Three people are in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/2483993827_243894a4f9.jpg': ['<start> Three greyhounds are racing on a track at night . <end>',\n",
              "  '<start> Three lean , numbered , greyhounds race along a track . <end>',\n",
              "  '<start> Two Greyhounds racing at night <end>',\n",
              "  '<start> Two horses are right alongside each other in the race . <end>',\n",
              "  '<start> White , black , and brown greyhounds racing in numbered shirts . <end>'],\n",
              " 'Flicker8k_Dataset/3603064161_a8f3b6455d.jpg': ['<start> A child uses a camera as another child looks on . <end>',\n",
              "  '<start> A little girl is standing next to another little girl who is taking a photograph . <end>',\n",
              "  '<start> A small boy and small girl setting up a camera <end>',\n",
              "  '<start> Child taking a picture while sister leans on the wall . <end>',\n",
              "  '<start> One child behind a camera on a tripod with one child in a beige shirt and black shorts standing against the wall . <end>'],\n",
              " 'Flicker8k_Dataset/2171154778_8189169336.jpg': ['<start> A boy in dark blue clothes is kneeling while holding a toy . <end>',\n",
              "  '<start> A boy playing with toys in a bedroom . <end>',\n",
              "  '<start> A boy plays in his bedroom with an air powered rocket . <end>',\n",
              "  '<start> A boy plays with some toys in the house with a blue chair in the background . <end>',\n",
              "  '<start> a young boy wearing a blue outfit playing with a rocket . <end>'],\n",
              " 'Flicker8k_Dataset/3590557969_d0270d518b.jpg': ['<start> A man wearing no shirt and a hat jumps in the air on a red bicycle . <end>',\n",
              "  '<start> A man wearing no shirt does a trick on his red and black bicycle . <end>',\n",
              "  '<start> A man wearing very little clothing is doing a jump on a red bicycle . <end>',\n",
              "  '<start> A shirtless man jumping a bike in the woods . <end>',\n",
              "  '<start> A shirtless man jumps his bmx bike . <end>'],\n",
              " 'Flicker8k_Dataset/293151893_ee7249eccb.jpg': ['<start> A silhouette of one dog chasing another dog . <end>',\n",
              "  '<start> A silhouette of two dogs running by a lake . <end>',\n",
              "  '<start> Two dogs are silhouette as they chase each other along the water . <end>',\n",
              "  '<start> Two dogs running on land along the water . <end>',\n",
              "  '<start> Two dogs running on the shore . <end>'],\n",
              " 'Flicker8k_Dataset/2662816021_ac474e0fde.jpg': ['<start> A dog emerges form the water with a stick in its mouth . <end>',\n",
              "  '<start> A dog in a harness holds a stick in his mouth while standing in the water . <end>',\n",
              "  '<start> A dog retrieves a stick from a body of water . <end>',\n",
              "  '<start> A white dog holds a stick in its mouth as it comes out of the water . <end>',\n",
              "  '<start> The white dog is standing in the water with a stick in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/241346352_c5a0ea43c6.jpg': ['<start> A football player is kicking the ball while the opposing fans watch . <end>',\n",
              "  '<start> A football player kicks the ball during a game with a red shirted crowd looking on . <end>',\n",
              "  '<start> A male wearing a football uniform kicking a football during a football game . <end>',\n",
              "  '<start> A man punting a football as fans from the opposing team watch in the background <end>',\n",
              "  '<start> The Sooners play another football team , number 17 goes after the ball . <end>'],\n",
              " 'Flicker8k_Dataset/2354540393_a149722680.jpg': ['<start> A little girl is falling backwards onto a bed . <end>',\n",
              "  '<start> A young girl jumps on a bed . <end>',\n",
              "  '<start> The young girl is happily standing inside the house . <end>',\n",
              "  '<start> Two children play on the bed with a remote control . <end>',\n",
              "  '<start> Young blond girl in blue jeans falls back on bed while another child looks on . <end>'],\n",
              " 'Flicker8k_Dataset/3222496967_45d468ee66.jpg': ['<start> A blonde girl is laughing at a guy in front of her . <end>',\n",
              "  \"<start> A lady laughs at a man 's gestures . <end>\",\n",
              "  '<start> A pretty blonde haired woman is talking to a professionally dressed man on the sidewalk . <end>',\n",
              "  '<start> A woman with a newspaper is looking at a man with a side pack on a street sidewalk . <end>',\n",
              "  '<start> The blonde woman holding a newspaper is smiling at the man in the white shirt . <end>'],\n",
              " 'Flicker8k_Dataset/2546959333_23b957988f.jpg': ['<start> a dog nipping at the feet of a cow . <end>',\n",
              "  '<start> a dog pounces on the grass . <end>',\n",
              "  '<start> The dog is running after the bull . <end>',\n",
              "  '<start> The large brown dog is playing in the grass with a brown cow . <end>',\n",
              "  '<start> Two dogs outside on green grass . <end>'],\n",
              " 'Flicker8k_Dataset/1962729184_6996e128e7.jpg': ['<start> A girl kisses her mother goodbye before she waits with the other children to start school . <end>',\n",
              "  '<start> A group of children in blue clothes stand by a gate . <end>',\n",
              "  '<start> A group of students in uniform stand in front of the gate . <end>',\n",
              "  '<start> Crowd of people near the water . <end>',\n",
              "  '<start> Group of schoolchildren in uniforms standing at a gate , one kissing her mother goodbye . <end>'],\n",
              " 'Flicker8k_Dataset/2972929655_04233b5489.jpg': ['<start> The boys draw in the sand with sticks . <end>',\n",
              "  '<start> The children are playing in the sand at a rocky beach . <end>',\n",
              "  '<start> Two men draw in the wet sand of a beach . <end>',\n",
              "  '<start> Two men in black shorts are in the sand on the shoreline . <end>',\n",
              "  '<start> Two men writing in the sand on a rocky beach . <end>'],\n",
              " 'Flicker8k_Dataset/3671933270_d124e9a1a4.jpg': ['<start> A bicyclist is drinking out of a bottle of water while riding . <end>',\n",
              "  '<start> A biker takes a drink of water . <end>',\n",
              "  '<start> A cyclist drinks water . <end>',\n",
              "  '<start> A man riding a bicycle drinks from a bottle of water . <end>',\n",
              "  '<start> A person takes a drink of water while riding on a bike . <end>'],\n",
              " 'Flicker8k_Dataset/3294202771_e8ee78a439.jpg': ['<start> A guy in boarding shorts is trying to do a flip or handstand on the beach . <end>',\n",
              "  '<start> A man doing an acrobatic move on the seashore . <end>',\n",
              "  '<start> A man is doing a back flip on a beach in front of the ocean . <end>',\n",
              "  '<start> A man turning a somersault at the beach . <end>',\n",
              "  '<start> A shirtless man is doing a back flip on a beach . <end>'],\n",
              " 'Flicker8k_Dataset/2396746868_0727e06983.jpg': ['<start> A boy going down a small blue slide . <end>',\n",
              "  '<start> a kid sliding down a slide while another kid looks on <end>',\n",
              "  '<start> A little boy is going down a blue slide . <end>',\n",
              "  '<start> A little boy is watching another little boy ride on a blue slide . <end>',\n",
              "  '<start> Two little blonde boys play on a slide in the backyard . <end>'],\n",
              " 'Flicker8k_Dataset/2111360187_d2505437b7.jpg': ['<start> Three children covered in soap bubbles smile . <end>',\n",
              "  '<start> Three children in bathing suits are playing in foam <end>',\n",
              "  '<start> Three children standing by a pool are covered in foam bubbles . <end>',\n",
              "  '<start> three little boys cover themselves with bubbles . <end>',\n",
              "  '<start> Three young children are covered in foam . <end>'],\n",
              " 'Flicker8k_Dataset/3367053761_8ec5834bf3.jpg': ['<start> A girl with a bun is sitting at a desk . <end>',\n",
              "  '<start> Group of people , from behind , seated in a line of desks by windows in library . <end>',\n",
              "  '<start> People are sitting at desks in a library . <end>',\n",
              "  '<start> Person sitting at a desk in a library . <end>',\n",
              "  '<start> two people are sitting at desks by the windows in a library . <end>'],\n",
              " 'Flicker8k_Dataset/2081679622_6f1442367d.jpg': ['<start> A boy in grey pajamas is jumping on the couch . <end>',\n",
              "  '<start> A boy in pajama pants jumps on a red couch . <end>',\n",
              "  '<start> A boy smiles at the camera and jumps in the air over the couch . <end>',\n",
              "  '<start> a shirtless boy jumps onto the couch . <end>',\n",
              "  '<start> The boy in pajama pants jumps off the sofa . <end>'],\n",
              " 'Flicker8k_Dataset/2204550058_2707d92338.jpg': ['<start> A lady stands in the middle of a crowd wearing white gloves . <end>',\n",
              "  '<start> A woman tilts her face upward and lifts her white gloved hand <end>',\n",
              "  '<start> A woman wearing a white glove peers over the crowd . <end>',\n",
              "  '<start> A woman with a white glove and several others . <end>',\n",
              "  '<start> A woman with brown hair wearing white gloves . <end>'],\n",
              " 'Flicker8k_Dataset/3186527735_6e9fe2cf88.jpg': ['<start> A man and a woman in a silver coat are on a city sidewalk with their backs to the camera . <end>',\n",
              "  '<start> A woman walks with another person at night . <end>',\n",
              "  '<start> Couple waiting on sidewalk . <end>',\n",
              "  '<start> People are outside at night . <end>',\n",
              "  '<start> Two people outside looking to get a paper . <end>'],\n",
              " 'Flicker8k_Dataset/421932359_edbf181f44.jpg': ['<start> A black and white dog is running towards the viewer . <end>',\n",
              "  '<start> A brown and white dog is running across a brown field . <end>',\n",
              "  '<start> A dog running through a field towards a camera . <end>',\n",
              "  '<start> A dog with its ears up runs on brown grass . <end>',\n",
              "  '<start> A white dog running on dirt . <end>'],\n",
              " 'Flicker8k_Dataset/2474918824_88660c7757.jpg': ['<start> A guy tries to climb a stone cliff while his friend helps him . <end>',\n",
              "  '<start> A man in a red shirt climbs a rock while another man stands behind to help him . <end>',\n",
              "  '<start> A man in a red shirt is learning how to climb a cliff . <end>',\n",
              "  '<start> A man in brown is helping a man in red climb a rock . <end>',\n",
              "  '<start> A man wearing a brown sweatshirt helps a man in red climb a rock . <end>'],\n",
              " 'Flicker8k_Dataset/1419385780_1383ec7ba9.jpg': ['<start> a man wearing blue has a Mohawk <end>',\n",
              "  '<start> A man with a brown Mohawk and white shirt is wrapping his arm . <end>',\n",
              "  '<start> A man with gelled hair in a Mohawk style sitting in the shade . <end>',\n",
              "  '<start> The man has a large Mohawk and is sitting outside . <end>',\n",
              "  '<start> The man is tying a yellow ribbon on his wrist . <end>'],\n",
              " 'Flicker8k_Dataset/2712352554_1cafd32812.jpg': ['<start> A boy does a skateboard trick off a metal plank . <end>',\n",
              "  '<start> a guy with no shirt on is skateboarding . <end>',\n",
              "  '<start> A young man jumps in the air on a skateboard . <end>',\n",
              "  '<start> Skateboarder on a rail . <end>',\n",
              "  '<start> Skater does a trick on a rail . <end>'],\n",
              " 'Flicker8k_Dataset/3711826708_bba64fb1e1.jpg': ['<start> A brown dog is walking on a wooded path with white flowers . <end>',\n",
              "  '<start> A corgi is walking down a path in a forest . <end>',\n",
              "  '<start> A dog is running through a very wooded area with large white flowers . <end>',\n",
              "  '<start> A dog is walking through an area of heavy foliage along a dirt path . <end>',\n",
              "  '<start> a dog runs across the path . <end>'],\n",
              " 'Flicker8k_Dataset/2817847072_5eb3bc30ac.jpg': ['<start> A boy in a soccer uniform running in a field during a game . <end>',\n",
              "  '<start> A boy in a soccer uniform running on a field <end>',\n",
              "  '<start> A boy in green and white looks alert during a soccer game . <end>',\n",
              "  '<start> A soccer player is running on the field <end>',\n",
              "  '<start> A soccer player running on the field . <end>'],\n",
              " 'Flicker8k_Dataset/2110898123_07729c1461.jpg': ['<start> A brown dog wearing a red vest is running in the grass . <end>',\n",
              "  '<start> A brown dog wearing a red vest is running through the grass . <end>',\n",
              "  '<start> a dog sprints across the grass . <end>',\n",
              "  '<start> A dog wearing a red cape runs quickly across a field . <end>',\n",
              "  '<start> The brown dog is running on the grass whilst wearing an orange jacket . <end>'],\n",
              " 'Flicker8k_Dataset/3540416139_c884f38351.jpg': ['<start> A dog chases a toy in the grass with its owner in the background . <end>',\n",
              "  '<start> A dog chases a white animal on a green lawn . <end>',\n",
              "  '<start> A dog playing outside in the grass . <end>',\n",
              "  '<start> A golden dog is running across the grass chasing a white toy on the ground . <end>',\n",
              "  '<start> The brown dog is running outside on the grass . <end>'],\n",
              " 'Flicker8k_Dataset/381052465_722e00807b.jpg': ['<start> a firetruck fights a fire . <end>',\n",
              "  '<start> a yellow firetruck is parked next to a fire with a man on a ladder pouring water on it <end>',\n",
              "  '<start> Firefighters putting out a big fire . <end>',\n",
              "  '<start> Fireman fighting a fire . <end>',\n",
              "  '<start> People putting out a fire . <end>'],\n",
              " 'Flicker8k_Dataset/3356369156_074750c6cc.jpg': ['<start> A blue boat with a yellow canopy is floating on calm waters . <end>',\n",
              "  '<start> A boat in the water . <end>',\n",
              "  '<start> A boat with a roof on green water . <end>',\n",
              "  '<start> The boat is in the middle of the water . <end>',\n",
              "  '<start> The solitude boat floats on the lake . <end>'],\n",
              " 'Flicker8k_Dataset/3685373706_37f2ced9ff.jpg': ['<start> A man is shirtless and is covered in red marks . <end>',\n",
              "  '<start> A man with several red marks on his body is holding a flag while people in the background are cheering <end>',\n",
              "  '<start> A shirtless man covered in red lipstick kisses waving a blue flag . <end>',\n",
              "  '<start> A shirtless man waaves a flag . <end>',\n",
              "  '<start> A shirtless man with red paint on his torso holding a stick . <end>'],\n",
              " 'Flicker8k_Dataset/3468130925_2b1489d19a.jpg': ['<start> One man in a rugby uniform is grabbing the arm of another man holding a football . <end>',\n",
              "  '<start> The rugby player in the black strip is trying to keep the player in red and yellow from taking the ball . <end>',\n",
              "  '<start> The rugby players play on a field . <end>',\n",
              "  '<start> Two men are playing rugby . <end>',\n",
              "  '<start> Two men on a playing field , one of them holding a football . <end>'],\n",
              " 'Flicker8k_Dataset/3066491113_86569e15be.jpg': ['<start> a black dog is following a brown dog that is carrying a brown plate through a grassy field . <end>',\n",
              "  '<start> A black dog following a tan dog fetching a large shallow bowl . <end>',\n",
              "  '<start> A brown dog carrying a Frisbee like object in its mouth <end>',\n",
              "  '<start> A dog runs with a large plate in its mouth . <end>',\n",
              "  '<start> Two dogs , one carrying a large dish in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/3288174272_2daa06d360.jpg': ['<start> Africans gather water at an outdoor tap . <end>',\n",
              "  '<start> Africans wearing colorful clothing gather behind a fence . <end>',\n",
              "  '<start> A tribal group filling water jugs in the desert . <end>',\n",
              "  '<start> People filling a large black container with water . <end>',\n",
              "  '<start> Women of African origin are colecting water at common water tap , near wire fence . <end>'],\n",
              " 'Flicker8k_Dataset/3484576025_a8c50942aa.jpg': ['<start> A dog is running through an obstacle course <end>',\n",
              "  '<start> A dog jumps over a jump . <end>',\n",
              "  '<start> A small dog jumps over a bar with its toy , awards are on the bar . <end>',\n",
              "  '<start> A small dog with a toy in its mouth is jumping over a pole . <end>',\n",
              "  '<start> Dog with toy in mouth jumps over bar decorated with prize ribbons . <end>'],\n",
              " 'Flicker8k_Dataset/3091916691_b1c96669c6.jpg': ['<start> A man in a bright pink shirt shakes the hand of a bearded man in a saffron shirt . <end>',\n",
              "  '<start> A man in a pink shirt stands next to a man in orange . <end>',\n",
              "  '<start> Three men stand around in bright solid colored shirts and colorful hats . <end>',\n",
              "  '<start> Three smiling men in brightly-colored shirts . <end>',\n",
              "  '<start> Two men shaking hands and smiling at the camera , while a third man stands behind them . <end>'],\n",
              " 'Flicker8k_Dataset/883040210_3c4a10f030.jpg': ['<start> A climber is sillhouetted against the sky and rocks as he hangs by a rope from another rock . <end>',\n",
              "  '<start> A person hangs from a safety rope as he climbs down a large cliff . <end>',\n",
              "  '<start> A person is abseiling down a rock face attached to a rope . <end>',\n",
              "  '<start> A person jumping down a rope on a cliff . <end>',\n",
              "  '<start> The man repels down the side of a cliff . <end>'],\n",
              " 'Flicker8k_Dataset/3356284586_21c6f155a5.jpg': ['<start> An Asian girl is standing in a crowd wearing red lipstick . <end>',\n",
              "  '<start> an asian woman holds her fur scarf . <end>',\n",
              "  '<start> Asian woman in traditional dress and white fur collar <end>',\n",
              "  '<start> A woman dressed in elegant clothing is looking down while inside a crowd of people . <end>',\n",
              "  '<start> Girl wears white feather boa and kimono . <end>'],\n",
              " 'Flicker8k_Dataset/3534668485_6887629ff0.jpg': ['<start> A woman in white and woman in black are standing by each other talking on cellphones . <end>',\n",
              "  '<start> These two girls in a booth are talking on cellphones . <end>',\n",
              "  '<start> two girls , one in black and one in white are talking on cellphones in front a wall covered in music posters . <end>',\n",
              "  '<start> Two women are talking each on a cellphone while walking <end>',\n",
              "  '<start> Two women talking on cellphones , with posters behind them . <end>'],\n",
              " 'Flicker8k_Dataset/2832453252_a06f7826a8.jpg': ['<start> Four children are playing in some water . <end>',\n",
              "  '<start> Four young girls playing in the water . <end>',\n",
              "  '<start> Kids play in water . <end>',\n",
              "  '<start> Little girls play in the water . <end>',\n",
              "  '<start> Young girls in bathing suits playing in the knee deep water beyond the blue railing . <end>'],\n",
              " 'Flicker8k_Dataset/403678611_73978faed7.jpg': ['<start> A man in a cap with a goatee leans against the window and reads a magazine . <end>',\n",
              "  '<start> A man sitting on an empty train <end>',\n",
              "  '<start> A man with a black hat and black beard is reading a magazine sitting on a blue bench . <end>',\n",
              "  '<start> A man with a hat sits in a booth and reads . <end>',\n",
              "  '<start> The man reading a magazine is sitting in the large room . <end>'],\n",
              " 'Flicker8k_Dataset/3585123310_9a8e94bd2b.jpg': ['<start> The white puppies are playing on a couch with a baby bottle . <end>',\n",
              "  '<start> Three puppies are lying on a couch beside a baby bottle . <end>',\n",
              "  '<start> Three puppies laying on a couch with a bottle of milk , one with its mouth wide open . <end>',\n",
              "  '<start> Three puppies on a couch next to a bottle of milk . <end>',\n",
              "  '<start> Three puppies play on a couch . <end>'],\n",
              " 'Flicker8k_Dataset/1731546544_9fbf14617b.jpg': ['<start> a black dog jumping through some water <end>',\n",
              "  '<start> A black dog leaps out of the water . <end>',\n",
              "  '<start> a black dog runs through the water . <end>',\n",
              "  '<start> A black dog splashes in the water . <end>',\n",
              "  '<start> A large black dog is playing in the ocean . <end>'],\n",
              " 'Flicker8k_Dataset/3335997221_254366c400.jpg': ['<start> A group of dressed-up people talking . <end>',\n",
              "  '<start> a group of five young people all dressed in black in a dimlight room <end>',\n",
              "  '<start> A total of five people in black clothes are having conversations in a plain white room . <end>',\n",
              "  '<start> Three men and two women talking . <end>',\n",
              "  '<start> Two groups of people dressed in black clothes and with brown hair , except for one blonde woman , hold separate conversations . <end>'],\n",
              " 'Flicker8k_Dataset/1434607942_da5432c28c.jpg': [\"<start> A child rides on a man 's shoulders . <end>\",\n",
              "  \"<start> A child wearing a red jacket is sitting on the man 's shoulders . <end>\",\n",
              "  '<start> A man carrying a girl on his shoulders . <end>',\n",
              "  \"<start> A small child in a red jacket is sitting on a man 's shoulders and holding his head . <end>\",\n",
              "  '<start> A white man with carrying hair and a beard with a child on his shoulders . <end>'],\n",
              " 'Flicker8k_Dataset/3478084305_9e1219c3b6.jpg': ['<start> A boy jumps off a short wall with his arms out . <end>',\n",
              "  '<start> A dark haired boy in sunglasses is jumping . <end>',\n",
              "  '<start> a little boy jumps off a yellow railling . <end>',\n",
              "  '<start> A young boy is jumping in the air in front of a concrete wall . <end>',\n",
              "  '<start> The boy is wearing blue sunglasses and jumping by a yellow rail . <end>'],\n",
              " 'Flicker8k_Dataset/1874617189_e85d3f4326.jpg': ['<start> The three people are squatting by the water . <end>',\n",
              "  '<start> Three children bend over to look at the waters edge at a lake . <end>',\n",
              "  '<start> Three kids lean into the water edge wearing bright pants . <end>',\n",
              "  '<start> Three kids squat down and look at the ground on the shore of a lake . <end>',\n",
              "  '<start> Three people squat down on the edge of a lake . <end>'],\n",
              " 'Flicker8k_Dataset/548751378_c657401312.jpg': ['<start> A child in yellow overalls is walking over packed dirt . <end>',\n",
              "  '<start> A child without a shirt running in the dirt . <end>',\n",
              "  '<start> A little boy in overalls runs fast on a dirt trail . <end>',\n",
              "  '<start> A small child in overalls running . <end>',\n",
              "  '<start> A toddler is running down the path with an orange toy in his hand . <end>'],\n",
              " 'Flicker8k_Dataset/495340319_705f2e63d6.jpg': ['<start> Boys playing tag football run down the field . <end>',\n",
              "  '<start> One kid is chasing another kid who is holding a football . <end>',\n",
              "  '<start> One kid is running across a field carrying a football while another is close behind grabbing for his flags . <end>',\n",
              "  '<start> Two children playing tag football . <end>',\n",
              "  '<start> Two little boys play football on green grass . <end>'],\n",
              " 'Flicker8k_Dataset/2766926202_4201bf2bf9.jpg': ['<start> Two children playing with fireworks in shallow water <end>',\n",
              "  '<start> Two children wearing glow necklaces play with sparklers while standing in water . <end>',\n",
              "  '<start> Two men are playing with glow sticks and sparklers . <end>',\n",
              "  '<start> Two men play with fireworks on the beach . <end>',\n",
              "  '<start> Two people are standing in shallow water , waving sparklers around <end>'],\n",
              " 'Flicker8k_Dataset/3582048078_7bac2d8473.jpg': ['<start> A boy coming out of the pool . <end>',\n",
              "  '<start> A man and a boy are in the swimming pool . <end>',\n",
              "  '<start> Father and son swimming . <end>',\n",
              "  '<start> Man and boy are swimming in a pool . <end>',\n",
              "  '<start> The man and child are swimming . <end>'],\n",
              " 'Flicker8k_Dataset/299676757_571ee47280.jpg': ['<start> A redheaded woman looks behind her in a European courtyard . <end>',\n",
              "  '<start> a woman stamds in the middle of a brick road . <end>',\n",
              "  '<start> A woman with orange shoes stops in a square . <end>',\n",
              "  '<start> Lady in dark top , pring skirt , red socks and shoes walking . <end>',\n",
              "  '<start> Woman in long skirt in a town square . <end>'],\n",
              " 'Flicker8k_Dataset/3194134352_bc1b2a25d7.jpg': ['<start> A blond boy wipes his nose on his light blue shirt . <end>',\n",
              "  '<start> a blond boy wiping his nose on his blue shirt <end>',\n",
              "  '<start> A little boy wipes his nose with his blue shirt . <end>',\n",
              "  '<start> Blond boy wiping his face with his blue shirt . <end>',\n",
              "  '<start> The small boy is using his blue shirt to wipe his face , exposing his belly . <end>'],\n",
              " 'Flicker8k_Dataset/3266406566_d64e57e65a.jpg': ['<start> A black woman and two black children are sitting in a thatched tent . <end>',\n",
              "  '<start> A woman and two kids sit in a straw hut with a blue blanket on the floor . <end>',\n",
              "  '<start> Three African children sitting in a bamboo tent . <end>',\n",
              "  '<start> Three young children are sitting on the floor of a grass hut . <end>',\n",
              "  '<start> Two children and one young woman inside a straw hut , looking outwards . <end>'],\n",
              " 'Flicker8k_Dataset/3601803640_5f3cb05acf.jpg': ['<start> A man and a woman kissing . <end>',\n",
              "  '<start> A man and woman kissing in front of a crowd of people . <end>',\n",
              "  '<start> a man is kissing a woman . <end>',\n",
              "  '<start> A young couple kiss while a crowd mills in the background on a sunny day . <end>',\n",
              "  '<start> Two people kiss near a crowd . <end>'],\n",
              " 'Flicker8k_Dataset/3080891382_edf83dde18.jpg': ['<start> A child covers their mouth as they whisper to a friend . <end>',\n",
              "  '<start> A child in green winter clothes is holding his or her hand up while two other children look at him or her . <end>',\n",
              "  '<start> Three children , dressed in heavy coats , gloves , and knit caps , cover their mouths . <end>',\n",
              "  '<start> Two children stand and whisper to each other as another looks on . <end>',\n",
              "  '<start> two young children wearing wool caps and mitten covering their mouths while whispering to each other . <end>'],\n",
              " 'Flicker8k_Dataset/2418191216_82711d5c5c.jpg': ['<start> An older woman in hiking clothing and a summer hat smiles . <end>',\n",
              "  '<start> An old lady wearing a hat and smiling . <end>',\n",
              "  '<start> A woman in a sunhat is wearing sunglasses and laughing . <end>',\n",
              "  '<start> A woman with a hat , sunglasses and a backpack walks outdoors . <end>',\n",
              "  '<start> Women in hat and sunglasses smiles . <end>'],\n",
              " 'Flicker8k_Dataset/2330843604_b8d75d6ac7.jpg': ['<start> A blond child jumping rope on a sidewalk . <end>',\n",
              "  '<start> A girl jumping rope on a sidewalk near a parking garage . <end>',\n",
              "  '<start> A girl jumping rope on a sidewalk with a parking garage to the left . <end>',\n",
              "  '<start> A girl jumps rope on a sidewalk . <end>',\n",
              "  '<start> A small girl jumping rope . <end>'],\n",
              " 'Flicker8k_Dataset/3171066023_ec60ba30f3.jpg': ['<start> A downhill skier races near trees . <end>',\n",
              "  '<start> A person skis down a snowy and tree-filled hill . <end>',\n",
              "  '<start> A person skis down a forested hill . <end>',\n",
              "  '<start> A person skis through a forest of tall trees . <end>',\n",
              "  '<start> A skier is riding skis along a tree lined trail . <end>'],\n",
              " 'Flicker8k_Dataset/3330102093_1d6e35e78d.jpg': ['<start> A cyclist in a midair jump . <end>',\n",
              "  '<start> A man on a bike in the air he is wearing a blue hsirt and a yellow and white helmet . <end>',\n",
              "  '<start> A person has ridden their bicycle into the air . <end>',\n",
              "  '<start> A person riding a bike jumps through the air high above a bumpy racetrack . <end>',\n",
              "  '<start> Someone riding a bicycle is up in the air over a dirt and hill trail . <end>'],\n",
              " 'Flicker8k_Dataset/551664516_78a5131dc4.jpg': ['<start> A woman in a black jacket and black and white skirt walks down the street . <end>',\n",
              "  '<start> A woman in a dark jacket and black and white skirt walks down the street . <end>',\n",
              "  '<start> A woman wearing black and white crossing a road . <end>',\n",
              "  '<start> a woman with a bag around her standing in the street <end>',\n",
              "  '<start> woman in black and sunglasses standing in road <end>'],\n",
              " 'Flicker8k_Dataset/2860872588_f2c7b30e1a.jpg': ['<start> A black and a blonde dog are either playing or fighting with each other . <end>',\n",
              "  '<start> A white and a black dog fighting in a fenced in room . <end>',\n",
              "  '<start> Two dogs are jumping up at each other . <end>',\n",
              "  '<start> Two dogs fighting , one is black , the other beige . <end>',\n",
              "  '<start> Two dogs in a kennel on their hind legs facing one another . <end>'],\n",
              " 'Flicker8k_Dataset/2861100960_457ceda7fa.jpg': ['<start> A man wearing a straw hat smokes a cigarette . <end>',\n",
              "  '<start> A man with a straw hat is smoking a cigarette with a crowd nearby . <end>',\n",
              "  '<start> The man in the straw hat is smoking a cigarette . <end>',\n",
              "  '<start> The man in the straw hat smokes a cigarette . <end>',\n",
              "  '<start> The man is wearing a straw hat and smoking a cigarette . <end>'],\n",
              " 'Flicker8k_Dataset/3557295488_600d387347.jpg': ['<start> A lacross player hitting an oppenents stick . <end>',\n",
              "  '<start> A man in a red and white jersey is hitting a man in a blue and white jersey during a field hockey game . <end>',\n",
              "  '<start> A man in a red uniform swings while another in a blue uniform jumps and others look on . <end>',\n",
              "  '<start> Two field hockey players collide . <end>',\n",
              "  '<start> Two men attempt to hit a ball on a sports field with their team members standing by . <end>'],\n",
              " 'Flicker8k_Dataset/1352398363_9cc8ffcce9.jpg': ['<start> A boy is covered with marker . <end>',\n",
              "  '<start> A dirty child plays in the house <end>',\n",
              "  '<start> A small boy wearing a diaper stands near the door and is covered in marker . <end>',\n",
              "  '<start> A young boy covered in ink stands in front of a white door . <end>',\n",
              "  '<start> A young boy in a pullup is covered in marker ink . <end>'],\n",
              " 'Flicker8k_Dataset/3549006919_3604bc813e.jpg': ['<start> A man in a yellow helmet climbs up a rock cliff . <end>',\n",
              "  '<start> a man wearing a yellow helmet climbing the side of a large rock wall . <end>',\n",
              "  '<start> A man wearing a yellow helmet tries to climb a rock with his hands . <end>',\n",
              "  '<start> A mountain climber reaches the top of a cliff . <end>',\n",
              "  '<start> A person wearing a yellow helmet is climbing a cliff . <end>'],\n",
              " 'Flicker8k_Dataset/3154152744_4e93ec8a62.jpg': ['<start> two black dogs playing fetch with a red toy <end>',\n",
              "  \"<start> Two black dogs run through the snow with a red toy in one dog 's mouth . <end>\",\n",
              "  '<start> Two dogs are chewing at a red object whilst running in the snow . <end>',\n",
              "  '<start> Two dogs fighting over a toy in the snow . <end>',\n",
              "  '<start> Two dogs playing together in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/1473618073_7db56a5237.jpg': ['<start> A boy on a green plastic swing . <end>',\n",
              "  '<start> A little boy sitting on a green swing . <end>',\n",
              "  '<start> A smiling boy plays on a green plastic swing-toy . <end>',\n",
              "  '<start> Boy swinging on a swing set . <end>',\n",
              "  '<start> Little boy riding on green swing in a playground . <end>'],\n",
              " 'Flicker8k_Dataset/2201192417_d934730fea.jpg': ['<start> a boy runs through the grass . <end>',\n",
              "  '<start> A child in a green and white sports uniform is running over grass . <end>',\n",
              "  '<start> A little boy in a green soccer uniform is running on the grass . <end>',\n",
              "  '<start> A little boy wearing a green soccer strip is running on the grass . <end>',\n",
              "  '<start> Boy wearing a green and white soccer uniform running through the grass . <end>'],\n",
              " 'Flicker8k_Dataset/2999638340_75bc8b165d.jpg': ['<start> A brown dog is laying in the snow . <end>',\n",
              "  '<start> A brown dog is laying on snow . <end>',\n",
              "  '<start> A brown dog lays in the snow while posing for a picture . <end>',\n",
              "  '<start> A brown dog playing in the snow . <end>',\n",
              "  '<start> a tan dog is sitting in some snow <end>'],\n",
              " 'Flicker8k_Dataset/3526431764_056d2c61dc.jpg': ['<start> A woman taking a photo standing next to a tall man and in front of another man who is also taking a photo . <end>',\n",
              "  '<start> Three people are outdoors taking pictures . <end>',\n",
              "  '<start> Three people holding cameras are standing on a dirt trail with grass on the side of it . <end>',\n",
              "  '<start> Three people taking pictures with their cameras <end>',\n",
              "  '<start> Two people are taking pictures while a third is holding a camera . <end>'],\n",
              " 'Flicker8k_Dataset/2318721455_80c6644441.jpg': ['<start> A boy in a diaper jumping onto a couch . <end>',\n",
              "  '<start> A boy in a diaper jumps onto a bed with a striped covering and red pillow in a room with toys and a chair . <end>',\n",
              "  '<start> A child jumps onto a bed . <end>',\n",
              "  '<start> A child leaping onto a bed in a room with toys on the floor . <end>',\n",
              "  '<start> Young boy jumping on to his bed . <end>'],\n",
              " 'Flicker8k_Dataset/1540631615_8b42c1b160.jpg': ['<start> A boy in a red jacket does a gymnastic maneuver on a grassy athletic field . <end>',\n",
              "  '<start> A child in a red jacket doing a handstand on green grass . <end>',\n",
              "  '<start> A little boy in red doing a handstand . <end>',\n",
              "  '<start> Boy wearing a red jacket performs a handstand on the grass . <end>',\n",
              "  '<start> Young boy in red jacket doing a handstand on a sports field . <end>'],\n",
              " 'Flicker8k_Dataset/2251418114_2b0cd4c139.jpg': ['<start> A boy stands on a rocky mountain . <end>',\n",
              "  '<start> A child on a rock formation . <end>',\n",
              "  '<start> A child sitting on a rock formation . <end>',\n",
              "  '<start> a little boy sitts on top of a big rock . <end>',\n",
              "  '<start> A person in a red jacket on top of rocks . <end>'],\n",
              " 'Flicker8k_Dataset/2708634088_a4686be24c.jpg': ['<start> two brown dogs one with a stick in its mouth <end>',\n",
              "  '<start> Two dogs are running side by side through long grass . <end>',\n",
              "  '<start> Two large black and brown dogs run through the tall grass . <end>',\n",
              "  '<start> Two large dogs bound through a field . <end>',\n",
              "  '<start> Two tall black dogs run through tall grass . <end>'],\n",
              " 'Flicker8k_Dataset/3679707139_1cc1e71237.jpg': ['<start> A brown dog is running through the ocean . <end>',\n",
              "  '<start> A brown dog swimming through murky water . <end>',\n",
              "  '<start> A brown dog with a silver collar runs through shallow water . <end>',\n",
              "  '<start> A small brown dog swims in the water . <end>',\n",
              "  '<start> The dog is swimming across the water . <end>'],\n",
              " 'Flicker8k_Dataset/3192311620_99bda27fbd.jpg': ['<start> A brown dog is about to catch a treat . <end>',\n",
              "  '<start> A brown dog opens his mouth to catch a piece of food . <end>',\n",
              "  '<start> A dog is about to catch a treat in his mouth . <end>',\n",
              "  '<start> A dog opens its mouth to catch a treat <end>',\n",
              "  '<start> The dog is catching a treat . <end>'],\n",
              " 'Flicker8k_Dataset/3368207495_1e2dbd6d3f.jpg': ['<start> A dog is leaping for a tennis ball . <end>',\n",
              "  '<start> A dog leaps in the air parallel to a tennis ball . <end>',\n",
              "  '<start> A dog leaps in the air while chasing a tennis ball . <end>',\n",
              "  '<start> Two dogs chasing a ball . <end>',\n",
              "  '<start> Two dogs in a field are running to catch a tennis ball . <end>'],\n",
              " 'Flicker8k_Dataset/3210419174_d083a16f77.jpg': ['<start> A group of young people smile for the camera . <end>',\n",
              "  '<start> Several people are hugging each other inside a bar . <end>',\n",
              "  '<start> some people at a part gather to take a picture <end>',\n",
              "  '<start> Two guys pose with two women , everyone is wearing black and white . <end>',\n",
              "  '<start> Two women of African descent , a dark skinned man and western man in a white shirt posing for a photograph . <end>'],\n",
              " 'Flicker8k_Dataset/1801188148_a176954965.jpg': ['<start> A brown dog is running towards three other dogs . <end>',\n",
              "  '<start> Four dogs are running around in the grass . <end>',\n",
              "  '<start> Four dogs of varying breeds running through a field . <end>',\n",
              "  '<start> Four dogs playing in a field <end>',\n",
              "  '<start> Four dogs play together on a grassy and leafy ground . <end>'],\n",
              " 'Flicker8k_Dataset/3420323191_d66e003264.jpg': ['<start> A man in a red kayak . <end>',\n",
              "  '<start> a man in a red kayak pedalling through a wave <end>',\n",
              "  '<start> A man is kayaking in the ocean on an orange kayak . <end>',\n",
              "  '<start> A person in a kayak rides waves in the ocean . <end>',\n",
              "  '<start> The male kayaker is moving through the rough water . <end>'],\n",
              " 'Flicker8k_Dataset/387830531_e89c192b92.jpg': ['<start> a brown dog about to jump on a smaller black and tan dog <end>',\n",
              "  '<start> Large dog playing with smaller dog <end>',\n",
              "  '<start> Two dogs are playing together outside . <end>',\n",
              "  '<start> Two dogs playing in the grass with an adult nearby . <end>',\n",
              "  '<start> Two dogs playing with each other . <end>'],\n",
              " 'Flicker8k_Dataset/2312984882_bec7849e09.jpg': ['<start> A drummer and three saxophones players outside a storefront . <end>',\n",
              "  '<start> A small band of guys are playing their saxophones and one man is playing the drums with buckets . <end>',\n",
              "  '<start> Four people play instruments on the sidewalk . <end>',\n",
              "  '<start> Three guys play saxophone while another drums on buckets . <end>',\n",
              "  '<start> Three men play saxophones while one man play makeshift drum on a corner <end>'],\n",
              " 'Flicker8k_Dataset/519059913_4906fe4050.jpg': ['<start> A boy doing a back flip into a swimming pool . <end>',\n",
              "  '<start> A boy falling headfirst into a pool <end>',\n",
              "  '<start> A boy wearing red and blue swim trunks jumping headfirst into a swimming pool . <end>',\n",
              "  '<start> A brown-haired boy in swim trunks is flipped backwards over a swimming pool . <end>',\n",
              "  '<start> A young boy jumping upside-down into a pool . <end>'],\n",
              " 'Flicker8k_Dataset/2174206711_11cb712a8d.jpg': ['<start> Two Asian cheerleaders are facing forward waving silver pom-poms , whilst other cheerleaders are performing facing the other way . <end>',\n",
              "  '<start> Two asian cheerleaders are holding out silver pompoms . <end>',\n",
              "  '<start> Two asian girls cheerleading for a sporting event <end>',\n",
              "  '<start> Two girls dressed in light brown wearing black neckties hold foil pom poms while doing a routine with others . <end>',\n",
              "  '<start> Two young girl cheerleaders wearing a khaki shirt with a black tie cheering . <end>'],\n",
              " 'Flicker8k_Dataset/535399240_0714a6e950.jpg': ['<start> A boy and a girl are riding in a red seat on a fairground ride . <end>',\n",
              "  '<start> A girl and a boy enjoy a fast amusement ride . <end>',\n",
              "  '<start> A young girl and boy on a ride at an amusement park . <end>',\n",
              "  '<start> Two children ride in a red seat on a fair ride and smile . <end>',\n",
              "  '<start> Two kids are on a fair ride and are slipping to one side of the car . <end>'],\n",
              " 'Flicker8k_Dataset/3520922312_e58a6cfd9c.jpg': ['<start> A couple walking down the street . <end>',\n",
              "  '<start> A man and a woman walk in across a courtyard with black messenger bags on their shoulders . <end>',\n",
              "  '<start> A man and woman walk hand-in-hand surrounded by large trees . <end>',\n",
              "  '<start> a young couple both wearing white shirts and blue jeans walking down a wooden pier . <end>',\n",
              "  '<start> Two people carrying bags walk together . <end>'],\n",
              " 'Flicker8k_Dataset/3285214689_f0219e9671.jpg': ['<start> A basketball player jumps to make the shot while another tries to stop him . <end>',\n",
              "  '<start> Man in blue sport uniform with basketball in right hand attempting to score basket while being blocked by player in white uniform . <end>',\n",
              "  '<start> The basketball player in white is defending the basket against the player wearing blue . <end>',\n",
              "  '<start> Two basketball players oppose each other at the net . <end>',\n",
              "  '<start> Two men are playing basketball and one is trying to block the others shot . <end>'],\n",
              " 'Flicker8k_Dataset/3683644335_b70bed1d83.jpg': ['<start> a girl is swimming in a clear water in a blue pool . <end>',\n",
              "  '<start> A girl swims through clear blue water . <end>',\n",
              "  '<start> A person is swimming underwater in a pool . <end>',\n",
              "  '<start> A person swimming underwater in a swimming pool . <end>',\n",
              "  '<start> A picture of somebody under blue water . <end>'],\n",
              " 'Flicker8k_Dataset/1517807181_ca6588f2a0.jpg': ['<start> Two children are playing with a kite out in wide open countryside . <end>',\n",
              "  '<start> Two children running in a field . <end>',\n",
              "  '<start> Two children running in a field with a kite there is a fence in the background and mountains <end>',\n",
              "  '<start> two young girls fly a kite . <end>',\n",
              "  '<start> Two young girls run across a field as they fly a kite in the cloud-covered sky . <end>'],\n",
              " 'Flicker8k_Dataset/3690425778_3b390b3ea5.jpg': ['<start> A man jumps off of a dock and into the water . <end>',\n",
              "  '<start> A person jumping off a dock into water . <end>',\n",
              "  '<start> Person jumping into the water . <end>',\n",
              "  '<start> The boy jumps into the water off of a dock . <end>',\n",
              "  '<start> The person wearing shorts and a shirt is jumping off a dock , into the water . <end>'],\n",
              " 'Flicker8k_Dataset/2905948395_ca3e6b3c9a.jpg': ['<start> a lone bicyclist jumping in the air over a ramp . <end>',\n",
              "  '<start> A man does bike jumps in the dark in an empty pool . <end>',\n",
              "  '<start> A man is doing a trick on his bike in a skatepark . <end>',\n",
              "  '<start> A person doing a leap with his bike over a hill <end>',\n",
              "  '<start> A person on a bike in the air over a ramp . <end>'],\n",
              " 'Flicker8k_Dataset/2701487024_e866eb4550.jpg': ['<start> A boy plays in the ocean with a boogie board . <end>',\n",
              "  '<start> An excited boy playing in the surf with a body board . <end>',\n",
              "  '<start> A smiling young boy wearing a bathing suit is holding a surfboard and laying down in the ocean water . <end>',\n",
              "  '<start> A young boy holds his boogie board in shallow ocean water . <end>',\n",
              "  '<start> A young boy with a blue body board . <end>'],\n",
              " 'Flicker8k_Dataset/3627676364_1dc9294ec5.jpg': ['<start> A crowd of people are walking down a city street . <end>',\n",
              "  '<start> A group a people walk around the corner near a brick building . <end>',\n",
              "  '<start> A group of people stands in front of a yellow building . <end>',\n",
              "  '<start> People gather together outdoors . <end>',\n",
              "  '<start> The people walk near a brick building . <end>'],\n",
              " 'Flicker8k_Dataset/2252635585_b48b3485b0.jpg': ['<start> Two big dogs play in the snow under a tree . <end>',\n",
              "  '<start> Two dogs are playing in the snow next to a tree . <end>',\n",
              "  '<start> Two dogs are playing with a tennis ball in snow near a tree . <end>',\n",
              "  '<start> Two dogs play in the snow on the ground near a tree , with one on top of the other . <end>',\n",
              "  '<start> Two dogs tussle in the snow over a tennis ball . <end>'],\n",
              " 'Flicker8k_Dataset/278608022_4175813019.jpg': ['<start> A girl , in a green field , plays soccer . <end>',\n",
              "  '<start> A girl is about to kick a soccer ball in the grass . <end>',\n",
              "  '<start> A girl prepares to kick a soccer ball while a boy looks on . <end>',\n",
              "  '<start> A male watches a young female playing soccer . <end>',\n",
              "  '<start> Two kids playing soccer in a field . <end>'],\n",
              " 'Flicker8k_Dataset/449287870_f17fb825d7.jpg': ['<start> A female toddler wearing a pink shirt is playing on a playground . <end>',\n",
              "  '<start> A little girl in pink and purple stands on a playground . <end>',\n",
              "  '<start> A very young girl is walking on a playground . <end>',\n",
              "  '<start> The little girl is playing at the playground . <end>',\n",
              "  '<start> Young child in pink top and purple pants clutching a turquoise guard rail . <end>'],\n",
              " 'Flicker8k_Dataset/2822891602_ff61df2ece.jpg': ['<start> A boy in an orange snorkel mask swims underwater . <end>',\n",
              "  '<start> A kid is diving underwater while wearing swim gear and orange goggles . <end>',\n",
              "  '<start> Boy swims underwater with orange mask on . <end>',\n",
              "  '<start> The boy in red goggles swims underwater . <end>',\n",
              "  '<start> The little boy swims under the water . <end>'],\n",
              " 'Flicker8k_Dataset/2949497756_be8e58e6bd.jpg': ['<start> Three brown dogs on the patchy grass . <end>',\n",
              "  \"<start> Three tan dogs are outside , one licks the other 's nose . <end>\",\n",
              "  '<start> Two dogs are nose to nose while a third dog stands next to them . <end>',\n",
              "  '<start> Two dogs touching noses near another dog . <end>',\n",
              "  '<start> Two tan dogs smell each others faces . <end>'],\n",
              " 'Flicker8k_Dataset/2692635048_16c279ff9e.jpg': ['<start> A black dog lays next to a ball . <end>',\n",
              "  '<start> A black dog sitting in brown grass with a colorful ball . <end>',\n",
              "  '<start> A brown and black dog laying next to a colourful ball . <end>',\n",
              "  '<start> A doberman mix takes a break in the hay from playing with his ball . <end>',\n",
              "  '<start> The dog rests after playing catch . <end>'],\n",
              " 'Flicker8k_Dataset/3665569615_9a71c4b6e4.jpg': ['<start> A baseball pitcher wearing a white and red uniform caught in midpitch of the ball . <end>',\n",
              "  '<start> a baseball player in white uniform throwing baseball <end>',\n",
              "  '<start> A profession baseball player pitches a ball in a baseball game . <end>',\n",
              "  '<start> The man in the white and red uniform gets ready to throw the baseball . <end>',\n",
              "  '<start> There is a man pitching a baseball and has a glove his left hand . <end>'],\n",
              " 'Flicker8k_Dataset/3304030264_da3dd18c7b.jpg': ['<start> A boy in black pants and green t-shirt jumps high with his skateboard . <end>',\n",
              "  '<start> A guy on a skateboard , jumping off some steps . <end>',\n",
              "  '<start> A person in a green shirt on a skateboard jumping off of a short set of stairs . <end>',\n",
              "  '<start> a skateboarder in a green shirt is taking a jump of a step in front of a pink building . <end>',\n",
              "  '<start> He is in the air on his skateboard . <end>'],\n",
              " 'Flicker8k_Dataset/160805827_5e6646b753.jpg': ['<start> A man in a boat in front of a sunset . <end>',\n",
              "  '<start> A man in a grey shirt is on a boat with a flag . <end>',\n",
              "  '<start> A man sits on a boat in the sunset near a flag . <end>',\n",
              "  '<start> A man sits on a sailboat with the sun setting behind him . <end>',\n",
              "  '<start> A man sitting on a boat with a flag and the sunset in the background . <end>'],\n",
              " 'Flicker8k_Dataset/2689491604_d8760f57b4.jpg': ['<start> a boy in an inflatable pool is being splashed with water . <end>',\n",
              "  '<start> A little boy is splashing in an inflatable pool . <end>',\n",
              "  '<start> A little boy splashing in a blue inflatable pool . <end>',\n",
              "  '<start> A small child is being splashed by water from an inflatable pool . <end>',\n",
              "  '<start> The boy splashed the water . <end>'],\n",
              " 'Flicker8k_Dataset/1402640441_81978e32a9.jpg': ['<start> A boy in red and blue shorts is trying to catch a soccer ball while running in sand . <end>',\n",
              "  '<start> A young boy wearing a red bathing suit reaches for a soccer ball . <end>',\n",
              "  '<start> Kid guards face from soccer ball <end>',\n",
              "  '<start> The little boy in red trunks is attempting to catch a soccer ball that is coming towards him . <end>',\n",
              "  '<start> Young boy plays ball on the beach . <end>'],\n",
              " 'Flicker8k_Dataset/405534893_2d0f3b0147.jpg': ['<start> a man climbs a mountain . <end>',\n",
              "  '<start> A man climbs the side of a mountain . <end>',\n",
              "  '<start> A shirtless man climbs a wall in nature . <end>',\n",
              "  '<start> One man is climbing a rock wall , while another man , below , holds a rope . <end>',\n",
              "  '<start> two men climbing a mountain <end>'],\n",
              " 'Flicker8k_Dataset/3335692531_dd4a995f91.jpg': ['<start> Brown dog and two black dogs have three-way tug on red object , outdoors . <end>',\n",
              "  '<start> Three dogs are all tugging on the same toy as they stand behind a house . <end>',\n",
              "  '<start> Three large dogs , one brown and the others black , tussle over a red toy in the grass outside a building . <end>',\n",
              "  '<start> two black dogs and a brown dog are tugging at a red object with their mouths . <end>',\n",
              "  \"<start> Two black dogs are tugging on a red toy that is in a brown dog 's mouth . <end>\"],\n",
              " 'Flicker8k_Dataset/3687996279_05b5a2a706.jpg': ['<start> A man in a uniform smiling and waving at the camera . <end>',\n",
              "  '<start> A man in a uniform waves while holding a banner during an event . <end>',\n",
              "  '<start> A man in uniform waves and smiles at camera <end>',\n",
              "  '<start> A police officer waves at a street fair . <end>',\n",
              "  '<start> The man in a black uniform and hat , holding part of a banner , is waving . <end>'],\n",
              " 'Flicker8k_Dataset/3023178539_836b50cd43.jpg': ['<start> The boys dressed in athletic wear perform exercises on the grass . <end>',\n",
              "  '<start> Two boys are running around a field . <end>',\n",
              "  '<start> Two men are running side by side in a field . <end>',\n",
              "  '<start> Two men run across a field near a parking lot <end>',\n",
              "  '<start> two teenagers playing ultimate Frisbee <end>'],\n",
              " 'Flicker8k_Dataset/3467073304_aefe553c4d.jpg': ['<start> A female volleyball player wearing a bikini jumps and spikes the ball . <end>',\n",
              "  '<start> a skinny woman spikes a volleyball over the net . <end>',\n",
              "  '<start> A woman is playing volleyball . <end>',\n",
              "  '<start> A woman playing volleyball at the beach . <end>',\n",
              "  '<start> A woman plays volleyball . <end>'],\n",
              " 'Flicker8k_Dataset/3705976184_53ae07e898.jpg': ['<start> A lady and her large brown and black dog out for a run in a grassy place <end>',\n",
              "  '<start> a woman and her black and brown dog running through a field in the woods <end>',\n",
              "  '<start> A woman in a white shirt is running with a dog in the grass . <end>',\n",
              "  '<start> A woman is running with a dog in a grassy field with trees in the background . <end>',\n",
              "  '<start> A woman running through a grassy area with a brown and black dog . <end>'],\n",
              " 'Flicker8k_Dataset/3197917064_e679a44b8e.jpg': ['<start> A dog running through the snow with what appears to be a chunk of wood in its mouth . <end>',\n",
              "  '<start> A white dog carries something in its mouth through the snow . <end>',\n",
              "  '<start> A white dog in the snow running with an object in its mouth <end>',\n",
              "  '<start> A white dog runs over a snowy field or lawn , with a log in his jaws . <end>',\n",
              "  '<start> A white dog with a purple necklace on plays in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/2699125097_c6801d80ed.jpg': ['<start> A bare chested man with a Mohawk , beard and glasses . <end>',\n",
              "  '<start> A large man with a Mohawk and two nipple rings . <end>',\n",
              "  '<start> An older man with his nipples peirced stands shirtless . <end>',\n",
              "  '<start> A tanned man with dark glasses on , punk style hair and tattoos on arms and chest . <end>',\n",
              "  '<start> The man with a shaved head and nipple piercings is wearing sunglasses . <end>'],\n",
              " 'Flicker8k_Dataset/1341787777_4f1ebb1793.jpg': ['<start> A brown dog is bending down trying to drink from a jet of water . <end>',\n",
              "  '<start> A brown dog slurps water from a sprinkler on the grass . <end>',\n",
              "  '<start> A dog drinking from a creek . <end>',\n",
              "  '<start> A large brown dog is sticking his face in the sprinkler . <end>',\n",
              "  '<start> Brown dog on grass , drinking water spray from left side of frame . <end>'],\n",
              " 'Flicker8k_Dataset/2543017787_9720b4fa1c.jpg': ['<start> A child in a red shirt and hat enjoys a tire-shaped swing at the playground . <end>',\n",
              "  '<start> A child rides a swing . <end>',\n",
              "  '<start> A girl in a red shirt is on a tire swing . <end>',\n",
              "  '<start> A small child riding on a ring swing . <end>',\n",
              "  '<start> A young child wearing a red shirt swinging on a faux tire swing . <end>'],\n",
              " 'Flicker8k_Dataset/3269380710_9161b0bd00.jpg': ['<start> A man in a blue shirt smoking a cigarette . <end>',\n",
              "  '<start> a man smokes a cigarette . <end>',\n",
              "  '<start> a man wearing a blue shirt smoking a cigarette in front of a building <end>',\n",
              "  '<start> A redheaded man smokes a cigarette while leaning his head forward . <end>',\n",
              "  '<start> man in blue shirt smoking <end>'],\n",
              " 'Flicker8k_Dataset/3654869593_c8599a8e20.jpg': ['<start> A few young boys throwing a football over a volleyball net . <end>',\n",
              "  '<start> Boys are throwing a football on the beach . <end>',\n",
              "  '<start> The children are playing a game , with a volleyball net and a football , on the beach . <end>',\n",
              "  '<start> three boys play volleyball on a busy beach . <end>',\n",
              "  '<start> three boys play with a football near a volleyball net at the beach . <end>'],\n",
              " 'Flicker8k_Dataset/3532412342_e0a004b404.jpg': ['<start> A child rolls around in a large tire . <end>',\n",
              "  '<start> A little boy is in a tire <end>',\n",
              "  '<start> Boy crouched and gesturing with hands , inside of a tire . <end>',\n",
              "  '<start> Child crouches in tire . <end>',\n",
              "  '<start> The child is sitting in a large truck tire . <end>'],\n",
              " 'Flicker8k_Dataset/2466420387_86fe77c966.jpg': ['<start> A woman wearing a bathing suit points in a case as another looks on . <end>',\n",
              "  '<start> A young woman in a bikini looking at something in a glass case . <end>',\n",
              "  '<start> Two girls lean over and look at something in a case . <end>',\n",
              "  '<start> two woman looking into a glass case . <end>',\n",
              "  '<start> Two women are looking into a glass case . <end>'],\n",
              " 'Flicker8k_Dataset/1466479163_439db855af.jpg': ['<start> A brown dog runs through the grass holding something in its mouth . <end>',\n",
              "  '<start> A brown dog runs with a toy in its mouth . <end>',\n",
              "  '<start> A small dog runs in a field , with a toy in its mouth . <end>',\n",
              "  '<start> Chocolate brown dog running on grass with something in its mouth . <end>',\n",
              "  '<start> The dog is running with food in his mouth . <end>'],\n",
              " 'Flicker8k_Dataset/3480052428_c034b98a08.jpg': ['<start> A family at a military camp <end>',\n",
              "  '<start> A small crowd watches military men in a tent area . <end>',\n",
              "  '<start> A woman holding a pitcher waits among others outside the opening of a tent . <end>',\n",
              "  '<start> People under a tent . <end>',\n",
              "  '<start> Two soldiers are going into a tent with men and women watching them . <end>'],\n",
              " 'Flicker8k_Dataset/1019604187_d087bf9a5f.jpg': ['<start> A dog prepares to catch a thrown object in a field with nearby cars . <end>',\n",
              "  '<start> A white dog is about to catch a yellow ball in its mouth . <end>',\n",
              "  '<start> A white dog is about to catch a yellow dog toy . <end>',\n",
              "  '<start> A white dog is ready to catch a yellow ball flying through the air . <end>',\n",
              "  '<start> A white dog running after a yellow ball <end>'],\n",
              " 'Flicker8k_Dataset/3628059004_5c3529b120.jpg': ['<start> A woman is laughing while playing guitar . <end>',\n",
              "  '<start> A woman with a guitar smiles in front of a microphone . <end>',\n",
              "  '<start> Two smiling women in costumes standing in front of a microphone . <end>',\n",
              "  '<start> Two women are smiling next to a microphone on a stage . <end>',\n",
              "  '<start> Two women stand at a microphone , and one has a guitar . <end>'],\n",
              " 'Flicker8k_Dataset/3226541300_6c81711e8e.jpg': ['<start> Two men in magenta costumes performing . <end>',\n",
              "  '<start> two men in red fight . <end>',\n",
              "  '<start> Two men in red robes performing martial arts . <end>',\n",
              "  '<start> Two people dressed in pink . <end>',\n",
              "  '<start> two people in red traditional Chinese garb are performing with sticks <end>'],\n",
              " 'Flicker8k_Dataset/2029280005_a19609c81a.jpg': ['<start> a man in a black shirt is rollerblading past a bench in the city . <end>',\n",
              "  '<start> A man is inline skating in front of a wooden bench . <end>',\n",
              "  '<start> A man is wearing Rollerblades standing on a paved area near a park bench . <end>',\n",
              "  '<start> A man on Rollerblades travelling down the sidewalk . <end>',\n",
              "  '<start> A man wearing a black shirt and brown pants skates on a concrete surface near a park bench . <end>'],\n",
              " 'Flicker8k_Dataset/637342973_89f6fac1f7.jpg': ['<start> A pink ball is being held up before three dogs on a beach . <end>',\n",
              "  '<start> Three dogs look as a human holds a pink ball on the beach . <end>',\n",
              "  '<start> three dogs on a beach looking at a red ball in someones hand <end>',\n",
              "  '<start> Three dogs stare at a red ball at the beach . <end>',\n",
              "  '<start> Three dogs stare curiously at a chewed up toy <end>'],\n",
              " 'Flicker8k_Dataset/3595992258_6f192e6ae7.jpg': ['<start> A brown dog is running on a rock . <end>',\n",
              "  '<start> A brown dog running . <end>',\n",
              "  '<start> A brown dog running across a flat rock . <end>',\n",
              "  '<start> A brown dog runs in the woods with a serious look on its face . <end>',\n",
              "  '<start> A reddish brown dog running . <end>'],\n",
              " 'Flicker8k_Dataset/3507076266_8b17993fbb.jpg': ['<start> A man in a brown jacket is leading a black shire horse . <end>',\n",
              "  '<start> A man walking a large black horse . <end>',\n",
              "  '<start> Man in brown jacket leading black horse <end>',\n",
              "  '<start> Man leads a black show horse as crowd observes . <end>',\n",
              "  '<start> The man is walking with a draft horse <end>'],\n",
              " 'Flicker8k_Dataset/583174725_6b522b621f.jpg': ['<start> A girl is in a parking lot jumping rope . <end>',\n",
              "  '<start> A little girl is jumping rope in a parking lot . <end>',\n",
              "  '<start> A little girl jumps rope through a parking lot <end>',\n",
              "  '<start> A young girl jumps rope in a parking lot in the mid-day sun . <end>',\n",
              "  '<start> Girl jumping rope in parking lot <end>'],\n",
              " 'Flicker8k_Dataset/541063419_a5f3672d59.jpg': ['<start> A male hiker sits perched on a high rock in the mountains . <end>',\n",
              "  '<start> A man is sitting on a rock high up in the mountains . <end>',\n",
              "  '<start> A man is sitting on top of a snow covered mountaintop . <end>',\n",
              "  '<start> A man sits on a rock near mountains . <end>',\n",
              "  '<start> A man wearing sunglasses is sitting on top of some jagged rocks with mountains in the background . <end>'],\n",
              " 'Flicker8k_Dataset/2894229082_ddc395f138.jpg': ['<start> A child with a pink hat and a white and pink shirt standing in grass . <end>',\n",
              "  '<start> A little girl in a football jersy and pink snow hat is standing on a football field . <end>',\n",
              "  '<start> A small child wearing a pink hat , bluejeans , and white shirt standing in a grass field . <end>',\n",
              "  '<start> A young girl wearing a pink hat stands on a grassy field . <end>',\n",
              "  '<start> A young girl with a pink hat on with a yellow building in the background . <end>'],\n",
              " 'Flicker8k_Dataset/535529555_583d89b7f2.jpg': ['<start> two brown and white dogs fighting over a Frisbee <end>',\n",
              "  '<start> Two dogs fighting over a Frisbee <end>',\n",
              "  '<start> Two dogs outside fighting over a red Frisbee . <end>',\n",
              "  '<start> Two dogs play with a Frisbee on the lawn . <end>',\n",
              "  '<start> Two dogs try to get the chewed-up red Frisbee from the other . <end>'],\n",
              " 'Flicker8k_Dataset/2557972410_6925fe695c.jpg': ['<start> A goalie is guarding the goal . <end>',\n",
              "  '<start> Kids in helmets play hockey outside . <end>',\n",
              "  '<start> Several players playing a game of hockey outside on the road . <end>',\n",
              "  '<start> Some children play hockey outside . <end>',\n",
              "  '<start> Two children play street hockey in front of a goal . <end>'],\n",
              " 'Flicker8k_Dataset/3099965396_2a0018cb9e.jpg': ['<start> A man is waiting in a public area while people pass behind him . <end>',\n",
              "  '<start> An old man in a black trench coat standing in a marketplace . <end>',\n",
              "  '<start> An old man in a long black coat stands on the street . <end>',\n",
              "  '<start> A white haired man in a black coat is standing on a city street . <end>',\n",
              "  '<start> A woman is waiting alone outside while a bird walks behind her . <end>'],\n",
              " 'Flicker8k_Dataset/341430859_4519802e8f.jpg': ['<start> A brown and white dog stands in the deep snow . <end>',\n",
              "  '<start> A dog in the snow . <end>',\n",
              "  '<start> A dog stands in deep snow surrounded by trees . <end>',\n",
              "  '<start> A dog stands up to his elbows in snow . <end>',\n",
              "  '<start> Dog sits in snow . <end>'],\n",
              " 'Flicker8k_Dataset/2238759450_6475641bdb.jpg': ['<start> A curly haired girl is dragging a grey inflatable raft with a red paddle into the water . <end>',\n",
              "  '<start> A girl in a yellow headscarf is pulling a boat to the water . <end>',\n",
              "  '<start> A woman pulls an inflatable boat into the water . <end>',\n",
              "  '<start> a woman pulls her raft into the water . <end>',\n",
              "  '<start> Someone is pulling an inflatable boat with an oar in it . <end>'],\n",
              " 'Flicker8k_Dataset/3009644534_992e9ea2a7.jpg': ['<start> a closeup photo of a small dog with a holey ball in his mouth . <end>',\n",
              "  '<start> A dog carrying a white ball . <end>',\n",
              "  '<start> A dog fetches a ball in a field . <end>',\n",
              "  '<start> A dog trots with a ball in its mouth . <end>',\n",
              "  '<start> The dog is carrying a whiffle ball outside <end>'],\n",
              " 'Flicker8k_Dataset/2938120171_970564e3d8.jpg': ['<start> A large dog sniffing a smaller dog outside . <end>',\n",
              "  '<start> Two blond dogs are standing together on a patio . <end>',\n",
              "  '<start> Two dogs are standing together on a patio . <end>',\n",
              "  '<start> Two golden dogs are standing on a wooden patio . <end>',\n",
              "  '<start> Two golden dogs on a wood deck . <end>'],\n",
              " 'Flicker8k_Dataset/3091338773_9cf10467b4.jpg': ['<start> A brown dog is biting a green object . <end>',\n",
              "  '<start> A brown dog is jumping up to catch a green strap in its mouth . <end>',\n",
              "  '<start> A dog has its mouth wide open trying to bite something . <end>',\n",
              "  '<start> A grey dog jumps to bite a green leash . <end>',\n",
              "  '<start> A short-haired brown dog is snapping at a long green strip . <end>'],\n",
              " 'Flicker8k_Dataset/2375924666_fee50f1cba.jpg': ['<start> A brown dog holding a foam bat aiming for a ball . <end>',\n",
              "  '<start> A brown dog in front of a white fence with a blue and red bat-shaped object in its mouth . <end>',\n",
              "  '<start> A brown dog is playing with a blue and red bat in his mouth . <end>',\n",
              "  '<start> A brown dog plays with a toy bat hanging out its mouth . <end>',\n",
              "  '<start> A long-haired dog is playing with a small , blue bat . <end>'],\n",
              " 'Flicker8k_Dataset/2281054343_95d6d3b882.jpg': ['<start> A man wearing a black hat is walking through a busy city street . <end>',\n",
              "  '<start> A silhouette of a man in a hat on a busy city street . <end>',\n",
              "  '<start> Person with black hat and black coat near buildings with signs . <end>',\n",
              "  '<start> Three people in a crowded city area . <end>',\n",
              "  '<start> Thre is a shot of man with his back turned in a city . <end>'],\n",
              " 'Flicker8k_Dataset/3332202255_a30c522664.jpg': ['<start> A man with a white guitar plays with another in a striped shirt . <end>',\n",
              "  '<start> One guy sings while another plays guitar . <end>',\n",
              "  '<start> Two men are playing in a band . <end>',\n",
              "  '<start> two men performing each playing guitars while one is singing <end>',\n",
              "  '<start> Two young men are playing guitars in the corner of a room . <end>'],\n",
              " 'Flicker8k_Dataset/3343197133_9256848fa9.jpg': ['<start> A biker gets high in the air against a skyline . <end>',\n",
              "  '<start> A boy wearing a white helmet jumping on his bike . <end>',\n",
              "  '<start> a cyclist is performing a jumping stunt in front of a city skyline . <end>',\n",
              "  '<start> A man is in the air on his bicycle . <end>',\n",
              "  '<start> A person doing a bicycle jump , a skyline in the background . <end>'],\n",
              " 'Flicker8k_Dataset/336460583_6c8ccb7188.jpg': ['<start> A little brown dog is running in a field . <end>',\n",
              "  '<start> A little brown dog is running on the grass . <end>',\n",
              "  '<start> A little brown dog runs through the grass . <end>',\n",
              "  '<start> A puppy runs in a grassy field , a dirt road in the background . <end>',\n",
              "  '<start> A small brown dog is running over grass littered with dry leaves . <end>'],\n",
              " 'Flicker8k_Dataset/367925122_335ed279a8.jpg': ['<start> A blonde toddler in a light green shirt sitting in a green chair surrounded by other green chairs . <end>',\n",
              "  '<start> A cute toddler girl waits in her stroller . <end>',\n",
              "  '<start> A little blonde girl is sitting on a green chair . <end>',\n",
              "  '<start> A little girl is turned around in her seat at an event . <end>',\n",
              "  '<start> A young girl with blond hair holding onto a rail <end>'],\n",
              " 'Flicker8k_Dataset/99171998_7cc800ceef.jpg': ['<start> A group is sitting around a snowy crevasse . <end>',\n",
              "  '<start> A group of people sit atop a snowy mountain . <end>',\n",
              "  '<start> A group of people sit in the snow overlooking a mountain scene . <end>',\n",
              "  '<start> Five children getting ready to sled . <end>',\n",
              "  '<start> Five people are sitting together in the snow . <end>'],\n",
              " 'Flicker8k_Dataset/3214885227_2be09e7cfb.jpg': ['<start> A man boating along a river near the shore . <end>',\n",
              "  '<start> A man paddling a kayak along the shore of a river . <end>',\n",
              "  '<start> A person is riding in a canoe on a lake next to green trees . <end>',\n",
              "  '<start> A person is wading through a river near an eroded embankment . <end>',\n",
              "  '<start> A single person rowing a small boat on a lake . <end>'],\n",
              " 'Flicker8k_Dataset/542648687_adf13c406b.jpg': ['<start> Two dogs run in a field looking at an unseen Frisbee . <end>',\n",
              "  '<start> Two black and white dogs in a field of flowers and grass . <end>',\n",
              "  '<start> Two black and white dogs look toward something in the air while running in a grassy field . <end>',\n",
              "  '<start> two black and white dogs running in a flowery field <end>',\n",
              "  '<start> Two dogs change direction in an uncut field surrounded by low brush . <end>'],\n",
              " 'Flicker8k_Dataset/2696394827_7342ced36f.jpg': ['<start> A bird is splashing in the water next to the swimming dog wearing the blue collar . <end>',\n",
              "  '<start> a dog chases a bird in the water . <end>',\n",
              "  '<start> A dog swims in a body of water while , slightly ahead , a black duck takes flight . <end>',\n",
              "  '<start> Dog and bird together in water . <end>',\n",
              "  '<start> The retriever is swimming out to the goose who is about to get away . <end>'],\n",
              " 'Flicker8k_Dataset/2655196158_5c878a4af0.jpg': ['<start> A dog chews on a toy on a blue blanket . <end>',\n",
              "  '<start> A dog is laying on a blue rug , chewing and making a mess . <end>',\n",
              "  '<start> A gray dog chewing on a toy . <end>',\n",
              "  '<start> A grey dog with blue eyes laying on a bright blue carpet while chewing on something . <end>',\n",
              "  '<start> The gray , blue eyed hound puppy is laying on a blue carpet chewing on a toy . <end>'],\n",
              " 'Flicker8k_Dataset/774009278_8e75b7d498.jpg': ['<start> A dog is jumping to play in the water <end>',\n",
              "  '<start> A white dog is jumping up at a jet of water . <end>',\n",
              "  '<start> a white dog jumping in green grass by a brickwall and a stream of water <end>',\n",
              "  '<start> A white dog jumps from the grass into water from a hose . <end>',\n",
              "  '<start> A white dog jumps on the green grass next to a brick building . <end>'],\n",
              " 'Flicker8k_Dataset/3046430047_d7b10123d0.jpg': ['<start> A man and two woman dressed like vampires complete with scary makeup . <end>',\n",
              "  '<start> A man and two women dressed in costumes . <end>',\n",
              "  '<start> One man and two women dressed in vampire costumes <end>',\n",
              "  '<start> Some party goers pose in their costumes at a halloween party . <end>',\n",
              "  '<start> Three people wearing dark costumes and make-up pose for a picture . <end>'],\n",
              " 'Flicker8k_Dataset/3703035378_c6034cac51.jpg': ['<start> A big sister in pink is giving her little sister a piggy back ride . <end>',\n",
              "  '<start> An Asian girl is riding piggy back on another girl as they pass some red tape . <end>',\n",
              "  '<start> One child carries another child on her back . <end>',\n",
              "  '<start> One little girl standing with another little girl piggybacking on her back look at an object . <end>',\n",
              "  '<start> Two girls in pink shirts looking at a fountain from behind a red velvet rope . <end>'],\n",
              " 'Flicker8k_Dataset/3336065481_2c21e622c8.jpg': ['<start> A small girl in yellow slides down an orange slide . <end>',\n",
              "  '<start> A young girl dressed in yellow sliding down a curvy , red slide at a playground . <end>',\n",
              "  '<start> A young girl on an orange slide <end>',\n",
              "  '<start> A young girl sliding down an orange slide <end>',\n",
              "  '<start> Little girl sliding down an orange playground slide . <end>'],\n",
              " 'Flicker8k_Dataset/2194797921_96af7a9467.jpg': ['<start> A woman is climbing a volleyball net on a beach as two others watch . <end>',\n",
              "  '<start> Girl climbs volleyball net at beach <end>',\n",
              "  '<start> People hanging up a volleyball net . <end>',\n",
              "  '<start> People put up a volleyball net at the beach . <end>',\n",
              "  '<start> The girl in the brown shirt is hanging onto a blue pole . <end>'],\n",
              " 'Flicker8k_Dataset/3282634762_2650d0088a.jpg': ['<start> A swan is flying through a body of water . <end>',\n",
              "  '<start> A swan preparing for flight across the pond <end>',\n",
              "  '<start> A swan taking off from a lake <end>',\n",
              "  '<start> The white swan is taking off from the water . <end>',\n",
              "  '<start> White bird flying above water . <end>'],\n",
              " 'Flicker8k_Dataset/2935703360_4f794f7f09.jpg': ['<start> A black and white dog is running between yellow poles . <end>',\n",
              "  '<start> A black dog running through yellow cones . <end>',\n",
              "  '<start> A dog is running in and out of a line of posts on an obstacle course . <end>',\n",
              "  '<start> A little dog running between yellow poles . <end>',\n",
              "  '<start> Dog in field with yellow posts . <end>'],\n",
              " 'Flicker8k_Dataset/1925434818_2949a8f6d8.jpg': ['<start> Several children playing in a ball pit . <end>',\n",
              "  '<start> Some children playing in a pit full of colorful balls <end>',\n",
              "  '<start> Three children in a ball pit . <end>',\n",
              "  '<start> Two children fall headfirst into a colorful ball pit while a third child watches . <end>',\n",
              "  '<start> Two children slide down a slide into a ball pit while another child looks on . <end>'],\n",
              " 'Flicker8k_Dataset/2978236380_fb24c43f1e.jpg': ['<start> A man playing guitar sings into a microphone . <end>',\n",
              "  '<start> A man plays guitar and sings into a microphone . <end>',\n",
              "  '<start> An older man is playing a guitar and singing into a microphone . <end>',\n",
              "  '<start> Hawaiian man singing into a red microphone . <end>',\n",
              "  '<start> The Hawaiian singer belts out a tune . <end>'],\n",
              " 'Flicker8k_Dataset/3451345621_fe470d4cf8.jpg': ['<start> A man holding a political sign . <end>',\n",
              "  '<start> A man in jeans & a cowboy hat holds up a sign . <end>',\n",
              "  '<start> a man wearing a cowboy hat holding a protest sign . <end>',\n",
              "  '<start> A man with a cowboy hat and an anti-tax sign . <end>',\n",
              "  '<start> A protester in a cowboy gear holds up a sign that says , \" Dont tax me bro! \" <end>'],\n",
              " 'Flicker8k_Dataset/3246190363_68d903bfcb.jpg': ['<start> A black dog leaps in the water . <end>',\n",
              "  '<start> A black dog runs fast into shallow water . <end>',\n",
              "  '<start> A dog bounds into the water . <end>',\n",
              "  '<start> Black dog running into the water . <end>',\n",
              "  '<start> Black dog running through water next to beach . <end>'],\n",
              " 'Flicker8k_Dataset/2882893687_1d10d68f2b.jpg': ['<start> A dark haired boy and dark haired girl stand on the grass . <end>',\n",
              "  '<start> Two children are walking towards a house with a red van parked outside . <end>',\n",
              "  '<start> Two children in the grass in front of a house . <end>',\n",
              "  '<start> Two children play outside in the yard . <end>',\n",
              "  '<start> Two kids play in the grass near a red car . <end>'],\n",
              " 'Flicker8k_Dataset/3188044631_ca3a9cc737.jpg': ['<start> A man and a woman in a apron stand near a fireplace and Christmas tree . <end>',\n",
              "  '<start> A man and a woman posing in front of a christmas tree . <end>',\n",
              "  '<start> A man and a woman stand in front of a Christmas tree contemplating a single thought . <end>',\n",
              "  '<start> A man and woman with their hands on their chins are standing next to a Christmas tree . <end>',\n",
              "  '<start> A young couple thinking about their Christmas decorations . <end>'],\n",
              " 'Flicker8k_Dataset/2939464283_fc1a834976.jpg': ['<start> a football player catching the football . <end>',\n",
              "  '<start> a football player in a brown jersey jumping up to catch a football <end>',\n",
              "  '<start> A football player jumps up to catch the ball while others run towards him . <end>',\n",
              "  '<start> Football players playing football . <end>',\n",
              "  '<start> The football player jumps into the air to catch a football . <end>'],\n",
              " 'Flicker8k_Dataset/1814391289_83a1eb71d3.jpg': ['<start> A boy dressed as Spiderman ringing a door bell <end>',\n",
              "  '<start> A child dressed as Spiderman ringing a doorbell . <end>',\n",
              "  '<start> A child that is dressed as Spiderman is ringing the doorbell . <end>',\n",
              "  '<start> At Halloween , this little spiderman waits to get some candy . <end>',\n",
              "  '<start> A young child in a costume rings the door bell of a gray house . <end>'],\n",
              " 'Flicker8k_Dataset/2541104331_a2d65cfa54.jpg': ['<start> A brown dog splashing through water . <end>',\n",
              "  '<start> A dog is running through a pond <end>',\n",
              "  '<start> a dog pounces into the water . <end>',\n",
              "  '<start> The large brown dog is running through shallow water . <end>',\n",
              "  '<start> There is a chocolate brown dog running in water . <end>'],\n",
              " 'Flicker8k_Dataset/3393343330_b13df4d8ec.jpg': ['<start> A large man sits in a military accessories store . <end>',\n",
              "  '<start> A man in glasses is sitting behind a table laden with military memorabilia . <end>',\n",
              "  '<start> A man is sitting at a table full of military items and clothing . <end>',\n",
              "  '<start> A man sits at a table crowded with military merchandise . <end>',\n",
              "  '<start> Veteran shows off different things from a war . <end>'],\n",
              " 'Flicker8k_Dataset/3306951622_93b82cac21.jpg': ['<start> A far off view of a surfer and a person on a seedoo . <end>',\n",
              "  '<start> A man on a jet ski is watching a surfer ride the waves . <end>',\n",
              "  '<start> A person surfing a big wave . <end>',\n",
              "  '<start> A surfer catches a wave as a man on a jet ski looks on in case of an accident . <end>',\n",
              "  '<start> A surfer in a red shirt is under a large wave . <end>'],\n",
              " 'Flicker8k_Dataset/3416246113_1745559b6b.jpg': ['<start> A man in a blue headband plays tennis . <end>',\n",
              "  '<start> A man running during a tennis match . <end>',\n",
              "  '<start> A tennis player is running across the court with a racquet in his hand . <end>',\n",
              "  '<start> Closeup of a man running with a tennis racket <end>',\n",
              "  '<start> This man , wearing a blue headband and white shirt , is playing tennis . <end>'],\n",
              " 'Flicker8k_Dataset/3680218298_582e6a2289.jpg': ['<start> A man in a green Speedo dancing . <end>',\n",
              "  '<start> A muscular black man dancing in short shorts . <end>',\n",
              "  '<start> A shirtless man in striped shorts and sunglasses with a man in white shirt and sunglasses . <end>',\n",
              "  '<start> The muscular black man is dancing while the man behind him wears green beads . <end>',\n",
              "  '<start> Two men in green underwear and green beads dance together . <end>'],\n",
              " 'Flicker8k_Dataset/3691670743_0ed111bcf3.jpg': ['<start> A boy is jumping on skateboard in the middle of a red bridge . <end>',\n",
              "  '<start> a kid doing tricks on a skateboard on a bridge <end>',\n",
              "  '<start> A skateboarder is airborne on a bridge . <end>',\n",
              "  '<start> A skateboard jumps down a bridge . <end>',\n",
              "  '<start> The skateboarder in the white shirt jumped into the air . <end>'],\n",
              " 'Flicker8k_Dataset/482830610_13a0a6c924.jpg': ['<start> A girl reads and listens to music on a bus . <end>',\n",
              "  '<start> a woman reads a book on a train . <end>',\n",
              "  '<start> A woman reads while on public transportation . <end>',\n",
              "  '<start> The girl is sitting on a train and reading a book . <end>',\n",
              "  '<start> Woman on a train , reading and listening to headphones . <end>'],\n",
              " 'Flicker8k_Dataset/3526897578_3cf77da99b.jpg': ['<start> A black dog is carrying a red bucket in its mouth . <end>',\n",
              "  '<start> A black dog runs with a red bucket . <end>',\n",
              "  '<start> a small black and white dog carrying a red bucket in his mouth <end>',\n",
              "  '<start> Black and white dog running carrying red bucket in mouth . <end>',\n",
              "  '<start> The black and white dog is running with a red pail in its mouth . <end>'],\n",
              " 'Flicker8k_Dataset/3435035138_af32890a4c.jpg': ['<start> A dog runs along a forest lane . <end>',\n",
              "  '<start> A pale dog is running along a dirt path . <end>',\n",
              "  '<start> A shaggy dog runs down a dirt trail in a lush forest . <end>',\n",
              "  '<start> A white and brown shaggy dog is running down a dirt path in a park . <end>',\n",
              "  '<start> The curly haired white dog is running down a wooded path . <end>'],\n",
              " 'Flicker8k_Dataset/3665987581_5e6b0a65f2.jpg': ['<start> A brown and white corgi trailing a leash chasing sheep . <end>',\n",
              "  '<start> A dog chasing livestock on sand . <end>',\n",
              "  '<start> A short brown and white dog chasing sheep . <end>',\n",
              "  '<start> a small tan dog herding some sheep <end>',\n",
              "  '<start> Brown and white dog , running on sand with livestock animals partially out of frame . <end>'],\n",
              " 'Flicker8k_Dataset/2968216482_ede65b20a8.jpg': ['<start> A biker patiently waits as his friend bikes ahead of him . <end>',\n",
              "  '<start> A man in a leather outfit prepares to ride a motorcycle . <end>',\n",
              "  '<start> One motorcyclist speeds away from a parked motorcyclist along a drag strip . <end>',\n",
              "  '<start> Two men on motorcycles are driving down an empty street . <end>',\n",
              "  '<start> Two people in black leather ride motorcycles . <end>'],\n",
              " 'Flicker8k_Dataset/125319704_49ead3463c.jpg': ['<start> Person standing beside bike in stream . <end>',\n",
              "  '<start> Two bicyclists pose by a stream for a picture . <end>',\n",
              "  '<start> two biker walk across the ground . <end>',\n",
              "  '<start> Two off road bikers stopped in a creek . <end>',\n",
              "  '<start> Two people , in bike gear , stand with bicycles near a rocky waterbed . <end>'],\n",
              " 'Flicker8k_Dataset/276699720_fe6718fd03.jpg': ['<start> A man on a four-wheeler jumps while in a field . <end>',\n",
              "  '<start> A person jumping a 4-wheel off road vehicle . <end>',\n",
              "  '<start> A person riding a yellow ATV over tall grass . <end>',\n",
              "  '<start> A yellow ATV is airborne in field of long grass . <end>',\n",
              "  '<start> The person with a helmet is doing a jumping trick on a 4-wheeler . <end>'],\n",
              " 'Flicker8k_Dataset/2095078658_c14ba89bc2.jpg': ['<start> A dog runs through snow in front of the woods . <end>',\n",
              "  '<start> Large dog running in snow <end>',\n",
              "  '<start> The dog runs through the snow . <end>',\n",
              "  '<start> The German shepherd dog is running through the snow . <end>',\n",
              "  '<start> The German Shepherd is running through the white snow . <end>'],\n",
              " 'Flicker8k_Dataset/3293751136_b0ce285dc3.jpg': ['<start> A couple is sharing a kiss on a cold sunny day . <end>',\n",
              "  '<start> A couple kissing on a sidewalk in a city during winter . <end>',\n",
              "  '<start> a man in a tan jacket is kissing a girl in a pink jacket on a city street as a yellow taxi passes by . <end>',\n",
              "  '<start> Teen girl in a parka kissing teen boy in a brown jacket on a snowy street <end>',\n",
              "  '<start> Two people in coats kiss on the side of a road . <end>'],\n",
              " 'Flicker8k_Dataset/1222322358_225067636e.jpg': ['<start> A boy in a red and white shirt is on a swing . <end>',\n",
              "  '<start> A child looking back on a fast moving swing . <end>',\n",
              "  '<start> A litlle boy playing on a swing <end>',\n",
              "  '<start> A young boy in orange and white swings in a playground at a park . <end>',\n",
              "  '<start> A young boy plays on a swing . <end>'],\n",
              " 'Flicker8k_Dataset/3500399969_f54ce5848f.jpg': ['<start> Seven people are posing over a structure that extends over a watery area and ocean . <end>',\n",
              "  '<start> Seven people jumping into the clear blue water . <end>',\n",
              "  '<start> Seven people jumping into water . <end>',\n",
              "  '<start> seven people jump into the water . <end>',\n",
              "  '<start> Seven people leaping into the air over a walk over blue water . <end>'],\n",
              " 'Flicker8k_Dataset/3183195185_cd0ff994a1.jpg': ['<start> A man and a boy sitting with their back to a stone wall , the man paying a flute . <end>',\n",
              "  '<start> A man and a small boy sit and rest against a stone wall . <end>',\n",
              "  '<start> A man holding a flute and a boy sit on a street against a red wall . <end>',\n",
              "  '<start> Man and young child sitting on the ground in front of red rock wall . <end>',\n",
              "  '<start> The man and boy sit on the ground , next to a rocky wall . <end>'],\n",
              " 'Flicker8k_Dataset/1389651420_8d95d8f6ed.jpg': ['<start> A boy stands beside a railing at a go kart track . <end>',\n",
              "  '<start> A little boy grinning with a go cart in the background . <end>',\n",
              "  '<start> A little boy in a red shirt is making a face into the camera while waiting at a go cart track . <end>',\n",
              "  '<start> A little boy is standing in line for go-karts . <end>',\n",
              "  '<start> The small boy is excited he will be riding a go-cart . <end>'],\n",
              " 'Flicker8k_Dataset/3174156702_95a1cda2d9.jpg': ['<start> A boy playing in a mud puddle . <end>',\n",
              "  '<start> A young shirtless boy in kakhi pants is kneeling in a marsh while someone splashes nearby . <end>',\n",
              "  '<start> Boy laughs while playing in mud puddle . <end>',\n",
              "  '<start> Boys splash in the muddy puddle in the grass . <end>',\n",
              "  '<start> Two boys playing and splashing around in muddy water . <end>'],\n",
              " 'Flicker8k_Dataset/3669069522_555c97fbfb.jpg': ['<start> One woman and two men on a bench . <end>',\n",
              "  '<start> one woman holding flowers and two men on a bench <end>',\n",
              "  '<start> Three middle aged people sitting on a park bench , with a rock wall in the background . <end>',\n",
              "  '<start> Three people sit on a bench outside . <end>',\n",
              "  '<start> Two men and a woman sitting on a bench . <end>'],\n",
              " 'Flicker8k_Dataset/3415003392_139c0f3586.jpg': ['<start> A BMX bike rider in a black and red uniform on a dirt bike . <end>',\n",
              "  '<start> A person on a bmx bike . <end>',\n",
              "  '<start> A person wearing a black helmet rides a red bike through the woods . <end>',\n",
              "  '<start> Biker with helmet riding red dirt bike in the woods . <end>',\n",
              "  '<start> Dirt bike rider getting ready to start down the slope . <end>'],\n",
              " 'Flicker8k_Dataset/3489774350_a94e6c7bfc.jpg': ['<start> A child eating food and smiling at the camera . <end>',\n",
              "  '<start> A little child in a green shirt eats a crust of bread , smiling . <end>',\n",
              "  '<start> A small child in a green jacket eating something . <end>',\n",
              "  '<start> A small child looks and smiles as she eats . <end>',\n",
              "  '<start> A smiling little boy in a green jacket eats a snack . <end>'],\n",
              " 'Flicker8k_Dataset/2601612082_4b9be27426.jpg': ['<start> A family jumps into a blow up raft in their living room . <end>',\n",
              "  '<start> a group of young children playing on a plastic boat inside a house <end>',\n",
              "  '<start> Children are playing in a raft inside of a house . <end>',\n",
              "  '<start> Some kids are wrestling on an inflatable raft <end>',\n",
              "  '<start> Two parents and a young girl blow up a raft . <end>'],\n",
              " 'Flicker8k_Dataset/2746910139_77ba5be2c5.jpg': ['<start> A child leans over a vat . <end>',\n",
              "  \"<start> A child playing with water in a children 's discovery museum . <end>\",\n",
              "  '<start> A child plays in a multi-colored fountain . <end>',\n",
              "  '<start> A little child playing in water with a hose . <end>',\n",
              "  '<start> A young child is playing in a water tank with toys . <end>'],\n",
              " 'Flicker8k_Dataset/482088914_e6ea4501e9.jpg': ['<start> A kayaker almost turns over . <end>',\n",
              "  '<start> A kayaker traverses some churning rapids . <end>',\n",
              "  '<start> A man is kayaking in rough water . <end>',\n",
              "  '<start> A man kayaks in wavy water . <end>',\n",
              "  '<start> A person in a blue kayak battles the waves . <end>'],\n",
              " 'Flicker8k_Dataset/2521770311_3086ca90de.jpg': ['<start> A boy holds a picture over his head . <end>',\n",
              "  '<start> A boy in a long sleeve shirt is holding a box above his head . <end>',\n",
              "  '<start> A boy is inside holding something on top of his head . <end>',\n",
              "  '<start> A little boy holds a decorated cardboard box on his head . <end>',\n",
              "  '<start> a young boy with a samll cardboard box atop his head . <end>'],\n",
              " 'Flicker8k_Dataset/3095225232_2e6e6dc92e.jpg': ['<start> People are standing on an escalator moving up . <end>',\n",
              "  '<start> people go up the escalator . <end>',\n",
              "  '<start> People ride up an escalator . <end>',\n",
              "  '<start> People travel up the elevator together . <end>',\n",
              "  '<start> Several people ride up an escalator . <end>'],\n",
              " 'Flicker8k_Dataset/1295669416_21cabf594d.jpg': ['<start> A girl dressed in a red and black top with black pants is sitting on a wall . <end>',\n",
              "  '<start> A girl in a red and black striped shirt sits on a brick wall in front of a tropical plant . <end>',\n",
              "  '<start> A girl wearing a red and black striped shirt is sitting on a brick wall near a flower garden . <end>',\n",
              "  '<start> A lady in a red and black striped shirt is sitting on a retaining wall . <end>',\n",
              "  '<start> A woman in semi-formal attire is sitting on a concrete wall . <end>'],\n",
              " 'Flicker8k_Dataset/3552796830_2dd2aa9c2c.jpg': ['<start> Two men in camouflage pants are running past a parking lot . <end>',\n",
              "  '<start> Two men in camouflage pants are running past a parking lot . <end>',\n",
              "  '<start> Two men run through a parking lot wearing camouflage pants . <end>',\n",
              "  '<start> Two men wearing army pants are running next to a fence . <end>',\n",
              "  '<start> Two soldiers are running down a track . <end>'],\n",
              " 'Flicker8k_Dataset/408627152_1feaa4b94e.jpg': ['<start> A dog in a life jacket sitting on a boat with a man in the cockpit . <end>',\n",
              "  '<start> A man looking at his small white dog wearing an orange life jacket <end>',\n",
              "  '<start> a shite dog in an orange life vest looking at a man in a blue shirt while riding in a boat . <end>',\n",
              "  '<start> A white dog in a life jacket looks at a man in a boat . <end>',\n",
              "  '<start> A white dog with a life vest accompanies a man in a boat . <end>'],\n",
              " 'Flicker8k_Dataset/751074141_feafc7b16c.jpg': ['<start> A boy being pulled on a shovel . <end>',\n",
              "  '<start> A happy child play in the scoop of a shovel by a chair in a grassy backyard . <end>',\n",
              "  '<start> A little boy in red flowered shorts is sitting on a shovel . <end>',\n",
              "  '<start> A little boy smiling and riding in a shovel . <end>',\n",
              "  '<start> Small boy in red shorts with blue flowers sitting on shovel in the grass near a tan chair . <end>'],\n",
              " 'Flicker8k_Dataset/3457210101_3533edebc8.jpg': ['<start> A woman from CBS talking to a man in a white shirt . <end>',\n",
              "  '<start> A woman holding a microphone speaks to a man wearing a white shirt . <end>',\n",
              "  '<start> a woman interviews a man . <end>',\n",
              "  '<start> A woman with a mic interviews the soccer player . <end>',\n",
              "  '<start> A woman with a microphone from CBS is asking a man a question . <end>'],\n",
              " 'Flicker8k_Dataset/3103231330_db98b14501.jpg': ['<start> A man in a blue jacket and gloves is standing in the street among other people . <end>',\n",
              "  '<start> A man in a brightly-colored ski jacket stands with others on a European street . <end>',\n",
              "  '<start> A man in a colorful jacket walks down the street surrounded by women in winter clothing . <end>',\n",
              "  '<start> The man in a blue jacket is standing in a crowd . <end>',\n",
              "  '<start> The man in the blue jacket is walking in a crowd of people past an English pub . <end>'],\n",
              " 'Flicker8k_Dataset/2718495608_d8533e3ac5.jpg': ['<start> a brunette girl wearing sunglasses and a yellow shirt <end>',\n",
              "  '<start> A girl in sunglasses smiles . <end>',\n",
              "  '<start> A girl wearing a yellow shirt and sunglasses smiles . <end>',\n",
              "  '<start> a girl wearing sunglasses smiles for the camera . <end>',\n",
              "  '<start> A woman with a yellow shirt wears sunglasses and smiles . <end>'],\n",
              " 'Flicker8k_Dataset/3295680663_af21ea648b.jpg': ['<start> A man jumps train cars with his bike . <end>',\n",
              "  '<start> A man on a bmx bike jumps over a train <end>',\n",
              "  '<start> A person is in the air while riding his bicycle on top of the train on a clear blue sky day . <end>',\n",
              "  '<start> A person is jumping over a train car while on their bicycle . <end>',\n",
              "  '<start> A person on a bicycle moving across the top of a train . <end>'],\n",
              " 'Flicker8k_Dataset/3207676216_48478bce97.jpg': ['<start> A man being pulled behind a sled led by numerous dogs in the snow . <end>',\n",
              "  '<start> A man dressed in warm clothing sleds behind four dogs in the snow . <end>',\n",
              "  '<start> A man is running behind a dogsled being pulled by four dogs . <end>',\n",
              "  '<start> A man rides a sled pulled by a team of dogs . <end>',\n",
              "  '<start> four husky dogs are pulling a sled in a race through the snow guided by a man wearing number eleven . <end>'],\n",
              " 'Flicker8k_Dataset/2461372011_ebbf513766.jpg': ['<start> A person and a black dog are walking through the snow . <end>',\n",
              "  '<start> A person climbs a snowy hill while a black dog follows . <end>',\n",
              "  '<start> A person climbs up a snowy hill while their dog follows . <end>',\n",
              "  '<start> A person hiking up a hill in the snow with a dog . <end>',\n",
              "  '<start> The hiker is walking up a snow covered hill with a black dog . <end>'],\n",
              " 'Flicker8k_Dataset/2991993027_36ac04e9a0.jpg': ['<start> A group of people dressed as zombies . <end>',\n",
              "  '<start> A large group of people with facepaint on gather outside . <end>',\n",
              "  '<start> Everybody is dressed as a zombie at this party . <end>',\n",
              "  '<start> Many people have painted faces at night . <end>',\n",
              "  '<start> people dressed up in zombie costumes are standing around . <end>'],\n",
              " 'Flicker8k_Dataset/3107513635_fe8a21f148.jpg': ['<start> A bunch of people at a train station . <end>',\n",
              "  '<start> A photo of a train platform on a chilly day . <end>',\n",
              "  '<start> A train station says \" tychy miasto \" <end>',\n",
              "  '<start> People are boarding two yellow and blue trains . <end>',\n",
              "  '<start> Several people waiting outside a train station . <end>'],\n",
              " 'Flicker8k_Dataset/2856524322_1d04452a21.jpg': ['<start> A man on a bicycle jumping off a dirt ramp with one foot on the ground <end>',\n",
              "  '<start> A man on a bmx . <end>',\n",
              "  '<start> A man riding a bicycle performs a trick above a dirt mound . <end>',\n",
              "  '<start> A young man in tan shorts and green shirt is falling off his bicycle . <end>',\n",
              "  '<start> Man doing a jumping bike trick on dirt mound at night . <end>'],\n",
              " 'Flicker8k_Dataset/2270483627_16fe41b063.jpg': ['<start> A big tan dog jumps in the water . <end>',\n",
              "  '<start> A light brown dog is running in the water . <end>',\n",
              "  '<start> A light colored dog splashes through the water . <end>',\n",
              "  '<start> A tan dog splashing in water on the bank of a pond or river . <end>',\n",
              "  '<start> A white dog is splashing through the water . <end>'],\n",
              " 'Flicker8k_Dataset/260828892_7925d27865.jpg': ['<start> a lone person walking in the distance on a long beach . <end>',\n",
              "  '<start> A man is walking on the beach and leaving some footprints behind <end>',\n",
              "  '<start> A person walks along the beach and leaves footprints in the sand . <end>',\n",
              "  '<start> A woman in a black dress is leaving footprints in the sand as she walks towards the ocean . <end>',\n",
              "  '<start> woman walking on sand leaving footprints <end>'],\n",
              " 'Flicker8k_Dataset/3243233886_235a80e8c7.jpg': ['<start> A child in a red child plays on playground equipment . <end>',\n",
              "  '<start> A little kid plays on the equipment at the park . <end>',\n",
              "  '<start> A small blond child wearing a red jacket climbs on a playground . <end>',\n",
              "  '<start> Blond child wearing a red jacket and crawling on playground equipment . <end>',\n",
              "  '<start> The kid at the playground has a red sweater on . <end>'],\n",
              " 'Flicker8k_Dataset/2346401538_f5e8da66fc.jpg': ['<start> A woman holding onto a camera smiling at the camera . <end>',\n",
              "  '<start> A woman with a blue hat and blue and red jacket setting up a camera on a tripod . <end>',\n",
              "  '<start> A woman with a camera on a tripod is smiling for another camera . <end>',\n",
              "  '<start> People at a photo shoot . <end>',\n",
              "  '<start> The woman in blue is operating a camera in front of two other women . <end>'],\n",
              " 'Flicker8k_Dataset/1425919702_ddb761aeec.jpg': ['<start> A crowd of people are sitting in seats in a sports ground bleachers . <end>',\n",
              "  '<start> a group of people sitting at a sporting event . <end>',\n",
              "  '<start> A group of people sit watching an event behind a Tim hortons sign . <end>',\n",
              "  '<start> People wait patiently in the seats for the show to begin . <end>',\n",
              "  '<start> Two men wearing hats are shown at the front of a crowd of people . <end>'],\n",
              " 'Flicker8k_Dataset/2283966256_70317e1759.jpg': ['<start> A brown dog walks on the rocks near a river . <end>',\n",
              "  '<start> A dog is walking through some gravel beside a river . <end>',\n",
              "  '<start> A dog with a snub nose smells for somthing on a riverbank . <end>',\n",
              "  '<start> A large brown dog is walking along side a river . <end>',\n",
              "  '<start> a large tan bulldog walking along the rocky shore of a small stream . <end>'],\n",
              " 'Flicker8k_Dataset/1428578577_82864facae.jpg': ['<start> Two hikers wearing dark clothes rest on a snow covered peak . <end>',\n",
              "  '<start> Two people pose for a picture amidst a snowy , rocky landscape . <end>',\n",
              "  '<start> Two people standing at the edge of a snow covered cliff . <end>',\n",
              "  '<start> Two people standing on top of a rock in the middle of snow and cloud . <end>',\n",
              "  '<start> Two people stand on the edge of a recently snowed on cliff . <end>'],\n",
              " 'Flicker8k_Dataset/3410215754_5d5caeffaf.jpg': ['<start> Boys at an amphitheater . <end>',\n",
              "  '<start> Four guys are posed on a stone platform . <end>',\n",
              "  '<start> Four guys in front of a abandoned building trying to make a letter with their bodies <end>',\n",
              "  '<start> four kids playfully pose in unusual architectural structure <end>',\n",
              "  '<start> Four kids pose on a stage . <end>'],\n",
              " 'Flicker8k_Dataset/3457856049_2de173e818.jpg': ['<start> a boy is creating large splashes whilst swimming in the ocean . <end>',\n",
              "  '<start> A boy with black hair and dark skin is swimming in murky water . <end>',\n",
              "  '<start> A child splashes in a lake . <end>',\n",
              "  '<start> A little boy jumped into the water and made a big splash . <end>',\n",
              "  '<start> A young boy falling into a body of water . <end>'],\n",
              " 'Flicker8k_Dataset/3048380686_732db55281.jpg': ['<start> A goalie blocking the goal with assistance from a teammate during a hockey game . <end>',\n",
              "  '<start> A hockey player tries to make a goal while the goalie and another player look on . <end>',\n",
              "  '<start> A hockey play shooting for a goal in a professional game . <end>',\n",
              "  '<start> Hockey players scramble in front of the goal . <end>',\n",
              "  '<start> The goalie with the white jersey allowed a goal by the player on the red team . <end>'],\n",
              " 'Flicker8k_Dataset/3459362347_c412ef9901.jpg': ['<start> A woman and two elderly men are standing in front of a speaker . <end>',\n",
              "  '<start> A woman and two men wearing black jackets . <end>',\n",
              "  '<start> A woman and two men wearing hats and glassess are standing under a avrovulcan.com sign . <end>',\n",
              "  '<start> A woman and two older gentlemen who are both wearing hats . <end>',\n",
              "  '<start> Three older people stand in front of an avrovulcan.com sign . <end>'],\n",
              " 'Flicker8k_Dataset/3291255271_a185eba408.jpg': ['<start> A boy leans on a baseball bat and holds out one arm outstreached . <end>',\n",
              "  '<start> A child with a hat stands with a bat . <end>',\n",
              "  '<start> A young boy poses in a field with a baseball bat . <end>',\n",
              "  '<start> A young boy with a baseball bat holing his arm out . <end>',\n",
              "  '<start> The boy is wearing a green cap and holding a black baseball bat . <end>'],\n",
              " 'Flicker8k_Dataset/213216174_0632af65a2.jpg': ['<start> A boy dives into a pool near a water slide . <end>',\n",
              "  '<start> A boy in blue swim trunks dives into a swimming pool while two adults look on . <end>',\n",
              "  '<start> A kid playing in a swimming pool . <end>',\n",
              "  '<start> A young boy wearing a blue bathing suit flies through the air above a swimming pool . <end>',\n",
              "  '<start> the boy is diving into the pool as the couple watch . <end>'],\n",
              " 'Flicker8k_Dataset/2341254813_c53a5ef27a.jpg': ['<start> a boy in a green shirt is jumping with his arms in the air at the end of a bowling alley . <end>',\n",
              "  '<start> A boy wearing a green shirt is jumping in front of a lane at a bowling alley . <end>',\n",
              "  '<start> A child jumps in the air at a bowling alley . <end>',\n",
              "  '<start> A young boy with a Mohawk and green shirt is excited about bowling . <end>',\n",
              "  '<start> A young boy with a Mohawk jumping at a bowling alley <end>'],\n",
              " 'Flicker8k_Dataset/3357937209_cf4a9512ac.jpg': ['<start> A black sheep with three white dogs . <end>',\n",
              "  '<start> four white dogs are standing beside a black sheep . <end>',\n",
              "  '<start> The white dogs look curiously at the black llama . <end>',\n",
              "  '<start> Three white dogs are near a black llama . <end>',\n",
              "  '<start> White dogs stand near a sheep or llama . <end>'],\n",
              " 'Flicker8k_Dataset/3106562372_e349a27764.jpg': ['<start> A girl in a dress is jumping in the air with legs bent while another girl in pink watches . <end>',\n",
              "  '<start> a girl jumps into the air while another girl watches . <end>',\n",
              "  '<start> A young girl is jumping on carpet while another girl standing in front of her looks to the left . <end>',\n",
              "  '<start> The two little girls jump on the bed . <end>',\n",
              "  '<start> Two little girls jump above the floor . <end>'],\n",
              " 'Flicker8k_Dataset/772403830_08b72c7da9.jpg': ['<start> A boy wearing black shorts is jumping into the ocean . <end>',\n",
              "  '<start> A child in swimming trunks jumping into the ocean . <end>',\n",
              "  '<start> A child jumps over ocean waves at a beach . <end>',\n",
              "  '<start> A child wearing blue and white shorts is jumping in the surf . <end>',\n",
              "  '<start> A little boy in black shorts is jumping in the water at the beach . <end>'],\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "strip_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
        "strip_chars = strip_chars.replace(\"<\", \"\")\n",
        "strip_chars = strip_chars.replace(\">\", \"\")\n",
        "\n",
        "vectorization = TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=SEQ_LENGTH,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "vectorization.adapt(text_data)\n",
        "\n",
        "# Data augmentation for image data\n",
        "image_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.2),\n",
        "        layers.RandomContrast(0.3),\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "qDY_YhXMS3mo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_and_resize(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMAGE_SIZE)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    return img\n",
        "\n",
        "\n",
        "def process_input(img_path, captions):\n",
        "    return decode_and_resize(img_path), vectorization(captions)\n",
        "\n",
        "\n",
        "def make_dataset(images, captions):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, captions))\n",
        "    dataset = dataset.shuffle(BATCH_SIZE * 8)\n",
        "    dataset = dataset.map(process_input, num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Pass the list of images and the list of corresponding captions\n",
        "train_dataset = make_dataset(list(train_data.keys()), list(train_data.values()))\n",
        "\n",
        "valid_dataset = make_dataset(list(valid_data.keys()), list(valid_data.values()))\n"
      ],
      "metadata": {
        "id": "bJ6JFROfW2G7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX2iDTanYS5y",
        "outputId": "fe34c3c0-9714-4eb2-bc0c-14f4ed5ecedd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, captions in train_dataset.take(1):\n",
        "    print(captions)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrDKhslwYbh-",
        "outputId": "00660eb2-8849-4432-fc29-713f5af42bb0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[   3    2   12 ...    0    0    0]\n",
            "  [   3    2   12 ...    0    0    0]\n",
            "  [   3    2   12 ...    0    0    0]\n",
            "  [   3    2   12 ...    0    0    0]\n",
            "  [   3   44   38 ...    0    0    0]]\n",
            "\n",
            " [[   3    2  114 ...    0    0    0]\n",
            "  [   3    2 1493 ...    0    0    0]\n",
            "  [   3    2   12 ...    0    0    0]\n",
            "  [   3    2   12 ...    0    0    0]\n",
            "  [   3   12    5 ...    0    0    0]]\n",
            "\n",
            " [[   3    2  251 ...    0    0    0]\n",
            "  [   3    2   12 ...    0    0    0]\n",
            "  [   3    2  269 ...    0    0    0]\n",
            "  [   3    2  269 ...    0    0    0]\n",
            "  [   3  269 1368 ...    0    0    0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[   3   14   81 ...    0    0    0]\n",
            "  [   3   14  694 ...    0    0    0]\n",
            "  [   3   14 6014 ...    0    0    0]\n",
            "  [   3   14  101 ...    0    0    0]\n",
            "  [   3   14   27 ...    0    0    0]]\n",
            "\n",
            " [[   3    2  580 ...    0    0    0]\n",
            "  [   3    2   53 ...    0    0    0]\n",
            "  [   3    2   15 ...    0    0    0]\n",
            "  [   3    2   15 ...    0    0    0]\n",
            "  [   3    6   39 ...    0    0    0]]\n",
            "\n",
            " [[   3    2   39 ...    0    0    0]\n",
            "  [   3    2   27 ...    0    0    0]\n",
            "  [   3    2   27 ...    0    0    0]\n",
            "  [   3    2   27 ...    0    0    0]\n",
            "  [   3    6   20 ...    0    0    0]]], shape=(64, 5, 25), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cnn_model():\n",
        "    base_model = efficientnet.EfficientNetB0(\n",
        "        input_shape=(*IMAGE_SIZE, 3),\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "    )\n",
        "    # We freeze our feature extractor\n",
        "    base_model.trainable = False\n",
        "    base_model_out = base_model.output\n",
        "    base_model_out = layers.Reshape((-1, base_model_out.shape[-1]))(base_model_out) # (batch, sequence, dim) as input for encoder\n",
        "    cnn_model = keras.models.Model(base_model.input, base_model_out)\n",
        "    return cnn_model"
      ],
      "metadata": {
        "id": "BwgP4XFeYtC1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim, dropout=0.0\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.dense_1 = layers.Dense(embed_dim, activation=\"relu\")\n",
        "\n",
        "    def call(self, inputs, training, mask=None):\n",
        "        inputs = self.layernorm_1(inputs)\n",
        "        inputs = self.dense_1(inputs)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=None,\n",
        "            training=training,\n",
        "        )\n",
        "        out_1 = self.layernorm_2(inputs + attention_output_1)\n",
        "        return out_1"
      ],
      "metadata": {
        "id": "1dtDNkdrbuge"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.embed_scale = tf.math.sqrt(tf.cast(embed_dim, tf.float32))\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_tokens = embedded_tokens * self.embed_scale\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)"
      ],
      "metadata": {
        "id": "bJi_pMsGc6e5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, ff_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.ff_dim = ff_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim, dropout=0.1\n",
        "        )\n",
        "        self.ffn_layer_1 = layers.Dense(ff_dim, activation=\"relu\")\n",
        "        self.ffn_layer_2 = layers.Dense(embed_dim)\n",
        "\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "\n",
        "        self.embedding = PositionalEmbedding(\n",
        "            embed_dim=EMBED_DIM,\n",
        "            sequence_length=SEQ_LENGTH,\n",
        "            vocab_size=VOCAB_SIZE,\n",
        "        )\n",
        "        self.out = layers.Dense(VOCAB_SIZE, activation=\"softmax\")\n",
        "\n",
        "        self.dropout_1 = layers.Dropout(0.3)\n",
        "        self.dropout_2 = layers.Dropout(0.5)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, training, mask=None):\n",
        "        inputs = self.embedding(inputs)\n",
        "        causal_mask = self.get_causal_attention_mask(inputs) # (batch, sequence, sequence)\n",
        "\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, :, tf.newaxis], dtype=tf.int32) # (batch, sequence, 1)\n",
        "            combined_mask = tf.cast(mask[:, tf.newaxis, :], dtype=tf.int32) # (batch, 1, sequence)\n",
        "            combined_mask = tf.minimum(combined_mask, causal_mask) # (batch, sequence, sequence)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=combined_mask,\n",
        "            training=training,\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "            training=training,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        ffn_out = self.ffn_layer_1(out_2)\n",
        "        ffn_out = self.dropout_1(ffn_out, training=training)\n",
        "        ffn_out = self.ffn_layer_2(ffn_out)\n",
        "\n",
        "        ffn_out = self.layernorm_3(ffn_out + out_2, training=training)\n",
        "        ffn_out = self.dropout_2(ffn_out, training=training)\n",
        "        preds = self.out(ffn_out)\n",
        "        return preds\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        # input: (batch, sequence, projection_dim)\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis] # (sequence, 1)\n",
        "        j = tf.range(sequence_length) # (sequence)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\") # (sequence, sequence)\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1])) # (1, sequence, sequence)\n",
        "        mult = tf.concat(\n",
        "            [\n",
        "                tf.expand_dims(batch_size, -1),\n",
        "                tf.constant([1, 1], dtype=tf.int32),\n",
        "            ],\n",
        "            axis=0,\n",
        "        ) # (batch, 1, 1)\n",
        "        return tf.tile(mask, mult) # (batch, sequence, sequence)"
      ],
      "metadata": {
        "id": "wWBe432AdT7e"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageCaptioningModel(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        cnn_model,\n",
        "        encoder,\n",
        "        decoder,\n",
        "        num_captions_per_image=5,\n",
        "        image_aug=None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.cnn_model = cnn_model\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.acc_tracker = keras.metrics.Mean(name=\"accuracy\")\n",
        "        self.num_captions_per_image = num_captions_per_image\n",
        "        self.image_aug = image_aug\n",
        "\n",
        "    def calculate_loss(self, y_true, y_pred, mask):\n",
        "        \"\"\"\n",
        "        mask: (batch, sequence)\n",
        "        y_true: (batch, sequence)\n",
        "        y_pred: (batch, sequence, vocab_size)\n",
        "        loss: (batch, sequence)\n",
        "        \"\"\"\n",
        "        loss = self.loss(y_true, y_pred)\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask\n",
        "        return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "\n",
        "    def calculate_accuracy(self, y_true, y_pred, mask):\n",
        "        \"\"\"\n",
        "        mask: (batch, sequence)\n",
        "        y_true: (batch, sequence)\n",
        "        y_pred: (batch, sequence, vocab_size)\n",
        "        tf.argmax(y_pred): (batch, sequence)\n",
        "        \"\"\"\n",
        "        accuracy = tf.equal(y_true, tf.argmax(y_pred, axis=2))\n",
        "        accuracy = tf.math.logical_and(mask, accuracy)\n",
        "        accuracy = tf.cast(accuracy, dtype=tf.float32)\n",
        "        mask = tf.cast(mask, dtype=tf.float32)\n",
        "        return tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n",
        "\n",
        "    # The method is only used in the class\n",
        "    def _compute_caption_loss_and_acc(self, img_embed, batch_seq, training=True):\n",
        "        encoder_out = self.encoder(img_embed, training=training)\n",
        "        batch_seq_inp = batch_seq[:, :-1]\n",
        "        batch_seq_true = batch_seq[:, 1:]\n",
        "        mask = tf.math.not_equal(batch_seq_true, 0)\n",
        "        batch_seq_pred = self.decoder(\n",
        "            batch_seq_inp, encoder_out, training=training, mask=mask\n",
        "        )\n",
        "        loss = self.calculate_loss(batch_seq_true, batch_seq_pred, mask)\n",
        "        acc = self.calculate_accuracy(batch_seq_true, batch_seq_pred, mask)\n",
        "        return loss, acc\n",
        "\n",
        "    def train_step(self, batch_data):\n",
        "        batch_img, batch_seq = batch_data\n",
        "        batch_loss = 0\n",
        "        batch_acc = 0\n",
        "\n",
        "        if self.image_aug:\n",
        "            batch_img = self.image_aug(batch_img)\n",
        "\n",
        "        # 1. Get image embeddings\n",
        "        img_embed = self.cnn_model(batch_img)\n",
        "\n",
        "        # 2. Pass each of the five captions one by one to the decoder\n",
        "        # along with the encoder outputs and compute the loss as well as accuracy\n",
        "        # for each caption.\n",
        "        for i in range(self.num_captions_per_image):\n",
        "            with tf.GradientTape() as tape:\n",
        "                loss, acc = self._compute_caption_loss_and_acc(\n",
        "                    img_embed, batch_seq[:, i, :], training=True\n",
        "                )\n",
        "\n",
        "                # 3. Update loss and accuracy\n",
        "                batch_loss += loss\n",
        "                batch_acc += acc\n",
        "\n",
        "            # 4. Get the list of all the trainable weights\n",
        "            train_vars = (\n",
        "                self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "            )\n",
        "\n",
        "            # 5. Get the gradients\n",
        "            grads = tape.gradient(loss, train_vars)\n",
        "\n",
        "            # 6. Update the trainable weights\n",
        "            self.optimizer.apply_gradients(zip(grads, train_vars))\n",
        "\n",
        "        # 7. Update the trackers\n",
        "        batch_acc /= float(self.num_captions_per_image)\n",
        "        # all_loss/= float(self.num_captions_per_image)\n",
        "        self.loss_tracker.update_state(batch_loss)\n",
        "        self.acc_tracker.update_state(batch_acc)\n",
        "\n",
        "        # 8. Return the loss and accuracy values\n",
        "        return {\n",
        "            \"loss\": self.loss_tracker.result(),\n",
        "            \"acc\": self.acc_tracker.result(),\n",
        "        }\n",
        "\n",
        "    def test_step(self, batch_data):\n",
        "        batch_img, batch_seq = batch_data\n",
        "        batch_loss = 0\n",
        "        batch_acc = 0\n",
        "\n",
        "        # 1. Get image embeddings\n",
        "        img_embed = self.cnn_model(batch_img)\n",
        "\n",
        "        # 2. Pass each of the five captions one by one to the decoder\n",
        "        # along with the encoder outputs and compute the loss as well as accuracy\n",
        "        # for each caption.\n",
        "        for i in range(self.num_captions_per_image):\n",
        "            loss, acc = self._compute_caption_loss_and_acc(\n",
        "                img_embed, batch_seq[:, i, :], training=False\n",
        "            )\n",
        "\n",
        "            # 3. Update batch loss and batch accuracy\n",
        "            batch_loss += loss\n",
        "            batch_acc += acc\n",
        "\n",
        "        batch_acc /= float(self.num_captions_per_image)\n",
        "\n",
        "        # 4. Update the trackers\n",
        "        self.loss_tracker.update_state(batch_loss)\n",
        "        # all_loss/= float(self.num_captions_per_image)\n",
        "        self.acc_tracker.update_state(batch_acc)\n",
        "\n",
        "        # 5. Return the loss and accuracy values\n",
        "        return {\n",
        "            \"loss\": self.loss_tracker.result(),\n",
        "            \"acc\": self.acc_tracker.result(),\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We need to list our metrics here so the `reset_states()` can be\n",
        "        # called automatically.\n",
        "        return [self.loss_tracker, self.acc_tracker]"
      ],
      "metadata": {
        "id": "zqtPpFIafBOC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = get_cnn_model()\n",
        "encoder = TransformerEncoderBlock(embed_dim=EMBED_DIM, dense_dim=FF_DIM, num_heads=1)\n",
        "decoder = TransformerDecoderBlock(embed_dim=EMBED_DIM, ff_dim=FF_DIM, num_heads=2)\n",
        "caption_model = ImageCaptioningModel(\n",
        "    cnn_model=cnn_model,\n",
        "    encoder=encoder,\n",
        "    decoder=decoder,\n",
        "    image_aug=image_augmentation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5O3oR5_txWh",
        "outputId": "9a8bd4d7-8646-408a-b5f9-fd5dec81c4d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    reduction=None,\n",
        ")\n",
        "\n",
        "# EarlyStopping criteria\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# Learning Rate Scheduler for the optimizer\n",
        "class LRSchedule(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, post_warmup_learning_rate, warmup_steps):\n",
        "        super().__init__()\n",
        "        self.post_warmup_learning_rate = post_warmup_learning_rate\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        global_step = tf.cast(step, tf.float32)\n",
        "        warmup_steps = tf.cast(self.warmup_steps, tf.float32)\n",
        "        warmup_progress = global_step / warmup_steps\n",
        "        warmup_learning_rate = self.post_warmup_learning_rate * warmup_progress\n",
        "        return tf.cond(\n",
        "            global_step < warmup_steps,\n",
        "            lambda: warmup_learning_rate,\n",
        "            lambda: self.post_warmup_learning_rate,\n",
        "        )\n",
        "\n",
        "\n",
        "# Create a learning rate schedule\n",
        "num_train_steps = len(train_dataset) * EPOCHS\n",
        "num_warmup_steps = num_train_steps // 15\n",
        "lr_schedule = LRSchedule(post_warmup_learning_rate=1e-4, warmup_steps=num_warmup_steps)\n",
        "\n",
        "# Compile the model\n",
        "caption_model.compile(optimizer=keras.optimizers.Adam(lr_schedule), loss=cross_entropy)\n",
        "\n",
        "# Fit the model\n",
        "caption_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_dataset,\n",
        "    callbacks=[early_stopping],\n",
        ")"
      ],
      "metadata": {
        "id": "D-NdjIpJt_ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vectorization.get_vocabulary()\n",
        "index_lookup = dict(zip(range(len(vocab)), vocab))\n",
        "max_decoded_sentence_length = SEQ_LENGTH - 1\n",
        "valid_images = list(valid_data.keys())"
      ],
      "metadata": {
        "id": "LinlOVOdxBOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_caption():\n",
        "    # Select a random image from the validation dataset\n",
        "    sample_img = np.random.choice(valid_images)\n",
        "\n",
        "    # Read the image from the disk\n",
        "    sample_img = decode_and_resize(sample_img)\n",
        "    img = sample_img.numpy().clip(0, 255).astype(np.uint8)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "    # Pass the image to the CNN\n",
        "    img = tf.expand_dims(sample_img, 0)\n",
        "    img = caption_model.cnn_model(img)\n",
        "\n",
        "    # Pass the image features to the Transformer encoder\n",
        "    encoded_img = caption_model.encoder(img, training=False)\n",
        "\n",
        "    # Generate the caption using the Transformer decoder\n",
        "    decoded_caption = \"<start> \"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_caption = vectorization([decoded_caption])[:, :-1] # Eliminate the token <end>\n",
        "        mask = tf.math.not_equal(tokenized_caption, 0)\n",
        "        predictions = caption_model.decoder(\n",
        "            tokenized_caption, encoded_img, training=False, mask=mask\n",
        "        )\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = index_lookup[sampled_token_index]\n",
        "        if sampled_token == \"<end>\":\n",
        "            break\n",
        "        decoded_caption += \" \" + sampled_token\n",
        "\n",
        "    decoded_caption = decoded_caption.replace(\"<start> \", \"\")\n",
        "    decoded_caption = decoded_caption.replace(\" <end>\", \"\").strip()\n",
        "    print(\"Predicted Caption: \", decoded_caption)\n",
        "\n",
        "\n",
        "# Check predictions for a few samples\n",
        "generate_caption()\n",
        "generate_caption()\n",
        "generate_caption()"
      ],
      "metadata": {
        "id": "8QVncKnEu3WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2, 3, 4, 5"
      ],
      "metadata": {
        "id": "Yba8X5XTrA6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(1/4)*(2++3+4+5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE0EYX2PrDZU",
        "outputId": "b5b50c0f-d371-45a4-f652-f83dc991a253"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "((1/2)*(2+3) + (1/2)*(4+5))/2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WCU0Nd9rI4O",
        "outputId": "a19f12d9-946b-4424-a76e-d267adcd4d86"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bibliothèque vs Module vs Framework**"
      ],
      "metadata": {
        "id": "A8db_sKVwEvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De manière générale, une bibliothèque (tensorflow, numpy, pandas, ...) Python est constituée d'une collection de modules (tf.keras, tf.audio, math, os, random, datetime, json, ...). C'est la somme des modules standards qui sont considérés comme des outils à fichier unique. Si le module est une salle regroupant plusieurs objets, la bibliothèque sera considérée comme le musée qui abrite la salle. La bibliothèque regroupe donc un ensemble de fonctions différentes ayant chacune une fonction spécifique. Le module est un fichier exécutable contrairement à la bibliothèque.\n"
      ],
      "metadata": {
        "id": "20hb6TE3wKuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une bibliothèque on l'installe avec **pip**<br>\n",
        "Un module on l'import directement, c'est générélament un fichier **.py** (Sur tensorflow un module  contient des sous modules)."
      ],
      "metadata": {
        "id": "7-gE8YjJyCEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.keras est un module<br>\n",
        "keras est une API d'apprentissage automatique (Une API est un ensemble de règles et de protocoles qui permettent à un logiciel d'interagir avec un autre.) Dans ce contexte, Keras permet aux développeurs de définir, de configurer et de former des modèles d'apprentissage automatique de manière plus intuitive et simplifiée.<br>\n",
        "\n",
        "Keras agit comme une couche d'abstraction au-dessus de bibliothèques d'apprentissage automatique sous-jacentes, telles que TensorFlow. Cela signifie que vous pouvez utiliser Keras pour définir et entraîner des modèles, et Keras se charge de communiquer avec la bibliothèque d'apprentissage automatique sous-jacente pour effectuer les calculs nécessaires. (voir https://www.tensorflow.org/api_docs/python/tf)"
      ],
      "metadata": {
        "id": "rc5gYYZUyg5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.gather\n",
        "tf.nn.embedding_lookup\n",
        "tf.einsum\n",
        "tf.not_equal\n",
        "tf.logical_and\n",
        "tf.cast\n",
        "a[:, tf.newaxis]\n",
        "tf.squeeze # éliminer axe\n",
        "tf.tile"
      ],
      "metadata": {
        "id": "E2xqilaVqyk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.gather**"
      ],
      "metadata": {
        "id": "Zm3SNx-NuHfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example tensor\n",
        "tensor = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Indices to gather\n",
        "indices = tf.constant([0, 2])\n",
        "\n",
        "# Gather values along axis 0\n",
        "result = tf.gather(tensor, indices, axis=0)\n",
        "\n",
        "print(result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtuLepD1uJfj",
        "outputId": "74015e56-db25-4989-d649-a291a3d5a51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example tensor\n",
        "tensor = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# Indices to gather62.48%\n",
        "indices = tf.constant([0, 1])\n",
        "\n",
        "# Gather values along axis 1\n",
        "result = tf.gather(tensor, indices, axis=1)\n",
        "\n",
        "result.numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VAmsqJnuPGL",
        "outputId": "4e1a249a-e213-404f-edc5-85cf2640ddda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4],\n",
              "       [5, 6]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.nn.embedding_lookup**"
      ],
      "metadata": {
        "id": "cNt548HJvPXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example embedding matrix\n",
        "embedding_matrix = tf.constant([[0.1, 0.2, 0.3],\n",
        "                               [0.4, 0.5, 0.6],\n",
        "                               [0.7, 0.8, 0.9]])\n",
        "\n",
        "# Indices to look up\n",
        "indices = tf.constant([0, 2])\n",
        "\n",
        "# Perform embedding lookup\n",
        "embeddings = tf.nn.embedding_lookup(embedding_matrix, indices)\n",
        "\n",
        "# Resulting embeddings\n",
        "print(embeddings.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1q_XkL2vSse",
        "outputId": "fd341eb7-9337-44dd-d545-6dd3d5db7052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.1 0.2 0.3]\n",
            " [0.7 0.8 0.9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example embedding matrix\n",
        "embedding_matrix = tf.constant([[0.1, 0.2, 0.3],\n",
        "                               [0.4, 0.5, 0.6],\n",
        "                               [0.7, 0.8, 0.9]])\n",
        "\n",
        "# Indices to look up\n",
        "indices = tf.constant([1])\n",
        "\n",
        "# Perform embedding lookup\n",
        "embeddings = tf.nn.embedding_lookup(embedding_matrix, indices)\n",
        "\n",
        "# Resulting embeddings\n",
        "print(embeddings.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYbtCfpzvo_V",
        "outputId": "6c20a7f6-f904-45d5-de59-d2f16cdba153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.4 0.5 0.6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.einsum**"
      ],
      "metadata": {
        "id": "CjQB276Lvtli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example usage of tf.einsum\n",
        "# Let's multiply two matrices A and B\n",
        "A = tf.constant([[1, 2], [3, 4]])\n",
        "B = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "# Using tf.einsum for matrix multiplication\n",
        "result = tf.einsum('ij,jk->ik', A, B)\n",
        "\n",
        "# Display the result\n",
        "print(result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_EKgjabvxdc",
        "outputId": "b4ae4abd-43b9-46c3-e1a8-60a143865e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19 22]\n",
            " [43 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example usage of tf.einsum\n",
        "# Let's multiply two matrices A and B\n",
        "A = tf.constant([[1, 2], [3, 4]])\n",
        "B = tf.constant([[5, 6], [7, 8]])\n",
        "\n",
        "# Using tf.einsum for matrix product *\n",
        "result = tf.einsum('ij,ij->ij', A, B)\n",
        "\n",
        "# Display the result\n",
        "print(result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nlToKOFwIH3",
        "outputId": "e5cf2f3c-8140-43e7-d161-407a9b5e2bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5 12]\n",
            " [21 32]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Example usage of tf.einsum for summing matrix elements\n",
        "A = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Compute the sum of matrix elements using tf.einsum\n",
        "matrix_sum = tf.einsum('ij->', A)\n",
        "\n",
        "# Display the result\n",
        "print(matrix_sum.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nsyYe7nxOye",
        "outputId": "5380c526-5433-45ad-cb59-61d0c5ed1b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.not_equal**"
      ],
      "metadata": {
        "id": "S9mhMqDSxUY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define two tensors\n",
        "tensor1 = tf.constant([1, 2, 3, 4, 5])\n",
        "tensor2 = tf.constant([5, 4, 3, 2, 1])\n",
        "\n",
        "# Use tf.not_equal to check element-wise inequality\n",
        "not_equal_result = tf.not_equal(tensor1, tensor2)\n",
        "\n",
        "# Display the result\n",
        "print(not_equal_result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjLEO84FxTkw",
        "outputId": "aa9d07f2-47ed-4524-e1b3-1ac9f362e667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True False  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define two tensors\n",
        "tensor1 = tf.constant([1, 0, 3, 0, 5])\n",
        "\n",
        "# Use tf.not_equal to check element-wise inequality\n",
        "not_equal_result = tf.not_equal(tensor1, 0)\n",
        "\n",
        "# Display the result\n",
        "print(not_equal_result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLvrh3tMx4G6",
        "outputId": "6e0f54b1-5b7b-4ade-80b0-2b0088e7355c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True False  True False  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.logical_and - tf.logical_or - tf.logical_xor**"
      ],
      "metadata": {
        "id": "kQXGJl33yM0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define two boolean tensors\n",
        "tensor1 = tf.constant([True, True, False, False])\n",
        "tensor2 = tf.constant([True, False, True, False])\n",
        "\n",
        "# Use tf.logical_and for element-wise logical AND\n",
        "result = tf.logical_and(tensor1, tensor2)\n",
        "\n",
        "# Display the result\n",
        "print(result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI_pmOKUymft",
        "outputId": "5d2cfeb6-be26-44b8-9be0-1251a86b45c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True False False False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define two boolean tensors\n",
        "tensor1 = tf.constant([True, True, False, False])\n",
        "\n",
        "# Use tf.logical_and for element-wise logical AND\n",
        "result = tf.logical_and(tensor1, True)\n",
        "\n",
        "# Display the result\n",
        "print(result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhgybdAiyrpr",
        "outputId": "9d95e910-5e69-4fad-c330-d2fca2b7549a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True False False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.cast**"
      ],
      "metadata": {
        "id": "qyEWrWhIy2Nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define two boolean tensors\n",
        "tensor1 = tf.constant([True, True, False, False])\n",
        "\n",
        "# Use tf.logical_and for element-wise logical AND\n",
        "result = tf.logical_and(tensor1, True)\n",
        "\n",
        "# Display the result\n",
        "print(result.numpy())\n",
        "result_to_int = tf.cast(result, dtype=\"int32\")\n",
        "print(result_to_int.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1RvvJzly43x",
        "outputId": "78d4be82-8872-44e5-ffb5-20f88b2fe721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ True  True False False]\n",
            "[1 1 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define a tensor with float32 data type\n",
        "float_tensor = tf.constant([1.5, 2.8, 3.2], dtype=tf.float32)\n",
        "\n",
        "# Use tf.cast to convert the tensor to int32 data type\n",
        "int_tensor = tf.cast(float_tensor, dtype=tf.int32)\n",
        "\n",
        "# Display the original and converted tensors\n",
        "print(\"Original Tensor (float32):\", float_tensor.numpy())\n",
        "print(\"Converted Tensor (int32):\", int_tensor.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y49Yazvxzgwu",
        "outputId": "52eea649-d2f1-4798-fd02-0bcf5d37665a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor (float32): [1.5 2.8 3.2]\n",
            "Converted Tensor (int32): [1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.newaxis**"
      ],
      "metadata": {
        "id": "VkKFBd_Dz0VJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a 1D tensor\n",
        "tensor_1d = tf.constant([1, 2, 3, 4])\n",
        "\n",
        "# Add a new axis to convert it to a 2D tensor\n",
        "tensor_2d = tensor_1d[:, tf.newaxis] # tensor_2d_alternative = tf.expand_dims(tensor_1d, axis=1)\n",
        "\n",
        "# Display the original and reshaped tensors\n",
        "print(\"Original Tensor (1D):\", tensor_1d.numpy()) # (3)\n",
        "print(\"Reshaped Tensor (2D):\", tensor_2d.numpy()) # (3, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc3E44D-z2d6",
        "outputId": "75deff68-27ad-4bb5-b5d2-3d4a03e96c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor (1D): [1 2 3 4]\n",
            "Reshaped Tensor (2D): [[1]\n",
            " [2]\n",
            " [3]\n",
            " [4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.squeeze**"
      ],
      "metadata": {
        "id": "LttWiqms0a5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a tensor with shape (1, 3, 1, 4)\n",
        "tensor_with_singleton_dims = tf.constant([[[[1, 2, 3, 4]]]])\n",
        "\n",
        "# Squeeze the tensor to remove singleton dimensions\n",
        "squeezed_tensor = tf.squeeze(tensor_with_singleton_dims)\n",
        "\n",
        "# Display the original and squeezed tensors\n",
        "print(\"Original Tensor:\", tensor_with_singleton_dims.numpy())\n",
        "print(\"Squeezed Tensor:\", squeezed_tensor.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8mCHk3o0c1e",
        "outputId": "e1381deb-6f26-4c77-d7ec-538cad1a6d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor: [[[[1 2 3 4]]]]\n",
            "Squeezed Tensor: [1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squeezed_tensor_axis = tf.squeeze(tensor_with_singleton_dims, axis=(0, 2)) # remove axis 0 and 2\n",
        "\n",
        "# Display the tensor after squeezing specified dimensions\n",
        "print(\"Squeezed Tensor (specified dimensions):\", squeezed_tensor_axis.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBS5hUq-0vUV",
        "outputId": "fc10405b-bd4d-49a5-ba6a-42603ce36631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squeezed Tensor (specified dimensions): [[1 2 3 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.tile**"
      ],
      "metadata": {
        "id": "dlxLrz3k03Cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a tensor with shape (2, 3)\n",
        "original_tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# Use tf.tile to replicate the tensor along specified dimensions\n",
        "tiled_tensor = tf.tile(original_tensor, multiples=[2, 1]) # dupliquer l'axe 0 2fois et l'axe 1 1fois\n",
        "\n",
        "# Display the original and tiled tensors\n",
        "print(\"Original Tensor:\")\n",
        "print(original_tensor.numpy())\n",
        "\n",
        "print(\"\\nTiled Tensor:\")\n",
        "print(tiled_tensor.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNaO4uIF07L2",
        "outputId": "f73bbc32-e203-4375-897b-98f283930376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "Tiled Tensor:\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tiled_tensor_2d = tf.tile(original_tensor, multiples=[2, 2]) # dupliquer l'axe 0 2fois et l'axe 1 2fois\n",
        "\n",
        "print(\"\\nTiled Tensor (2D):\")\n",
        "print(tiled_tensor_2d.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWLCTYQg13FN",
        "outputId": "0503dd82-d1e8-4f46-f23a-5a5f0181da34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tiled Tensor (2D):\n",
            "[[1 2 3 1 2 3]\n",
            " [4 5 6 4 5 6]\n",
            " [1 2 3 1 2 3]\n",
            " [4 5 6 4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.minimum** or **tf.maximum**"
      ],
      "metadata": {
        "id": "FiC_5uT6qL85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "3315psKBqUno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = tf.constant([\n",
        "    [\n",
        "        [1,0,0,0],\n",
        "        [1,1,0,0],\n",
        "        [1,1,1,0],\n",
        "        [1,1,1,1],\n",
        "    ]\n",
        "])\n",
        "q.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epzBmyP9qZnW",
        "outputId": "0921cdda-6247-488e-cf3a-4643c2a5b5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = tf.constant([\n",
        "    [1,1,0,1]\n",
        "])\n",
        "v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8kH0fs_qgxU",
        "outputId": "568dd22f-1816-4712-abc3-df53311e17f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.minimum(q, v[:, :, tf.newaxis]) # le premier 1 est comparé avec le premier vecteur de q; le deuxième 1 avec le deuxième vecteur ainsi de suite."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWFvZ0jtqjaI",
        "outputId": "1d867d4b-fe49-4222-c796-9aa63454e1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 4, 4), dtype=int32, numpy=\n",
              "array([[[1, 0, 0, 0],\n",
              "        [1, 1, 0, 0],\n",
              "        [0, 0, 0, 0],\n",
              "        [1, 1, 1, 1]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "    Math Operations:\n",
        "        tf.add: Element-wise addition.\n",
        "        tf.subtract: Element-wise subtraction.\n",
        "        tf.multiply: Element-wise multiplication.\n",
        "        tf.divide: Element-wise division.\n",
        "        tf.square: Element-wise square.\n",
        "        tf.sqrt: Element-wise square root.\n",
        "\n",
        "    Reduction Operations:\n",
        "        tf.reduce_sum: Computes the sum of elements along specified dimensions.\n",
        "        tf.reduce_mean: Computes the mean of elements along specified dimensions.\n",
        "        tf.reduce_max: Computes the maximum value along specified dimensions.\n",
        "        tf.reduce_min: Computes the minimum value along specified dimensions.\n",
        "\n",
        "    Activation Functions:\n",
        "        tf.nn.relu: Rectified Linear Unit (ReLU) activation function.\n",
        "        tf.nn.sigmoid: Sigmoid activation function.\n",
        "        tf.nn.tanh: Hyperbolic Tangent (tanh) activation function.\n",
        "\n",
        "    Loss Functions:\n",
        "        tf.losses.mean_squared_error: Mean Squared Error loss.\n",
        "        tf.losses.softmax_cross_entropy: Softmax Cross-Entropy loss.\n",
        "\n",
        "    Optimizers:\n",
        "        tf.optimizers.Adam: Adam optimizer.\n",
        "        tf.optimizers.SGD: Stochastic Gradient Descent (SGD) optimizer.\n",
        "\n",
        "    Matrix Operations:\n",
        "        tf.matmul: Matrix multiplication.\n",
        "        tf.linalg.inv: Computes the matrix inverse.\n",
        "\n",
        "    Random Operations:\n",
        "        tf.random.normal: Generates random values from a normal distribution.\n",
        "        tf.random.uniform: Generates random values from a uniform distribution.\n",
        "\n",
        "    Indexing and Slicing:\n",
        "        tf.gather: Gathers slices from a tensor along a specified axis.\n",
        "        tf.slice: Extracts a slice from a tensor."
      ],
      "metadata": {
        "id": "TuoKRr8q3G6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.reshape and tf.permute**"
      ],
      "metadata": {
        "id": "jz5W__wIhhH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = [[1, 2, 3],\n",
        "     [4, 5, 6]]"
      ],
      "metadata": {
        "id": "pABqd7F4hkMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.reshape(t, [3, 2]).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7pSkUMLhnWH",
        "outputId": "9c1836b9-4eb1-452b-b7b4-1c62c603b7dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4],\n",
              "       [5, 6]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.transpose(t, perm=[1, 0]).numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNAfMQk1hpjE",
        "outputId": "3b38047c-cf17-4713-a66b-2054f09ddfb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 4],\n",
              "       [2, 5],\n",
              "       [3, 6]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss et accuracy sans tenir compte le padding**"
      ],
      "metadata": {
        "id": "uVrVpL3sRF19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cas des labels sous forme de vecteur**"
      ],
      "metadata": {
        "id": "OHge8GUYRgbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "bQDirRmbMgOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=\"none\")"
      ],
      "metadata": {
        "id": "MxSWH71VMklg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = tf.constant([\n",
        "    [1,2,3,0,0],\n",
        "    [2,1,0,0,0]\n",
        "])\n",
        "y_true.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8KnovxEM5p0",
        "outputId": "66c335fb-1aba-4806-8b18-e8891281c633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = tf.random.normal((2,5,4))\n",
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY9R1CH_NKTI",
        "outputId": "079fa51f-7ea5-4af2-d5b4-147a504eb23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_loss = loss(y_true, y_pred)\n",
        "my_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo-xmx3RNia1",
        "outputId": "dd7d391f-7478-4141-d053-d1bc04a40f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
              "array([[0.6720696, 2.0252216, 1.1525719, 2.2148185, 1.1491641],\n",
              "       [1.2105818, 1.571936 , 1.6144471, 1.7997637, 2.2102833]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = tf.not_equal(y_true, 0)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRpmPB2aP0M4",
        "outputId": "24153125-5e61-4a0b-a7ea-552e245b3df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, False, False],\n",
              "       [ True,  True, False, False, False]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = tf.cast(mask, dtype=my_loss.dtype)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQIRI5NXP_Xl",
        "outputId": "7dfd2a4d-3af9-4b75-ca35-09255cb12ddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
              "array([[1., 1., 1., 0., 0.],\n",
              "       [1., 1., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_with_mask = my_loss*mask\n",
        "loss_with_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MftyLZ-zP_d7",
        "outputId": "df91835a-3b01-4ad9-95da-7708b194b174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
              "array([[0.6720696, 2.0252216, 1.1525719, 0.       , 0.       ],\n",
              "       [1.2105818, 1.571936 , 0.       , 0.       , 0.       ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_loss = tf.reduce_sum(loss_with_mask)/tf.reduce_sum(mask)\n",
        "final_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3ISZB2-Q5bs",
        "outputId": "7c2d8668-1a70-4b11-da3c-0828360cdfed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=1.3264761>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cas des labels sous forme de sequence**"
      ],
      "metadata": {
        "id": "CmInkdHORUal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=\"none\")\n"
      ],
      "metadata": {
        "id": "ayUjVw-wOv6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBJjtuO_SjG2",
        "outputId": "b22b141e-74df-4a91-8913-b03b02a95288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
              "array([[0.6720696, 2.0252216, 1.1525719, 2.2148185, 1.1491641],\n",
              "       [1.2105818, 1.571936 , 1.6144471, 1.7997637, 2.2102833]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = tf.constant([\n",
        "    [1,2,3,0,0],\n",
        "    [2,1,0,0,0]\n",
        "])\n",
        "y_true.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUFNbRL1O0YJ",
        "outputId": "d2053e5f-e8fc-4a00-ebab-cb05ef934cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = tf.constant([\n",
        "    [\n",
        "        [0,1,0,0],\n",
        "        [0,0,1,0],\n",
        "        [0,0,0,1],\n",
        "        [1,0,0,0],\n",
        "        [1,0,0,0]\n",
        "    ],\n",
        "    [\n",
        "        [0,0,1,0],\n",
        "        [0,1,0,0],\n",
        "        [1,0,0,0],\n",
        "        [1,0,0,0],\n",
        "        [1,0,0,0]\n",
        "    ]\n",
        "])\n",
        "y_true.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmySRWNtN44l",
        "outputId": "3d977bca-d19a-4fd7-f7af-1cb6ec83de9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = tf.random.normal((2,5,4))\n",
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7oB3j12O7-F",
        "outputId": "1fddba56-35f0-43d2-dc09-2495c9b16976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohdWRWmjPBiN",
        "outputId": "6aaec503-0bf6-4cc5-fbe0-a0d9ae126cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=float32, numpy=\n",
              "array([[3.207738  , 0.9270947 , 1.3194504 , 2.437703  , 2.453485  ],\n",
              "       [3.755856  , 3.2157564 , 1.2249858 , 0.85812813, 1.892122  ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**accuracy**"
      ],
      "metadata": {
        "id": "K0ZrhKAScKiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = tf.constant([\n",
        "    [1,2,3,0,0],\n",
        "    [2,1,0,0,0]\n",
        "])\n",
        "y_true.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpzFCiuzcMZA",
        "outputId": "0f8a6fc3-37bb-4b1b-e6a5-7ebe81829fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = tf.random.normal((2,5,4))\n",
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-52wjmbccUnM",
        "outputId": "345c3564-24af-4b2a-b5d8-e792a16e1385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 sur si pad not 0 and 0 otherwise\n",
        "mask = tf.not_equal(y_true, 0)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngnwLlH-cWpB",
        "outputId": "69f05b7d-6a7c-4b66-b7cc-3763530d28bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, False, False],\n",
              "       [ True,  True, False, False, False]])>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "prediction = tf.argmax(y_pred, axis=-1)\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYy7Tz0kcu5h",
        "outputId": "3bc7efd9-d1a9-4806-c2d8-6cbd1e2dcef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              "array([[1, 1, 3, 1, 0],\n",
              "       [2, 3, 1, 0, 3]])>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_prediction = tf.equal(tf.cast(y_true, dtype=prediction.dtype), prediction)\n",
        "correct_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHDyVcYFdcGK",
        "outputId": "392cf5eb-1221-460a-e497-1157d99afe45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=bool, numpy=\n",
              "array([[ True, False,  True, False,  True],\n",
              "       [ True, False, False,  True, False]])>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On sauvegarde que les True dans prediction et don le padding est différent 0\n",
        "return_prediction = tf.logical_and(mask, correct_prediction)\n",
        "return_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEftz3khd9pK",
        "outputId": "aea2f129-cd31-4dfe-badd-4d284c0495f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=bool, numpy=\n",
              "array([[ True, False,  True, False, False],\n",
              "       [ True, False, False, False, False]])>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert return_prediction\n",
        "return_prediction = tf.cast(return_prediction, dtype=\"int32\")\n",
        "return_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnYFhABgeZqU",
        "outputId": "0c369e90-d0b0-452e-b4f9-f0b02418d162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
              "array([[1, 0, 1, 0, 0],\n",
              "       [1, 0, 0, 0, 0]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = tf.reduce_sum(return_prediction)/tf.reduce_sum(tf.cast(mask, dtype=\"int32\"))\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veWCaJAqenF_",
        "outputId": "31a56d4a-d4c0-4382-8a42-5248264f2a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float64, numpy=0.6>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()"
      ],
      "metadata": {
        "id": "uQaHQbodoQbG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}