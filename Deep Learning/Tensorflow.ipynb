{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "PKIp_xaO5psn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>KERAS.LOSSES</h1></center>**<br>\n",
        "Dans keras.losses, on a des fonctions et des classes:<br>\n",
        "1. **keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True)** est une fonction qu'on directement utilisée dans tf.GradientTape.<br>\n",
        "2. **a = keras.losses.CategoricalCrossentropy(from_logits=True)** est une classe, on fait **a(y_true, y_pred)**.<br>\n",
        "On a aussi **KERAS.METRICS**, **KERAS.OPTIMIZERS**, ETC.<br>\n",
        "\n",
        "**<center><h1>Training Keras Model</h1></center>**<br>\n",
        "On peut noter **04** approches:<br>\n",
        "1. **fit:** c'est la méthode standard.<br>\n",
        "\n",
        "2. **keras.Model:** Créer une classe qui hérite de la classe **keras.models.Model** or **keras.Model**. Cette classe doit implémenter **train_step** qui utilise **tf.GradientTape** pour mettre à jour les **poids** du modèle par **batch**. On peut aussi implémenter **test_step** pour le test, **call** pour le **forward**, **metrics** qui retourne la liste des métriques (mise à jour), **computer_loss** pour retourner la **loss**.<br>\n",
        "\n",
        "3. **@tf.function:** Créer une fonction en la faisant précédée par **@tf.function**. Cette approche permet à la fonction créée de pouvoir être compiler c'est à dire utiliser le **tf.GradientTape**. La fonction ainsi créée peut être utilisée dans une fonction qui fait une boucle sur le nombre d'époques et donne entrée **batch** par **batch** à la fonction qui met à jour les poids suivant les batchs donnés.<br>\n",
        "\n",
        "4. **train_on_batch:** C'est une **méthode** de la classe Model de keras, tout modèle de keras peut donc y accéder. On crée d'abord un modèle **model**, on utilise d'abord une boucle sur le nombre d'époque suivie d'une boucle qui prend **batch par batch**, on fait à chaque fois **model.train_on_batch(x_batch, y_batch)** qui retourne la **loss** sur le batch et les métriques si c'es définit dans le compile de **model**.<br>\n",
        "\n",
        "**<center><h1>Passage par valeur des modèles</h1></center>**<br>\n",
        "Supposons qu'on ait 03 modèles: <br>\n",
        "\n",
        "**model1 = tf.keras.models.Sequential()**<br>\n",
        "**model2 = tf.keras.models.Sequential()**<br>\n",
        "**model3 = tf.keras.models.Sequential()**<br>\n",
        "\n",
        "**model3.add(model1**)<br>\n",
        "**mdoel3.model1.trainable = False** <br>\n",
        "**model3.add(model2)**<br>\n",
        "\n",
        "model1 est utilisé dans model3, même si c'est son trainable=False, toute modification (mise à jour) fait sur model1 en dehors va se répercuter sur model3.model1, même si les modifications sont faites à l'intérieur d'une fonction.<br>\n",
        "**NB:** Dès qu'on crée un modèle, on l'utilise pour intialiser ou l'affecter ou à un autre modèle les modifications apportées sur un de ces modèles affectent le modèle de base. Voir la section: Method using train_on_batch.<br>\n",
        "\n",
        "**<center><h1>Bahdanau Attention</h1></center>**<br>\n",
        "C'est une attention additive, l'objectif est de prendre l'état caché du decoder comme query et le output de l'encoder comme value pour produre un vecteur de contexte. Le vecteur de contexte est concaténé avec l'embedding de l'entrée du decoder (qui prend token par token), et sert d'entrée à la couche rnn, lstm ou gru.<br>\n",
        "\n",
        "Q = Decoder hidden state (None, decoder_unit)<br>\n",
        "    at the begining, Q = Encoder hidden state<br>\n",
        "\n",
        "V = Encoder output (None, sequence, feature)<br>\n",
        "\n",
        "Q = tf.expand_dims(Q, axis=1) # (None, 1, decoder_unit)<br>\n",
        "EncQ = Dense1(Q) # (None, 1, units)<br>\n",
        "EncV = Dense2(V) # (None, sequence, units)<br>\n",
        "sum = tf.nn.tanh(EncQ+EncV) # activation (None, sequence, units)<br>\n",
        "\n",
        "score = Dense3(sum) # (None, sequence, 1)<br>\n",
        "attention = tf.nn.softmax(score, axis=1) # (None, sequence, 1) softmax based on token position<br>\n",
        "\n",
        "context_vector = attention*V # (None, sequence, feature)<br>\n",
        "context_vector = tf.nn.sum(context_vector, axis=1) # (None, feature)<br>\n",
        "\n",
        "context_vector sera utilisé dans le decoder et concaténer avec l'entrée (qui se fait token par token)<br>\n",
        "x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # (None, 1, feature+embedding_dim_x) x vient de l'embedding x est de type (None, 1) car on traite par token Embedding donne (None, 1, embedding_dim_x)<br>\n",
        "\n",
        "\n",
        "**<center><h1>Paramètres et Sorties</h1></center>**<br>\n",
        "\n",
        "**<h2>MLP (Dense)</h2>**<br>\n",
        "**1. Sortie:** Si l'entrée est de dimension 2, la sortie sera **(None, units)**, si l'entrée est de dimension 3 (séquences), la sortie sera **(None, sequence, units)**, si l'entrée est de dimension 4 (convolutions ou images), la sortie sera **(None, H, W, units)**.<br>\n",
        "\n",
        "**2. Paramètres:** **D*W + W**, avec D la dimension de l'entrée, W le nombre de units.<br>\n",
        "\n",
        "**<h2>CNN (Conv2D)</h2>**<br>\n",
        "**1. Sortie:** **math.floor((n - f + p) / s) + 1**, avec n la taille de l'entrée, f la taille du filtre, p = f - 1 si padding = 'same' et p = 0 si padding='valid', s est la taille du stride. ON considère la partie entière inférieure.<br>\n",
        "**NB:** Si conv2DTranspose ou UpSampling2D, on effectue l'opération inverse **s × (n + f - p)**.<br>\n",
        "\n",
        "\n",
        "**Paramètres:** Le nombre de paramètres de la couche, dépend du nombre de canal de la couche précédente. La couche actuelle contient par exemple 2 filtres, et que la couche précédente contient 3 canaux, le filtre 1 va être dupliqué sur les 3 canaux et si la taille du filtre est (2, 2), donc y aura 3 × (2 × 2) paramètres à apprendre avec le même biais donc 3 × (2 × 2) + 1. Le même processus s'applique sur le filtre 2. La formule générale est alors:<br> <center>**(hauteur_filtre × largeur_filtre × nombre_canaux_couche_precedente + 1 ) × nombre_filtres**</center><br>\n",
        "\n",
        "**Les couches de Pooling n'ont pas de paramètres à apprendre**<br>\n",
        "\n",
        "\n",
        "**<h2>RNN</h2>**<br>\n",
        "**1. Sortie:** Par défaut, retourne (None, units). Si return_sequences = True, (None, sequence, units). Si return_state = True, on aura deux outputs, (None, units), (None, units). Si return_sequences=True et return_state=True on aura (None, sequence, units), (None, units).<br>\n",
        "**NB:** Ceci est valable pour les **GRU**, pour les **LSTM**, return_sate=True donne deux état (None, units) pour hidden_state et (None, units) pour cell_state.\n",
        "\n",
        "**2. Paramètres:** L'entrée correspond à deux vecteurs concaténés: x (dernière dimension de l'entrée: **shape[-1]**) et h. x le token d'entrée et h l'état caché.<br>\n",
        "**<center>RNN: (x + h) × h + h</center>**<br>\n",
        "**<center>LSTM: 4 × [(x + h) × h + h] </center>** <br>\n",
        "**<center>GRU: 3 × [(x + h) × h + h]</center>**"
      ],
      "metadata": {
        "id": "jjT2qFZpM6_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calcul de AP (Average Precision) et mAP (mean Average Precision)**<br>\n",
        "https://www.youtube.com/watch?v=FppOzcDvaDI&list=PL3Q9L9bKi20IatsPIesEJeu6JYBY-Wk1G&index=3&t=394s"
      ],
      "metadata": {
        "id": "0eORfXkDK1LI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random projection: https://scikit-learn.org/stable/modules/random_projection.html"
      ],
      "metadata": {
        "id": "Lq6mGpSwiTck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. loss = tf.losses.BinaryCrossEntropy(): loss(y_true, y_pred) fait la somme et retourne une seule valeur\n",
        "   Pour que loss soit une liste, il faut mettre reduction = 'none' sur la classe BinaryCrossEtropy(reduction='none')\n",
        "\n",
        "2. loss = tf.losses.binary_crossentropy(y_true, y_pred) retourne une liste de loss\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YrM0wXLO4CQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
        "# GradientTape permet d'effectuer une opération différentielle\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  y = x * x\n",
        "dy_dx = g.gradient(y, x)\n",
        "print(dy_dx)"
      ],
      "metadata": {
        "id": "005CLkXttZDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(5.0)\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  with tf.GradientTape() as gg:\n",
        "    gg.watch(x)\n",
        "    y = x * x\n",
        "  dy_dx = gg.gradient(y, x)  # dy_dx = 2 * x\n",
        "d2y_dx2 = g.gradient(dy_dx, x)  # d2y_dx2 = 2\n",
        "\n",
        "\n",
        "print(dy_dx)\n",
        "print(d2y_dx2)\n"
      ],
      "metadata": {
        "id": "Eflq0DJeuTe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persitent = True permet d'appeller le tape plusieurs fois\n",
        "\n",
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape(persistent=True) as g:\n",
        "  g.watch(x)\n",
        "  y = x * x\n",
        "  z = y * y\n",
        "dz_dx = g.gradient(z, x)  # (4*x^3 at x = 3)\n",
        "print(dz_dx)\n",
        "\n",
        "dy_dx = g.gradient(y, x)\n",
        "print(dy_dx)\n",
        "\n",
        "\"\"\"\n",
        "NB: si on utilise un modèle sans watch, par défaut toutes les trainable_variables sont mis dans watch de manière implicite, donc on a pas besoin de le spéficier\n",
        "    car les poids sont des tf.Variable pas des tf.constant, et par défaut un tf.Variable est directement mis dans watch.\n",
        "    Si on veut enléver cet effet par défaut, on utilise le paramètre watch_accessed_variables=False (voir exemple suivant)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "vRkS-ESJud2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(2.0) # watch actif par défaut\n",
        "w = tf.Variable(5.0) # watch actif par défaut\n",
        "with tf.GradientTape(\n",
        "    watch_accessed_variables=False, persistent=True) as tape:\n",
        "  tape.watch(x)\n",
        "  y = x ** 2  # Gradients will be available for `x`.\n",
        "  z = w ** 3  # No gradients will be available as `w` isn't being watched.\n",
        "dy_dx = tape.gradient(y, x)\n",
        "print(dy_dx) # tf.Tensor(4.0, shape=(), dtype=tf.float32)\n",
        "\n",
        "# No gradients will be available as `w` isn't being watched.\n",
        "dz_dw = tape.gradient(z, w)\n",
        "print(dz_dw) # None"
      ],
      "metadata": {
        "id": "zHgbIm1lvk4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.keras.layers.Dense(32)\n",
        "b = tf.keras.layers.Dense(32)\n",
        "\n",
        "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
        "  tape.watch(a.variables)  # Since `a.build` has not been called at this point\n",
        "                           # `a.variables` will return an empty list and the\n",
        "                           # tape will not be watching anything. a.variables = []\n",
        "  result = b(a(inputs))\n",
        "\n",
        "tape.gradient(result, a.variables)  # The result of this computation will be\n",
        "                                      # a list of `None`s since a's variables\n",
        "                                      # are not being watched."
      ],
      "metadata": {
        "id": "ADEwaXi7w4JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept: GradientTape**"
      ],
      "metadata": {
        "id": "QRjAeZCYzgh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "@propety:\n",
        "En Python, @property est un décorateur utilisé pour définir une méthode au sein d'une classe qui agit comme un attribut en lecture seule.\n",
        "Lorsqu'une classe hérite d'une autre classe, la notation @property sur une méthode permet à la classe dérivée d'accéder à cette méthode comme\n",
        "un attribut en lecture seule sans avoir besoin d'appeler explicitement la méthode. Cela permet d'encapsuler la logique de calcul d'un attribut au\n",
        "sein de la classe et de fournir un accès plus propre à cet attribut pour les classes dérivées.\n",
        "\n",
        "@tf.function est un décorateur, qui permet de transformer une fonction en un graphe de calcul tensorflow.\n",
        "Il permet dans certains contextes d'accélérer le calcul. IL est conseillé si la fonction contient\n",
        "des opérations tensorflow.\n",
        "\"\"\"\n",
        "\n",
        "class BaseClass:\n",
        "    def __init__(self, value):\n",
        "        self._value = value\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self._value\n",
        "\n",
        "class DerivedClass(BaseClass):\n",
        "    def __init__(self, value, extra):\n",
        "        super().__init__(value)\n",
        "        self.extra = extra\n",
        "\n",
        "# Utilisation\n",
        "obj = DerivedClass(42, \"extra_data\")\n",
        "print(obj.value)  # Accès à l'attribut \"value\" comme s'il s'agissait d'un attribut direct\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Dans cet exemple, la classe BaseClass définit un attribut en lecture seule value en utilisant @property.\n",
        "La classe dérivée DerivedClass peut y accéder comme si c'était un attribut direct,\n",
        "même si la logique pour le calcul de value est encapsulée dans BaseClass.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "Avec metrics, si on fait self.metrics on aura une liste de metriques\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "oCw6DA5jc2zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# *args\n",
        "\"\"\"\n",
        "En Python, *args est une syntaxe utilisée pour permettre à une fonction de recevoir un nombre variable d'arguments positionnels. Lorsque vous\n",
        "utilisez *args comme paramètre dans la définition d'une fonction, cela signifie que la fonction peut accepter\n",
        "un nombre arbitraire d'arguments positionnels, et ces arguments seront regroupés dans un tuple.\n",
        "\"\"\"\n",
        "def fonction_avec_args(arg1, *args):\n",
        "    print(\"arg1:\", arg1)\n",
        "    print(\"args:\", args)\n",
        "\n",
        "# Utilisation de la fonction\n",
        "fonction_avec_args(1, 2, 3, 4, 5)\n",
        "\n",
        "\"\"\"\n",
        "Dans cet exemple, arg1 est un argument positionnel classique, tandis que *args est utilisé pour collecter tous les arguments positionnels supplémentaires dans un tuple appelé args.\n",
        "Lorsque la fonction est appelée avec plusieurs arguments après arg1, ils sont automatiquement regroupés dans le tuple args. Vous pouvez ensuite parcourir ce tuple pour traiter\n",
        "les arguments supplémentaires comme vous le souhaitez.\n",
        "\n",
        "L'utilisation de *args est courante lorsque vous devez définir une fonction qui peut prendre un nombre\n",
        "variable d'arguments, par exemple, pour implémenter des fonctions génériques ou des wrappers autour d'autres fonctions.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9ZyZwFOPgC00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# **kwargs\n",
        "\"\"\"\n",
        "\n",
        "En Python, **kwargs est une syntaxe similaire à *args, mais elle est utilisée pour permettre à une fonction de recevoir un nombre variable d'arguments mots-clés (ou paramètres nommés). Lorsque vous utilisez **kwargs\n",
        "comme paramètre dans la définition d'une fonction, cela signifie que la fonction peut accepter un nombre arbitraire d'arguments mots-clés, et ces arguments seront regroupés dans un dictionnaire.\n",
        "\"\"\"\n",
        "\n",
        "def fonction_avec_kwargs(arg1, **kwargs):\n",
        "    print(\"arg1:\", arg1)\n",
        "    print(\"kwargs:\", kwargs)\n",
        "\n",
        "# Utilisation de la fonction\n",
        "fonction_avec_kwargs(1, a=2, b=3, c=4)\n",
        "\n",
        "\"\"\"\n",
        "Dans cet exemple, arg1 est un argument positionnel classique, tandis que **kwargs est utilisé pour collecter tous les\n",
        "arguments mots-clés supplémentaires dans un dictionnaire appelé kwargs. Lorsque la fonction est appelée avec des arguments mots-clés supplémentaires (par exemple, a=2, b=3, c=4),\n",
        "ces arguments sont regroupés dans le dictionnaire kwargs, où les noms des arguments sont les clés et leurs valeurs sont les valeurs correspondantes.\n",
        "\n",
        "L'utilisation de **kwargs est courante lorsque vous devez définir une fonction qui peut accepter un nombre variable d'arguments mots-clés, ce qui peut être utile pour personnaliser\n",
        "le comportement d'une fonction ou pour transmettre un grand nombre de paramètres de manière plus flexible.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aeH49dHHgle5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OBAyQqIzcx8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "EXAMPLE : LOSS IS NOT GIVEN IN COMPILE\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_states()` yourself at the time of your choosing.\n",
        "        return [self.loss_tracker, self.mae_metric] ## List all metrics\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute our own loss\n",
        "            loss = keras.losses.mean_squared_error(y, y_pred) ## if loss if given in comile, we can use by self.compute_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars)) ## optimizer is given in self.optimizer\n",
        "\n",
        "        # Compute our own metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()} ## bar progress for user {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        # Compute predictions\n",
        "        y_pred = self(x, training=False) ## Freeze weights\n",
        "        loss = keras.losses.mean_squared_error(y, y_pred)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "# Construct an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "# We don't passs a loss or metrics here.\n",
        "model.compile(optimizer=\"adam\")\n",
        "\n",
        "# Just use `fit` as usual -- you can use callbacks, etc.\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "model.fit(x, y, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EXAMPLE : LOSS IS GIVEN IN COMPILE\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_states()` yourself at the time of your choosing.\n",
        "        return [self.loss_tracker, self.mae_metric] ## List all metrics\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute our own loss\n",
        "            loss = self.compute_loss(y, y_pred) ### Changed line\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars)) ## optimizer is given in self.optimizer\n",
        "\n",
        "        # Compute our own metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()} ## bar progress for user {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        # Compute predictions\n",
        "        y_pred = self(x, training=False) ## Freeze weights\n",
        "        loss = self.compute_loss(y, y_pred) ### Changed line\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "# Construct an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "# We don't passs a loss or metrics here.\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Just use `fit` as usual -- you can use callbacks, etc.\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "model.fit(x, y, epochs=5)"
      ],
      "metadata": {
        "id": "keMpVnjq4d6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EXAMPLE: PONDERATION OF CLASSES USING WEIGHTS\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        if len(data) == 3:\n",
        "            x, y, sample_weight = data\n",
        "        else:\n",
        "            sample_weight = None\n",
        "            x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute the loss value.\n",
        "            # The loss function is configured in `compile()`.\n",
        "            loss = self.compute_loss(\n",
        "                y=y,\n",
        "                y_pred=y_pred,\n",
        "                sample_weight=sample_weight,\n",
        "            )\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics.\n",
        "        # Metrics are configured in `compile()`.\n",
        "        for metric in self.metrics:\n",
        "            if metric.name == \"loss\":\n",
        "                metric.update_state(loss)\n",
        "            else:\n",
        "                metric.update_state(y, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        "# Construct and compile an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# You can now use sample_weight argument\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "sw = np.random.random((1000, 1))\n",
        "model.fit(x, y, sample_weight=sw, epochs=3)"
      ],
      "metadata": {
        "id": "okfA_q-F6f4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept - GAN EXAMPLE: GradientTape**"
      ],
      "metadata": {
        "id": "W4skGjP66yW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create the discriminator\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
        "        layers.Dense(7 * 7 * 128),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((7, 7, 128)),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ],
      "metadata": {
        "id": "XxDQ3-Av64lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_loss_tracker = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_tracker = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape: ##  We can either use with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics and return their value.\n",
        "        self.d_loss_tracker.update_state(d_loss)\n",
        "        self.g_loss_tracker.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_tracker.result(),\n",
        "            \"g_loss\": self.g_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "JoWOgMs76-ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset. We use both the training & test MNIST digits.\n",
        "batch_size = 64\n",
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "# To limit the execution time, we only train on 100 batches. You can train on\n",
        "# the entire dataset. You will need about 20 epochs to get nice results.\n",
        "gan.fit(dataset.take(100), epochs=1)"
      ],
      "metadata": {
        "id": "6FQZPGe17JJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept - Image and Text Similarity: GradientTape**"
      ],
      "metadata": {
        "id": "-LGdVM2_Atrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EXAMPLE: In this example, the loss is computing on the class\n",
        "         the optimizer is given in compile, we use self.optimizer to use it.\n",
        "         https://keras.io/examples/vision/nl_image_search/\n",
        "\"\"\"\n",
        "class DualEncoder(keras.Model):\n",
        "    def __init__(self, text_encoder, image_encoder, temperature=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.text_encoder = text_encoder\n",
        "        self.image_encoder = image_encoder\n",
        "        self.temperature = temperature\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def call(self, features, training=False):\n",
        "        # Place each encoder on a separate GPU (if available).\n",
        "        # TF will fallback on available devices if there are fewer than 2 GPUs.\n",
        "        with tf.device(\"/gpu:0\"):\n",
        "            # Get the embeddings for the captions.\n",
        "            caption_embeddings = text_encoder(features[\"caption\"], training=training)\n",
        "        with tf.device(\"/gpu:1\"):\n",
        "            # Get the embeddings for the images.\n",
        "            image_embeddings = vision_encoder(features[\"image\"], training=training)\n",
        "        return caption_embeddings, image_embeddings\n",
        "\n",
        "    def compute_loss(self, caption_embeddings, image_embeddings):\n",
        "        # logits[i][j] is the dot_similarity(caption_i, image_j).\n",
        "        logits = (\n",
        "            tf.matmul(caption_embeddings, image_embeddings, transpose_b=True)\n",
        "            / self.temperature\n",
        "        )\n",
        "        # images_similarity[i][j] is the dot_similarity(image_i, image_j).\n",
        "        images_similarity = tf.matmul(\n",
        "            image_embeddings, image_embeddings, transpose_b=True\n",
        "        )\n",
        "        # captions_similarity[i][j] is the dot_similarity(caption_i, caption_j).\n",
        "        captions_similarity = tf.matmul(\n",
        "            caption_embeddings, caption_embeddings, transpose_b=True\n",
        "        )\n",
        "        # targets[i][j] = avarage dot_similarity(caption_i, caption_j) and dot_similarity(image_i, image_j).\n",
        "        targets = keras.activations.softmax(\n",
        "            (captions_similarity + images_similarity) / (2 * self.temperature)\n",
        "        )\n",
        "        # Compute the loss for the captions using crossentropy\n",
        "        captions_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=targets, y_pred=logits, from_logits=True\n",
        "        )\n",
        "        # Compute the loss for the images using crossentropy\n",
        "        images_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=tf.transpose(targets), y_pred=tf.transpose(logits), from_logits=True\n",
        "        )\n",
        "        # Return the mean of the loss over the batch.\n",
        "        return (captions_loss + images_loss) / 2\n",
        "\n",
        "    def train_step(self, features):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            caption_embeddings, image_embeddings = self(features, training=True)\n",
        "            loss = self.compute_loss(caption_embeddings, image_embeddings)\n",
        "        # Backward pass\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        # Monitor loss\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def test_step(self, features):\n",
        "        caption_embeddings, image_embeddings = self(features, training=False)\n",
        "        loss = self.compute_loss(caption_embeddings, image_embeddings)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}"
      ],
      "metadata": {
        "id": "593tvL0vA2nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5  # In practice, train for at least 30 epochs\n",
        "batch_size = 256\n",
        "\n",
        "vision_encoder = create_vision_encoder(\n",
        "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
        ")\n",
        "text_encoder = create_text_encoder(\n",
        "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
        ")\n",
        "dual_encoder = DualEncoder(text_encoder, vision_encoder, temperature=0.05)\n",
        "dual_encoder.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.001)\n",
        ")"
      ],
      "metadata": {
        "id": "nnK4nwxM7qFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept - Relevant method for GAN - @tf.function: GradientTape**"
      ],
      "metadata": {
        "id": "WOJ400nj8UxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "\n",
        "# save checkpoints\n",
        "checkpoint_dir = \"training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator=discriminator)\n",
        "\n",
        "# Constant\n",
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal((num_examples_to_generate, noise_dim))\n",
        "\n",
        "# @tf.function enables to use compile with train_step\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "# Train function\n",
        "def train(datasets, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for img_batch in datasets:\n",
        "            train_step(img_batch)\n",
        "\n",
        "        # Produce images for the GIF\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator,\n",
        "                                epoch+1,\n",
        "                                seed)\n",
        "\n",
        "        # Save the model every 15 epochs\n",
        "        if (epoch+1)%15 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "\n",
        "        print(\"Time for epoch {} is {} sec\".format(epoch+1, time.time()-start))\n",
        "\n",
        "    # Generate after the final epoch\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                                epoch,\n",
        "                                seed)\n",
        "\n",
        "# Predicion\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4,4,i+1)\n",
        "        plt.imshow(predictions[i, :, :, :]*127.5 + 127.5)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('generated_image/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "# Train\n",
        "train(train_dataset, EPOCHS)\n",
        "\n",
        "# Restore\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# Plot\n",
        "def display_image(epoch):\n",
        "    return PIL.Image.open(\"generated_image/image_at_epoch_{:04d}.png\".format(epoch))\n",
        "display_image(EPOCHs)"
      ],
      "metadata": {
        "id": "UltzLG6r8fMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We can use an other approach\n",
        "\"\"\"\n",
        "# @tf.function enables to use compile with train_step\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "        # Train discriminator\n",
        "        noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
        "        generated_images = generator.predict(noise)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Train generator\n",
        "        noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
        "        generated_images = generator(noise, training=True)\n",
        "        fake_output = discriminator(generated_images, training=False)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n"
      ],
      "metadata": {
        "id": "a-kBS1vQAVn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method using train_on_batch**"
      ],
      "metadata": {
        "id": "cX1lFt5UEtua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This method use an other approach for training : train_on_batch\n",
        "https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch/\n",
        "\"\"\"\n",
        "\n",
        "# Define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(32, 32, 3)):\n",
        "    in_image = Input(shape=in_shape)\n",
        "    # Normal\n",
        "    x = Conv2D(64, (3, 3), padding='same')(in_image)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Downsample\n",
        "    x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Downsample\n",
        "    x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Downsample\n",
        "    x = Conv2D(256, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Classifier\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(in_image, x)\n",
        "\n",
        "    # Compile model\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "    in_lat = Input(shape=(latent_dim,))\n",
        "    # Foundation for 4x4 image\n",
        "    n_nodes = 256 * 4 * 4\n",
        "    x = Dense(n_nodes)(in_lat)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Reshape((4, 4, 256))(x)\n",
        "\n",
        "    # Upsample to 8x8\n",
        "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Upsample to 16x16\n",
        "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Upsample to 32x32\n",
        "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = Conv2D(3, (3, 3), activation='tanh', padding='same')(x)\n",
        "\n",
        "    model = Model(in_lat, x)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4vUhW-GkEzQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Define the gan model that combine discriminator that is frozen and generator that is not frozen\n",
        "NB: Freeze discriminator\n",
        "    Not Freeze generator\n",
        "\"\"\"\n",
        "def define_gan(g_model, d_model):\n",
        "    # make weights in the discriminator not trainable\n",
        "    d_model.trainable = False\n",
        "    # connect them\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(g_model)\n",
        "    # add the discriminator\n",
        "    model.add(d_model)\n",
        "    # compile model\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Wqy5HvpEJYBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and prepare cifar10 training images\n",
        "def load_real_samples():\n",
        "    # load cifar10 dataset\n",
        "    (trainX, _), (_, _) = load_data()\n",
        "    # convert from unsigned ints to floats\n",
        "    X = trainX.astype('float32')\n",
        "    # scale from [0,255] to [-1,1]\n",
        "    X = (X - 127.5) / 127.5\n",
        "    return X\n",
        "\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "    # choose random instances\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    # retrieve selected images\n",
        "    X = dataset[ix]\n",
        "    # generate 'real' class labels (1)\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # generate points in the latent space\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    # reshape into a batch of inputs for the network\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    # generate points in latent space\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    # predict outputs\n",
        "    X = g_model.predict(x_input, verbose=0)\n",
        "    # create 'fake' class labels (0)\n",
        "    y = zeros((n_samples, 1))\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "oNd7sF7mLGin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create and save a plot of generated images\n",
        "def save_plot(examples, epoch, n=7):\n",
        "     # scale from [-1,1] to [0,1]\n",
        "     examples = (examples + 1) / 2.0\n",
        "     # plot images\n",
        "     for i in range(n * n):\n",
        "         # define subplot\n",
        "         pyplot.subplot(n, n, 1 + i)\n",
        "         # turn off axis\n",
        "         pyplot.axis('off')\n",
        "         # plot raw pixel data\n",
        "         pyplot.imshow(examples[i])\n",
        "     # save plot to file\n",
        "     filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "     pyplot.savefig(filename)\n",
        "     pyplot.show()"
      ],
      "metadata": {
        "id": "bmrZgAQYLRTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n",
        "     # prepare real samples\n",
        "     X_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "     # evaluate discriminator on real examples\n",
        "     _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "     # prepare fake examples\n",
        "     x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "     # evaluate discriminator on fake examples\n",
        "     _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "     # summarize discriminator performance\n",
        "     print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "     # save plot\n",
        "     save_plot(x_fake, epoch)\n",
        "     # save the generator model tile file\n",
        "     filename = 'generator_model_%03d.h5' % (epoch+1)\n",
        "     g_model.save(filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "k8xdX-hMLodD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):\n",
        "     bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "     half_batch = int(n_batch / 2)\n",
        "     # manually enumerate epochs\n",
        "     for i in range(n_epochs):\n",
        "     # enumerate batches over the training set\n",
        "         for j in range(bat_per_epo):\n",
        "            \"\"\"\n",
        "              Train the discriminator\n",
        "              NB: The same discriminator and generator is used in all training\n",
        "            \"\"\"\n",
        "             # get randomly selected 'real' samples\n",
        "             X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "             # update discriminator model weights\n",
        "             d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "             # generate 'fake' examples\n",
        "             X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "             # update discriminator model weights\n",
        "             d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "              Train the generator\n",
        "            \"\"\"\n",
        "             # prepare points in latent space as input for the generator\n",
        "             X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "             # create inverted labels for the fake samples\n",
        "             y_gan = ones((n_batch, 1))\n",
        "             # update the generator via the discriminator's error\n",
        "             g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "             # summarize loss on this batch\n",
        "         print('epoch %d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "         (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "         # evaluate the model performance, sometimes\n",
        "         if (i+1) % 10 == 0:\n",
        "             summarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ],
      "metadata": {
        "id": "A2I2fUiQLq1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NB: d_model et g_model sont utilisés pour créer gan_model\n",
        "    Il faut noter que d_model.train_on_batch va mettre à jour les poids de d_model dans gan_model (c'est le même d_model)\n",
        "    aussi toutes les modifications de g_model vont répercuter sur le g_model dans gan_model donc c'est le même\n",
        "    \"\"\"\n",
        "\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "metadata": {
        "id": "x1KpLF68MvYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Translation**"
      ],
      "metadata": {
        "id": "io0_fPX_EiAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dans cet exemple, on pose l'hypothèse que les données sont déjà représentées sous forme de séquence c'est à dire qu'on n'a\n",
        "pas besoin de la couche d'Embedding. Dans le cas courant, où les données sont représentées sous forme de vecteur, il faut nécessairement un embedding\n",
        "pour avoir chaque mot représenté en vecteur.\n",
        "https://www.kaggle.com/code/akshat0007/machine-translation-english-to-french-rnn-lstm\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BtVyENa2yVvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "input_encoder = Input(shape=(None, features))\n",
        "encoder = LSTM(units=latent_dim, return_states=True)\n",
        "output_encoder, state_h, state_c = encoder(input_encoder)\n",
        "\n",
        "# Decoder\n",
        "input_decoder = Input(shape=(None, features))\n",
        "decoder = LSTM(units=latent_dim, return_states=True, return_sequences=True)\n",
        "output_lstm, _, _ = decoder(input_decoder, initial_state=[state_h, state_c])\n",
        "dense_layer = Dense(units=vocab_size, activation=\"softmax\")\n",
        "dense_output = dense_layer(output_lstm)\n",
        "\n",
        "# Model\n",
        "model = Model([input_encoder, input_encoder], dense_output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) # one hot in label\n",
        "\n",
        "# Train\n",
        "model.fit([encoder_data, decoder_data], y_decoder, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "Qe9VyiFrEmNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "After training, we build an encoder and decoder depending on the training model for prediction\n",
        "\"\"\"\n",
        "\n",
        "# Build Encoder\n",
        "encoder = Model(input_encoder, [output_encoder, state_h, state_c])\n",
        "\n",
        "# Build Decoder\n",
        "input_decoder = Input(shape=(1, features))\n",
        "input_h = Input(shape=(latent_dim, ))\n",
        "input_c = Input(shape=(latent_dim, ))\n",
        "output_lstm, state_h state_c = decoder(input_decoder, initial_state=[input_h, input_c])\n",
        "output_decoder = dense_layer(output_lstm)\n",
        "\n",
        "decoder = Model([input_decoder, input_h, input_c], [output_decoder, state_h, state_c])"
      ],
      "metadata": {
        "id": "iGceijhDj4Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "aZSdXGBOwV9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "metadata": {
        "id": "nHWRPsmZyK-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BahdanauAttention in LSTM using Hidden state as query**"
      ],
      "metadata": {
        "id": "lYCKFjVaREXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ChatBot Introduction Colab: https://www.kaggle.com/code/alincijov/dialog-chatbot-using-bahdanau-attention\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ilKSwJYkoAME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset for train and test\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)  # Define the buffer size, typically the number of training examples.\n",
        "BATCH_SIZE = 64  # Define the batch size for training data.\n",
        "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE  # Calculate the number of steps per training epoch.\n",
        "embedding_dim = 256  # Define the dimension of word embeddings.\n",
        "units = 1024  # Define the number of units or neurons in a recurrent neural network (RNN) layer.\n",
        "vocab_inp_size = len(inp_lang.word_index) + 1  # Calculate the size of the input vocabulary.\n",
        "vocab_tar_size = len(targ_lang.word_index) + 1  # Calculate the size of the target vocabulary.\n",
        "\n",
        "# Create a TensorFlow dataset from the input and target tensors, and shuffle it using the specified BUFFER_SIZE.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Batch the dataset into batches of BATCH_SIZE and drop any remaining examples that don't fit into a batch.\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Get an example input batch and an example target batch from the dataset.\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "\n",
        "# Print the shapes of the example input and target batches.\n",
        "print(\"Example Input Batch Shape:\", example_input_batch.shape)\n",
        "print(\"Example Target Batch Shape:\", example_target_batch.shape)"
      ],
      "metadata": {
        "id": "9dyI5sSvntWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "BahdanauAttention: prend en entrée le hidden_state de l'encoder considéré comme query, et la sortie de l'encoder considéré comme key et value\n",
        "La sortie de la couche BahdanauAttention utilisée dans le décodeur et concaténer avec le mot en cours de traitement (son embedding)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ia1vR80aYOxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom class called \"Encoder\" that inherits from the tf.keras.Model class.\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()  # Call the constructor of the parent class.\n",
        "        self.batch_sz = batch_sz  # Store the batch size as an instance variable.\n",
        "        self.enc_units = enc_units  # Store the number of units in the GRU layer.\n",
        "\n",
        "        # Create an embedding layer to convert input tokens into dense vectors.\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Create a GRU (Gated Recurrent Unit) layer with specified parameters.\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # Define the forward pass for the encoder.\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)  # Pass the input through the embedding layer. --------------------------------(None, sequence, embedding_dim)\n",
        "        output, state = self.gru(x, initial_state=hidden)  # Pass through the GRU. --------------------------(None, sequence, enc_units), (None, enc_units)\n",
        "        return output, state  # Return the output sequence and final hidden state. --------------------------(None, sequence, enc_units), (None, enc_units)\n",
        "\n",
        "    # Initialize the hidden state (typically with zeros).\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "Cdj5ig4yzWcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Q = Decoder hidden state (None, decoder_unit)\n",
        "    at the begining, Q = Encoder hidden state\n",
        "\n",
        "V = Encoder output (None, sequence, feature)\n",
        "\n",
        "Q = tf.expand_dims(Q, axis=1) # (None, 1, decoder_unit)\n",
        "EncQ = Dense1(Q) # (None, units)\n",
        "EncV = Dense2(V) # (None, sequence, units)\n",
        "sum = tf.nn.tanh(EncQ+EncV) # activation (None, sequence, units)\n",
        "\n",
        "score = Dense3(sum) # (None, sequence, 1)\n",
        "attention = tf.nn.softmax(score, axis=1) # (None, sequence, 1) softmax based on token position\n",
        "\n",
        "context_vector = attention*V # (None, sequence, feature)\n",
        "context_vector = tf.nn.sum(context_vector, axis=1) # (None, feature)\n",
        "\n",
        "context_vector sera utilisé dans le decoder et concaténer avec l'entrée (qui se fait token par token)\n",
        "x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # (None, 1, feature+embedding_dim_x) x vient de l'embedding x est de type (None, 1) car on traite par token Embedding donne (None, 1, embedding_dim_x)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DM5eeUy8OkQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        \"\"\"\n",
        "          query = hidden state dec = (None, latent_dim)\n",
        "          values = outputs of enc = (None, sequence, latent_dim)\n",
        "        \"\"\"\n",
        "        # (None, 1, latent_dim)\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        # (None, sequence, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        # (batch_size, sequence, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # (None, sequence, latent_dim)\n",
        "        context_vector = attention_weights * values\n",
        "\n",
        "        # (None, latent_dim)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "iZCkRue02acu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # used for attention\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ],
      "metadata": {
        "id": "rg4J57zf5JAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0)) # return False if 0 and True else (0 is the pad token)\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask # reduce to 0 if correspond to pad token (False)\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "29PQAbBOe5sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "loss = 1\n",
        "print(tf.reduce_mean([0, 0.2,0.3]))\n",
        "loss+=tf.reduce_mean([0, 0.2,0.3])\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSNyDhPq9lJ6",
        "outputId": "525aeeac-5f4a-4133-eb0a-11a4e6ddf2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.16666667, shape=(), dtype=float32)\n",
            "tf.Tensor(1.1666666, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        # (BATCH_SIZE, 1)\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<sos>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "metadata": {
        "id": "g69pILvhe8t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 40\n",
        "\n",
        "# Training taking batch per batch\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "    if(epoch % 4 == 0):\n",
        "        print('Epoch:{:3d} Loss:{:.4f}'.format(epoch,\n",
        "                                          total_loss / steps_per_epoch))"
      ],
      "metadata": {
        "id": "VVIdz4EJe9lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **tf.data.Dataset**"
      ],
      "metadata": {
        "id": "6u9ZLl7tCsOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator\n",
        "# + load image: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ohFAFc_cHltF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "l = [1,2,9,8,4]\n",
        "np.random.shuffle(l)"
      ],
      "metadata": {
        "id": "5N8fIqP3v8Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEwMkq-jwLUu",
        "outputId": "64edc318-9246-454f-e043-4072db358d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 9, 1, 8, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class CustomDataGenerator(Sequence):\n",
        "    def __init__(self, x_data, y_data, batch_size, shuffle=True):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.x_data))\n",
        "\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x_data) / self.batch_size)) # np.ceil : partie entière inférieure -->\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = (index + 1) * self.batch_size\n",
        "\n",
        "        batch_x = self.x_data[self.indexes[start:end]]\n",
        "        batch_y = self.y_data[self.indexes[start:end]]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "# Example usage:\n",
        "# Create some example data\n",
        "x_data = np.random.rand(100, 32, 32, 3)\n",
        "y_data = np.random.randint(0, 2, size=(100,))\n",
        "\n",
        "# Create an instance of the custom data generator\n",
        "batch_size = 32\n",
        "data_generator = CustomDataGenerator(x_data, y_data, batch_size)\n",
        "\n",
        "# Iterate through the data generator for training\n",
        "for epoch in range(epochs):\n",
        "    for batch_x, batch_y in data_generator:\n",
        "        # Train your model on batch_x and batch_y\n"
      ],
      "metadata": {
        "id": "APK-wSal437N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Source dataset**"
      ],
      "metadata": {
        "id": "WjdSkMTOLmKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data don't fit in memory\n",
        "data = [1,2,3]\n",
        "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mFQ8YeACwgP",
        "outputId": "1f241c63-5cc9-49a1-ffc8-f6176cb7c609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read lines from Files\n",
        "files = [\"text1\", \"text2\"]\n",
        "dataset = tf.data.TextLineDataset(files)\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoV_Jm-JItVI",
        "outputId": "6b0a220f-7472-4985-f83f-42c18f243640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Le senegal', shape=(), dtype=string)\n",
            "tf.Tensor(b'La gambie', shape=(), dtype=string)\n",
            "tf.Tensor(b'Le Maroc', shape=(), dtype=string)\n",
            "tf.Tensor(b'La Tunisie', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read name of files giving extension\n",
        "path = '*.txt'\n",
        "dataset = tf.data.Dataset.list_files(path)\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh6moXcKJ-eh",
        "outputId": "15a1c852-cee7-4d26-fa6c-ea761b4da963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'./text1.txt', shape=(), dtype=string)\n",
            "tf.Tensor(b'./text2.txt', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformation**"
      ],
      "metadata": {
        "id": "9eUcOl4NLpNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map\n",
        "map(\n",
        "    map_func,\n",
        "    num_parallel_calls=None,  # representing the number elements to process asynchronously in parallel. If not specified, elements will be processed sequentially. If the value tf.data.AUTOTUNE is used, then the number of parallel calls is set dynamically based on available CPU.\n",
        "    deterministic=None,\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "o4W2UqQ7hDiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. map\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1,2,3])\n",
        "dataset = dataset.map(lambda x: x**2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qS2dzYTLrGM",
        "outputId": "7d138890-13b4-4d2c-b406-603dddcfb26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. map\n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1,2,3], [0,1,1]))\n",
        "dataset = dataset.map(lambda x1, x2: (x1**2, x2))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyj1SdH5M8Yy",
        "outputId": "5516bfcf-9e01-4f43-d4a5-fee2694bc773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0), (4, 1), (9, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter\n",
        "dataset = tf.data.Dataset.range(100)\n",
        "dataset = dataset.filter(lambda x: x < 5)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1033XrBxOEmE",
        "outputId": "764fdcd9-e533-4c4d-d99e-763e6d51f095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply\n",
        "dataset = tf.data.Dataset.range(100)\n",
        "\n",
        "def my_filter(ds):\n",
        "    return ds.filter(lambda x: x < 5)\n",
        "\n",
        "dataset = dataset.apply(my_filter)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT836A9IO8WW",
        "outputId": "a5e9a7cc-6220-47d4-dd18-bb0ab02ba9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as_numpy_iterator\n",
        "dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),\n",
        "                                              'b': [5, 6]})\n",
        "list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5},\n",
        "                                      {'a': (2, 4), 'b': 6}]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zre3TDYjPk1e",
        "outputId": "0b2d73bc-79c8-42cd-f94c-a63007469857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch\n",
        "batch(\n",
        "    batch_size,\n",
        "    drop_remainder=False, # representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n",
        "    num_parallel_calls=None, # number of batches to compute asynchronously in parallel tf.data.AUTOTUNE\n",
        "    deterministic=None,\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "L3wubBukS7NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch\n",
        "dataset = tf.data.Dataset.range(8)\n",
        "dataset = dataset.batch(3)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpWQFS3HTgEa",
        "outputId": "507624ca-0a4c-40b0-b46f-55831cbaa811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(8)\n",
        "dataset = dataset.batch(3, drop_remainder=True)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WLNHRHjTqJ4",
        "outputId": "e435bbb8-5882-4566-d6b3-4db2fb89f80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5])]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cardinality\n",
        "dataset = tf.data.Dataset.range(42)\n",
        "print(dataset.cardinality().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq5IHbdsUGew",
        "outputId": "3c33d032-ea0c-4691-ee12-5d32bc90c7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flat_map\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "dataset = dataset.flat_map(tf.data.Dataset.from_tensor_slices)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyeFZgNOX9Pe",
        "outputId": "01a378e4-6923-4d56-88c4-8827c217d7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from_tensors: Creates a Dataset with a single element, comprising the given tensors.\n",
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E3zcl10d99L",
        "outputId": "1c9db929-328e-4bb2-8c54-a8e2d9f6fe5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from_tensors: Creates a Dataset with a single element, comprising the given tensors.\n",
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMx4A6FidrWR",
        "outputId": "0fc911d6-a77b-41ae-8bc3-5bf0cbec857e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2, 3], dtype=int32)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make dataset**"
      ],
      "metadata": {
        "id": "LpL4Hh9ogXLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.data.Dataset.range(10)\n",
        "dataset = (\n",
        "    data\n",
        "    .map(lambda x: x**2, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(2)\n",
        ")\n",
        "\n",
        "for element in dataset:\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoR_EVxif2j-",
        "outputId": "b576c596-9687-437e-8c2d-fddc470b678e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
            "tf.Tensor([4 9], shape=(2,), dtype=int64)\n",
            "tf.Tensor([16 25], shape=(2,), dtype=int64)\n",
            "tf.Tensor([36 49], shape=(2,), dtype=int64)\n",
            "tf.Tensor([64 81], shape=(2,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements.\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UpA-D10k6SM",
        "outputId": "f210ac99-ae09-4000-aec8-9d8718c066d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a 2D tensor produces 1D tensor elements.\n",
        "dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxIVOUzAlILU",
        "outputId": "58024479-926d-4e82-abf8-2b1e6fafd994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2], dtype=int32), array([3, 4], dtype=int32)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a tuple of 1D tensors produces tuple elements containing WAY FOR DATASET PROCESSING\n",
        "# scalar tensors.\n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwIGJN_VlKhf",
        "outputId": "8b7d0c38-db61-491c-9c4a-7ea058a21113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 3, 5), (2, 4, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary structure is also preserved.\n",
        "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
        "list(dataset.as_numpy_iterator())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhFuHt-rlgEB",
        "outputId": "c23972dd-c59f-482d-80b6-2fcc0dfa600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'a': 1, 'b': 3}, {'a': 2, 'b': 4}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two tensors can be combined into one Dataset object.\n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfzsesavoLss",
        "outputId": "1df4e2de-1f24-4c23-b87b-11d494c85624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 3], dtype=int32), b'A'),\n",
              " (array([2, 1], dtype=int32), b'B'),\n",
              " (array([3, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two tensors can be combined into one Dataset object.\n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "# Both the features and the labels tensors can be converted\n",
        "# to a Dataset object separately and combined after.\n",
        "features_dataset = tf.data.Dataset.from_tensor_slices(features)\n",
        "labels_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
        "dataset = tf.data.Dataset.zip((features_dataset, labels_dataset))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C0IIy3El_w2",
        "outputId": "dab322d4-00c0-4b36-ae98-e3748d229678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 3], dtype=int32), b'A'),\n",
              " (array([2, 1], dtype=int32), b'B'),\n",
              " (array([3, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A batched feature and label set can be converted to a Dataset\n",
        "# in similar fashion.\n",
        "batched_features = tf.constant([[[1, 3], [2, 3]],\n",
        "                                [[2, 1], [1, 2]],\n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
        "batched_labels = tf.constant([['A', 'A'],\n",
        "                              ['B', 'B'],\n",
        "                              ['A', 'B']], shape=(3, 2, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices((batched_features, batched_labels))\n",
        "for element in dataset.as_numpy_iterator():\n",
        "    print(element)\n",
        "# show shape\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvb5qWxAmhWJ",
        "outputId": "9e5e556f-5f37-458b-ceb0-4d4ef7a9dddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([[b'A'],\n",
            "       [b'A']], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([[b'B'],\n",
            "       [b'B']], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([[b'A'],\n",
            "       [b'B']], dtype=object))\n",
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(2, 1), dtype=tf.string, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A batched feature and label set can be converted to a Dataset\n",
        "# in similar fashion.\n",
        "batched_features = tf.constant([[[1, 3], [2, 3]],\n",
        "                                [[2, 1], [1, 2]],\n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
        "batched_labels = tf.constant([['A', 'A'],\n",
        "                              ['B', 'B'],\n",
        "                              ['A', 'B']], shape=(3, 2)) # change shape\n",
        "dataset = tf.data.Dataset.from_tensor_slices((batched_features, batched_labels))\n",
        "for element in dataset.as_numpy_iterator():\n",
        "    print(element)\n",
        "# show shape\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0sNf58ZnaNw",
        "outputId": "d248faad-825b-4261-fe98-f512e9261c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([b'A', b'A'], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([b'B', b'B'], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([b'A', b'B'], dtype=object))\n",
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(2,), dtype=tf.string, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**prefetch**"
      ],
      "metadata": {
        "id": "fX7ffpU5pxW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a Dataset that prefetches elements from this dataset.\n",
        "\n",
        "Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n",
        "\n",
        "Note: Like other Dataset methods, prefetch operates on the elements of the input dataset. It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 batches, of 20 examples each)."
      ],
      "metadata": {
        "id": "p3COrWBzqI8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefetch(\n",
        "    buffer_size, # \tA tf.int64 scalar tf.Tensor, representing the maximum number of elements that will be buffered when prefetching. If the value tf.data.AUTOTUNE is used, then the buffer size is dynamically tuned.\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "fQhednphqdZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.prefetch(2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1Z9_4_Gpzds",
        "outputId": "9985df51-9471-42c9-a2bb-0e8a64b378b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**shuffle**"
      ],
      "metadata": {
        "id": "MsfWy4RirprZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
        "dataset = dataset.repeat(2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0ULYvLnrzY_",
        "outputId": "83636872-c6b4-4a7b-840f-07b070ca4911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2, 1, 0, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
        "dataset = dataset.repeat(2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqXtVp1yrrJ_",
        "outputId": "b8e60c1a-ca71-4b60-baee-1833e4ddfbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 0, 1, 0, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**take**"
      ],
      "metadata": {
        "id": "aDsa7tmQswPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.take(3)\n",
        "list(dataset.as_numpy_iterator())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glWxAt5zsxqW",
        "outputId": "22e3937b-c980-42fe-dce0-bd7af708fcbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**take_while**"
      ],
      "metadata": {
        "id": "1aI88Jlqs14S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.take_while(lambda x: x < 5)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORT2p2o1s3i1",
        "outputId": "f7f0f5ff-9eef-4cc9-e5af-2b0c11740e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**unbatch**"
      ],
      "metadata": {
        "id": "nSJOfv6BtCHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splits elements of a dataset into multiple elements.\n",
        "\n",
        "For example, if elements of the dataset are shaped [B, a0, a1, ...], where B may vary for each input element, then for each element in the dataset, the unbatched dataset will contain B consecutive elements of shape [a0, a1, ...]."
      ],
      "metadata": {
        "id": "UN-J8a8stFYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\n",
        "dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\n",
        "dataset = dataset.unbatch()\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tfBZ9M3tDvQ",
        "outputId": "ac24ecd0-fdb8-4234-cb61-05107c4a8559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 1, 2, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**unique**"
      ],
      "metadata": {
        "id": "07Kj5p7DtNMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 37, 2, 37, 2, 1])\n",
        "dataset = dataset.unique()\n",
        "sorted(list(dataset.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW_WECHitOh3",
        "outputId": "9e7ea7e0-970e-4fdf-ca7e-dc2f4667d8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 37]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**window**"
      ],
      "metadata": {
        "id": "_VnJMIsDuVU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returns a dataset of \"windows\".\n",
        "\n",
        "Each \"window\" is a dataset that contains a subset of elements of the input dataset. These are finite datasets of size size (or possibly fewer if there are not enough input elements to fill the window and drop_remainder evaluates to False).\n",
        "\n"
      ],
      "metadata": {
        "id": "tbKmDjA6vxvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "  print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeVOk5gBuWwU",
        "outputId": "3014d67b-aa94-4e47-b150-ba232faf9c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2]\n",
            "[3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shift argument determines the number of input elements to shift between the start of each window. If windows and elements are both numbered starting at 0, the first element in window k will be element k * shift of the input dataset. In particular, the first element of the first window will always be the first element of the input dataset."
      ],
      "metadata": {
        "id": "3JFCs1jhwzvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "    print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSAuUKPYw0VX",
        "outputId": "0a5dabdd-fdc4-4801-e477-94458cef8b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2]\n",
            "[1, 2, 3]\n",
            "[2, 3, 4]\n",
            "[3, 4, 5]\n",
            "[4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stride argument determines the stride between input elements within a window."
      ],
      "metadata": {
        "id": "upwjM_YHxITF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1, stride=2,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "  print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1JAVcYKxJk2",
        "outputId": "fa1de2fb-e6cf-412b-a247-630b4df72709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 4]\n",
            "[1, 3, 5]\n",
            "[2, 4, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
        "                                              [6, 7, 8, 9, 10]))\n",
        "dataset = dataset.window(2)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4LcuZNexgtZ",
        "outputId": "74ab4620-fdf1-4244-9d55-9e5a8f92536b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_WindowDataset element_spec=(DatasetSpec(TensorSpec(shape=(), dtype=tf.int32, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(), dtype=tf.int32, name=None), TensorShape([])))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
        "                                              [6, 7, 8, 9, 10]))\n",
        "dataset = dataset.window(2)\n",
        "\n",
        "for w in dataset: # w is a tuple\n",
        "  print(\"#############\")\n",
        "  print(w[0].batch(2))\n",
        "  print(list(w[0].as_numpy_iterator()))\n",
        "  print(list(w[1].as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e_YNOVtxkY2",
        "outputId": "c25e9bb8-d7c9-4e4d-f910-53f11c50529c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#############\n",
            "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "[1, 2]\n",
            "[6, 7]\n",
            "#############\n",
            "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "[3, 4]\n",
            "[8, 9]\n",
            "#############\n",
            "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "[5]\n",
            "[10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
        "                                          drop_remainder=True)\n",
        "batched = dataset.flat_map(lambda x:x.batch(3))\n",
        "for batch in batched:\n",
        "  print(batch)\n",
        "  print(batch.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa8Aw8ZC0c2O",
        "outputId": "9c1fb0aa-303c-4e59-ef29-18249440468e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2], shape=(3,), dtype=int64)\n",
            "[0 1 2]\n",
            "tf.Tensor([1 2 3], shape=(3,), dtype=int64)\n",
            "[1 2 3]\n",
            "tf.Tensor([2 3 4], shape=(3,), dtype=int64)\n",
            "[2 3 4]\n",
            "tf.Tensor([3 4 5], shape=(3,), dtype=int64)\n",
            "[3 4 5]\n",
            "tf.Tensor([4 5 6], shape=(3,), dtype=int64)\n",
            "[4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**zip**"
      ],
      "metadata": {
        "id": "KOnM-gqg4yd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
        "b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\n",
        "ds = tf.data.Dataset.zip(a, b)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfm5Srm_40hY",
        "outputId": "fa34d2e6-a43c-4069-d663-863c80aa7852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 4), (2, 5), (3, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.zip(b, a)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy6UQ0Xq4-si",
        "outputId": "dd809439-a662-4655-bdca-b51a70f8fc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4, 1), (5, 2), (6, 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The `datasets` argument may contain an arbitrary number of datasets.\n",
        "c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\n",
        "                                           #       [9, 10],\n",
        "                                           #       [11, 12] ]\n",
        "ds = tf.data.Dataset.zip(a, b, c)\n",
        "for element in ds.as_numpy_iterator():\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK-YTFxY5JA6",
        "outputId": "197b1d22-c685-4f57-a06e-f517c88b38c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4, array([7, 8]))\n",
            "(2, 5, array([ 9, 10]))\n",
            "(3, 6, array([11, 12]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of elements in the resulting dataset is the same as\n",
        "# the size of the smallest dataset in `datasets`.\n",
        "d = tf.data.Dataset.range(13, 15)  # ==> [ 13, 14 ]\n",
        "ds = tf.data.Dataset.zip(a, d)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4gAECr15N7V",
        "outputId": "baeaaa16-4c3b-4a8f-8700-ea9edbbcc059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 13), (2, 14)]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.data.Dataset.from_tensor_slices(([1,2,3], [5,5,7]))\n",
        "for i in a:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NJqbgsj8KDS",
        "outputId": "346dcab5-f7b7-44f0-fddd-33d685bce68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=7>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image - Text - Sequence**"
      ],
      "metadata": {
        "id": "YTh6vXLEWatx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Module**\n",
        "\n",
        "* **Class**\n",
        "\n",
        "* **Function**"
      ],
      "metadata": {
        "id": "dsojJ4J0k7_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sur Tensorflow, on a des modules, des classes et des fonctions\n",
        "tf.keras.preprocessing: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing [Module: image, text, sequence]\n",
        "tf.keras.utils: https://www.tensorflow.org/api_docs/python/tf/keras/utils: exemple :\n",
        "tf.keras.utils.to_categorical(\n",
        "    y, num_classes=None, dtype='float32'\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kolFTPjHYqUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune model application\n",
        "https://keras.io/api/applications/"
      ],
      "metadata": {
        "id": "lTqpBUOxWckZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Callbacks**"
      ],
      "metadata": {
        "id": "9Su900NJyWDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "callbacks permet de controler le train\n",
        "tf.keras.callbacks.Callback\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks [Callback, ModelCheckpoint]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9Re2h08fyYgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\"\"\"\n",
        "self c'est le modèle\n",
        "\"\"\"\n",
        "class MyCustomCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print(f\"Starting epoch {epoch}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Finished epoch {epoch}. Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}\")\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        print(f\"Training batch {batch}...\")\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        print(f\"Finished training batch {batch}. Loss: {logs['loss']:.4f}\")\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        print(\"Starting validation...\")\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        print(\"Finished validation. Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}\")\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        print(\"Starting prediction...\")\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        print(\"Finished prediction.\")\n",
        "\n",
        "# Créez un modèle Keras simple à des fins d'exemple\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Générez des données factices pour l'exemple\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Entraînez le modèle avec l'utilisation de votre callback personnalisé\n",
        "history = model.fit(x_train, y_train, epochs=3, callbacks=[MyCustomCallback()])\n",
        "\n",
        "# Effectuez une évaluation du modèle\n",
        "model.evaluate(x_test, y_test, callbacks=[MyCustomCallback()])\n",
        "\n",
        "# Effectuez des prédictions\n",
        "model.predict(x_test[:5], callbacks=[MyCustomCallback()])\n"
      ],
      "metadata": {
        "id": "dle0BHI75shA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = 'drive/MyDrive/autoACN_densenet40_cifar100'\n",
        "# Créer un callback pour enregistrer les checkpoints tous les 50 époques\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, 'model_weights_{epoch:03d}.h5'),\n",
        "    save_weights_only=True,\n",
        "    save_best_only=False,\n",
        "    save_freq=SAVE_PERIOD*STEPS_PER_EPOCH # Sauvegarder tous les 50 époques\n",
        ")\n",
        "# Train the DenseNet-40 model\n",
        "history = model_densenet40.fit(train_gen,\n",
        "                     steps_per_epoch=x_train.shape[0] // batch_size, epochs=epochs,\n",
        "                     validation_data=(x_val, y_val), callbacks=[keras.callbacks.LearningRateScheduler(lr_schedule), checkpoint_callback])\n"
      ],
      "metadata": {
        "id": "rIFsfz1_46AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * 2.08))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULhea89O6paT",
        "outputId": "f4b4a6bd-2123-46ec-f93d-93474a1c0f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored model, accuracy: 208.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemple plus avancé\n",
        "class GradientStabilityCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, source_ds, target_ds):\n",
        "        self.source_ds = source_ds\n",
        "        self.target_ds = target_ds\n",
        "        self.gradient_variances_source = []\n",
        "        self.gradient_variances_target = []\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        trainable_weights = self.model.model.trainable_weights\n",
        "        gradients_source = []\n",
        "        gradients_target = []\n",
        "\n",
        "        # Choisissez un lot de données à partir de l'ensemble source\n",
        "        source_batch = next(iter(self.source_ds))\n",
        "        target_batch = next(iter(self.target_ds))\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape_source,  tf.GradientTape(persistent=True) as tape_target:\n",
        "            # Passe avant avec les données source\n",
        "            source_input = source_batch[0][0] # (x, y, context), (x, y, context)\n",
        "            target_input = target_batch[0][0]\n",
        "\n",
        "            source_logits = self.model.model(source_input, training=True)\n",
        "            target_logits = self.model.model(target_input, training=True)\n",
        "\n",
        "\n",
        "        # trainable_weights: liste de tf.Variables, avec chaque tf.Variables les poids d'une couche (une matrice)\n",
        "        for weight in trainable_weights:\n",
        "            # Vérifiez si le poids est connecté au calcul de source_logits\n",
        "            gradients_source.append(tape_source.gradient(source_logits, weight)) # weight est de type tf.Variables et contient les poids d'une couche donnée\n",
        "            gradients_target.append(tape_target.gradient(target_logits, weight))\n",
        "\n",
        "\n",
        "        gradient_variance_source = [np.var(grad.numpy()) for grad in gradients_source]\n",
        "        gradient_variance_target = [np.var(grad.numpy()) for grad in gradients_target]\n",
        "\n",
        "        # Enregistrez ou stockez éventuellement gradient_variance selon vos besoins\n",
        "\n",
        "        self.gradient_variances_source.append(gradient_variance_source)\n",
        "        self.gradient_variances_target.append(gradient_variance_target)\n",
        "        #print(f\"Époque {epoch + 1}, Variance des gradients : {gradient_variance}\")\n",
        "\n",
        "# Create an instance of the GradientStabilityCallback with your source and target datasets\n",
        "gradient_stability_callback = GradientStabilityCallback(final_source_ds, final_target_ds)\n"
      ],
      "metadata": {
        "id": "oiVjqmp3qro_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value = 10*3.09\n",
        "a = '{:.05f}'.format(value)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B0boIbhs6wtt",
        "outputId": "51c6e84e-8feb-4925-ef0f-77c70fa0239e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'30.90000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value = 10*3.09\n",
        "a = f'{value:.02f}'\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "p4p2yww39AF5",
        "outputId": "8ef75da5-4d9c-46d2-f25e-327b3b677db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'30.90'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value = 1009*3.09\n",
        "a = f'{value:19.02f}'\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "drHoivvfZVP9",
        "outputId": "a68ebd43-0c50-4405-ca09-1d6a5cea567d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'            3117.81'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = '{:2d}'.format(10)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Dz3GKPBW8WW_",
        "outputId": "fc2ce253-aa80-49cf-ab44-73fa484f0ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = '{:03d}'.format(10)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5M3NS6CP8eGy",
        "outputId": "b2c8310c-c79d-42c0-eda3-733ba5eb3623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'010'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Value: %03d\" % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wPpH66PI8GfZ",
        "outputId": "e354ab48-551d-4352-b523-19c25795cad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Value: 002'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Value: %.03f\" % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dvAgObS_8itP",
        "outputId": "000af559-6237-47e6-c16d-402beaf723c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Value: 2.000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Value: %.03f %02d\" % (2, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NyAtywTa9aGx",
        "outputId": "5157eb71-65ed-4863-d978-ee123333aa85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Value: 2.000 02'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save Model**"
      ],
      "metadata": {
        "id": "UFsVm-srMhSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://www.tensorflow.org/tutorials/keras/save_and_load"
      ],
      "metadata": {
        "id": "LKrVSGWLXfGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les formats de fichiers .keras, .ckpt (Checkpoint), et .h5 (HDF5) sont tous utilisés pour enregistrer des modèles TensorFlow (notamment avec l'API Keras). Chacun a ses propres caractéristiques et avantages. Voici les principales différences entre ces formats de fichiers :\n",
        "\n",
        "**.keras (SavedModel):**\n",
        "\n",
        "Format par défaut lors de l'enregistrement d'un modèle Keras avec TensorFlow.\n",
        "Contient le modèle complet, y compris l'architecture, les poids, la configuration et les informations d'entraînement.\n",
        "Peut être utilisé pour le déploiement en production et pour la reprise de l'entraînement sans avoir à répéter la définition du modèle.\n",
        "Fournit une structure hiérarchique qui permet de stocker plusieurs versions du modèle et des signatures de fonction pour le déploiement.<br>\n",
        "**Le modèle est enrégistrer sur un fichier zip. model.save(\"model.keras\")**<br>\n",
        "\n",
        "**.ckpt (Checkpoint):**\n",
        "\n",
        "Enregistre principalement les poids du modèle, pas l'architecture.\n",
        "Utilisé pour sauvegarder uniquement les poids d'un modèle, ce qui permet de réutiliser les mêmes couches avec des architectures différentes.\n",
        "Souvent utilisé pour la reprise de l'entraînement et la sauvegarde de points de contrôle (checkpoints) à différents stades de l'entraînement.\n",
        "Vous devez spécifier l'architecture du modèle lors du chargement des poids depuis un fichier .ckpt.<br>\n",
        "**Enrégistre trois fichiers. model.save_weights(\"model.ckpt\")**<br>\n",
        "\n",
        "\n",
        "**.h5 (HDF5):**\n",
        "\n",
        "Peut enregistrer l'ensemble du modèle, y compris l'architecture, les poids et la configuration.\n",
        "Facile à partager avec d'autres utilisateurs, car il contient toutes les informations nécessaires pour reconstruire et utiliser le modèle.\n",
        "Utile pour enregistrer des modèles complets pour la reprise de l'entraînement ou pour des expériences de recherche.\n",
        "Peut également être utilisé pour enregistrer uniquement les poids si vous le souhaitez.\n",
        "En résumé, le format .keras (SavedModel) est généralement recommandé pour le déploiement en production, car il contient toutes les informations nécessaires pour le modèle, tandis que le format .ckpt est idéal pour la reprise de l'entraînement et la sauvegarde des poids. Le format .h5 est polyvalent, car il peut enregistrer l'ensemble du modèle ou uniquement les poids, ce qui le rend pratique pour diverses situations. Le choix du format dépend de l'utilisation spécifique de votre modèle et de vos besoins en matière de partage et de reprise de l'entraînement.<br>\n",
        "**Enrégistre un seul fichier avec model.save(\"model.h5\") ou model.save_weights(\"model.h5\")**"
      ],
      "metadata": {
        "id": "LAV8F4kDfTui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embedding**"
      ],
      "metadata": {
        "id": "Dp6QtMEhGYaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A voir obligatoirement pour construire une couche embedding from scratch: https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup\n",
        "class CustomEmbedding(keras.layers.Layer):\n",
        "    def __init__(self, input_dim, output_dim, mask_zero=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.mask_zero = mask_zero\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.embeddings = self.add_weight(\n",
        "            shape=(self.input_dim, self.output_dim),\n",
        "            initializer=\"random_normal\",\n",
        "            dtype=\"float32\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.nn.embedding_lookup(self.embeddings, inputs) # voir : https://www.tensorflow.org/api_docs/python/tf/nn/embedding_lookup\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if not self.mask_zero:\n",
        "            return None\n",
        "        return tf.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "layer = CustomEmbedding(10, 32, mask_zero=True)\n",
        "x = np.random.random((3, 10)) * 9\n",
        "x = x.astype(\"int32\")\n",
        "\n",
        "y = layer(x)\n",
        "mask = layer.compute_mask(x)\n",
        "a = LSTM(3)(y, mask=mask)\n",
        "\n",
        "print(mask)\n",
        "\n",
        "params: correspond aux tensors de paramètres nombre de ligne taille du vocabulaire, nombre de colonne output_dim\n",
        "ids: les ids ou tokens pour l'entrée donnée\n",
        "\n",
        "\"\"\"\n",
        "EXEMPLE:\n",
        "SOIT Params = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]\n",
        "et ids = [0, 3, 4]\n",
        "\n",
        "alors l'embedding va être calculé de la façon suivante: pour 0 on prend [1,2], pour 3 on prend [7, 8], 4 prend [9, 10]\n",
        "\n",
        "Voir embedding avec mask = True dans https://www.tensorflow.org/guide/keras/understanding_masking_and_padding\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_cIA6DEzGdaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Réseau de neurones séquentiel**"
      ],
      "metadata": {
        "id": "2n7XxItEXUCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LSTM**"
      ],
      "metadata": {
        "id": "08eGL_H2YdmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = tf.keras.layers.LSTM(2, return_sequences=True, return_state=True)\n",
        "o, c, h = lstm(b)"
      ],
      "metadata": {
        "id": "yJGECWQHYnm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e6175f2-bc00-4ba4-cf03-e9a5949264de",
        "id": "LR1ibfbLYnm2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 2), dtype=float32, numpy=\n",
              "array([[[-0.0064925 ,  0.00696212],\n",
              "        [-0.00547939,  0.0159462 ],\n",
              "        [-0.0029227 ,  0.00401334],\n",
              "        [-0.0029227 ,  0.00401334],\n",
              "        [-0.0029227 ,  0.00401334],\n",
              "        [-0.0029227 ,  0.00401334]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675402a7-e472-4993-f988-36fbf7858879",
        "id": "kRUwlMO8Ynm4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.0029227 ,  0.00401334]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f81a16e-6aba-459f-fcb8-af9868648991",
        "id": "bbOx1JejYnm5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.00583435,  0.00805774]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GRU**"
      ],
      "metadata": {
        "id": "q6Xs5zNXYbfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = tf.keras.layers.SimpleRNN(2, return_sequences=True, return_state=True, activation=\"softmax\")\n",
        "o,  h = lstm(b)"
      ],
      "metadata": {
        "id": "3Ojc8nzUY_N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05e248b-653a-4be3-d04e-87a4834fd309",
        "id": "O2BEEksaY_N7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 2), dtype=float32, numpy=\n",
              "array([[[0.5032558 , 0.4967442 ],\n",
              "        [0.6602687 , 0.33973125],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4307c3-ff82-44c5-8390-1b6e622963b1",
        "id": "ElL73DMoY_N8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.70205325, 0.29794678]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **RNN**"
      ],
      "metadata": {
        "id": "JOtSpgQwXnwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output = Hidden\n",
        "lstm = tf.keras.layers.SimpleRNN(2, return_sequences=True, return_state=True, activation=\"softmax\")\n",
        "o,  h = lstm(b)"
      ],
      "metadata": {
        "id": "kGBwxVZxWVjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veFV9V0YWadU",
        "outputId": "b05e248b-653a-4be3-d04e-87a4834fd309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 6, 2), dtype=float32, numpy=\n",
              "array([[[0.5032558 , 0.4967442 ],\n",
              "        [0.6602687 , 0.33973125],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678],\n",
              "        [0.70205325, 0.29794678]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipy_M_vQWcKI",
        "outputId": "cf4307c3-ff82-44c5-8390-1b6e622963b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.70205325, 0.29794678]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec**"
      ],
      "metadata": {
        "id": "7HwdG2W_XLpu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "L'entraînement d'un modèle Word2Vec implique l'utilisation d'un corpus de texte pour créer des représentations vectorielles des mots, de manière à capturer leurs relations sémantiques et syntaxiques. Voici une procédure générale pour entraîner un modèle Word2Vec :\n",
        "\n",
        "Préparation du Corpus : Rassemblez un corpus de texte qui sera utilisé pour entraîner le modèle. Plus le corpus est vaste, mieux le modèle peut apprendre les relations entre les mots.\n",
        "\n",
        "Tokenisation : Divisez le texte en unités plus petites, telles que des phrases ou des mots. Pour Word2Vec, la tokenisation est généralement effectuée au niveau des mots.\n",
        "\n",
        "Création de Paires de Contexte-Cible : Pour chaque mot dans le corpus, créez des paires de mots qui apparaissent dans son contexte. Par exemple, pour le mot \"chat\", les paires de contexte-cible pourraient être (\"animal\", \"mignon\"), (\"grimpe\", \"arbre\"), etc.\n",
        "\n",
        "Encodage One-Hot : Convertissez les mots en vecteurs one-hot. Chaque mot est représenté par un vecteur où un seul élément est défini à 1, indiquant la position du mot dans le vocabulaire.\n",
        "\n",
        "Construction du Modèle Word2Vec : Utilisez le corpus préparé pour entraîner le modèle Word2Vec. Deux architectures couramment utilisées sont Skip-Gram et Continuous Bag of Words (CBOW). Dans Skip-Gram, le modèle prédit les mots voisins à partir du mot actuel, tandis que dans CBOW, il prédit le mot actuel à partir de ses voisins.\n",
        "\n",
        "Entraînement du Modèle : Entraînez le modèle en ajustant les poids des vecteurs de mots pour minimiser une fonction de perte. Les algorithmes populaires pour cet entraînement incluent l'algorithme Skip-Gram négatif (Negative Sampling) et l'algorithme de Hierarchical Softmax.\n",
        "\n",
        "Obtention des Vecteurs de Mots : Une fois l'entraînement terminé, les vecteurs de mots appris peuvent être extraits du modèle. Ces vecteurs représentent la sémantique des mots dans un espace vectoriel.\n",
        "\n",
        "Évaluation (Facultatif) : Si des données d'évaluation sont disponibles, vous pouvez évaluer la qualité du modèle en vérifiant sa capacité à effectuer des tâches spécifiques telles que la similarité sémantique ou la complétion de mots.\n",
        "\n",
        "\n",
        "\n",
        "La sémantique se réfère à la signification des mots, des phrases, des expressions et du langage en général."
      ],
      "metadata": {
        "id": "tL45s2_sXOq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Syntaxe : La syntaxe concerne la structure formelle d'une langue. Elle spécifie comment les mots et les phrases doivent être ordonnés pour former des énoncés corrects sur le plan grammatical. Les règles syntaxiques définissent la manière dont les éléments du langage peuvent être combinés pour créer des unités plus grandes, comme les phrases et les paragraphes.\n",
        "\n",
        "Sémantique : La sémantique concerne la signification des éléments linguistiques. Elle explore comment les mots, les phrases et les discours transmettent des informations et des idées. La sémantique examine les relations sémantiques entre les mots, les nuances de sens, et la manière dont le contexte influence l'interprétation du langage.\n",
        "\n",
        "Lexique : Le lexique fait référence à l'ensemble des mots d'une langue, y compris leurs significations et leurs propriétés grammaticales. C'est la collection des termes et expressions utilisés dans une langue particulière."
      ],
      "metadata": {
        "id": "FtcqSSE7XUbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.andreaperlato.com/theorypost/introduction-to-word2vec/\n",
        "# https://colab.research.google.com/github/davidarps/2022_course_embeddings_and_transformers/blob/main/Visualizing_Attention_with_BertViz.ipynb attention\n",
        "# https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb bert\n",
        "# https://colab.research.google.com/github/BritneyMuller/colab-notebooks/blob/master/Easy_Text_Summarization_with_BART.ipynb#scrollTo=CdyRipC0o8vR: Text Summarisation avec BART\n",
        "# https://lesdieuxducode.com/blog/2019/4/bert--le-transformer-model-qui-sentraine-et-qui-represente tout sur BERT a voir obligatoirement\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Embedding, Reshape, Activation, Input\n",
        "from keras.preprocessing import text\n",
        "from keras.preprocessing.sequence import skipgrams\n",
        "\n",
        "# Exemple de corpus\n",
        "corpus = [\"le petit chat noir\", \"le chien marron\", \"la souris grise\"]\n",
        "\n",
        "# Tokenisation et création des paires de contexte-cible\n",
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "skip_grams = [skipgrams(sequence, vocabulary_size=total_words, window_size=2) for sequence in sequences]\n",
        "data, labels = zip(*skip_grams)"
      ],
      "metadata": {
        "id": "z-T-859WPbeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUnV2tEVBJcI",
        "outputId": "3aa3279e-b3dc-4a13-b58d-2ffd7ba5b8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([[2, 4],\n",
              "   [4, 3],\n",
              "   [2, 3],\n",
              "   [1, 3],\n",
              "   [3, 4],\n",
              "   [1, 8],\n",
              "   [3, 8],\n",
              "   [3, 2],\n",
              "   [3, 1],\n",
              "   [1, 9],\n",
              "   [2, 2],\n",
              "   [2, 1],\n",
              "   [4, 2],\n",
              "   [1, 2],\n",
              "   [4, 8],\n",
              "   [2, 7],\n",
              "   [4, 9],\n",
              "   [3, 5],\n",
              "   [2, 3],\n",
              "   [3, 4]],\n",
              "  [1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1]),\n",
              " ([[5, 1],\n",
              "   [5, 3],\n",
              "   [5, 6],\n",
              "   [5, 1],\n",
              "   [6, 6],\n",
              "   [6, 5],\n",
              "   [6, 1],\n",
              "   [1, 5],\n",
              "   [1, 1],\n",
              "   [6, 8],\n",
              "   [1, 6],\n",
              "   [1, 6]],\n",
              "  [0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1]),\n",
              " ([[8, 6],\n",
              "   [8, 7],\n",
              "   [9, 8],\n",
              "   [7, 1],\n",
              "   [9, 5],\n",
              "   [7, 8],\n",
              "   [8, 9],\n",
              "   [8, 7],\n",
              "   [9, 7],\n",
              "   [9, 6],\n",
              "   [7, 9],\n",
              "   [7, 2]],\n",
              "  [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0])]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hralMPZoBu0G",
        "outputId": "eeeb5a2b-869d-407c-e1cc-96b0eba9a97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[2, 4],\n",
              "  [4, 3],\n",
              "  [2, 3],\n",
              "  [1, 3],\n",
              "  [3, 4],\n",
              "  [1, 8],\n",
              "  [3, 8],\n",
              "  [3, 2],\n",
              "  [3, 1],\n",
              "  [1, 9],\n",
              "  [2, 2],\n",
              "  [2, 1],\n",
              "  [4, 2],\n",
              "  [1, 2],\n",
              "  [4, 8],\n",
              "  [2, 7],\n",
              "  [4, 9],\n",
              "  [3, 5],\n",
              "  [2, 3],\n",
              "  [3, 4]],\n",
              " [[5, 1],\n",
              "  [5, 3],\n",
              "  [5, 6],\n",
              "  [5, 1],\n",
              "  [6, 6],\n",
              "  [6, 5],\n",
              "  [6, 1],\n",
              "  [1, 5],\n",
              "  [1, 1],\n",
              "  [6, 8],\n",
              "  [1, 6],\n",
              "  [1, 6]],\n",
              " [[8, 6],\n",
              "  [8, 7],\n",
              "  [9, 8],\n",
              "  [7, 1],\n",
              "  [9, 5],\n",
              "  [7, 8],\n",
              "  [8, 9],\n",
              "  [8, 7],\n",
              "  [9, 7],\n",
              "  [9, 6],\n",
              "  [7, 9],\n",
              "  [7, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D_gKHl8B4aK",
        "outputId": "961a862b-74b4-4018-f76a-c70f9072f629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1],\n",
              " [0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1],\n",
              " [0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = ([ [1,2], [3,4] ], [ [5,6], [7,8] ])\n",
        "c, d = zip(*a)"
      ],
      "metadata": {
        "id": "ZIJPc8HlB8SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTPU8i-zCT1d",
        "outputId": "b9675a5c-c178-4e63-b028-501271f380b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 2], [5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dKHArTBCVCP",
        "outputId": "909a66a1-4787-4789-d74f-a5bc12bc8320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([3, 4], [7, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "CBOW: predict target word in a given context words\n",
        "SKIP-GRAMS: predict context words, given target word\n",
        "see the implementation: https://radimrehurek.com/gensim/models/word2vec.html\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "c2Vsrv0IZzP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvTEv_jwPfhU",
        "outputId": "ef5b8f7e-2f5d-4f21-d17f-9c40ad52594d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4], [1, 5, 6], [7, 8, 9]]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.index_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--nQn81yTbpO",
        "outputId": "652b5682-1747-4490-feeb-445bc74e1bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'le',\n",
              " 2: 'petit',\n",
              " 3: 'chat',\n",
              " 4: 'noir',\n",
              " 5: 'chien',\n",
              " 6: 'marron',\n",
              " 7: 'la',\n",
              " 8: 'souris',\n",
              " 9: 'grise'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skip_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqkbPgFiPyAF",
        "outputId": "e3a5d8ef-be64-4cad-f895-5331c4a0fb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([[2, 1],\n",
              "   [4, 3],\n",
              "   [2, 3],\n",
              "   [3, 1],\n",
              "   [1, 1],\n",
              "   [4, 1],\n",
              "   [1, 2],\n",
              "   [3, 4],\n",
              "   [3, 2],\n",
              "   [4, 2],\n",
              "   [1, 3],\n",
              "   [2, 1],\n",
              "   [3, 7],\n",
              "   [3, 6],\n",
              "   [2, 4],\n",
              "   [4, 4],\n",
              "   [2, 7],\n",
              "   [2, 4],\n",
              "   [3, 7],\n",
              "   [1, 7]],\n",
              "  [0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
              " ([[6, 1],\n",
              "   [6, 2],\n",
              "   [5, 1],\n",
              "   [5, 6],\n",
              "   [1, 6],\n",
              "   [6, 5],\n",
              "   [5, 3],\n",
              "   [6, 6],\n",
              "   [1, 5],\n",
              "   [5, 1],\n",
              "   [1, 1],\n",
              "   [1, 3]],\n",
              "  [1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0]),\n",
              " ([[7, 8],\n",
              "   [8, 9],\n",
              "   [8, 5],\n",
              "   [7, 9],\n",
              "   [9, 8],\n",
              "   [9, 3],\n",
              "   [8, 9],\n",
              "   [7, 6],\n",
              "   [9, 7],\n",
              "   [8, 7],\n",
              "   [7, 6],\n",
              "   [9, 7]],\n",
              "  [1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1])]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exemple 0**"
      ],
      "metadata": {
        "id": "KZZLm5MQ1RzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cet exemple, pour chaque target, 1 contexte positif et 4 contextes négatifs sont utilisés. Les targets et contextes sont donnés en entrée. Un Embedding est utilisé pour le target et 1 Embedding pour les contextes. https://www.tensorflow.org/text/tutorials/word2vec"
      ],
      "metadata": {
        "id": "tx0n4UaC756O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le principe de cet exercice est de construire est de construire une matrice de **target**, **context** et **label**. <br>\n",
        "\n",
        "**target** correspond aux mots cibles. On les répresente en se basant sur les ids des tokens, ça va être un tableau de taille (N, 1) ou (N, ).<br>\n",
        "\n",
        "**context** correspond aux mots contexte, des targets. Pour cet exemple, chaque target aura 5 contextes, le premier c'est le contexte positif et les 4 suivants, les contextes négatifs. Donc un tableau de taille (N, 5).<br>\n",
        "\n",
        "**label** c'est un tableau de taille (N, 5) avec chaque vecteur sous la forme (1, 0, 0, 0, 0) avec 1 pour dire contexte positif et 0 pour dire contexte négatif.<br>\n",
        "\n",
        "Les contextes positifs sont construits avec **tf.keras.preprocessing.skipgrams** et les contextes négatifs par **tf.random.log_uniform_candidate_sampler**<br>\n",
        "\n",
        "\n",
        "Le modèle est entrainé en utilisant deux Embedding, car prenant deux entrées. Le premier Embedding pour le target et le deuxième pour context. tf.einsum est utilisé pour multiplié le codage du target sur le codage du context."
      ],
      "metadata": {
        "id": "y9JSTMGNVxm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construire contextes positif:\n",
        "\n",
        "# Get target and context words for one positive skip-gram.\n",
        "target_word, context_word = positive_skip_grams[0]\n",
        "\n",
        "# Set the number of negative samples per positive context.\n",
        "num_ns = 4\n",
        "\n",
        "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
        "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
        "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
        "    num_sampled=num_ns,  # number of negative context words to sample\n",
        "    unique=True,  # all the negative samples should be unique\n",
        "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
        "    seed=SEED,  # seed for reproducibility\n",
        "    name=\"negative_sampling\"  # name of this operation\n",
        ")\n",
        "\n",
        "# Construire pair positif:\n",
        "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "      example_sequence,\n",
        "      vocabulary_size=vocab_size,\n",
        "      window_size=window_size,\n",
        "      negative_samples=0 # 0 pour dire qu'on ne prend pas de pair négatif\n",
        "      )\n"
      ],
      "metadata": {
        "id": "NDuyphtwFZVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Création d'un tenseur avec une dimension de taille 1\n",
        "tensor_with_singleton_dim = tf.constant([[[1]], [[2]], [[3]]])\n",
        "\n",
        "# Utilisation de tf.squeeze pour supprimer la dimension de taille 1\n",
        "squeezed_tensor = tf.squeeze(tensor_with_singleton_dim, axis=(1,2)) # élimine l'axe 1 et 2\n",
        "\n",
        "# Affichage des formes avant et après l'opération\n",
        "print(\"Avant squeeze :\", tensor_with_singleton_dim.shape)\n",
        "print(\"Après squeeze :\", squeezed_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biO7sq3tF_bw",
        "outputId": "24d7a224-45c5-4331-97d4-f9e1627be18e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avant squeeze : (3, 1, 1)\n",
            "Après squeeze : (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p, l = tf.keras.preprocessing.sequence.skipgrams(\n",
        "      [2,3,4,0,0,0],\n",
        "      vocabulary_size=5,\n",
        "      window_size=2,\n",
        "      negative_samples=0)\n",
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8-JrCo2Go5a",
        "outputId": "d340d661-2431-4c4a-9888-2bf066a3ddc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 2], [4, 3], [2, 4], [2, 3], [3, 4], [4, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu0fzocvUFo0",
        "outputId": "11eb828d-30e5-447f-c9ee-bf15ad4a0afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azIO9K05KXMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/text/tutorials/word2vec\n",
        "import tensorflow as tf\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "\n",
        "with open(path_to_file) as f:\n",
        "  lines = f.read().splitlines()\n",
        "for line in lines[:20]:\n",
        "  print(line)\n",
        "\n",
        "\n",
        "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4TGScAo1T5B",
        "outputId": "05e311d0-c2bc-41be-d21d-a50921e95861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KuOd3p8-FYhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in text_ds.take(10):\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ3c7aqZ1hUb",
        "outputId": "5f3a1dc1-f675-491e-fce7-d5c309c16b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'First Citizen:', shape=(), dtype=string)\n",
            "tf.Tensor(b'Before we proceed any further, hear me speak.', shape=(), dtype=string)\n",
            "tf.Tensor(b'All:', shape=(), dtype=string)\n",
            "tf.Tensor(b'Speak, speak.', shape=(), dtype=string)\n",
            "tf.Tensor(b'First Citizen:', shape=(), dtype=string)\n",
            "tf.Tensor(b'You are all resolved rather to die than to famish?', shape=(), dtype=string)\n",
            "tf.Tensor(b'All:', shape=(), dtype=string)\n",
            "tf.Tensor(b'Resolved. resolved.', shape=(), dtype=string)\n",
            "tf.Tensor(b'First Citizen:', shape=(), dtype=string)\n",
            "tf.Tensor(b'First, you know Caius Marcius is chief enemy to the people.', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, create a custom standardization function to lowercase the text and\n",
        "# remove punctuation.\n",
        "import re\n",
        "import string\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  return tf.strings.regex_replace(lowercase,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "\n",
        "# Define the vocabulary size and the number of words in a sequence.\n",
        "vocab_size = 4096\n",
        "sequence_length = 10\n",
        "\n",
        "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
        "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
        "# same length.\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n"
      ],
      "metadata": {
        "id": "YMdj_5br18kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(text_ds.batch(1024))"
      ],
      "metadata": {
        "id": "4y2m_69t2Byq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the created vocabulary for reference.\n",
        "inverse_vocab = vectorize_layer.get_vocabulary()\n",
        "print(inverse_vocab[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z3P0YA-2Odp",
        "outputId": "0530f1ac-5f8c-4581-aa8d-fd31c2ca8207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data in text_ds.\n",
        "text_vector_ds = text_ds.batch(1024).prefetch(tf.data.AUTOTUNE).map(vectorize_layer).unbatch()"
      ],
      "metadata": {
        "id": "wyoLKqVi2Xmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = list(text_vector_ds.as_numpy_iterator())\n",
        "print(len(sequences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDi2GbZp2f2r",
        "outputId": "e23f9b1c-4533-4a7b-8acc-6f06f9d23f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
        "# (int-encoded sentences) based on window size, number of negative samples\n",
        "# and vocabulary size.\n",
        "import tqdm\n",
        "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
        "  # Elements of each training example are appended to these lists.\n",
        "  targets, contexts, labels = [], [], []\n",
        "\n",
        "  # Build the sampling table for `vocab_size` tokens.\n",
        "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "\n",
        "  # Iterate over all sequences (sentences) in the dataset.\n",
        "  for sequence in tqdm.tqdm(sequences):\n",
        "\n",
        "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
        "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "          sequence,\n",
        "          vocabulary_size=vocab_size,\n",
        "          sampling_table=sampling_table,\n",
        "          window_size=window_size,\n",
        "          negative_samples=0)\n",
        "\n",
        "    # Iterate over each positive skip-gram pair to produce training examples\n",
        "    # with a positive context word and negative samples.\n",
        "    for target_word, context_word in positive_skip_grams:\n",
        "      context_class = tf.expand_dims(\n",
        "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "          true_classes=context_class,\n",
        "          num_true=1,\n",
        "          num_sampled=num_ns,\n",
        "          unique=True,\n",
        "          range_max=vocab_size,\n",
        "          seed=seed,\n",
        "          name=\"negative_sampling\")\n",
        "\n",
        "      # Build context and label vectors (for one target word)\n",
        "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
        "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "\n",
        "      # Append each element from the training example to global lists.\n",
        "      targets.append(target_word)\n",
        "      contexts.append(context)\n",
        "      labels.append(label)\n",
        "\n",
        "  return targets, contexts, labels"
      ],
      "metadata": {
        "id": "qaBx5W6O26Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets, contexts, labels = generate_training_data(\n",
        "    sequences=sequences,\n",
        "    window_size=2,\n",
        "    num_ns=4,\n",
        "    vocab_size=vocab_size,\n",
        "    seed=242)\n",
        "\n",
        "targets = np.array(targets)\n",
        "contexts = np.array(contexts)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"targets.shape: {targets.shape}\")\n",
        "print(f\"contexts.shape: {contexts.shape}\")\n",
        "print(f\"labels.shape: {labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR5-4jaC2whE",
        "outputId": "f4a74208-f693-46cb-ac84-88abd4993843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32777/32777 [00:43<00:00, 761.86it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "targets.shape: (64702,)\n",
            "contexts.shape: (64702, 5)\n",
            "labels.shape: (64702, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf6Jbj-Q3DMu",
        "outputId": "9fbf8359-978a-4e98-9118-ea6b0b65d74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([125, 125, 125, ...,  82,  82,  82])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ycjld_S3Puv",
        "outputId": "3c1b689e-114b-487b-c612-9bfc3063d61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64702,)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl1eWoWG3RCF",
        "outputId": "1ffb39fd-8038-487d-cc9d-5285237b7b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 673,   69,    5,   57, 2119],\n",
              "       [ 144, 1170,   95,    1,   34],\n",
              "       [  16, 1057,  581,  108,    8],\n",
              "       ...,\n",
              "       [   3,  252,   13,  491,  536],\n",
              "       [  28,   40,    4,   61,  753],\n",
              "       [ 674,  133,  244, 3461,   60]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contexts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeeARcsF3RGA",
        "outputId": "5a409457-22a2-40dc-8a2d-68a5583889d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64702, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Le premier mot dans contexts est le mot qui se trouve sur le target et les 4 mots qui reste ne sont pas dans le contexte donc faux d'où 0.\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6arJ-yY5duj",
        "outputId": "b5a76eb6-a262-441c-d562-212f0ccdc7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuPPGrQ73bTG",
        "outputId": "73d537f3-921e-4100-b5cd-6a7f7924f135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([64702,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weFHjgAf3dQN",
        "outputId": "e17012fe-5ac6-4f11-b390-4267420a408a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64702, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfog0Wbb36YC",
        "outputId": "fd76d4aa-a936-43da-8170-bcf48b111fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa5YKCF74CNW",
        "outputId": "aaa353d0-eeb7-4df0-d71d-993e9db7914a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number of negative samples per positive context.\n",
        "num_ns = 4\n",
        "\n",
        "class Word2Vec(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Word2Vec, self).__init__()\n",
        "    self.target_embedding = tf.keras.layers.Embedding(vocab_size,\n",
        "                                      embedding_dim,\n",
        "                                      input_length=1,\n",
        "                                      name=\"w2v_embedding\")\n",
        "    self.context_embedding = tf.keras.layers.Embedding(vocab_size,\n",
        "                                       embedding_dim,\n",
        "                                       input_length=num_ns+1)\n",
        "\n",
        "  def call(self, pair):\n",
        "    target, context = pair\n",
        "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
        "    # context: (batch, context)\n",
        "    if len(target.shape) == 2:\n",
        "      target = tf.squeeze(target, axis=1)\n",
        "    # target: (batch,)\n",
        "    word_emb = self.target_embedding(target)\n",
        "    # word_emb: (batch, embed)\n",
        "    context_emb = self.context_embedding(context)\n",
        "    # context_emb: (batch, context, embed)\n",
        "    dots = tf.einsum('be,bce->bc', word_emb, context_emb) # b: batch, c: sequence = 5, e: embedding_dim\n",
        "    # dots: (batch, context)\n",
        "    return dots"
      ],
      "metadata": {
        "id": "-FySRXls5Gib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_embedding = tf.keras.layers.Embedding(5,\n",
        "                                  5,\n",
        "                                  input_length=1,\n",
        "                                  name=\"w2v_embedding\")"
      ],
      "metadata": {
        "id": "I_bjjWRm8iWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_embedding(np.array([2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8cRIKZR8pVn",
        "outputId": "2d7f5b4c-f520-402b-83c3-4d21fb6eb338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
              "array([[ 0.01872643,  0.04774718, -0.03377201, -0.0115474 , -0.02404326]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 128\n",
        "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
        "word2vec.compile(optimizer='adam',\n",
        "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                 metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "VwoS98Ty6M41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n"
      ],
      "metadata": {
        "id": "022ovM4E6PxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])\n"
      ],
      "metadata": {
        "id": "lrWr89yB6Tfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#docs_infra: no_execute\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "vg4N5DSr67Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "LH5uiCaV7AOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 3\n",
        "vec = weights[index]"
      ],
      "metadata": {
        "id": "DhLWNHR57Wf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Example 1: TimeDistributed et einsum**"
      ],
      "metadata": {
        "id": "b5fBuwtrnLDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TimeDistributed enveloppe une couche Dense dans cet exemple pour traiter l'entrée (la séquence) de manière indépendante, c'est à dire chaque timestamp est considéré comme un vecteur d'entrée. Si on ne l'utilise pas, la couche Dense considère toute la séquence comme un vecteur simple donc supprime l'ordre."
      ],
      "metadata": {
        "id": "6ZwUMRKQJopt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, RepeatVector, TimeDistributed\n",
        "\n",
        "# Création du modèle séquentiel\n",
        "model = Sequential()\n",
        "\n",
        "# Ajout d'une couche Dense pour traiter le vecteur d'entrée de dimension 1\n",
        "model.add(Dense(8, input_dim=1, activation='relu'))\n",
        "\n",
        "# Ajout d'une couche RepeatVector pour répéter le vecteur de sortie\n",
        "model.add(RepeatVector(2))\n",
        "\n",
        "# Ajout d'une couche TimeDistributed pour appliquer la couche Dense à chaque pas de temps de la séquence au lieu de considérer la séquence comme un vecteur\n",
        "model.add(TimeDistributed(Dense(4, activation='softmax')))\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Affichage de la structure du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESx8LOAlr71r",
        "outputId": "7c03ad9f-71e8-4dbf-ba9a-6eb9a0f96cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 16        \n",
            "                                                                 \n",
            " repeat_vector (RepeatVecto  (None, 2, 8)              0         \n",
            " r)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, 2, 4)              36        \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52 (208.00 Byte)\n",
            "Trainable params: 52 (208.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, RepeatVector, TimeDistributed\n",
        "\n",
        "# Création du modèle séquentiel\n",
        "model = Sequential()\n",
        "\n",
        "# Ajout d'une couche Dense pour traiter le vecteur d'entrée de dimension 1\n",
        "model.add(Dense(8, input_dim=1, activation='relu'))\n",
        "\n",
        "# Ajout d'une couche RepeatVector pour répéter le vecteur de sortie\n",
        "model.add(RepeatVector(2))\n",
        "\n",
        "# Ajout d'une couche TimeDistributed pour appliquer la couche Dense à chaque pas de temps de la séquence\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compilation du modèle\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Affichage de la structure du modèle\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtgIzZxJw4E4",
        "outputId": "71fa4506-8edf-4f0d-fc5a-f3f695c754d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 8)                 16        \n",
            "                                                                 \n",
            " repeat_vector_1 (RepeatVec  (None, 2, 8)              0         \n",
            " tor)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2, 4)              36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52 (208.00 Byte)\n",
            "Trainable params: 52 (208.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Tenseurs d'exemple\n",
        "a = tf.constant([[1, 2], [3, 4]])\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L7Mh8eq_v58",
        "outputId": "3272d062-4a01-428b-c59a-c55f164bbbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[1, 2],\n",
              "       [3, 4]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = tf.constant([[[5, 6], [7, 8], [9, 10]], [[11, 12], [13, 14], [15, 16]]])\n",
        "b"
      ],
      "metadata": {
        "id": "sRqo9ttY_zrS",
        "outputId": "456b87ce-ab75-4e4b-b909-9c0e8d7ecc83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
              "array([[[ 5,  6],\n",
              "        [ 7,  8],\n",
              "        [ 9, 10]],\n",
              "\n",
              "       [[11, 12],\n",
              "        [13, 14],\n",
              "        [15, 16]]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Opération einsum\n",
        "result = tf.einsum('be,bce->bc', a, b)\n",
        "\n",
        "# Affichage du résultat\n",
        "print(result.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YJT2e1q_tZG",
        "outputId": "35ed6bbb-d647-4a4c-97a9-3a856e304e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 17  23  29]\n",
            " [ 81  95 109]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QVlyvyH_Z6Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WkokC8HXZ6X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  return tf.strings.regex_replace(lowercase,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "\n",
        "# Define the vocabulary size and the number of words in a sequence.\n",
        "vocab_size = 4096\n",
        "sequence_length = 10\n",
        "\n",
        "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
        "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
        "# same length.\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int')\n"
      ],
      "metadata": {
        "id": "ZOlUQ7axZ6aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\"I am very pround\", \"you are here\"]\n",
        "\n",
        "vectorize_layer.adapt(data)"
      ],
      "metadata": {
        "id": "mmJ1zUeEaCxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9JGlwl-aSF2",
        "outputId": "8e8ea697-d1af-4db5-e828-51ca31092b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'you', 'very', 'pround', 'i', 'here', 'are', 'am']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL1sjwcKaZtZ",
        "outputId": "0acb94c8-4ccd-47bc-87e5-bfa02303d301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 4), dtype=int64, numpy=\n",
              "array([[5, 8, 3, 4],\n",
              "       [2, 7, 6, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attention**"
      ],
      "metadata": {
        "id": "MK44Ilq7Xico"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dot product Attention**"
      ],
      "metadata": {
        "id": "2ycATS9U0u8U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour deux vecteurs $h_i$ et $h_j$, le produit scalaire donne le poids d'attention. on considère que $h$ est un vecteur colonne :<br><br>\n",
        "$score  = h_i^T.h_j$<br><br>\n",
        "$AttentionDot(h_i, h_j) = \\frac{\\exp(score(h_i, h_j))}{\\sum_k \\exp(score(h_i, h_k))}$"
      ],
      "metadata": {
        "id": "b85t8Wkt0zXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class DotProductAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(DotProductAttention, self).__init__()\n",
        "\n",
        "    def call(self, query, keys, values):\n",
        "        \"\"\"\n",
        "          Trois réseaux doivent être utilisés chacun de units = dim, qui produisent query, keys et values\n",
        "          query: (batch, Tq, dim)\n",
        "          keys: (batch, Tk, dim)\n",
        "          values: (batch, Tv, dim)\n",
        "        \"\"\"\n",
        "        # Calcul du produit scalaire entre la requête et les clés\n",
        "        scores = tf.matmul(query, keys, transpose_b=True) # (batch, Tq, Tk)\n",
        "\n",
        "        # Calcul des poids d'attention avec la fonction softmax\n",
        "        attention_weights = tf.nn.softmax(scores, axis=-1) # (batch, Tq, Tk)\n",
        "\n",
        "        # Calcul de la somme pondérée des valeurs\n",
        "        context_vector = tf.matmul(attention_weights, values) # (batch, Tq, dim)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "# Exemple d'utilisation\n",
        "attention_layer = DotProductAttention()\n",
        "\n",
        "# Création d'une requête, de clés et de valeurs fictives\n",
        "query = tf.random.normal([1, 32])\n",
        "keys = tf.random.normal([1, 10, 32])\n",
        "values = tf.random.normal([1, 10, 64])\n",
        "\n",
        "# Calcul de l'attention\n",
        "context_vector, attention_weights = attention_layer(query, keys, values)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Values:\", values)\n",
        "print(\"Attention Weights:\", attention_weights)\n",
        "print(\"Context Vector:\", context_vector)\n"
      ],
      "metadata": {
        "id": "9MeV2RCQGx0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Luong Attention**"
      ],
      "metadata": {
        "id": "pFFcDU4U2mya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour deux vecteurs $h_i$ et $h_j$, le produit scalaire donne le poids d'attention :<br><br>\n",
        "$score  = h_i.W_a.h_j$<br><br>\n",
        "$W_a$ matrices de poids (plusieurs neurones = units=n)<br><br>\n",
        "$AttentionLuong(h_i, h_j) = \\frac{\\exp(score(h_i, h_j))}{\\sum_k \\exp(score(h_i, h_k))}$"
      ],
      "metadata": {
        "id": "VA_wonyM2sQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(LuongAttention, self).__init__()\n",
        "        self.W = tf.keras.layers.Dense(units)\n",
        "\n",
        "    def call(self, query, keys):\n",
        "        \"\"\"\n",
        "        query: (batch, dim) souvent le hidden state du decoder (dim=units)\n",
        "        keys: (batch, Tk, dim)\n",
        "        \"\"\"\n",
        "        # Ajout d'une nouvelle dimension à la requête pour permettre la concaténation\n",
        "        query_with_time_axis = tf.expand_dims(query, 1) # (batch, 1, dim)\n",
        "\n",
        "        # Calcul des scores d'attention\n",
        "        score = tf.matmul(query_with_time_axis, self.W(keys), transpose_b=True) # (batch, 1, Tk)\n",
        "\n",
        "        # Calcul des poids d'attention avec la fonction softmax\n",
        "        attention_weights = tf.nn.softmax(score, axis=2) # (batch, 1, Tk)\n",
        "\n",
        "        # Calcul de la somme pondérée des valeurs\n",
        "        context_vector = tf.matmul(attention_weights, keys) # (batch, 1, dim)\n",
        "\n",
        "        return tf.squeeze(context_vector, axis=1), attention_weights # (batch, dim), (batch, 1, Tk)\n",
        "\n",
        "# Exemple d'utilisation\n",
        "units = 32\n",
        "attention_layer = LuongAttention(units)\n",
        "\n",
        "# Création d'une requête et de clés fictives\n",
        "query = tf.random.normal([1, units])\n",
        "keys = tf.random.normal([1, 10, units])\n",
        "\n",
        "# Calcul de l'attention\n",
        "context_vector, attention_weights = attention_layer(query, keys)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Keys:\", keys)\n",
        "print(\"Attention Weights:\", attention_weights)\n",
        "print(\"Context Vector:\", context_vector)\n"
      ],
      "metadata": {
        "id": "CMbcTZUfHk77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bahdanau Attention (Additive)**"
      ],
      "metadata": {
        "id": "FAabTCHr29XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour deux vecteurs $h_i$ et $h_j$, le produit scalaire donne le poids d'attention :<br><br>\n",
        "$score  = v_a^T.tanh(W_{a1}.h_i + W_{a2}.h_j)$<br><br>\n",
        "$W_{a1}, W_{a2}$ matrices de poids (plusieurs neurones, units=n) <br><br>\n",
        "$v_a$ vecteur de poids (1 neurone = units=1)<br><br>\n",
        "$AttentionBahdanau(h_i, h_j) = \\frac{\\exp(score(h_i, h_j))}{\\sum_k \\exp(score(h_i, h_k))}$"
      ],
      "metadata": {
        "id": "m4n9VlT83FM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        \"\"\"\n",
        "        query: (batch, dim) souvent le hidden state du decoder\n",
        "        values: (batch, Tv, dim)\n",
        "        \"\"\"\n",
        "        # Ajout d'une nouvelle dimension à la requête pour permettre la concaténation\n",
        "        query_with_time_axis = tf.expand_dims(query, 1) # (batch, 1, dim)\n",
        "\n",
        "        # Calcul des scores d'attention\n",
        "        score = tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)) # (batch, Tv, dim)\n",
        "\n",
        "        # Calcul des poids d'attention\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1) # (batch, Tv, 1)\n",
        "\n",
        "        # Calcul de la somme pondérée des valeurs\n",
        "        context_vector = attention_weights * values # (batch, Tv, dim)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1) # (batch, dim)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "# Exemple d'utilisation\n",
        "units = 32\n",
        "attention_layer = BahdanauAttention(units)\n",
        "\n",
        "# Création d'une requête et de valeurs fictives\n",
        "query = tf.random.normal([1, units])\n",
        "values = tf.random.normal([1, 10, units])\n",
        "\n",
        "# Calcul de l'attention\n",
        "context_vector, attention_weights = attention_layer(query, values)\n",
        "\n",
        "print(\"Query:\", query)\n",
        "print(\"Values:\", values)\n",
        "print(\"Attention Weights:\", attention_weights)\n",
        "print(\"Context Vector:\", context_vector)\n"
      ],
      "metadata": {
        "id": "oohF0rNkHrNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$Attention(Q,K,V)=softmax(Q⋅W_q+K⋅W_k)⋅V$"
      ],
      "metadata": {
        "id": "ScLzFk0iF1J8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapes algorithmes: <br>\n",
        "1. Expands query si nécessaire<br>\n",
        "2. Calculer scores<br>\n",
        "3. caculer attention<br>\n",
        "4. Faire matmul (dot et Luong) ou * (Bahdanau) de attention avec values.<br>\n",
        "5. Retourner sortie pour dot (sequence), retourner squeeze(sortie, axis=1) pour Luong (vecteur) et reduce_sum(sortie, axis=1) (vecteur).<br>"
      ],
      "metadata": {
        "id": "7vt8Q3FEUMvi"
      }
    }
  ]
}