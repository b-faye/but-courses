{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<center><h1>KERAS.LOSSES</h1></center>**<br>\n",
        "Dans keras.losses, on a des fonctions et des classes:<br>\n",
        "1. **keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True)** est une fonction qu'on directement utilisée dans tf.GradientTape.<br>\n",
        "2. **a = keras.losses.CategoricalCrossentropy(from_logits=True)** est une classe, on fait **a(y_true, y_pred)**.<br>\n",
        "On a aussi **KERAS.METRICS**, **KERAS.OPTIMIZERS**, ETC.<br>\n",
        "\n",
        "**<center><h1>Training Keras Model</h1></center>**<br>\n",
        "On peut noter **04** approches:<br>\n",
        "1. **fit:** c'est la méthode standard.<br>\n",
        "\n",
        "2. **keras.Model:** Créer une classe qui hérite de la classe **keras.models.Model** or **keras.Model**. Cette classe doit implémenter **train_step** qui utilise **tf.GradientTape** pour mettre à jour les **poids** du modèle par **batch**. On peut aussi implémenter **test_step** pour le test, **call** pour le **forward**, **metrics** qui retourne la liste des métriques (mise à jour), **computer_loss** pour retourner la **loss**.<br>\n",
        "\n",
        "3. **@tf.function:** Créer une fonction en la faisant précédée par **@tf.function**. Cette approche permet à la fonction créée de pouvoir être compiler c'est à dire utiliser le **tf.GradientTape**. La fonction ainsi créée peut être utilisée dans une fonction qui fait une boucle sur le nombre d'époques et donne entrée **batch** par **batch** à la fonction qui met à jour les poids suivant les batchs donnés.<br>\n",
        "\n",
        "4. **train_on_batch:** C'est une **méthode** de la classe Model de keras, tout modèle de keras peut donc y accéder. On crée d'abord un modèle **model**, on utilise d'abord une boucle sur le nombre d'époque suivie d'une boucle qui prend **batch par batch**, on fait à chaque fois **model.train_on_batch(x_batch, y_batch)** qui retourne la **loss** sur le batch et les métriques si c'es définit dans le compile de **model**.<br>\n",
        "\n",
        "**<center><h1>Passage par valeur des modèles</h1></center>**<br>\n",
        "Supposons qu'on ait 03 modèles: <br>\n",
        "\n",
        "**model1 = tf.keras.models.Sequential()**<br>\n",
        "**model2 = tf.keras.models.Sequential()**<br>\n",
        "**model3 = tf.keras.models.Sequential()**<br>\n",
        "\n",
        "**model3.add(model1**)<br>\n",
        "**mdoel3.model1.trainable = False** <br>\n",
        "**model3.add(model2)**<br>\n",
        "\n",
        "model1 est utilisé dans model3, même si c'est son trainable=False, toute modification (mise à jour) fait sur model1 en dehors va se répercuter sur model3.model1, même si les modifications sont faites à l'intérieur d'une fonction.<br>\n",
        "**NB:** Dès qu'on crée un modèle, on l'utilise pour intialiser ou l'affecter ou à un autre modèle les modifications apportées sur un de ces modèles affectent le modèle de base. Voir la section: Method using train_on_batch.<br>\n",
        "\n",
        "**<center><h1>Bahdanau Attention</h1></center>**<br>\n",
        "C'est une attention additive, l'objectif est de prendre l'état caché du decoder comme query et le output de l'encoder comme value pour produre un vecteur de contexte. Le vecteur de contexte est concaténé avec l'embedding de l'entrée du decoder (qui prend token par token), et sert d'entrée à la couche rnn, lstm ou gru.<br>\n",
        "\n",
        "Q = Decoder hidden state (None, decoder_unit)<br>\n",
        "    at the begining, Q = Encoder hidden state<br>\n",
        "\n",
        "V = Encoder output (None, sequence, feature)<br>\n",
        "\n",
        "Q = tf.expand_dims(Q, axis=1) # (None, 1, decoder_unit)<br>\n",
        "EncQ = Dense1(Q) # (None, units)<br>\n",
        "EncV = Dense2(V) # (None, sequence, units)<br>\n",
        "sum = tf.nn.tanh(EncQ+EncV) # activation (None, sequence, units)<br>\n",
        "\n",
        "score = Dense3(sum) # (None, sequence, 1)<br>\n",
        "attention = tf.nn.softmax(score, axis=1) # (None, sequence, 1) softmax based on token position<br>\n",
        "\n",
        "context_vector = attention*V # (None, sequence, feature)<br>\n",
        "context_vector = tf.nn.sum(context_vector, axis=1) # (None, feature)<br>\n",
        "\n",
        "context_vector sera utilisé dans le decoder et concaténer avec l'entrée (qui se fait token par token)<br>\n",
        "x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # (None, 1, feature+embedding_dim_x) x vient de l'embedding x est de type (None, 1) car on traite par token Embedding donne (None, 1, embedding_dim_x)<br>\n",
        "\n",
        "\n",
        "**<center><h1>Paramètres et Sorties</h1></center>**<br>\n",
        "\n",
        "**<h2>MLP (Dense)</h2>**<br>\n",
        "**1. Sortie:** Si l'entrée est de dimension 2, la sortie sera **(None, units)**, si l'entrée est de dimension 3 (séquences), la sortie sera **(None, sequence, units)**, si l'entrée est de dimension 4 (convolutions ou images), la sortie sera **(None, H, W, units)**.<br>\n",
        "\n",
        "**2. Paramètres:** **D*W + W**, avec D la dimension de l'entrée, W le nombre de units.<br>\n",
        "\n",
        "**<h2>CNN (Conv2D)</h2>**<br>\n",
        "**1. Sortie:** **(n - f + p) / s**, avec n la taille de l'entrée, f la taille du filtre, p = taille du filtre si padding = 'same' et p = 0 si padding='valid', s est la taille du stride. ON considère la partie entière inférieure.<br>\n",
        "**NB:** Si conv2DTranspose ou UpSampling2D, on effectue l'opération inverse **s × (n + f - p)**.<br>\n",
        "\n",
        "\n",
        "**Paramètres:** Le nombre de paramètres de la couche, dépend du nombre de canal de la couche précédente. La couche actuelle contient par exemple 2 filtres, et que la couche précédente contient 3 canaux, le filtre 1 va être dupliqué sur les 3 canaux et si la taille du filtre est (2, 2), donc y aura 3 × (2 × 2) paramètres à apprendre avec le même biais donc 3 × (2 × 2) + 1. Le même processus s'applique sur le filtre 2. La formule générale est alors:<br> <center>**(hauteur_filtre × largeur_filtre × nombre_canaux_couche_precedente + 1 ) × nombre_filtres**</center><br>\n",
        "\n",
        "**Les couches de Pooling n'ont pas de paramètres à apprendre**<br>\n",
        "\n",
        "\n",
        "**<h2>RNN</h2>**<br>\n",
        "**1. Sortie:** Par défaut, retourne (None, units). Si return_sequences = True, (None, sequence, units). Si return_state = True, on aura deux outputs, (None, units), (None, units). Si return_sequences=True et return_state=True on aura (None, sequence, units), (None, units).<br>\n",
        "**NB:** Ceci est valable pour les **GRU**, pour les **LSTM**, return_sate=True donne deux état (None, units) pour hidden_state et (None, units) pour cell_state.\n",
        "\n",
        "**2. Paramètres:** L'entrée correspond à deux vecteurs concaténés: x (dernière dimension de l'entrée: **shape[-1]**) et h. x le token d'entrée et h l'état de caché.<br>\n",
        "**<center>RNN: (x + h) × h + h</center>**<br>\n",
        "**<center>LSTM: 4 × [(x + h) × h + h] </center>** <br>\n",
        "**<center>GRU: 3 × [(x + h) × h + h]</center>**"
      ],
      "metadata": {
        "id": "jjT2qFZpM6_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept: GradientTape**"
      ],
      "metadata": {
        "id": "QRjAeZCYzgh3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OBAyQqIzcx8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "EXAMPLE : LOSS IS NOT GIVEN IN COMPILE\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_states()` yourself at the time of your choosing.\n",
        "        return [self.loss_tracker, self.mae_metric] ## List all metrics\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute our own loss\n",
        "            loss = keras.losses.mean_squared_error(y, y_pred) ## if loss if given in comile, we can use by self.compute_loss\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars)) ## optimizer is given in self.optimizer\n",
        "\n",
        "        # Compute our own metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()} ## bar progress for user {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        # Compute predictions\n",
        "        y_pred = self(x, training=False) ## Freeze weights\n",
        "        loss = keras.losses.mean_squared_error(y, y_pred)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "# Construct an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "# We don't passs a loss or metrics here.\n",
        "model.compile(optimizer=\"adam\")\n",
        "\n",
        "# Just use `fit` as usual -- you can use callbacks, etc.\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "model.fit(x, y, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EXAMPLE : LOSS IS GIVEN IN COMPILE\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_states()` yourself at the time of your choosing.\n",
        "        return [self.loss_tracker, self.mae_metric] ## List all metrics\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute our own loss\n",
        "            loss = self.compute_loss(y, y_pred) ### Changed line\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars)) ## optimizer is given in self.optimizer\n",
        "\n",
        "        # Compute our own metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()} ## bar progress for user {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        # Compute predictions\n",
        "        y_pred = self(x, training=False) ## Freeze weights\n",
        "        loss = self.compute_loss(y, y_pred) ### Changed line\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {m.name:m.result() for m in self.metrics}\n",
        "\n",
        "# Construct an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "# We don't passs a loss or metrics here.\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "# Just use `fit` as usual -- you can use callbacks, etc.\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "model.fit(x, y, epochs=5)"
      ],
      "metadata": {
        "id": "keMpVnjq4d6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EXAMPLE: PONDERATION OF CLASSES USING WEIGHTS\n",
        "\"\"\"\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        if len(data) == 3:\n",
        "            x, y, sample_weight = data\n",
        "        else:\n",
        "            sample_weight = None\n",
        "            x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute the loss value.\n",
        "            # The loss function is configured in `compile()`.\n",
        "            loss = self.compute_loss(\n",
        "                y=y,\n",
        "                y_pred=y_pred,\n",
        "                sample_weight=sample_weight,\n",
        "            )\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics.\n",
        "        # Metrics are configured in `compile()`.\n",
        "        for metric in self.metrics:\n",
        "            if metric.name == \"loss\":\n",
        "                metric.update_state(loss)\n",
        "            else:\n",
        "                metric.update_state(y, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        "# Construct and compile an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# You can now use sample_weight argument\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "sw = np.random.random((1000, 1))\n",
        "model.fit(x, y, sample_weight=sw, epochs=3)"
      ],
      "metadata": {
        "id": "okfA_q-F6f4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept - GAN EXAMPLE: GradientTape**"
      ],
      "metadata": {
        "id": "W4skGjP66yW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create the discriminator\n",
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "\n",
        "# Create the generator\n",
        "latent_dim = 128\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
        "        layers.Dense(7 * 7 * 128),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Reshape((7, 7, 128)),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")"
      ],
      "metadata": {
        "id": "XxDQ3-Av64lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_loss_tracker = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_tracker = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape: ##  We can either use with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics and return their value.\n",
        "        self.d_loss_tracker.update_state(d_loss)\n",
        "        self.g_loss_tracker.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_tracker.result(),\n",
        "            \"g_loss\": self.g_loss_tracker.result(),\n",
        "        }"
      ],
      "metadata": {
        "id": "JoWOgMs76-ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset. We use both the training & test MNIST digits.\n",
        "batch_size = 64\n",
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "# To limit the execution time, we only train on 100 batches. You can train on\n",
        "# the entire dataset. You will need about 20 epochs to get nice results.\n",
        "gan.fit(dataset.take(100), epochs=1)"
      ],
      "metadata": {
        "id": "6FQZPGe17JJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept - Image and Text Similarity: GradientTape**"
      ],
      "metadata": {
        "id": "-LGdVM2_Atrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "EXAMPLE: In this example, the loss is computing on the class\n",
        "         the optimizer is given in compile, we use self.optimizer to use it.\n",
        "         https://keras.io/examples/vision/nl_image_search/\n",
        "\"\"\"\n",
        "class DualEncoder(keras.Model):\n",
        "    def __init__(self, text_encoder, image_encoder, temperature=1.0, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.text_encoder = text_encoder\n",
        "        self.image_encoder = image_encoder\n",
        "        self.temperature = temperature\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def call(self, features, training=False):\n",
        "        # Place each encoder on a separate GPU (if available).\n",
        "        # TF will fallback on available devices if there are fewer than 2 GPUs.\n",
        "        with tf.device(\"/gpu:0\"):\n",
        "            # Get the embeddings for the captions.\n",
        "            caption_embeddings = text_encoder(features[\"caption\"], training=training)\n",
        "        with tf.device(\"/gpu:1\"):\n",
        "            # Get the embeddings for the images.\n",
        "            image_embeddings = vision_encoder(features[\"image\"], training=training)\n",
        "        return caption_embeddings, image_embeddings\n",
        "\n",
        "    def compute_loss(self, caption_embeddings, image_embeddings):\n",
        "        # logits[i][j] is the dot_similarity(caption_i, image_j).\n",
        "        logits = (\n",
        "            tf.matmul(caption_embeddings, image_embeddings, transpose_b=True)\n",
        "            / self.temperature\n",
        "        )\n",
        "        # images_similarity[i][j] is the dot_similarity(image_i, image_j).\n",
        "        images_similarity = tf.matmul(\n",
        "            image_embeddings, image_embeddings, transpose_b=True\n",
        "        )\n",
        "        # captions_similarity[i][j] is the dot_similarity(caption_i, caption_j).\n",
        "        captions_similarity = tf.matmul(\n",
        "            caption_embeddings, caption_embeddings, transpose_b=True\n",
        "        )\n",
        "        # targets[i][j] = avarage dot_similarity(caption_i, caption_j) and dot_similarity(image_i, image_j).\n",
        "        targets = keras.activations.softmax(\n",
        "            (captions_similarity + images_similarity) / (2 * self.temperature)\n",
        "        )\n",
        "        # Compute the loss for the captions using crossentropy\n",
        "        captions_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=targets, y_pred=logits, from_logits=True\n",
        "        )\n",
        "        # Compute the loss for the images using crossentropy\n",
        "        images_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=tf.transpose(targets), y_pred=tf.transpose(logits), from_logits=True\n",
        "        )\n",
        "        # Return the mean of the loss over the batch.\n",
        "        return (captions_loss + images_loss) / 2\n",
        "\n",
        "    def train_step(self, features):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            caption_embeddings, image_embeddings = self(features, training=True)\n",
        "            loss = self.compute_loss(caption_embeddings, image_embeddings)\n",
        "        # Backward pass\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        # Monitor loss\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def test_step(self, features):\n",
        "        caption_embeddings, image_embeddings = self(features, training=False)\n",
        "        loss = self.compute_loss(caption_embeddings, image_embeddings)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}"
      ],
      "metadata": {
        "id": "593tvL0vA2nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5  # In practice, train for at least 30 epochs\n",
        "batch_size = 256\n",
        "\n",
        "vision_encoder = create_vision_encoder(\n",
        "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
        ")\n",
        "text_encoder = create_text_encoder(\n",
        "    num_projection_layers=1, projection_dims=256, dropout_rate=0.1\n",
        ")\n",
        "dual_encoder = DualEncoder(text_encoder, vision_encoder, temperature=0.05)\n",
        "dual_encoder.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.001)\n",
        ")"
      ],
      "metadata": {
        "id": "nnK4nwxM7qFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow Graph concept - Relevant method for GAN - @tf.function: GradientTape**"
      ],
      "metadata": {
        "id": "WOJ400nj8UxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "\n",
        "# save checkpoints\n",
        "checkpoint_dir = \"training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                discriminator_optimizer=discriminator_optimizer,\n",
        "                                generator=generator,\n",
        "                                discriminator=discriminator)\n",
        "\n",
        "# Constant\n",
        "EPOCHS = 50\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "seed = tf.random.normal((num_examples_to_generate, noise_dim))\n",
        "\n",
        "# @tf.function enables to use compile with train_step\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "# Train function\n",
        "def train(datasets, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for img_batch in datasets:\n",
        "            train_step(img_batch)\n",
        "\n",
        "        # Produce images for the GIF\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator,\n",
        "                                epoch+1,\n",
        "                                seed)\n",
        "\n",
        "        # Save the model every 15 epochs\n",
        "        if (epoch+1)%15 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "\n",
        "        print(\"Time for epoch {} is {} sec\".format(epoch+1, time.time()-start))\n",
        "\n",
        "    # Generate after the final epoch\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                                epoch,\n",
        "                                seed)\n",
        "\n",
        "# Predicion\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4,4,i+1)\n",
        "        plt.imshow(predictions[i, :, :, :]*127.5 + 127.5)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('generated_image/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "# Train\n",
        "train(train_dataset, EPOCHS)\n",
        "\n",
        "# Restore\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# Plot\n",
        "def display_image(epoch):\n",
        "    return PIL.Image.open(\"generated_image/image_at_epoch_{:04d}.png\".format(epoch))\n",
        "display_image(EPOCHs)"
      ],
      "metadata": {
        "id": "UltzLG6r8fMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We can use an other approach\n",
        "\"\"\"\n",
        "# @tf.function enables to use compile with train_step\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "\n",
        "        # Train discriminator\n",
        "        noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
        "        generated_images = generator.predict(noise)\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Train generator\n",
        "        noise = tf.random.normal((BATCH_SIZE, noise_dim))\n",
        "        generated_images = generator(noise, training=True)\n",
        "        fake_output = discriminator(generated_images, training=False)\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "\n",
        "\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n"
      ],
      "metadata": {
        "id": "a-kBS1vQAVn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method using train_on_batch**"
      ],
      "metadata": {
        "id": "cX1lFt5UEtua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This method use an other approach for training : train_on_batch\n",
        "https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-cifar-10-small-object-photographs-from-scratch/\n",
        "\"\"\"\n",
        "\n",
        "# Define the standalone discriminator model\n",
        "def define_discriminator(in_shape=(32, 32, 3)):\n",
        "    in_image = Input(shape=in_shape)\n",
        "    # Normal\n",
        "    x = Conv2D(64, (3, 3), padding='same')(in_image)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Downsample\n",
        "    x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Downsample\n",
        "    x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Downsample\n",
        "    x = Conv2D(256, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    # Classifier\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(in_image, x)\n",
        "\n",
        "    # Compile model\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "    in_lat = Input(shape=(latent_dim,))\n",
        "    # Foundation for 4x4 image\n",
        "    n_nodes = 256 * 4 * 4\n",
        "    x = Dense(n_nodes)(in_lat)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Reshape((4, 4, 256))(x)\n",
        "\n",
        "    # Upsample to 8x8\n",
        "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Upsample to 16x16\n",
        "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Upsample to 32x32\n",
        "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x, training=True)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = Conv2D(3, (3, 3), activation='tanh', padding='same')(x)\n",
        "\n",
        "    model = Model(in_lat, x)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "4vUhW-GkEzQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Define the gan model that combine discriminator that is frozen and generator that is not frozen\n",
        "NB: Freeze discriminator\n",
        "    Not Freeze generator\n",
        "\"\"\"\n",
        "def define_gan(g_model, d_model):\n",
        "    # make weights in the discriminator not trainable\n",
        "    d_model.trainable = False\n",
        "    # connect them\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(g_model)\n",
        "    # add the discriminator\n",
        "    model.add(d_model)\n",
        "    # compile model\n",
        "    opt = Adam(learning_rate=0.0002, beta_1=0, beta_2=0.9)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Wqy5HvpEJYBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and prepare cifar10 training images\n",
        "def load_real_samples():\n",
        "    # load cifar10 dataset\n",
        "    (trainX, _), (_, _) = load_data()\n",
        "    # convert from unsigned ints to floats\n",
        "    X = trainX.astype('float32')\n",
        "    # scale from [0,255] to [-1,1]\n",
        "    X = (X - 127.5) / 127.5\n",
        "    return X\n",
        "\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "    # choose random instances\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    # retrieve selected images\n",
        "    X = dataset[ix]\n",
        "    # generate 'real' class labels (1)\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # generate points in the latent space\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    # reshape into a batch of inputs for the network\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    # generate points in latent space\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    # predict outputs\n",
        "    X = g_model.predict(x_input, verbose=0)\n",
        "    # create 'fake' class labels (0)\n",
        "    y = zeros((n_samples, 1))\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "oNd7sF7mLGin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create and save a plot of generated images\n",
        "def save_plot(examples, epoch, n=7):\n",
        "     # scale from [-1,1] to [0,1]\n",
        "     examples = (examples + 1) / 2.0\n",
        "     # plot images\n",
        "     for i in range(n * n):\n",
        "         # define subplot\n",
        "         pyplot.subplot(n, n, 1 + i)\n",
        "         # turn off axis\n",
        "         pyplot.axis('off')\n",
        "         # plot raw pixel data\n",
        "         pyplot.imshow(examples[i])\n",
        "     # save plot to file\n",
        "     filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "     pyplot.savefig(filename)\n",
        "     pyplot.show()"
      ],
      "metadata": {
        "id": "bmrZgAQYLRTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the discriminator, plot generated images, save generator model\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n",
        "     # prepare real samples\n",
        "     X_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "     # evaluate discriminator on real examples\n",
        "     _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "     # prepare fake examples\n",
        "     x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "     # evaluate discriminator on fake examples\n",
        "     _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "     # summarize discriminator performance\n",
        "     print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "     # save plot\n",
        "     save_plot(x_fake, epoch)\n",
        "     # save the generator model tile file\n",
        "     filename = 'generator_model_%03d.h5' % (epoch+1)\n",
        "     g_model.save(filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "k8xdX-hMLodD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=200, n_batch=128):\n",
        "     bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "     half_batch = int(n_batch / 2)\n",
        "     # manually enumerate epochs\n",
        "     for i in range(n_epochs):\n",
        "     # enumerate batches over the training set\n",
        "         for j in range(bat_per_epo):\n",
        "            \"\"\"\n",
        "              Train the discriminator\n",
        "              NB: The same discriminator and generator is used in all training\n",
        "            \"\"\"\n",
        "             # get randomly selected 'real' samples\n",
        "             X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "             # update discriminator model weights\n",
        "             d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "             # generate 'fake' examples\n",
        "             X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "             # update discriminator model weights\n",
        "             d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "\n",
        "            \"\"\"\n",
        "              Train the generator\n",
        "            \"\"\"\n",
        "             # prepare points in latent space as input for the generator\n",
        "             X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "             # create inverted labels for the fake samples\n",
        "             y_gan = ones((n_batch, 1))\n",
        "             # update the generator via the discriminator's error\n",
        "             g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "             # summarize loss on this batch\n",
        "         print('epoch %d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "         (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "         # evaluate the model performance, sometimes\n",
        "         if (i+1) % 10 == 0:\n",
        "             summarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ],
      "metadata": {
        "id": "A2I2fUiQLq1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "NB: d_model et g_model sont utilisés pour créer gan_model\n",
        "    Il faut noter que d_model.train_on_batch va mettre à jour les poids de d_model dans gan_model (c'est le même d_model)\n",
        "    aussi toutes les modifications de g_model vont répercuter sur le g_model dans gan_model donc c'est le même\n",
        "    \"\"\"\n",
        "\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "metadata": {
        "id": "x1KpLF68MvYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Translation**"
      ],
      "metadata": {
        "id": "io0_fPX_EiAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Dans cet exemple, on pose l'hypothèse que les données sont déjà représentées sous forme de séquence c'est à dire qu'on n'a\n",
        "pas besoin de la couche d'Embedding. Dans le cas courant, où les données sont représentées sous forme de vecteur, il faut nécessairement un embedding\n",
        "pour avoir chaque mot représenté en vecteur.\n",
        "https://www.kaggle.com/code/akshat0007/machine-translation-english-to-french-rnn-lstm\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BtVyENa2yVvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "input_encoder = Input(shape=(None, features))\n",
        "encoder = LSTM(units=latent_dim, return_states=True)\n",
        "output_encoder, state_h, state_c = encoder(input_encoder)\n",
        "\n",
        "# Decoder\n",
        "input_decoder = Input(shape=(None, features))\n",
        "decoder = LSTM(units=latent_dim, return_states=True, return_sequences=True)\n",
        "output_lstm, _, _ = decoder(input_decoder, initial_state=[state_h, state_c])\n",
        "dense_layer = Dense(units=vocab_size, activation=\"softmax\")\n",
        "dense_output = dense_layer(output_lstm)\n",
        "\n",
        "# Model\n",
        "model = Model([input_encoder, input_encoder], dense_output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]) # one hot in label\n",
        "\n",
        "# Train\n",
        "model.fit([encoder_data, decoder_data], y_decoder, epochs=100, batch_size=32)"
      ],
      "metadata": {
        "id": "Qe9VyiFrEmNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "After training, we build an encoder and decoder depending on the training model for prediction\n",
        "\"\"\"\n",
        "\n",
        "# Build Encoder\n",
        "encoder = Model(input_encoder, [output_encoder, state_h, state_c])\n",
        "\n",
        "# Build Decoder\n",
        "input_decoder = Input(shape=(1, features))\n",
        "input_h = Input(shape=(latent_dim, ))\n",
        "input_c = Input(shape=(latent_dim, ))\n",
        "output_lstm, state_h state_c = decoder(input_decoder, initial_state=[input_h, input_c])\n",
        "output_decoder = dense_layer(output_lstm)\n",
        "\n",
        "decoder = Model([input_decoder, input_h, input_c], [output_decoder, state_h, state_c])"
      ],
      "metadata": {
        "id": "iGceijhDj4Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "aZSdXGBOwV9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "metadata": {
        "id": "nHWRPsmZyK-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BahdanauAttention in LSTM using Hidden state as query**"
      ],
      "metadata": {
        "id": "lYCKFjVaREXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "ChatBot Introduction Colab: https://www.kaggle.com/code/alincijov/dialog-chatbot-using-bahdanau-attention\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ilKSwJYkoAME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset for train and test\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)  # Define the buffer size, typically the number of training examples.\n",
        "BATCH_SIZE = 64  # Define the batch size for training data.\n",
        "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE  # Calculate the number of steps per training epoch.\n",
        "embedding_dim = 256  # Define the dimension of word embeddings.\n",
        "units = 1024  # Define the number of units or neurons in a recurrent neural network (RNN) layer.\n",
        "vocab_inp_size = len(inp_lang.word_index) + 1  # Calculate the size of the input vocabulary.\n",
        "vocab_tar_size = len(targ_lang.word_index) + 1  # Calculate the size of the target vocabulary.\n",
        "\n",
        "# Create a TensorFlow dataset from the input and target tensors, and shuffle it using the specified BUFFER_SIZE.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# Batch the dataset into batches of BATCH_SIZE and drop any remaining examples that don't fit into a batch.\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Get an example input batch and an example target batch from the dataset.\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "\n",
        "# Print the shapes of the example input and target batches.\n",
        "print(\"Example Input Batch Shape:\", example_input_batch.shape)\n",
        "print(\"Example Target Batch Shape:\", example_target_batch.shape)"
      ],
      "metadata": {
        "id": "9dyI5sSvntWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "BahdanauAttention: prend en entrée le hidden_state de l'encoder considéré comme query, et la sortie de l'encoder considéré comme key et value\n",
        "La sortie de la couche BahdanauAttention utilisée dans le décodeur et concaténer avec le mot en cours de traitement (son embedding)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ia1vR80aYOxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom class called \"Encoder\" that inherits from the tf.keras.Model class.\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()  # Call the constructor of the parent class.\n",
        "        self.batch_sz = batch_sz  # Store the batch size as an instance variable.\n",
        "        self.enc_units = enc_units  # Store the number of units in the GRU layer.\n",
        "\n",
        "        # Create an embedding layer to convert input tokens into dense vectors.\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # Create a GRU (Gated Recurrent Unit) layer with specified parameters.\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # Define the forward pass for the encoder.\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)  # Pass the input through the embedding layer. --------------------------------(None, sequence, embedding_dim)\n",
        "        output, state = self.gru(x, initial_state=hidden)  # Pass through the GRU. --------------------------(None, sequence, enc_units), (None, enc_units)\n",
        "        return output, state  # Return the output sequence and final hidden state. --------------------------(None, sequence, enc_units), (None, enc_units)\n",
        "\n",
        "    # Initialize the hidden state (typically with zeros).\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "metadata": {
        "id": "Cdj5ig4yzWcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Q = Decoder hidden state (None, decoder_unit)\n",
        "    at the begining, Q = Encoder hidden state\n",
        "\n",
        "V = Encoder output (None, sequence, feature)\n",
        "\n",
        "Q = tf.expand_dims(Q, axis=1) # (None, 1, decoder_unit)\n",
        "EncQ = Dense1(Q) # (None, units)\n",
        "EncV = Dense2(V) # (None, sequence, units)\n",
        "sum = tf.nn.tanh(EncQ+EncV) # activation (None, sequence, units)\n",
        "\n",
        "score = Dense3(sum) # (None, sequence, 1)\n",
        "attention = tf.nn.softmax(score, axis=1) # (None, sequence, 1) softmax based on token position\n",
        "\n",
        "context_vector = attention*V # (None, sequence, feature)\n",
        "context_vector = tf.nn.sum(context_vector, axis=1) # (None, feature)\n",
        "\n",
        "context_vector sera utilisé dans le decoder et concaténer avec l'entrée (qui se fait token par token)\n",
        "x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # (None, 1, feature+embedding_dim_x) x vient de l'embedding x est de type (None, 1) car on traite par token Embedding donne (None, 1, embedding_dim_x)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "DM5eeUy8OkQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        \"\"\"\n",
        "          query = hidden state dec = (None, latent_dim)\n",
        "          values = outputs of enc = (None, sequence, latent_dim)\n",
        "        \"\"\"\n",
        "        # (None, 1, latent_dim)\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        # (None, sequence, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        # (batch_size, sequence, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # (None, sequence, latent_dim)\n",
        "        context_vector = attention_weights * values\n",
        "\n",
        "        # (None, latent_dim)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "metadata": {
        "id": "iZCkRue02acu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # used for attention\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ],
      "metadata": {
        "id": "rg4J57zf5JAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0)) # return False if 0 and True else (0 is the pad token)\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask # reduce to 0 if correspond to pad token (False)\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "29PQAbBOe5sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        # (BATCH_SIZE, 1)\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<sos>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "metadata": {
        "id": "g69pILvhe8t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 40\n",
        "\n",
        "# Training taking batch per batch\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "    if(epoch % 4 == 0):\n",
        "        print('Epoch:{:3d} Loss:{:.4f}'.format(epoch,\n",
        "                                          total_loss / steps_per_epoch))"
      ],
      "metadata": {
        "id": "VVIdz4EJe9lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **tf.data.Dataset**"
      ],
      "metadata": {
        "id": "6u9ZLl7tCsOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator\n",
        "# + load image: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ohFAFc_cHltF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class CustomDataGenerator(Sequence):\n",
        "    def __init__(self, x_data, y_data, batch_size, shuffle=True):\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.x_data))\n",
        "\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x_data) / self.batch_size)) # np.ceil : partie entière inférieure -->\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = (index + 1) * self.batch_size\n",
        "\n",
        "        batch_x = self.x_data[self.indexes[start:end]]\n",
        "        batch_y = self.y_data[self.indexes[start:end]]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "# Example usage:\n",
        "# Create some example data\n",
        "x_data = np.random.rand(100, 32, 32, 3)\n",
        "y_data = np.random.randint(0, 2, size=(100,))\n",
        "\n",
        "# Create an instance of the custom data generator\n",
        "batch_size = 32\n",
        "data_generator = CustomDataGenerator(x_data, y_data, batch_size)\n",
        "\n",
        "# Iterate through the data generator for training\n",
        "for epoch in range(epochs):\n",
        "    for batch_x, batch_y in data_generator:\n",
        "        # Train your model on batch_x and batch_y\n"
      ],
      "metadata": {
        "id": "APK-wSal437N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Source dataset**"
      ],
      "metadata": {
        "id": "WjdSkMTOLmKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data don't fit in memory\n",
        "data = [1,2,3]\n",
        "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mFQ8YeACwgP",
        "outputId": "1f241c63-5cc9-49a1-ffc8-f6176cb7c609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read lines from Files\n",
        "files = [\"text1\", \"text2\"]\n",
        "dataset = tf.data.TextLineDataset(files)\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoV_Jm-JItVI",
        "outputId": "6b0a220f-7472-4985-f83f-42c18f243640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Le senegal', shape=(), dtype=string)\n",
            "tf.Tensor(b'La gambie', shape=(), dtype=string)\n",
            "tf.Tensor(b'Le Maroc', shape=(), dtype=string)\n",
            "tf.Tensor(b'La Tunisie', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read name of files giving extension\n",
        "path = '*.txt'\n",
        "dataset = tf.data.Dataset.list_files(path)\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh6moXcKJ-eh",
        "outputId": "15a1c852-cee7-4d26-fa6c-ea761b4da963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'./text1.txt', shape=(), dtype=string)\n",
            "tf.Tensor(b'./text2.txt', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformation**"
      ],
      "metadata": {
        "id": "9eUcOl4NLpNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map\n",
        "map(\n",
        "    map_func,\n",
        "    num_parallel_calls=None,  # epresenting the number elements to process asynchronously in parallel. If not specified, elements will be processed sequentially. If the value tf.data.AUTOTUNE is used, then the number of parallel calls is set dynamically based on available CPU.\n",
        "    deterministic=None,\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "o4W2UqQ7hDiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. map\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1,2,3])\n",
        "dataset = dataset.map(lambda x: x**2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qS2dzYTLrGM",
        "outputId": "7d138890-13b4-4d2c-b406-603dddcfb26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. map\n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1,2,3], [0,1,1]))\n",
        "dataset = dataset.map(lambda x1, x2: (x1**2, x2))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyj1SdH5M8Yy",
        "outputId": "5516bfcf-9e01-4f43-d4a5-fee2694bc773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0), (4, 1), (9, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter\n",
        "dataset = tf.data.Dataset.range(100)\n",
        "dataset = dataset.filter(lambda x: x < 5)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1033XrBxOEmE",
        "outputId": "764fdcd9-e533-4c4d-d99e-763e6d51f095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply\n",
        "dataset = tf.data.Dataset.range(100)\n",
        "\n",
        "def my_filter(ds):\n",
        "    return ds.filter(lambda x: x < 5)\n",
        "\n",
        "dataset = dataset.apply(my_filter)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT836A9IO8WW",
        "outputId": "a5e9a7cc-6220-47d4-dd18-bb0ab02ba9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as_numpy_iterator\n",
        "dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),\n",
        "                                              'b': [5, 6]})\n",
        "list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5},\n",
        "                                      {'a': (2, 4), 'b': 6}]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zre3TDYjPk1e",
        "outputId": "0b2d73bc-79c8-42cd-f94c-a63007469857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch\n",
        "batch(\n",
        "    batch_size,\n",
        "    drop_remainder=False, # representing whether the last batch should be dropped in the case it has fewer than batch_size elements; the default behavior is not to drop the smaller batch.\n",
        "    num_parallel_calls=None, # number of batches to compute asynchronously in parallel\n",
        "    deterministic=None,\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "L3wubBukS7NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch\n",
        "dataset = tf.data.Dataset.range(8)\n",
        "dataset = dataset.batch(3)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpWQFS3HTgEa",
        "outputId": "507624ca-0a4c-40b0-b46f-55831cbaa811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(8)\n",
        "dataset = dataset.batch(3, drop_remainder=True)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WLNHRHjTqJ4",
        "outputId": "e435bbb8-5882-4566-d6b3-4db2fb89f80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5])]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cardinality\n",
        "dataset = tf.data.Dataset.range(42)\n",
        "print(dataset.cardinality().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq5IHbdsUGew",
        "outputId": "3c33d032-ea0c-4691-ee12-5d32bc90c7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flat_map\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "dataset = dataset.flat_map(tf.data.Dataset.from_tensor_slices)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyeFZgNOX9Pe",
        "outputId": "01a378e4-6923-4d56-88c4-8827c217d7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from_tensors: Creates a Dataset with a single element, comprising the given tensors.\n",
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
        "for element in dataset:\n",
        "    print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E3zcl10d99L",
        "outputId": "1c9db929-328e-4bb2-8c54-a8e2d9f6fe5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from_tensors: Creates a Dataset with a single element, comprising the given tensors.\n",
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMx4A6FidrWR",
        "outputId": "0fc911d6-a77b-41ae-8bc3-5bf0cbec857e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2, 3], dtype=int32)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make dataset**"
      ],
      "metadata": {
        "id": "LpL4Hh9ogXLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.data.Dataset.range(10)\n",
        "dataset = (\n",
        "    data\n",
        "    .map(lambda x: x**2, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(2)\n",
        ")\n",
        "\n",
        "for element in dataset:\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoR_EVxif2j-",
        "outputId": "b576c596-9687-437e-8c2d-fddc470b678e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
            "tf.Tensor([4 9], shape=(2,), dtype=int64)\n",
            "tf.Tensor([16 25], shape=(2,), dtype=int64)\n",
            "tf.Tensor([36 49], shape=(2,), dtype=int64)\n",
            "tf.Tensor([64 81], shape=(2,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements.\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UpA-D10k6SM",
        "outputId": "f210ac99-ae09-4000-aec8-9d8718c066d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a 2D tensor produces 1D tensor elements.\n",
        "dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxIVOUzAlILU",
        "outputId": "58024479-926d-4e82-abf8-2b1e6fafd994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2], dtype=int32), array([3, 4], dtype=int32)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing a tuple of 1D tensors produces tuple elements containing WAY FOR DATASET PROCESSING\n",
        "# scalar tensors.\n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwIGJN_VlKhf",
        "outputId": "8b7d0c38-db61-491c-9c4a-7ea058a21113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 3, 5), (2, 4, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary structure is also preserved.\n",
        "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
        "list(dataset.as_numpy_iterator())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhFuHt-rlgEB",
        "outputId": "c23972dd-c59f-482d-80b6-2fcc0dfa600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'a': 1, 'b': 3}, {'a': 2, 'b': 4}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two tensors can be combined into one Dataset object.\n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfzsesavoLss",
        "outputId": "1df4e2de-1f24-4c23-b87b-11d494c85624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 3], dtype=int32), b'A'),\n",
              " (array([2, 1], dtype=int32), b'B'),\n",
              " (array([3, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Two tensors can be combined into one Dataset object.\n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "# Both the features and the labels tensors can be converted\n",
        "# to a Dataset object separately and combined after.\n",
        "features_dataset = tf.data.Dataset.from_tensor_slices(features)\n",
        "labels_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
        "dataset = tf.data.Dataset.zip((features_dataset, labels_dataset))\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C0IIy3El_w2",
        "outputId": "dab322d4-00c0-4b36-ae98-e3748d229678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 3], dtype=int32), b'A'),\n",
              " (array([2, 1], dtype=int32), b'B'),\n",
              " (array([3, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A batched feature and label set can be converted to a Dataset\n",
        "# in similar fashion.\n",
        "batched_features = tf.constant([[[1, 3], [2, 3]],\n",
        "                                [[2, 1], [1, 2]],\n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
        "batched_labels = tf.constant([['A', 'A'],\n",
        "                              ['B', 'B'],\n",
        "                              ['A', 'B']], shape=(3, 2, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices((batched_features, batched_labels))\n",
        "for element in dataset.as_numpy_iterator():\n",
        "    print(element)\n",
        "# show shape\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvb5qWxAmhWJ",
        "outputId": "9e5e556f-5f37-458b-ceb0-4d4ef7a9dddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([[b'A'],\n",
            "       [b'A']], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([[b'B'],\n",
            "       [b'B']], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([[b'A'],\n",
            "       [b'B']], dtype=object))\n",
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(2, 1), dtype=tf.string, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A batched feature and label set can be converted to a Dataset\n",
        "# in similar fashion.\n",
        "batched_features = tf.constant([[[1, 3], [2, 3]],\n",
        "                                [[2, 1], [1, 2]],\n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
        "batched_labels = tf.constant([['A', 'A'],\n",
        "                              ['B', 'B'],\n",
        "                              ['A', 'B']], shape=(3, 2)) # change shape\n",
        "dataset = tf.data.Dataset.from_tensor_slices((batched_features, batched_labels))\n",
        "for element in dataset.as_numpy_iterator():\n",
        "    print(element)\n",
        "# show shape\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0sNf58ZnaNw",
        "outputId": "d248faad-825b-4261-fe98-f512e9261c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([b'A', b'A'], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([b'B', b'B'], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([b'A', b'B'], dtype=object))\n",
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(2, 2), dtype=tf.int32, name=None), TensorSpec(shape=(2,), dtype=tf.string, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**prefetch**"
      ],
      "metadata": {
        "id": "fX7ffpU5pxW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creates a Dataset that prefetches elements from this dataset.\n",
        "\n",
        "Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n",
        "\n",
        "Note: Like other Dataset methods, prefetch operates on the elements of the input dataset. It has no concept of examples vs. batches. examples.prefetch(2) will prefetch two elements (2 examples), while examples.batch(20).prefetch(2) will prefetch 2 elements (2 batches, of 20 examples each)."
      ],
      "metadata": {
        "id": "p3COrWBzqI8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefetch(\n",
        "    buffer_size, # \tA tf.int64 scalar tf.Tensor, representing the maximum number of elements that will be buffered when prefetching. If the value tf.data.AUTOTUNE is used, then the buffer size is dynamically tuned.\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "fQhednphqdZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.prefetch(2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1Z9_4_Gpzds",
        "outputId": "9985df51-9471-42c9-a2bb-0e8a64b378b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**shuffle**"
      ],
      "metadata": {
        "id": "MsfWy4RirprZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
        "dataset = dataset.repeat(2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0ULYvLnrzY_",
        "outputId": "83636872-c6b4-4a7b-840f-07b070ca4911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2, 1, 0, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(3)\n",
        "dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
        "dataset = dataset.repeat(2)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqXtVp1yrrJ_",
        "outputId": "b8e60c1a-ca71-4b60-baee-1833e4ddfbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 0, 1, 0, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**take**"
      ],
      "metadata": {
        "id": "aDsa7tmQswPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.take(3)\n",
        "list(dataset.as_numpy_iterator())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glWxAt5zsxqW",
        "outputId": "22e3937b-c980-42fe-dce0-bd7af708fcbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**take_while**"
      ],
      "metadata": {
        "id": "1aI88Jlqs14S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(10)\n",
        "dataset = dataset.take_while(lambda x: x < 5)\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORT2p2o1s3i1",
        "outputId": "f7f0f5ff-9eef-4cc9-e5af-2b0c11740e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**unbatch**"
      ],
      "metadata": {
        "id": "nSJOfv6BtCHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splits elements of a dataset into multiple elements.\n",
        "\n",
        "For example, if elements of the dataset are shaped [B, a0, a1, ...], where B may vary for each input element, then for each element in the dataset, the unbatched dataset will contain B consecutive elements of shape [a0, a1, ...]."
      ],
      "metadata": {
        "id": "UN-J8a8stFYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\n",
        "dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\n",
        "dataset = dataset.unbatch()\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tfBZ9M3tDvQ",
        "outputId": "ac24ecd0-fdb8-4234-cb61-05107c4a8559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 1, 2, 1, 2, 3, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**unique**"
      ],
      "metadata": {
        "id": "07Kj5p7DtNMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 37, 2, 37, 2, 1])\n",
        "dataset = dataset.unique()\n",
        "sorted(list(dataset.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW_WECHitOh3",
        "outputId": "9e7ea7e0-970e-4fdf-ca7e-dc2f4667d8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 37]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**window**"
      ],
      "metadata": {
        "id": "_VnJMIsDuVU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returns a dataset of \"windows\".\n",
        "\n",
        "Each \"window\" is a dataset that contains a subset of elements of the input dataset. These are finite datasets of size size (or possibly fewer if there are not enough input elements to fill the window and drop_remainder evaluates to False).\n",
        "\n"
      ],
      "metadata": {
        "id": "tbKmDjA6vxvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "  print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeVOk5gBuWwU",
        "outputId": "3014d67b-aa94-4e47-b150-ba232faf9c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2]\n",
            "[3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shift argument determines the number of input elements to shift between the start of each window. If windows and elements are both numbered starting at 0, the first element in window k will be element k * shift of the input dataset. In particular, the first element of the first window will always be the first element of the input dataset."
      ],
      "metadata": {
        "id": "3JFCs1jhwzvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "    print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSAuUKPYw0VX",
        "outputId": "0a5dabdd-fdc4-4801-e477-94458cef8b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2]\n",
            "[1, 2, 3]\n",
            "[2, 3, 4]\n",
            "[3, 4, 5]\n",
            "[4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The stride argument determines the stride between input elements within a window."
      ],
      "metadata": {
        "id": "upwjM_YHxITF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1, stride=2,\n",
        "                                          drop_remainder=True)\n",
        "for window in dataset:\n",
        "  print(list(window.as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1JAVcYKxJk2",
        "outputId": "fa1de2fb-e6cf-412b-a247-630b4df72709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 4]\n",
            "[1, 3, 5]\n",
            "[2, 4, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
        "                                              [6, 7, 8, 9, 10]))\n",
        "dataset = dataset.window(2)\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4LcuZNexgtZ",
        "outputId": "74ab4620-fdf1-4244-9d55-9e5a8f92536b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_WindowDataset element_spec=(DatasetSpec(TensorSpec(shape=(), dtype=tf.int32, name=None), TensorShape([])), DatasetSpec(TensorSpec(shape=(), dtype=tf.int32, name=None), TensorShape([])))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
        "                                              [6, 7, 8, 9, 10]))\n",
        "dataset = dataset.window(2)\n",
        "\n",
        "for w in dataset: # w is a tuple\n",
        "  print(\"#############\")\n",
        "  print(w[0].batch(2))\n",
        "  print(list(w[0].as_numpy_iterator()))\n",
        "  print(list(w[1].as_numpy_iterator()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e_YNOVtxkY2",
        "outputId": "c25e9bb8-d7c9-4e4d-f910-53f11c50529c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#############\n",
            "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "[1, 2]\n",
            "[6, 7]\n",
            "#############\n",
            "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "[3, 4]\n",
            "[8, 9]\n",
            "#############\n",
            "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>\n",
            "[5]\n",
            "[10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
        "                                          drop_remainder=True)\n",
        "batched = dataset.flat_map(lambda x:x.batch(3))\n",
        "for batch in batched:\n",
        "  print(batch)\n",
        "  print(batch.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa8Aw8ZC0c2O",
        "outputId": "9c1fb0aa-303c-4e59-ef29-18249440468e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2], shape=(3,), dtype=int64)\n",
            "[0 1 2]\n",
            "tf.Tensor([1 2 3], shape=(3,), dtype=int64)\n",
            "[1 2 3]\n",
            "tf.Tensor([2 3 4], shape=(3,), dtype=int64)\n",
            "[2 3 4]\n",
            "tf.Tensor([3 4 5], shape=(3,), dtype=int64)\n",
            "[3 4 5]\n",
            "tf.Tensor([4 5 6], shape=(3,), dtype=int64)\n",
            "[4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**zip**"
      ],
      "metadata": {
        "id": "KOnM-gqg4yd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
        "b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\n",
        "ds = tf.data.Dataset.zip(a, b)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfm5Srm_40hY",
        "outputId": "fa34d2e6-a43c-4069-d663-863c80aa7852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 4), (2, 5), (3, 6)]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.zip(b, a)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy6UQ0Xq4-si",
        "outputId": "dd809439-a662-4655-bdca-b51a70f8fc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4, 1), (5, 2), (6, 3)]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The `datasets` argument may contain an arbitrary number of datasets.\n",
        "c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\n",
        "                                           #       [9, 10],\n",
        "                                           #       [11, 12] ]\n",
        "ds = tf.data.Dataset.zip(a, b, c)\n",
        "for element in ds.as_numpy_iterator():\n",
        "  print(element)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK-YTFxY5JA6",
        "outputId": "197b1d22-c685-4f57-a06e-f517c88b38c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 4, array([7, 8]))\n",
            "(2, 5, array([ 9, 10]))\n",
            "(3, 6, array([11, 12]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of elements in the resulting dataset is the same as\n",
        "# the size of the smallest dataset in `datasets`.\n",
        "d = tf.data.Dataset.range(13, 15)  # ==> [ 13, 14 ]\n",
        "ds = tf.data.Dataset.zip(a, d)\n",
        "list(ds.as_numpy_iterator())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4gAECr15N7V",
        "outputId": "baeaaa16-4c3b-4a8f-8700-ea9edbbcc059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 13), (2, 14)]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.data.Dataset.from_tensor_slices(([1,2,3], [5,5,7]))\n",
        "for i in a:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NJqbgsj8KDS",
        "outputId": "346dcab5-f7b7-44f0-fddd-33d685bce68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=3>, <tf.Tensor: shape=(), dtype=int32, numpy=7>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image - Text - Sequence**"
      ],
      "metadata": {
        "id": "YTh6vXLEWatx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Module**\n",
        "\n",
        "* **Class**\n",
        "\n",
        "* **Function**"
      ],
      "metadata": {
        "id": "dsojJ4J0k7_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sur Tensorflow, on a des modules, des classes et des fonctions\n",
        "tf.keras.preprocessing: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing [Module: image, text, sequence]\n",
        "tf.keras.utils: https://www.tensorflow.org/api_docs/python/tf/keras/utils: exemple :\n",
        "tf.keras.utils.to_categorical(\n",
        "    y, num_classes=None, dtype='float32'\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kolFTPjHYqUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune model application\n",
        "https://keras.io/api/applications/"
      ],
      "metadata": {
        "id": "lTqpBUOxWckZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Callbacks**"
      ],
      "metadata": {
        "id": "9Su900NJyWDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "callbacks permet de controler le train\n",
        "tf.keras.callbacks.Callback\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks [Callback, ModelCheckpoint]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9Re2h08fyYgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\"\"\"\n",
        "self c'est le modèle\n",
        "\"\"\"\n",
        "class MyCustomCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print(f\"Starting epoch {epoch}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Finished epoch {epoch}. Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}\")\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        print(f\"Training batch {batch}...\")\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        print(f\"Finished training batch {batch}. Loss: {logs['loss']:.4f}\")\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        print(\"Starting validation...\")\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        print(\"Finished validation. Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}\")\n",
        "\n",
        "    def on_predict_begin(self, logs=None):\n",
        "        print(\"Starting prediction...\")\n",
        "\n",
        "    def on_predict_end(self, logs=None):\n",
        "        print(\"Finished prediction.\")\n",
        "\n",
        "# Créez un modèle Keras simple à des fins d'exemple\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Générez des données factices pour l'exemple\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# Entraînez le modèle avec l'utilisation de votre callback personnalisé\n",
        "history = model.fit(x_train, y_train, epochs=3, callbacks=[MyCustomCallback()])\n",
        "\n",
        "# Effectuez une évaluation du modèle\n",
        "model.evaluate(x_test, y_test, callbacks=[MyCustomCallback()])\n",
        "\n",
        "# Effectuez des prédictions\n",
        "model.predict(x_test[:5], callbacks=[MyCustomCallback()])\n"
      ],
      "metadata": {
        "id": "dle0BHI75shA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = 'drive/MyDrive/autoACN_densenet40_cifar100'\n",
        "# Créer un callback pour enregistrer les checkpoints tous les 50 époques\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join(checkpoint_dir, 'model_weights_{epoch:03d}.h5'),\n",
        "    save_weights_only=True,\n",
        "    save_best_only=False,\n",
        "    save_freq=SAVE_PERIOD*STEPS_PER_EPOCH # Sauvegarder tous les 50 époques\n",
        ")\n",
        "# Train the DenseNet-40 model\n",
        "history = model_densenet40.fit(train_gen,\n",
        "                     steps_per_epoch=x_train.shape[0] // batch_size, epochs=epochs,\n",
        "                     validation_data=(x_val, y_val), callbacks=[keras.callbacks.LearningRateScheduler(lr_schedule), checkpoint_callback])\n"
      ],
      "metadata": {
        "id": "rIFsfz1_46AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * 2.08))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULhea89O6paT",
        "outputId": "f4b4a6bd-2123-46ec-f93d-93474a1c0f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored model, accuracy: 208.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value = 10*3.09\n",
        "a = '{:.05f}'.format(value)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B0boIbhs6wtt",
        "outputId": "51c6e84e-8feb-4925-ef0f-77c70fa0239e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'30.90000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value = 10*3.09\n",
        "a = f'{value:.02f}'\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "p4p2yww39AF5",
        "outputId": "8ef75da5-4d9c-46d2-f25e-327b3b677db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'30.90'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "value = 1009*3.09\n",
        "a = f'{value:19.02f}'\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "drHoivvfZVP9",
        "outputId": "a68ebd43-0c50-4405-ca09-1d6a5cea567d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'            3117.81'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = '{:2d}'.format(10)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Dz3GKPBW8WW_",
        "outputId": "fc2ce253-aa80-49cf-ab44-73fa484f0ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = '{:03d}'.format(10)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5M3NS6CP8eGy",
        "outputId": "b2c8310c-c79d-42c0-eda3-733ba5eb3623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'010'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Value: %03d\" % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wPpH66PI8GfZ",
        "outputId": "e354ab48-551d-4352-b523-19c25795cad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Value: 002'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Value: %.03f\" % 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dvAgObS_8itP",
        "outputId": "000af559-6237-47e6-c16d-402beaf723c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Value: 2.000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Value: %.03f %02d\" % (2, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NyAtywTa9aGx",
        "outputId": "5157eb71-65ed-4863-d978-ee123333aa85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Value: 2.000 02'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save Model**"
      ],
      "metadata": {
        "id": "UFsVm-srMhSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://www.tensorflow.org/tutorials/keras/save_and_load"
      ],
      "metadata": {
        "id": "LKrVSGWLXfGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les formats de fichiers .keras, .ckpt (Checkpoint), et .h5 (HDF5) sont tous utilisés pour enregistrer des modèles TensorFlow (notamment avec l'API Keras). Chacun a ses propres caractéristiques et avantages. Voici les principales différences entre ces formats de fichiers :\n",
        "\n",
        "**.keras (SavedModel):**\n",
        "\n",
        "Format par défaut lors de l'enregistrement d'un modèle Keras avec TensorFlow.\n",
        "Contient le modèle complet, y compris l'architecture, les poids, la configuration et les informations d'entraînement.\n",
        "Peut être utilisé pour le déploiement en production et pour la reprise de l'entraînement sans avoir à répéter la définition du modèle.\n",
        "Fournit une structure hiérarchique qui permet de stocker plusieurs versions du modèle et des signatures de fonction pour le déploiement.<br>\n",
        "**Le modèle est enrégistrer sur un fichier zip. model.save(\"model.keras\")**<br>\n",
        "\n",
        "**.ckpt (Checkpoint):**\n",
        "\n",
        "Enregistre principalement les poids du modèle, pas l'architecture.\n",
        "Utilisé pour sauvegarder uniquement les poids d'un modèle, ce qui permet de réutiliser les mêmes couches avec des architectures différentes.\n",
        "Souvent utilisé pour la reprise de l'entraînement et la sauvegarde de points de contrôle (checkpoints) à différents stades de l'entraînement.\n",
        "Vous devez spécifier l'architecture du modèle lors du chargement des poids depuis un fichier .ckpt.<br>\n",
        "**Enrégistre trois fichiers. model.save_weights(\"model.ckpt\")**<br>\n",
        "\n",
        "\n",
        "**.h5 (HDF5):**\n",
        "\n",
        "Peut enregistrer l'ensemble du modèle, y compris l'architecture, les poids et la configuration.\n",
        "Facile à partager avec d'autres utilisateurs, car il contient toutes les informations nécessaires pour reconstruire et utiliser le modèle.\n",
        "Utile pour enregistrer des modèles complets pour la reprise de l'entraînement ou pour des expériences de recherche.\n",
        "Peut également être utilisé pour enregistrer uniquement les poids si vous le souhaitez.\n",
        "En résumé, le format .keras (SavedModel) est généralement recommandé pour le déploiement en production, car il contient toutes les informations nécessaires pour le modèle, tandis que le format .ckpt est idéal pour la reprise de l'entraînement et la sauvegarde des poids. Le format .h5 est polyvalent, car il peut enregistrer l'ensemble du modèle ou uniquement les poids, ce qui le rend pratique pour diverses situations. Le choix du format dépend de l'utilisation spécifique de votre modèle et de vos besoins en matière de partage et de reprise de l'entraînement.<br>\n",
        "**Enrégistre un seul fichier avec model.save(\"model.h5\") ou model.save_weights(\"model.h5\")**"
      ],
      "metadata": {
        "id": "LAV8F4kDfTui"
      }
    }
  ]
}