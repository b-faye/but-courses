{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLqTVcc8yrPN"
   },
   "source": [
    "**Traducteur anglais vers français**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9esTOP_2sPsi"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import bsr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZ9pDRzbsmmw"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64                     # taille des batchs pour le train\n",
    "EPOCHS = 20                         # Nombre d'époque pour le tarin  \n",
    "LSTM_NODES =256                     # taille des units pour les LSTM\n",
    "NUM_SENTENCES = 100 #20000          # nombre de phrases pour construire le traducteur\n",
    "MAX_SENTENCE_LENGTH = 50            # nombre de mots max sur une phrase\n",
    "MAX_NUM_WORDS = 20000               # taille du vocabulaire\n",
    "EMBEDDING_SIZE = 100                # Dimenision des embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beavZxHOv0Fw"
   },
   "source": [
    "**Gérer les fichiers**<br>\n",
    "Le modèle seq2seq doit avoir 03 fichiers <br>\n",
    "- input encodeur : phrase en anglais <br>\n",
    "- input decodeur : phrase en français précédé du token \\<sos\\> <br>\n",
    "- output decodeur : phrase en français suivi du token \\<eos\\> <br>\n",
    "\n",
    "Exemple de phrase dans fra.txt : <br>\n",
    "I want you to do something about it right away.\tJe veux que tu y fasses quelque chose derechef.\tCC-BY 2.0 (France)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyRzie4lzfSn",
    "outputId": "37922592-3077-4e09-a4a4-5804b1004cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence 1: \n",
      " Go.\n",
      "Output sentence 1: \n",
      " Va !<eos>\n",
      "Output sentence input 1: \n",
      " <sos>Va !\n"
     ]
    }
   ],
   "source": [
    "# Lire les fichiers\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_input = []\n",
    "count = 0\n",
    "with open('fra.txt') as f:\n",
    "  for line in f.readlines():\n",
    "    count+=1\n",
    "    if count > NUM_SENTENCES:\n",
    "      break\n",
    "    if '\\t' not in line:\n",
    "      continue\n",
    "    else:\n",
    "      input_sentence, output, source= line.strip().split('\\t')\n",
    "      input_sentence = input_sentence\n",
    "      output_sentence = output+'<eos>'\n",
    "      output_sentence_input = '<sos>'+output\n",
    "      input_sentences.append(input_sentence)\n",
    "      output_sentences.append(output_sentence)\n",
    "      output_sentences_input.append(output_sentence_input)\n",
    "\n",
    "print(\"Input sentence 1: \\n\", input_sentences[0])\n",
    "print(\"Output sentence 1: \\n\", output_sentences[0])\n",
    "print(\"Output sentence input 1: \\n\", output_sentences_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTd3lFDQyI3K"
   },
   "source": [
    "**Représentation numérique des textes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbzF42oTAKeN",
    "outputId": "783593c2-950e-4b3e-b8c6-e44127e02b73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0, 19],\n",
       "       [ 0,  0,  0,  0,  0,  0, 19],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 28],\n",
       "       [ 0,  0,  0,  0,  0,  0, 29],\n",
       "       [ 0,  0,  0,  0,  0,  0, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0, 30],\n",
       "       [ 0,  0,  0,  0,  0,  0, 31],\n",
       "       [ 0,  0,  0,  0,  0,  0, 20],\n",
       "       [ 0,  0,  0,  0,  0,  0, 20],\n",
       "       [ 0,  0,  0,  0,  0,  0, 21],\n",
       "       [ 0,  0,  0,  0,  0,  0, 21],\n",
       "       [ 0,  0,  0,  0,  0,  0, 11],\n",
       "       [ 0,  0,  0,  0,  0,  0, 11],\n",
       "       [ 0,  0,  0,  0,  0,  0, 11],\n",
       "       [ 0,  0,  0,  0,  0,  0,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0, 22],\n",
       "       [ 0,  0,  0,  0,  0,  0, 22],\n",
       "       [ 0,  0,  0,  0,  0,  4, 12],\n",
       "       [ 0,  0,  0,  0,  0,  4, 12],\n",
       "       [ 0,  0,  0,  0,  0,  4, 12],\n",
       "       [ 0,  0,  0,  0,  0,  0, 23],\n",
       "       [ 0,  0,  0,  0,  0,  0, 23],\n",
       "       [ 0,  0,  0,  0,  0,  6, 24],\n",
       "       [ 0,  0,  0,  0,  0,  6, 24],\n",
       "       [ 0,  0,  0,  0,  0,  6, 32],\n",
       "       [ 0,  0,  0,  0,  0,  6, 13],\n",
       "       [ 0,  0,  0,  0,  0,  6, 13],\n",
       "       [ 0,  0,  0,  0,  0,  6, 13],\n",
       "       [ 0,  0,  0,  0,  0, 33, 34],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0, 14],\n",
       "       [ 0,  0,  0,  0,  0,  0, 14],\n",
       "       [ 0,  0,  0,  0,  0,  0, 14],\n",
       "       [ 0,  0,  0,  0,  0,  0, 35],\n",
       "       [ 0,  0,  0,  0,  0,  0, 15],\n",
       "       [ 0,  0,  0,  0,  0,  0, 15],\n",
       "       [ 0,  0,  0,  0,  0,  0, 15],\n",
       "       [ 0,  0,  0,  0,  0,  8,  3],\n",
       "       [ 0,  0,  0,  0,  0,  8,  3],\n",
       "       [ 0,  0,  0,  0,  0,  8,  3],\n",
       "       [ 0,  0,  0,  0,  0,  8,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9],\n",
       "       [ 0,  0,  0,  0,  0, 25,  3],\n",
       "       [ 0,  0,  0,  0,  0, 25,  3],\n",
       "       [ 0,  0,  0,  0,  0, 16, 17],\n",
       "       [ 0,  0,  0,  0,  0, 16, 17],\n",
       "       [ 0,  0,  0,  0,  0, 16, 17],\n",
       "       [ 0,  0,  0,  0,  0,  4, 18],\n",
       "       [ 0,  0,  0,  0,  0,  4, 18],\n",
       "       [ 0,  0,  0,  0,  0,  4, 18],\n",
       "       [ 0,  0,  0,  0,  0,  7,  3],\n",
       "       [ 0,  0,  0,  0,  0,  7,  3],\n",
       "       [ 0,  0,  0,  0,  0,  7,  3],\n",
       "       [ 0,  0,  0,  0,  0,  7,  3],\n",
       "       [ 0,  0,  0,  0,  0,  7,  3],\n",
       "       [ 0,  0,  0,  0,  0,  7,  3],\n",
       "       [ 0,  0,  0,  0,  0, 26, 27],\n",
       "       [ 0,  0,  0,  0,  0, 26, 27],\n",
       "       [ 0,  0,  0,  0,  0, 36, 37]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numériser les inputs de l'encodeur (phrase en anglais) \n",
    "\n",
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)                                # Tokenizer avec keras avec la taille du vocab\n",
    "input_tokenizer.fit_on_texts(input_sentences)                                       # Entraîner le tokenizer sur les données d'entrée\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)             # Transformer le texte en format numérique\n",
    "word2idx_inputs = input_tokenizer.word_index                                        # Recupérer l'ensemble des ids (chaque mot est représenté par un id) un dictionnaire keys=mots, values=ids\n",
    "max_len_inputs = max(len(s) for s in input_sentences)                               # Taille max des sentences\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_len_inputs)   # Avoir des vecteurs de même taille (max_len_inputs)\n",
    "num_words_input = len(word2idx_inputs) + 1                                          # Taille du vocabulaire +1 pour les embeddings\n",
    "encoder_input_sequences                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isKIu6ewDOoC"
   },
   "outputs": [],
   "source": [
    "# Numériser les inputs du décodeur (entrées et sorties) en français \n",
    "\n",
    "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "output_tokenizer.fit_on_texts(output_sentences+output_sentences_input)                 # Entraîner le tokenizer sur la concaténation des deux listes\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)             # Numériser les sorties du décodeur\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_input) # Numériser les entrées du décodeur\n",
    "word2idx_outputs = output_tokenizer.word_index                                         # Les ids des entrées et sorties du décodeur\n",
    "max_len_outputs = max(len(s) for s in output_sentences)                                # Taille de la plus longue phrase\n",
    "num_words_output = len(word2idx_outputs)+1                                             # Taiile du vocabulaire + 1\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_len_outputs, padding='post') # vecteurs de même taille (entrées)\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_len_outputs, padding='post')      # vecteurs de même taille (sorties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNjp-B9loSr2",
    "outputId": "e2640445-5bff-4737-a336-3c5bbeadfe4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple de concaténation de liste\n",
    "[1,2]+[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ti3ysOBU8EJn"
   },
   "source": [
    "**One Hot Encoding pour les sorties du décodeur**<br>\n",
    "Dans la section précédente, les sorties de l'encodeur avaient déjà une représentation numérique. Chaque phrase était représentée par un vecteur de taille **max_len_outputs** avec des ids qui remplacent les mots. Les ids sont compris entre 0 et la taille du vocabulaire.<br>\n",
    "\n",
    "Cette représentation va être changée par le **One Hot Encoding** : <br>\n",
    "Chaque phrase est maintenant représenté par une matrice de taille **max_len_outputs*num_words_output**. Chaque ligne de la matrice correspond à un mot de la phrase (dans l'ordre), sur la ligne de la matrice y'aura au plus un seul 1 qui se trouve à la position de l'id du mot donné dans la représentation de la section précedente, le reste est mis à 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EY1I-roTRuw-",
    "outputId": "5f9113c4-f1b5-47f2-9659-3aafcb30ae06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_one_hot = np.zeros((len(output_sentences), max_len_outputs, num_words_output))\n",
    "\n",
    "for index, sentence in enumerate(decoder_output_sequences):\n",
    "  for t, word in enumerate(sentence):\n",
    "    decoder_target_one_hot[index, t, word] = 1\n",
    "decoder_target_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0hmn7xC5fzI",
    "outputId": "1e239396-a62c-4332-835f-ca8fd752b400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words_output # Taille du vocabulaire du décodeur (phrase en anglais)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQaHNsz__PEB"
   },
   "source": [
    "**Construire l'encodeur**<br>\n",
    "L'embedding prend en entrée une matrice 2D. Pour chaque vecteur (une phrase), il represente chaque mot par un vecteur donc une sortie de taille nombre_de_mot_de_la_phrase*EMBEDDING_SIZE (LE NOMBRE DE MOT DES PHRASES EST max_len_inputs).<br>\n",
    "\n",
    "sur **LSTM**, return_sequences = False, donc chaque phrase va être représentée en sortie par un vecteur de taille LSTM_NODES, et sur le batch, **encoder_outputs**, sera de taille (BATCH_SIZE, LSTM_NODES).<br>\n",
    "Si return_sequences=True, la sortie pour chaque phrase sera une matrice 2D au lieu d'un vecteur max_len_inputs*LSTM_NODES et encoder_outputs de taille (BATCH_SIZE, MAX_LEN_INPUTS, LSTM_NODES).<br>\n",
    "\n",
    "h correspond à l'état de la cellule, si return_sequences = False, il correspond à encoder_outputs, sinon il correspond à la dernière ligne de la matrice pour chaque sortie du LSTM sur une phrase. C'est un vecteur de taille LSTM_NODES, sur le batch (BATCH_SIZE, LSTM_NODES).<br>\n",
    "\n",
    "c correspond à la mémoire à long terme, il est de même taille que h.<br>\n",
    "\n",
    "**LSTM outputs on keras**\n",
    "1. Default: Last Hidden State (Hidden State of the last time step)<br>\n",
    "2. return_sequences=True : All Hidden States (Hidden State of ALL the time steps)<br>\n",
    "3. return_state=True : Last Hidden State+ Last Hidden State (again!) + Last Cell State (Cell State of the last time step)<br>\n",
    "4. return_sequences=True + return_state=True: All Hidden States (Hidden State of ALL the time steps) + Last Hidden State + Last Cell State (Cell State of the last time step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vE6L7VSccGHa"
   },
   "outputs": [],
   "source": [
    "input_encoder = Input((max_len_inputs,))\n",
    "encoder_embbeding = Embedding(input_dim=num_words_input, input_length=max_len_inputs,output_dim=EMBEDDING_SIZE)\n",
    "encoder_input_x = encoder_embbeding(input_encoder)\n",
    "encoder = LSTM(LSTM_NODES, return_state=True)\n",
    "encoder_outputs,h,c = encoder(encoder_input_x)\n",
    "encoder_states = [h,c] # h et c des vecteurs de taille LSTM_NODES\n",
    "\n",
    "'''\n",
    "si return_sequences = False : (batch_size, units)\n",
    "si return_sequences = True : (batch_size, timestamps, units)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhO-uiX0GKIo"
   },
   "source": [
    "**Construction du décodeur**<br>\n",
    "Entrée embedding : (BATCH_SIZE, max_len_outputs)<br>\n",
    "Sortie embedding : (BATCH_SIZE, max_len_outputs, LSTM_NODES)<br>\n",
    "\n",
    "Entrée embedding : sortie embedding<br>\n",
    "Sortie decoder_outputs : (BATCH_SIZE, max_len_outputs, LSTM_NODES)<br>\n",
    "\n",
    "Entrée decoder_dense (MLP) : Sortie decoder_outputs<br>\n",
    "Sortie decoder_dense : (BATCH_SIZE, max_len_outputs, num_words_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SU1mTmX8cwQb"
   },
   "outputs": [],
   "source": [
    "input_decoder = Input((max_len_outputs,))\n",
    "decoder_embbeding = Embedding(num_words_output, LSTM_NODES)\n",
    "decoder_input_x = decoder_embbeding(input_decoder)\n",
    "decoder_lstm = LSTM(LSTM_NODES,return_state=True, return_sequences=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_input_x, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')  # Couche pour la prédiction \n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmUIHEFfMNAg"
   },
   "source": [
    "**Construction du modèle seq2seq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YlqukwY_iYFs"
   },
   "outputs": [],
   "source": [
    "model = Model([input_encoder, input_decoder], decoder_outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLDj7iP1GrbQ",
    "outputId": "b05c95e1-77ec-4da3-8926-fa08b512dfe7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'input_3')>,\n",
       " <KerasTensor: shape=(None, 35) dtype=float32 (created by layer 'input_4')>]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[input_encoder, input_decoder] # [(BATCH_SIZE, 7), (BATCH_SIZE, 35)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQ3MtX0bjfct",
    "outputId": "2c669b3d-593b-4e19-d8d9-2474f7c3a19e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 35)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 7, 100)       3800        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 35, 256)      27648       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 256), (None, 365568      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 35, 256), (N 525312      embedding_3[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 35, 108)      27756       lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 950,084\n",
      "Trainable params: 950,084\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cja-nQ8EFIuI",
    "outputId": "c9bf5621-f74c-4318-bba8-9734a73f572a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() # Exemple d'un jeu de données avec keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i96zqPYIk24d",
    "outputId": "5e5dd6b9-5734-4d19-e45f-68bad6ef86f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 11s 291ms/step - loss: 2.5623 - accuracy: 0.6531 - val_loss: 0.3810 - val_accuracy: 0.9200\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 0.3523 - accuracy: 0.9282 - val_loss: 0.3722 - val_accuracy: 0.9371\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 1s 134ms/step - loss: 0.2902 - accuracy: 0.9424 - val_loss: 0.3705 - val_accuracy: 0.9429\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.2617 - accuracy: 0.9489 - val_loss: 0.3820 - val_accuracy: 0.9429\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 1s 143ms/step - loss: 0.2614 - accuracy: 0.9465 - val_loss: 0.4045 - val_accuracy: 0.9429\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 1s 148ms/step - loss: 0.2385 - accuracy: 0.9543 - val_loss: 0.4019 - val_accuracy: 0.9429\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.2544 - accuracy: 0.9514 - val_loss: 0.4249 - val_accuracy: 0.9429\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 1s 138ms/step - loss: 0.2193 - accuracy: 0.9561 - val_loss: 0.3898 - val_accuracy: 0.9457\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 1s 142ms/step - loss: 0.2210 - accuracy: 0.9557 - val_loss: 0.4087 - val_accuracy: 0.9457\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 1s 153ms/step - loss: 0.2149 - accuracy: 0.9564 - val_loss: 0.4247 - val_accuracy: 0.9457\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 1s 157ms/step - loss: 0.2041 - accuracy: 0.9574 - val_loss: 0.4463 - val_accuracy: 0.9457\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.2101 - accuracy: 0.9553 - val_loss: 0.4531 - val_accuracy: 0.9457\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1924 - accuracy: 0.9578 - val_loss: 0.4438 - val_accuracy: 0.9457\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1793 - accuracy: 0.9606 - val_loss: 0.4574 - val_accuracy: 0.9457\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 1s 141ms/step - loss: 0.1829 - accuracy: 0.9584 - val_loss: 0.4942 - val_accuracy: 0.9457\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 1s 149ms/step - loss: 0.1857 - accuracy: 0.9569 - val_loss: 0.5067 - val_accuracy: 0.9457\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 1s 151ms/step - loss: 0.1721 - accuracy: 0.9587 - val_loss: 0.5007 - val_accuracy: 0.9457\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 1s 144ms/step - loss: 0.1732 - accuracy: 0.9583 - val_loss: 0.5328 - val_accuracy: 0.9371\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 1s 145ms/step - loss: 0.1698 - accuracy: 0.9595 - val_loss: 0.5092 - val_accuracy: 0.9371\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 1s 146ms/step - loss: 0.1754 - accuracy: 0.9589 - val_loss: 0.5481 - val_accuracy: 0.9371\n"
     ]
    }
   ],
   "source": [
    "## train the model\n",
    "r = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_target_one_hot,\n",
    "    batch_size=10,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sA9nM3W2QfZO"
   },
   "source": [
    "Une fois l'entraînement du modèle seq2seq fini, les poids sont obtenus.<br>\n",
    "On peut séparer l'encodeur et le décodeur maintenant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEcUgerySZkg"
   },
   "source": [
    "**Construire le modèle de l'encodeur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcDnnsHtMRS-",
    "outputId": "75a51505-20b3-4cf7-964e-fc3ddb2aac96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 7)]               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 7, 100)            3800      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                [(None, 256), (None, 256) 365568    \n",
      "=================================================================\n",
      "Total params: 369,368\n",
      "Trainable params: 369,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Pas besoin d'entraîner le modèle, car les poids sont déjà obtenus avec le modèle seq2seq\n",
    "encoder_model = Model(input_encoder, encoder_states) # encoder_states = [h,c]\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rslxplipSevH"
   },
   "source": [
    "**Construire le modèle du décodeur**<br>\n",
    "\n",
    "Le décodeur est initialisé par [h, c] de l'encodeur.<br>\n",
    "La prédiction se fait mot par mot.<br>\n",
    "decoder_embbeding(decoder_inputs_single) peut être utilisé avec un vecteur de talle 1 car dans l'initialisation de decoder_embedding, la taille des vecteurs d'entrée n'était pas spécifiée donc None.<br>\n",
    "\n",
    "Sortie decoder_embedding : (BATCH_SIZE, 1, LSTM_NODES)<br>\n",
    "decoder_outputs : (BATCH_SIZE, 1, LSTM_NODES)<br>\n",
    "h : (BATCH_SIZE, LSTM_NODES)<br>\n",
    "c : (BATCH_SIZE, LSTM_NODES)<br>\n",
    "decoder_outputs : (BATCH_SIZE, 1, num_words_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-gUvOWdMwGE",
    "outputId": "c144edee-f35a-4ccf-f839-caf4c6507bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         multiple             27648       input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   multiple             525312      embedding_3[3][0]                \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   multiple             27756       lstm_3[3][0]                     \n",
      "==================================================================================================\n",
      "Total params: 580,716\n",
      "Trainable params: 580,716\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# La prédiction se fait mot par mot\n",
    "decoder_state_input_h = Input(shape=(LSTM_NODES,))\n",
    "decoder_state_input_c = Input(shape=(LSTM_NODES,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embbeding(decoder_inputs_single) # decoder_embbeding = Embedding(num_words_output, LSTM_NODES)\n",
    "\n",
    "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs) # decoder_lstm = LSTM(LSTM_NODES,return_state=True, return_sequences=True)\n",
    "\n",
    "decoder_states = [h, c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs) # decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single]+decoder_states_inputs, # équivalent à [decoder_inputs_single, decoder_state_input_h, decoder_state_input_c]\n",
    "    [decoder_outputs]+decoder_states\n",
    ")\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64Vt4PFZGimn",
    "outputId": "7e836a8a-f8af-4bb7-d9a9-ce9a05ea42a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_13')>,\n",
       " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_11')>,\n",
       " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_12')>]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[decoder_inputs_single]+decoder_states_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JgcMfTMXGzya",
    "outputId": "469f439e-a828-4ce2-89be-48d2927f1793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_13')>,\n",
       " [<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_11')>,\n",
       "  <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_12')>]]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[decoder_inputs_single,decoder_states_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n9g6DJ2DGZzm",
    "outputId": "7efc16b4-89a8-4aea-8d8b-1422c1e2a1f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1, 108) dtype=float32 (created by layer 'dense')>,\n",
       " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm_3')>,\n",
       " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lstm_3')>]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[decoder_outputs]+decoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1WdvyOMX8Pt"
   },
   "outputs": [],
   "source": [
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOv3R8DyVOR5"
   },
   "outputs": [],
   "source": [
    "output_tokens = 0\n",
    "def translate_sentence(input_seq):\n",
    "    global output_tokens\n",
    "    states_value = encoder_model.predict(input_seq)     # states_value = [h,c]\n",
    "    target_seq = np.zeros((1, 1))                       # array([[0.]])\n",
    "    target_seq[0, 0] = word2idx_outputs['sos']\n",
    "    eos = word2idx_outputs['eos']\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_len_outputs):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq]+states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :]) # proba (batch, 35,108)\n",
    "\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        target_seq[0, 0] = idx\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzAJkcuPVfOD",
    "outputId": "503dd066-778a-48a6-e475-54645a51b9be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe906ba0ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "-\n",
      "Input: Go now.\n",
      "Response: détends toi\n"
     ]
    }
   ],
   "source": [
    "i = np.random.choice(len(input_sentences))\n",
    "input_seq = encoder_input_sequences[i:i+1] # array([[values]])\n",
    "translation = translate_sentence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_sentences[i])\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J_QC5WuyczbG",
    "outputId": "d743e363-8926-4347-b86c-6f075a23a8d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 7.91700780e-02, -3.59793752e-02, -4.47292656e-01,\n",
       "         -2.20333815e-01,  3.16692531e-01,  5.41000187e-01,\n",
       "         -3.93998176e-02,  1.63602665e-01, -3.88725728e-01,\n",
       "         -3.48533422e-01,  6.02608882e-02, -7.21993372e-02,\n",
       "         -1.79167032e-01,  3.52856487e-01, -9.08221304e-02,\n",
       "          3.29001814e-01,  2.64196336e-01, -1.44088805e-01,\n",
       "         -9.17000055e-01,  1.18501559e-01,  1.18383452e-01,\n",
       "          5.10759912e-02,  1.94317680e-02,  3.46476912e-01,\n",
       "          2.28997204e-03, -5.66138886e-02,  2.71178216e-01,\n",
       "          1.80324361e-01,  5.28350510e-02,  6.31491467e-02,\n",
       "          3.76654387e-01, -7.64216065e-01, -1.62652193e-03,\n",
       "         -1.31664440e-01, -3.26158613e-01,  6.29956186e-01,\n",
       "         -1.68976765e-02,  1.99221130e-02, -1.95001632e-01,\n",
       "         -2.79583409e-02, -6.82948351e-01, -2.99464971e-01,\n",
       "          1.67191550e-01, -4.28778291e-01,  7.64902174e-01,\n",
       "         -4.88313548e-02, -3.95147860e-01, -1.87446494e-02,\n",
       "          6.87573701e-02,  1.48658037e-01, -2.29212325e-02,\n",
       "          1.37167439e-01,  2.34662801e-01, -4.75492358e-01,\n",
       "         -3.42555553e-01,  5.43584228e-01, -5.88200241e-02,\n",
       "          1.25411332e-01, -2.08784342e-01, -4.88261938e-01,\n",
       "          1.49017826e-01, -2.66506732e-01,  1.50204316e-01,\n",
       "         -4.60765138e-02,  1.83720320e-01,  1.84680149e-01,\n",
       "         -2.07514808e-01,  4.46209237e-02, -6.06487244e-02,\n",
       "         -2.77445316e-01, -1.06393389e-01, -3.39947879e-01,\n",
       "         -2.38047969e-02,  1.21195652e-01,  1.84014410e-01,\n",
       "         -2.70739496e-01, -5.34979440e-03, -1.93520300e-02,\n",
       "          6.22611418e-02,  2.18881920e-01,  2.73742944e-01,\n",
       "          9.19625610e-02, -9.56602246e-02,  6.42369390e-02,\n",
       "          8.24741304e-01, -2.57757485e-01,  2.27293834e-01,\n",
       "         -7.90412724e-02, -1.54281989e-01, -2.93978155e-01,\n",
       "          3.35662872e-01, -8.55210349e-02,  6.05749823e-02,\n",
       "         -4.59422208e-02, -2.53335647e-02, -5.57973385e-01,\n",
       "          2.59029359e-01, -1.74329683e-01,  3.21551599e-02,\n",
       "         -2.54391015e-01, -3.62047777e-02, -1.63210303e-01,\n",
       "          2.27776244e-01,  2.91981131e-01, -1.68794379e-01,\n",
       "         -4.67552274e-01,  5.34964241e-02,  1.71428937e-02,\n",
       "          9.54399854e-02,  2.18897089e-01,  3.77333641e-01,\n",
       "         -6.87098205e-02, -3.13602865e-01, -8.21971521e-03,\n",
       "          1.95060730e-01, -1.05372116e-01, -6.73608705e-02,\n",
       "          1.90044746e-01,  3.67564112e-02, -8.39492530e-02,\n",
       "          8.68316710e-01, -9.50514153e-02,  2.08481580e-01,\n",
       "         -2.99829274e-01, -3.57351542e-01,  2.40103751e-01,\n",
       "          1.46813363e-01,  1.09078832e-01,  8.77910137e-01,\n",
       "         -8.11664611e-02, -1.33964922e-02,  4.20935825e-02,\n",
       "          1.90438032e-01,  2.38646597e-01,  1.13611454e-02,\n",
       "         -1.28577054e-01,  8.44127119e-01, -4.00548190e-01,\n",
       "          2.74036527e-01,  4.78005916e-01,  7.18529597e-02,\n",
       "          6.34284094e-02,  2.68888354e-01, -5.64591348e-01,\n",
       "          1.00297168e-01, -7.72908926e-02,  3.36585432e-01,\n",
       "         -3.92971262e-02,  1.17067397e-01,  1.44181058e-01,\n",
       "         -1.67961553e-01, -6.70986027e-02,  9.38468128e-02,\n",
       "         -1.32196443e-02,  2.30270654e-01, -3.49233091e-01,\n",
       "         -9.48559586e-03,  4.43543971e-01,  7.28526793e-05,\n",
       "          7.14148998e-01,  2.26401851e-01,  5.93697932e-03,\n",
       "         -1.04322486e-01, -7.27040842e-02,  1.73144802e-01,\n",
       "          5.98035380e-02,  3.56385969e-02,  3.46888378e-02,\n",
       "          2.69912213e-01,  2.37238631e-01, -1.73056632e-01,\n",
       "         -2.54540026e-01,  1.87225814e-03,  3.70730549e-01,\n",
       "         -6.83536404e-04,  7.00323284e-01, -6.39478723e-03,\n",
       "          5.86353503e-02, -2.80979630e-02,  5.33719398e-02,\n",
       "          1.53916851e-02, -5.96869811e-02,  2.78870195e-01,\n",
       "          2.84430653e-01, -8.18694532e-01,  3.59615833e-01,\n",
       "          2.71655113e-01,  9.48866382e-02,  8.70314538e-02,\n",
       "         -5.37451878e-02,  1.40861750e-01,  6.12882227e-02,\n",
       "          1.32133111e-01,  3.51017565e-01, -8.33335161e-01,\n",
       "          4.93402064e-01,  2.34880686e-01, -1.34192079e-01,\n",
       "         -6.08774647e-02,  1.36289075e-01,  2.06397697e-01,\n",
       "          1.47522435e-01,  1.39604121e-01, -2.86073655e-01,\n",
       "         -1.87541977e-01,  1.68376923e-01, -2.65566438e-01,\n",
       "         -1.19436324e-01, -2.33947739e-01,  2.49224305e-01,\n",
       "         -7.39238977e-01, -2.93015949e-02,  2.15914443e-01,\n",
       "         -7.16302633e-01,  2.16715947e-01,  1.95174515e-01,\n",
       "         -1.30322471e-01, -5.06141484e-01, -2.94100285e-01,\n",
       "         -8.16311002e-01, -6.39636908e-03, -1.75467938e-01,\n",
       "          6.37286842e-01,  7.68789053e-02, -4.46440488e-01,\n",
       "          6.84336364e-01, -9.99520570e-02, -7.79673159e-02,\n",
       "         -1.03357038e-03, -1.72343805e-01,  7.16788769e-02,\n",
       "         -5.00750802e-02,  1.20603643e-01,  2.36315429e-01,\n",
       "          1.17014825e-01, -2.06032008e-01,  5.72633147e-02,\n",
       "          2.79863089e-01, -6.19437814e-01, -7.80483305e-01,\n",
       "          2.38857731e-01, -8.80984962e-03, -6.75738692e-01,\n",
       "          2.30205029e-01, -7.53977299e-02,  3.99970300e-02,\n",
       "         -4.23422843e-01, -2.45788768e-01, -3.33508015e-01,\n",
       "         -8.00193310e-01, -1.35762198e-02,  3.41106534e-01,\n",
       "          2.91453540e-01, -2.75252283e-01,  1.80423379e-01,\n",
       "          2.11198395e-03]], dtype=float32),\n",
       " array([[ 1.63243353e-01, -2.46149570e-01, -6.06234670e-01,\n",
       "         -1.71568787e+00,  4.02673244e-01,  1.18448389e+00,\n",
       "         -6.01007342e-01,  8.46921563e-01, -6.11703157e-01,\n",
       "         -5.30347705e-01,  1.59727991e-01, -2.05724895e-01,\n",
       "         -1.84369659e+00,  2.22690392e+00, -2.14803249e-01,\n",
       "          2.68599319e+00,  5.85009992e-01, -5.11667371e-01,\n",
       "         -2.54591465e+00,  4.14631188e-01,  1.84630170e-01,\n",
       "          1.23952746e-01,  6.88416436e-02,  1.48793530e+00,\n",
       "          8.90039559e-03, -1.01728320e-01,  4.03624117e-01,\n",
       "          4.01027799e-01,  1.03396192e-01,  1.21758461e-01,\n",
       "          1.77054191e+00, -1.23554337e+00, -5.14791161e-03,\n",
       "         -2.08718610e+00, -1.73543346e+00,  2.47689795e+00,\n",
       "         -4.88325208e-02,  8.72050226e-02, -7.69795895e-01,\n",
       "         -7.28137046e-02, -9.50955272e-01, -5.28240740e-01,\n",
       "          4.95996267e-01, -3.08898711e+00,  1.33507299e+00,\n",
       "         -2.43421346e-01, -4.93231326e-01, -5.33538498e-02,\n",
       "          1.92529067e-01,  1.21458530e+00, -8.70015919e-02,\n",
       "          4.74688947e-01,  2.12375402e+00, -1.08956516e+00,\n",
       "         -1.86688197e+00,  7.22690284e-01, -2.53209889e-01,\n",
       "          1.85796845e+00, -3.78653407e-01, -6.67552948e-01,\n",
       "          9.23535943e-01, -1.23241293e+00,  1.94554329e-01,\n",
       "         -1.30278170e-01,  1.73012400e+00,  3.17808062e-01,\n",
       "         -9.72656965e-01,  1.06575392e-01, -1.75145432e-01,\n",
       "         -2.86683440e+00, -5.47808886e-01, -8.87198925e-01,\n",
       "         -4.36762236e-02,  4.61869270e-01,  1.84016991e+00,\n",
       "         -3.82024765e-01, -1.64046623e-02, -6.64831921e-02,\n",
       "          1.89603224e-01,  1.21542084e+00,  1.11393547e+00,\n",
       "          1.69768274e-01, -2.09582120e-01,  2.09581375e-01,\n",
       "          1.70633531e+00, -2.93571949e+00,  6.78585649e-01,\n",
       "         -1.42140657e-01, -6.04038656e-01, -3.65393728e-01,\n",
       "          2.71293688e+00, -4.86886889e-01,  1.93887025e-01,\n",
       "         -6.09858871e-01, -7.40207583e-02, -1.45532560e+00,\n",
       "          4.34112966e-01, -3.53776515e-01,  7.54054561e-02,\n",
       "         -1.74999571e+00, -1.18631370e-01, -1.08699429e+00,\n",
       "          1.79436731e+00,  2.12995481e+00, -6.59725010e-01,\n",
       "         -1.07134795e+00,  2.77123779e-01,  4.57181893e-02,\n",
       "          2.51982033e-01,  5.80387950e-01,  2.33112240e+00,\n",
       "         -2.55000234e-01, -4.99119371e-01, -1.79181490e-02,\n",
       "          5.97509503e-01, -3.28563392e-01, -1.67396665e-01,\n",
       "          2.78324842e-01,  1.45997807e-01, -2.10974529e-01,\n",
       "          2.67145848e+00, -2.97227204e-01,  4.42086935e-01,\n",
       "         -2.72150707e+00, -4.87160325e-01,  6.21285677e-01,\n",
       "          4.84543651e-01,  2.48513713e-01,  2.34199929e+00,\n",
       "         -1.50718570e-01, -4.31014560e-02,  1.06229335e-01,\n",
       "          6.03228092e-01,  1.20204759e+00,  4.07808945e-02,\n",
       "         -3.91032934e-01,  1.87613082e+00, -1.28873205e+00,\n",
       "          1.16043615e+00,  7.15498328e-01,  1.70016348e-01,\n",
       "          1.05471797e-01,  1.71679366e+00, -2.51614046e+00,\n",
       "          2.81029761e-01, -1.85156554e-01,  4.61035132e-01,\n",
       "         -7.69499764e-02,  5.19374490e-01,  2.90973157e-01,\n",
       "         -3.96017194e-01, -1.54153749e-01,  3.61348569e-01,\n",
       "         -2.54084989e-02,  2.58874059e+00, -1.62989306e+00,\n",
       "         -5.82418144e-02,  7.01951385e-01,  2.45667994e-04,\n",
       "          3.28603148e+00,  2.17888808e+00,  2.58589499e-02,\n",
       "         -3.41138542e-01, -2.52775460e-01,  1.92180610e+00,\n",
       "          1.17603593e-01,  5.73872142e-02,  4.62785661e-02,\n",
       "          1.10644877e+00,  1.63994431e+00, -2.52960533e-01,\n",
       "         -1.11070073e+00,  9.14518069e-03,  5.35382867e-01,\n",
       "         -2.44213687e-03,  1.27883410e+00, -1.12568177e-02,\n",
       "          1.52953997e-01, -4.01878476e-01,  1.45640075e-01,\n",
       "          6.40214086e-02, -1.98117584e-01,  8.90374064e-01,\n",
       "          1.01975369e+00, -1.66375458e+00,  1.65253031e+00,\n",
       "          3.61944497e-01,  2.57216603e-01,  3.03210050e-01,\n",
       "         -3.70208204e-01,  1.80489913e-01,  2.20822915e-01,\n",
       "          3.43994409e-01,  5.32460630e-01, -2.21125698e+00,\n",
       "          7.20554531e-01,  2.75478303e-01, -2.47729182e-01,\n",
       "         -1.95383340e-01,  3.69314760e-01,  8.99184942e-01,\n",
       "          6.05536342e-01,  7.78972626e-01, -3.71511072e-01,\n",
       "         -7.04277456e-01,  9.91269588e-01, -5.91413558e-01,\n",
       "         -2.89404452e-01, -8.49650025e-01,  9.64712501e-01,\n",
       "         -1.74291337e+00, -9.48192179e-02,  3.15531999e-01,\n",
       "         -2.66003704e+00,  6.69888675e-01,  3.85082543e-01,\n",
       "         -5.56522071e-01, -1.53479421e+00, -4.56963331e-01,\n",
       "         -2.13809729e+00, -1.80012397e-02, -1.40192735e+00,\n",
       "          1.62092531e+00,  2.38300651e-01, -1.86210644e+00,\n",
       "          1.34950423e+00, -2.35415864e+00, -1.43643841e-01,\n",
       "         -2.54129898e-03, -2.73923218e-01,  3.64082575e-01,\n",
       "         -9.79432911e-02,  4.74672675e-01,  1.22541487e+00,\n",
       "          2.87160575e-01, -6.19849443e-01,  1.48351848e-01,\n",
       "          1.45967543e+00, -7.90150464e-01, -1.58716345e+00,\n",
       "          1.95700192e+00, -2.43942495e-02, -1.75839663e+00,\n",
       "          1.52806866e+00, -1.47247314e-01,  8.71516466e-02,\n",
       "         -2.47967672e+00, -1.32766056e+00, -7.03894317e-01,\n",
       "         -1.60519314e+00, -4.81107906e-02,  4.51897979e-01,\n",
       "          4.70655859e-01, -1.61458290e+00,  3.47280174e-01,\n",
       "          4.96093184e-03]], dtype=float32)]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.predict(input_seq) # (h,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2uAjP3m6gqcl",
    "outputId": "efdf2b7b-ba7e-43a2-9126-6ef345b594aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00917078, 0.00928607, 0.00883926, 0.00946218, 0.00953896,\n",
       "         0.00953365, 0.00919233, 0.00931299, 0.00948264, 0.00942557,\n",
       "         0.00944672, 0.00921851, 0.00929877, 0.00916996, 0.00928405,\n",
       "         0.00944088, 0.00924674, 0.00936707, 0.00939569, 0.00934956,\n",
       "         0.00916197, 0.00934398, 0.00937026, 0.00933487, 0.00927241,\n",
       "         0.00929015, 0.00932668, 0.00932862, 0.00932082, 0.00920961,\n",
       "         0.0094407 , 0.00927543, 0.00955082, 0.00937454, 0.00926919,\n",
       "         0.00962851, 0.00939844, 0.00919239, 0.00927307, 0.00928615,\n",
       "         0.00935162, 0.00950285, 0.00930571, 0.0090495 , 0.00921396,\n",
       "         0.00940089, 0.00928133, 0.009334  , 0.0093665 , 0.00927674,\n",
       "         0.00917016, 0.00925401, 0.00921759, 0.00935428, 0.00940239,\n",
       "         0.00928428, 0.0093721 , 0.0091899 , 0.00911624, 0.00925829,\n",
       "         0.00923131, 0.00947088, 0.00930714, 0.00946948, 0.00928259,\n",
       "         0.00916231, 0.00941814, 0.00936416, 0.00934095, 0.00933816,\n",
       "         0.00924574, 0.00924785, 0.00906537, 0.00918351, 0.00924974,\n",
       "         0.00907416, 0.00923211, 0.00936548, 0.00930156, 0.00930532,\n",
       "         0.00941742, 0.00923988, 0.00944472, 0.00936901, 0.00929936,\n",
       "         0.00921101, 0.0092022 , 0.00913825, 0.00929451, 0.00943108,\n",
       "         0.00941249, 0.0094187 , 0.00933047, 0.00944535, 0.00884111,\n",
       "         0.00903182, 0.00888225, 0.00884405, 0.00889555, 0.00905934,\n",
       "         0.00905919, 0.00884748, 0.00878788, 0.0089304 , 0.00894677,\n",
       "         0.00895316, 0.00892255, 0.00887465]]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGDqUy_3hYJE",
    "outputId": "8bd61144-cc40-4bdb-cae8-92daf02ae52a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 108)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comment créer un modèle seq2se?\n",
    "\"\"\"\n",
    "1) Ajouter les balises <sos> et <eos> sur chaque début et fin de phrase du target.\n",
    "\n",
    "2) Créer un modèle générique qui fusionne l'encoder et le décoder donc compter 2 Input:\n",
    "   - L'encoder a un Input avec la taille des phrases de la source, une couche d'embedding, une couche de LSTM\n",
    "     avec return_state = True pour capter l'état de l'encoder qu'on va envoyer au decoder (h,c).\n",
    "   - Le decoder a un Input avec la taille des phrases du target précédées de <sos>, une couche d'embedding,\n",
    "     couche de LSTM avec initial_state = (h,c), (h,c) est founi par la couche LSTM de l'encoder, return_sequences = True\n",
    "     pour retourner (batch_size, timestamp, units); et une couche dense qui retourne une phrase prédite.\n",
    "     \n",
    "3) Entrainer le modèle ainsi créé.     \n",
    "\n",
    "4) Créer un modèle spécifique pour l'encoder contenant une couche Input prenant une sentence de la source, \n",
    "   une couche d'Embedding et une couche de LSTM avec return_state = True pour garder (h,c).\n",
    "   \n",
    "5) Créer un modèle spécifique pour le decoder contenant une couche Input prenant [un mot du target + \n",
    "   (h=Input,c=Input)], une couche d'Embedding, une couche de LSTM avec initial_state = (h,c) et \n",
    "   return_sequences = True, une couche Dense qui est connectée avec la couche LSTM (batch_size, timestamps,units)\n",
    "   \n",
    "6) Pour faire fonctionner le modèle, on donne une phrase du source à la fonction qui fait des boucles \n",
    "   sur le décoder afin de prédire mot par mot et pas sentence par sentence.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJb8F9U0hbZZ",
    "outputId": "d38d2477-e2c5-4720-cd12-e14f02345421"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSt3nibVhxc-",
    "outputId": "2a7e2d5e-7ace-4d41-f652-a034656f670e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/faye/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.array([np.zeros((1, 1))]+[np.array([1,2,3]), np.array([4,5,5])]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UStyqVPOfTZ2"
   },
   "source": [
    "**NB : les inputs doivent minimum être en 2D**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "seq2seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
